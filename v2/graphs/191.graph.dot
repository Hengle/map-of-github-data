digraph G {
"uber/petastorm" -> "webdataset/webdataset" ["e"=1]
"microsoft/unilm" -> "salesforce/LAVIS" ["e"=1]
"microsoft/unilm" -> "mlfoundations/open_clip" ["e"=1]
"sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" -> "rmokady/CLIP_prefix_caption" ["e"=1]
"katsura-jp/pytorch-cosine-annealing-with-warmup" -> "Zasder3/train-CLIP" ["e"=1]
"idealo/imagededup" -> "mlfoundations/open_clip" ["e"=1]
"idealo/imagededup" -> "rom1504/clip-retrieval" ["e"=1]
"VainF/DeepLabV3Plus-Pytorch" -> "NVlabs/SegFormer" ["e"=1]
"ultralytics/JSON2YOLO" -> "vietanhdev/anylabeling" ["e"=1]
"ultralytics/JSON2YOLO" -> "AILab-CVC/YOLO-World" ["e"=1]
"ultralytics/JSON2YOLO" -> "autodistill/autodistill" ["e"=1]
"NVIDIA/aistore" -> "webdataset/webdataset" ["e"=1]
"matsui528/faiss_tips" -> "criteo/autofaiss" ["e"=1]
"facebookresearch/mmf" -> "facebookresearch/multimodal" ["e"=1]
"pliang279/awesome-multimodal-ml" -> "salesforce/LAVIS" ["e"=1]
"pliang279/awesome-multimodal-ml" -> "mlfoundations/open_clip" ["e"=1]
"SkalskiP/make-sense" -> "autodistill/autodistill" ["e"=1]
"cvdfoundation/open-images-dataset" -> "raoyongming/DenseCLIP" ["e"=1]
"kshmelkov/incremental_detectors" -> "CanPeng123/Faster-ILOD"
"kshmelkov/incremental_detectors" -> "JosephKJ/iOD"
"kshmelkov/incremental_detectors" -> "Hi-FT/ERD"
"kshmelkov/incremental_detectors" -> "zhonhel/Incremental-Object-Detection-with-Feature-Pyramid-Network-and-Knowledge-Distillation"
"kshmelkov/incremental_detectors" -> "jinyu121/CIOD"
"jinyu121/CIOD" -> "DessiLBI2020/DessiLBI"
"TheShadow29/awesome-grounding" -> "microsoft/GLIP" ["e"=1]
"TheShadow29/awesome-grounding" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "lxtGH/Awesome-Segmentation-With-Transformer" ["e"=1]
"MarkMoHR/Awesome-Referring-Image-Segmentation" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" ["e"=1]
"li-xirong/coco-cn" -> "BAAI-WuDao/BriVL" ["e"=1]
"kaist-dmlab/SELFIE" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/MTA"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/TRAP"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/revisit"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/BlackHole"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/BioNER"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/NETS"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/PAS"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/RecencyBias"
"kaist-dmlab/SELFIE" -> "kaist-dmlab/Ada-Boundary"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/MTA"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/TRAP"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/revisit"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/NETS"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/BioNER"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/SELFIE"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/RecencyBias"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/BlackHole"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/PAS"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/k-Medoid"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/STARE"
"kaist-dmlab/RP-DBSCAN" -> "kaist-dmlab/Ada-Boundary"
"kaist-dmlab/revisit" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/revisit" -> "kaist-dmlab/MTA"
"kaist-dmlab/revisit" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/revisit" -> "kaist-dmlab/TRAP"
"kaist-dmlab/revisit" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/NETS" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/NETS" -> "kaist-dmlab/MTA"
"kaist-dmlab/NETS" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/NETS" -> "kaist-dmlab/TRAP"
"kaist-dmlab/NETS" -> "kaist-dmlab/revisit"
"kaist-dmlab/NETS" -> "kaist-dmlab/RecencyBias"
"kaist-dmlab/NETS" -> "kaist-dmlab/BioNER"
"kaist-dmlab/NETS" -> "kaist-dmlab/BlackHole"
"kaist-dmlab/NETS" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/NETS" -> "kaist-dmlab/PAS"
"kaist-dmlab/BioNER" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/BioNER" -> "kaist-dmlab/MTA"
"kaist-dmlab/BioNER" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/BioNER" -> "kaist-dmlab/revisit"
"kaist-dmlab/BioNER" -> "kaist-dmlab/TRAP"
"kaist-dmlab/BioNER" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/BioNER" -> "kaist-dmlab/BlackHole"
"kaist-dmlab/BioNER" -> "kaist-dmlab/PAS"
"kaist-dmlab/BioNER" -> "kaist-dmlab/RecencyBias"
"mhsamavatian/DAP" -> "zzyy0929/AAAI2020-RiskOracle"
"NielsRogge/Transformers-Tutorials" -> "salesforce/LAVIS" ["e"=1]
"NielsRogge/Transformers-Tutorials" -> "mlfoundations/open_clip" ["e"=1]
"open-mmlab/mmsegmentation" -> "NVlabs/SegFormer" ["e"=1]
"open-mmlab/mmsegmentation" -> "facebookresearch/Mask2Former" ["e"=1]
"VisDrone/VisDrone-Dataset" -> "lyuwenyu/RT-DETR" ["e"=1]
"voxel51/fiftyone" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"voxel51/fiftyone" -> "facebookresearch/dinov2" ["e"=1]
"voxel51/fiftyone" -> "mlfoundations/open_clip" ["e"=1]
"voxel51/fiftyone" -> "facebookresearch/sam2" ["e"=1]
"PaddlePaddle/PaddleSeg" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"unsplash/datasets" -> "haltakov/natural-language-image-search" ["e"=1]
"unsplash/datasets" -> "rom1504/img2dataset" ["e"=1]
"webdataset/webdataset" -> "rom1504/img2dataset"
"webdataset/webdataset" -> "libffcv/ffcv" ["e"=1]
"webdataset/webdataset" -> "NVIDIA/aistore" ["e"=1]
"webdataset/webdataset" -> "arogozhnikov/einops" ["e"=1]
"webdataset/webdataset" -> "facebookresearch/fairscale" ["e"=1]
"webdataset/webdataset" -> "mlfoundations/open_clip"
"webdataset/webdataset" -> "facebookresearch/vissl" ["e"=1]
"webdataset/webdataset" -> "facebookincubator/submitit" ["e"=1]
"webdataset/webdataset" -> "mosaicml/streaming" ["e"=1]
"webdataset/webdataset" -> "pytorch/data" ["e"=1]
"webdataset/webdataset" -> "kakaobrain/coyo-dataset"
"webdataset/webdataset" -> "mlfoundations/open_flamingo"
"webdataset/webdataset" -> "rom1504/clip-retrieval"
"webdataset/webdataset" -> "huggingface/accelerate" ["e"=1]
"webdataset/webdataset" -> "NVIDIA/DALI" ["e"=1]
"tryolabs/norfair" -> "Deci-AI/super-gradients" ["e"=1]
"facebookincubator/submitit" -> "webdataset/webdataset" ["e"=1]
"sebgao/LIP" -> "MCG-NJU/AdaMixer" ["e"=1]
"google-research/kubric" -> "qianqianwang68/omnimotion" ["e"=1]
"DessiLBI2020/DessiLBI" -> "jinyu121/CIOD"
"DessiLBI2020/DessiLBI" -> "apple2373/MetaIRNet"
"nang-dev/hover-paywalls-browser-extension" -> "everywall/ladder" ["e"=1]
"bowenc0221/panoptic-deeplab" -> "facebookresearch/MaskFormer" ["e"=1]
"bowenc0221/panoptic-deeplab" -> "facebookresearch/Mask2Former" ["e"=1]
"HumanSignal/label-studio-ml-backend" -> "open-mmlab/playground" ["e"=1]
"roboflow/roboflow-python" -> "roboflow/inference"
"roboflow/roboflow-python" -> "roboflow/roboflow-computer-vision-utilities"
"roboflow/roboflow-python" -> "roboflow/dji-aerial-georeferencing"
"roboflow/roboflow-python" -> "roboflow/polygonzone"
"dbolya/tide" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"alirezazareian/ovr-cnn" -> "dyabel/detpro"
"alirezazareian/ovr-cnn" -> "fcjian/PromptDet"
"alirezazareian/ovr-cnn" -> "yuhangzang/OV-DETR"
"alirezazareian/ovr-cnn" -> "salesforce/PB-OVD"
"alirezazareian/ovr-cnn" -> "hanoonaR/object-centric-ovd"
"alirezazareian/ovr-cnn" -> "tgxs002/CORA"
"alirezazareian/ovr-cnn" -> "microsoft/RegionCLIP"
"alirezazareian/ovr-cnn" -> "wusize/ovdet"
"alirezazareian/ovr-cnn" -> "xiaofeng94/VL-PLM"
"alirezazareian/ovr-cnn" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"JosephKJ/OWOD" -> "akshitac8/OW-DETR"
"JosephKJ/OWOD" -> "mmaaz60/mvits_for_class_agnostic_od"
"JosephKJ/OWOD" -> "JosephKJ/iOD"
"JosephKJ/OWOD" -> "mcahny/object_localization_network"
"JosephKJ/OWOD" -> "orrzohar/PROB"
"JosephKJ/OWOD" -> "amirbar/DETReg" ["e"=1]
"JosephKJ/OWOD" -> "megvii-model/YOLOF" ["e"=1]
"JosephKJ/OWOD" -> "ucbdrive/few-shot-object-detection" ["e"=1]
"JosephKJ/OWOD" -> "xieenze/DetCo" ["e"=1]
"JosephKJ/OWOD" -> "xingyizhou/CenterNet2" ["e"=1]
"JosephKJ/OWOD" -> "RE-OWOD/RE-OWOD"
"JosephKJ/OWOD" -> "implus/GFocalV2" ["e"=1]
"JosephKJ/OWOD" -> "PeizeSun/OneNet" ["e"=1]
"JosephKJ/OWOD" -> "dddzg/up-detr"
"JosephKJ/OWOD" -> "csuhan/opendet2"
"vahidk/tfrecord" -> "webdataset/webdataset" ["e"=1]
"georgian-io/Multimodal-Toolkit" -> "facebookresearch/multimodal" ["e"=1]
"microsoft/M3P" -> "zmykevin/UC2"
"shruti-jadon/Semantic-Segmentation-Loss-Functions" -> "facebookresearch/MaskFormer" ["e"=1]
"voxel51/fiftyone-brain" -> "voxel51/fiftyone-plugins"
"voxel51/fiftyone-brain" -> "voxel51/fiftyone-examples"
"voxel51/fiftyone-brain" -> "voxel51/papers-with-data"
"valeoai/ZS3" -> "MendelXu/zsseg.baseline" ["e"=1]
"kaist-dmlab/FL-Sim" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/FL-Sim" -> "kaist-dmlab/MTA"
"kaist-dmlab/TRAP" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/TRAP" -> "kaist-dmlab/MTA"
"kaist-dmlab/STARE" -> "kaist-dmlab/RecencyBias"
"kaist-dmlab/STARE" -> "kaist-dmlab/Ada-Boundary"
"kaist-dmlab/STARE" -> "kaist-dmlab/Hi-COVIDNet"
"kaist-dmlab/STARE" -> "kaist-dmlab/TensorSparkML"
"kaist-dmlab/RecencyBias" -> "kaist-dmlab/Ada-Boundary"
"yule-BUAA/DSTGCN" -> "Echohhhhhh/GSNet"
"yule-BUAA/DSTGCN" -> "kaist-dmlab/MG-TAR"
"yule-BUAA/DSTGCN" -> "yule-BUAA/DNNTSP"
"tingxueronghua/pytorch-classification-advprop" -> "meijieru/fast_advprop"
"tingxueronghua/pytorch-classification-advprop" -> "AI-secure/Big-but-Invisible-Adversarial-Attack"
"BradyFU/DVG" -> "BradyFU/DVG-Face"
"BradyFU/DVG-Face" -> "BradyFU/DVG"
"kaist-dmlab/Ada-Boundary" -> "kaist-dmlab/RecencyBias"
"xuefeng-cvr/Tiny-Obstacle-Discovery" -> "xuefeng-cvr/Tiny-Obstacle-Discovery-ROS"
"xuefeng-cvr/Tiny-Obstacle-Discovery-ROS" -> "xuefeng-cvr/Tiny-Obstacle-Discovery"
"zzyy0929/AAAI2020-RiskOracle" -> "Echohhhhhh/GSNet"
"CompVis/taming-transformers" -> "mlfoundations/open_clip" ["e"=1]
"google-research/vision_transformer" -> "mlfoundations/open_clip" ["e"=1]
"openai/CLIP" -> "mlfoundations/open_clip" ["e"=1]
"openai/CLIP" -> "salesforce/LAVIS" ["e"=1]
"openai/CLIP" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"SwinTransformer/Swin-Transformer-Semantic-Segmentation" -> "NVlabs/SegFormer" ["e"=1]
"SwinTransformer/Swin-Transformer-Semantic-Segmentation" -> "facebookresearch/MaskFormer" ["e"=1]
"Alibaba-MIIL/ImageNet21K" -> "mlfoundations/wise-ft" ["e"=1]
"Alibaba-MIIL/ImageNet21K" -> "UCSC-VLAA/CLIPA" ["e"=1]
"mlfoundations/open_clip" -> "openai/CLIP" ["e"=1]
"mlfoundations/open_clip" -> "salesforce/LAVIS"
"mlfoundations/open_clip" -> "haotian-liu/LLaVA" ["e"=1]
"mlfoundations/open_clip" -> "salesforce/BLIP"
"mlfoundations/open_clip" -> "rom1504/img2dataset"
"mlfoundations/open_clip" -> "facebookresearch/dinov2"
"mlfoundations/open_clip" -> "IDEA-Research/GroundingDINO"
"mlfoundations/open_clip" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"mlfoundations/open_clip" -> "IDEA-Research/Grounded-Segment-Anything"
"mlfoundations/open_clip" -> "OFA-Sys/Chinese-CLIP"
"mlfoundations/open_clip" -> "rom1504/clip-retrieval"
"mlfoundations/open_clip" -> "facebookresearch/mae" ["e"=1]
"mlfoundations/open_clip" -> "CompVis/latent-diffusion" ["e"=1]
"mlfoundations/open_clip" -> "huggingface/diffusers" ["e"=1]
"mlfoundations/open_clip" -> "microsoft/unilm" ["e"=1]
"YuqingWang1029/VisTR" -> "facebookresearch/MaskFormer" ["e"=1]
"microsoft/Cream" -> "mit-han-lab/efficientvit" ["e"=1]
"NVlabs/SegFormer" -> "open-mmlab/mmsegmentation" ["e"=1]
"NVlabs/SegFormer" -> "facebookresearch/Mask2Former"
"NVlabs/SegFormer" -> "facebookresearch/MaskFormer"
"NVlabs/SegFormer" -> "whai362/PVT" ["e"=1]
"NVlabs/SegFormer" -> "fudan-zvg/SETR" ["e"=1]
"NVlabs/SegFormer" -> "SwinTransformer/Swin-Transformer-Semantic-Segmentation" ["e"=1]
"NVlabs/SegFormer" -> "HRNet/HRNet-Semantic-Segmentation" ["e"=1]
"NVlabs/SegFormer" -> "lucidrains/segformer-pytorch" ["e"=1]
"NVlabs/SegFormer" -> "bubbliiiing/segformer-pytorch" ["e"=1]
"NVlabs/SegFormer" -> "Beckschen/TransUNet" ["e"=1]
"NVlabs/SegFormer" -> "VainF/DeepLabV3Plus-Pytorch" ["e"=1]
"NVlabs/SegFormer" -> "czczup/ViT-Adapter"
"NVlabs/SegFormer" -> "rstrudel/segmenter" ["e"=1]
"NVlabs/SegFormer" -> "HuCaoFighting/Swin-Unet" ["e"=1]
"NVlabs/SegFormer" -> "SHI-Labs/OneFormer"
"nadermx/backgroundremover" -> "geekyutao/Inpaint-Anything" ["e"=1]
"lucidrains/DALLE-pytorch" -> "mlfoundations/open_clip" ["e"=1]
"haltakov/natural-language-image-search" -> "haltakov/natural-language-youtube-search" ["e"=1]
"haltakov/natural-language-image-search" -> "haofanwang/natural-language-joint-query-search" ["e"=1]
"haltakov/natural-language-image-search" -> "kingyiusuen/clip-image-search"
"haltakov/natural-language-image-search" -> "Zasder3/train-CLIP"
"haltakov/natural-language-image-search" -> "rkouye/es-clip-image-search"
"haltakov/natural-language-image-search" -> "EdVince/CLIP-ImageSearch-NCNN" ["e"=1]
"haltakov/natural-language-image-search" -> "rmokady/CLIP_prefix_caption"
"haltakov/natural-language-image-search" -> "FreddeFrallan/Multilingual-CLIP"
"haltakov/natural-language-image-search" -> "rom1504/clip-retrieval"
"haltakov/natural-language-image-search" -> "nerdyrodent/CLIP-Guided-Diffusion" ["e"=1]
"haltakov/natural-language-image-search" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"haltakov/natural-language-image-search" -> "lucidrains/DALLE-pytorch" ["e"=1]
"haltakov/natural-language-image-search" -> "yzhuoning/Awesome-CLIP" ["e"=1]
"haltakov/natural-language-image-search" -> "eps696/stylegan2" ["e"=1]
"haltakov/natural-language-image-search" -> "ABaldrati/CLIP4Cir" ["e"=1]
"FreddeFrallan/Multilingual-CLIP" -> "LAION-AI/CLIP_benchmark"
"FreddeFrallan/Multilingual-CLIP" -> "Zasder3/train-CLIP"
"FreddeFrallan/Multilingual-CLIP" -> "kakaobrain/coyo-dataset"
"FreddeFrallan/Multilingual-CLIP" -> "rom1504/clip-retrieval"
"FreddeFrallan/Multilingual-CLIP" -> "facebookresearch/SLIP"
"FreddeFrallan/Multilingual-CLIP" -> "google-research-datasets/wit" ["e"=1]
"FreddeFrallan/Multilingual-CLIP" -> "BAAI-WuDao/BriVL"
"FreddeFrallan/Multilingual-CLIP" -> "rom1504/img2dataset"
"FreddeFrallan/Multilingual-CLIP" -> "LAION-AI/CLIP-based-NSFW-Detector" ["e"=1]
"FreddeFrallan/Multilingual-CLIP" -> "microsoft/M3P"
"FreddeFrallan/Multilingual-CLIP" -> "Lednik7/CLIP-ONNX"
"FreddeFrallan/Multilingual-CLIP" -> "lucidrains/x-clip"
"FreddeFrallan/Multilingual-CLIP" -> "OFA-Sys/OFA"
"FreddeFrallan/Multilingual-CLIP" -> "billjie1/Chinese-CLIP"
"FreddeFrallan/Multilingual-CLIP" -> "rom1504/laion-prepro"
"rom1504/clip-retrieval" -> "rom1504/img2dataset"
"rom1504/clip-retrieval" -> "mlfoundations/open_clip"
"rom1504/clip-retrieval" -> "mlfoundations/wise-ft"
"rom1504/clip-retrieval" -> "criteo/autofaiss"
"rom1504/clip-retrieval" -> "LAION-AI/CLIP_benchmark"
"rom1504/clip-retrieval" -> "OFA-Sys/Chinese-CLIP"
"rom1504/clip-retrieval" -> "salesforce/LAVIS"
"rom1504/clip-retrieval" -> "salesforce/BLIP"
"rom1504/clip-retrieval" -> "microsoft/GLIP"
"rom1504/clip-retrieval" -> "mlfoundations/open_flamingo"
"rom1504/clip-retrieval" -> "google-research/big_vision"
"rom1504/clip-retrieval" -> "rinongal/textual_inversion" ["e"=1]
"rom1504/clip-retrieval" -> "baaivision/EVA"
"rom1504/clip-retrieval" -> "FreddeFrallan/Multilingual-CLIP"
"rom1504/clip-retrieval" -> "pharmapsychotic/clip-interrogator" ["e"=1]
"rom1504/img2dataset" -> "rom1504/clip-retrieval"
"rom1504/img2dataset" -> "mlfoundations/open_clip"
"rom1504/img2dataset" -> "webdataset/webdataset"
"rom1504/img2dataset" -> "salesforce/LAVIS"
"rom1504/img2dataset" -> "salesforce/BLIP"
"rom1504/img2dataset" -> "mlfoundations/open_flamingo"
"rom1504/img2dataset" -> "kakaobrain/coyo-dataset"
"rom1504/img2dataset" -> "LAION-AI/CLIP_benchmark"
"rom1504/img2dataset" -> "baaivision/EVA"
"rom1504/img2dataset" -> "microsoft/GLIP"
"rom1504/img2dataset" -> "facebookresearch/DiT" ["e"=1]
"rom1504/img2dataset" -> "OFA-Sys/OFA"
"rom1504/img2dataset" -> "CompVis/latent-diffusion" ["e"=1]
"rom1504/img2dataset" -> "google-research/big_vision"
"rom1504/img2dataset" -> "facebookresearch/vissl" ["e"=1]
"obss/sahi" -> "Deci-AI/super-gradients" ["e"=1]
"obss/sahi" -> "lyuwenyu/RT-DETR" ["e"=1]
"obss/sahi" -> "CVHub520/X-AnyLabeling" ["e"=1]
"obss/sahi" -> "WongKinYiu/yolov9" ["e"=1]
"salesforce/ALBEF" -> "salesforce/BLIP" ["e"=1]
"salesforce/ALBEF" -> "salesforce/LAVIS" ["e"=1]
"salesforce/ALBEF" -> "OFA-Sys/OFA" ["e"=1]
"salesforce/ALBEF" -> "microsoft/GLIP" ["e"=1]
"luo3300612/Visualizer" -> "czczup/ViT-Adapter" ["e"=1]
"luo3300612/Visualizer" -> "IDEA-Research/detrex" ["e"=1]
"google-research/scenic" -> "microsoft/GLIP" ["e"=1]
"google-research/scenic" -> "google-research/big_vision" ["e"=1]
"google-research/scenic" -> "salesforce/LAVIS" ["e"=1]
"google-research/scenic" -> "mlfoundations/open_clip" ["e"=1]
"amusi/ICCV2023-Papers-with-Code" -> "facebookresearch/Mask2Former" ["e"=1]
"criteo/autofaiss" -> "rom1504/clip-retrieval"
"criteo/autofaiss" -> "facebookresearch/distributed-faiss" ["e"=1]
"criteo/autofaiss" -> "matsui528/faiss_tips" ["e"=1]
"criteo/autofaiss" -> "rom1504/embedding-reader"
"criteo/autofaiss" -> "lucidrains/RETRO-pytorch" ["e"=1]
"criteo/autofaiss" -> "LAION-AI/CLIP_benchmark"
"criteo/autofaiss" -> "rom1504/laion-prepro"
"criteo/autofaiss" -> "google-research-datasets/wit" ["e"=1]
"criteo/autofaiss" -> "dzryk/antarctic-captions"
"criteo/autofaiss" -> "rom1504/img2dataset"
"criteo/autofaiss" -> "KarelDO/xmc.dspy" ["e"=1]
"criteo/autofaiss" -> "currentslab/awesome-vector-search" ["e"=1]
"criteo/autofaiss" -> "FreddeFrallan/Multilingual-CLIP"
"songhwanjun/Awesome-Noisy-Labels" -> "kaist-dmlab/RecencyBias" ["e"=1]
"songhwanjun/Awesome-Noisy-Labels" -> "kaist-dmlab/STARE" ["e"=1]
"songhwanjun/Awesome-Noisy-Labels" -> "kaist-dmlab/Hi-COVIDNet" ["e"=1]
"songhwanjun/Awesome-Noisy-Labels" -> "kaist-dmlab/TensorSparkML" ["e"=1]
"songhwanjun/Awesome-Noisy-Labels" -> "kaist-dmlab/Ada-Boundary" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "IDEA-Research/DINO" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "IDEA-Research/detrex" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "facebookresearch/Mask2Former" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "IDEA-Research/DN-DETR" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "IDEA-Research/DAB-DETR" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "lyuwenyu/RT-DETR" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"fundamentalvision/Deformable-DETR" -> "ShoufaChen/DiffusionDet" ["e"=1]
"dk-liang/Awesome-Visual-Transformer" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"facebookresearch/dino" -> "facebookresearch/dinov2" ["e"=1]
"facebookresearch/dino" -> "mlfoundations/open_clip" ["e"=1]
"facebookresearch/dino" -> "IDEA-Research/DINO" ["e"=1]
"SwinTransformer/Swin-Transformer-Object-Detection" -> "IDEA-Research/DINO" ["e"=1]
"ZhangGongjie/Meta-DETR" -> "ZhangGongjie/SAM-DETR" ["e"=1]
"THUDM/CogView" -> "OFA-Sys/OFA" ["e"=1]
"Atten4Vis/ConditionalDETR" -> "IDEA-Research/DN-DETR"
"Atten4Vis/ConditionalDETR" -> "megvii-research/AnchorDETR"
"Atten4Vis/ConditionalDETR" -> "IDEA-Research/DAB-DETR"
"Atten4Vis/ConditionalDETR" -> "gaopengcuhk/SMCA-DETR"
"Atten4Vis/ConditionalDETR" -> "kakaobrain/sparse-detr"
"Atten4Vis/ConditionalDETR" -> "MCG-NJU/AdaMixer"
"Atten4Vis/ConditionalDETR" -> "twangnh/pnp-detr"
"Atten4Vis/ConditionalDETR" -> "HDETR/H-Deformable-DETR"
"Atten4Vis/ConditionalDETR" -> "jshilong/DDQ"
"Atten4Vis/ConditionalDETR" -> "dddzg/up-detr"
"Atten4Vis/ConditionalDETR" -> "ZhangGongjie/SAM-DETR"
"Atten4Vis/ConditionalDETR" -> "impiga/Plain-DETR"
"Atten4Vis/ConditionalDETR" -> "PeizeSun/SparseR-CNN" ["e"=1]
"Atten4Vis/ConditionalDETR" -> "IDEA-Research/awesome-detection-transformer"
"Atten4Vis/ConditionalDETR" -> "yuhangzang/OV-DETR"
"MichaelFan01/STDC-Seg" -> "facebookresearch/MaskFormer" ["e"=1]
"rafaelpadilla/review_object_detection_metrics" -> "autodistill/autodistill" ["e"=1]
"Yangzhangcst/Transformer-in-Computer-Vision" -> "lxtGH/Awesome-Segmentation-With-Transformer" ["e"=1]
"Yangzhangcst/Transformer-in-Computer-Vision" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"Yangzhangcst/Transformer-in-Computer-Vision" -> "liliu-avril/Awesome-Segment-Anything" ["e"=1]
"sithu31296/semantic-segmentation" -> "NVlabs/SegFormer" ["e"=1]
"google-research-datasets/wit" -> "allenai/mmc4" ["e"=1]
"google-research-datasets/wit" -> "FreddeFrallan/Multilingual-CLIP" ["e"=1]
"google-research-datasets/wit" -> "kakaobrain/coyo-dataset" ["e"=1]
"google-research-datasets/wit" -> "rom1504/img2dataset" ["e"=1]
"johanmodin/clifs" -> "wusize/ovdet" ["e"=1]
"BAAI-WuDao/BriVL" -> "chuhaojin/BriVL-BUA-applications"
"BAAI-WuDao/BriVL" -> "chuhaojin/WenLan-api-document"
"BAAI-WuDao/BriVL" -> "yuxie11/R2D2"
"BAAI-WuDao/BriVL" -> "li-xirong/coco-cn" ["e"=1]
"BAAI-WuDao/BriVL" -> "neilfei/brivl-nmi"
"BAAI-WuDao/BriVL" -> "uta-smile/TCL" ["e"=1]
"neuralmagic/deepsparse" -> "Deci-AI/super-gradients" ["e"=1]
"dandelin/ViLT" -> "salesforce/BLIP" ["e"=1]
"dandelin/ViLT" -> "OFA-Sys/OFA" ["e"=1]
"lucidrains/perceiver-pytorch" -> "lucidrains/flamingo-pytorch" ["e"=1]
"lucidrains/perceiver-pytorch" -> "NVlabs/GroupViT" ["e"=1]
"PeizeSun/SparseR-CNN" -> "facebookresearch/MaskFormer" ["e"=1]
"alibaba/AliceMind" -> "OFA-Sys/OFA" ["e"=1]
"hila-chefer/Transformer-MM-Explainability" -> "rmokady/CLIP_prefix_caption" ["e"=1]
"hila-chefer/Transformer-MM-Explainability" -> "facebookresearch/SLIP" ["e"=1]
"hila-chefer/Transformer-MM-Explainability" -> "Sense-GVT/DeCLIP" ["e"=1]
"hila-chefer/Transformer-MM-Explainability" -> "lucidrains/flamingo-pytorch" ["e"=1]
"google-research/deeplab2" -> "facebookresearch/MaskFormer" ["e"=1]
"google-research/deeplab2" -> "facebookresearch/Mask2Former" ["e"=1]
"google-research/deeplab2" -> "IDEA-Research/MaskDINO" ["e"=1]
"google-research/deeplab2" -> "bytedance/kmax-deeplab" ["e"=1]
"google-research/deeplab2" -> "SHI-Labs/OneFormer" ["e"=1]
"google-research/deeplab2" -> "NVlabs/SegFormer" ["e"=1]
"google-research/deeplab2" -> "ShoufaChen/DiffusionDet" ["e"=1]
"stephanecharette/DarkMark" -> "stephanecharette/DarkHelp"
"stephanecharette/DarkMark" -> "hank-ai/darknet"
"stephanecharette/DarkMark" -> "stephanecharette/DarkPlate"
"stephanecharette/DarkMark" -> "stephanecharette/MoveDetect"
"yurijmikhalevich/rclip" -> "kingyiusuen/clip-image-search" ["e"=1]
"facebookresearch/xcit" -> "facebookresearch/SLIP" ["e"=1]
"heroiclabs/nakama-dart" -> "Allan-Nava/nakama-flutter"
"whai362/PVT" -> "NVlabs/SegFormer" ["e"=1]
"whai362/PVT" -> "facebookresearch/MaskFormer" ["e"=1]
"Zasder3/train-CLIP" -> "revantteotia/clip-training"
"Zasder3/train-CLIP" -> "mlfoundations/wise-ft"
"Zasder3/train-CLIP" -> "Zasder3/train-CLIP-FT"
"Zasder3/train-CLIP" -> "moein-shariatnia/OpenAI-CLIP"
"Zasder3/train-CLIP" -> "FreddeFrallan/Multilingual-CLIP"
"Zasder3/train-CLIP" -> "facebookresearch/SLIP"
"Zasder3/train-CLIP" -> "clip-italian/clip-italian" ["e"=1]
"Zasder3/train-CLIP" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"Zasder3/train-CLIP" -> "mlfoundations/open_clip"
"Zasder3/train-CLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"Zasder3/train-CLIP" -> "rmokady/CLIP_prefix_caption"
"Zasder3/train-CLIP" -> "gaopengcuhk/CLIP-Adapter" ["e"=1]
"Zasder3/train-CLIP" -> "rom1504/clip-retrieval"
"Zasder3/train-CLIP" -> "arampacha/CLIP-rsicd" ["e"=1]
"Zasder3/train-CLIP" -> "haltakov/natural-language-image-search"
"microsoft/DynamicHead" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"microsoft/DynamicHead" -> "IDEA-Research/DINO" ["e"=1]
"facebookresearch/MaskFormer" -> "facebookresearch/Mask2Former"
"facebookresearch/MaskFormer" -> "NVlabs/SegFormer"
"facebookresearch/MaskFormer" -> "PeizeSun/SparseR-CNN" ["e"=1]
"facebookresearch/MaskFormer" -> "ZwwWayne/K-Net" ["e"=1]
"facebookresearch/MaskFormer" -> "fudan-zvg/SETR" ["e"=1]
"facebookresearch/MaskFormer" -> "whai362/PVT" ["e"=1]
"facebookresearch/MaskFormer" -> "dvlab-research/PanopticFCN" ["e"=1]
"facebookresearch/MaskFormer" -> "SwinTransformer/Swin-Transformer-Semantic-Segmentation" ["e"=1]
"facebookresearch/MaskFormer" -> "IDEA-Research/MaskDINO"
"facebookresearch/MaskFormer" -> "openseg-group/openseg.pytorch" ["e"=1]
"facebookresearch/MaskFormer" -> "czczup/ViT-Adapter"
"facebookresearch/MaskFormer" -> "tfzhou/ContrastiveSeg" ["e"=1]
"facebookresearch/MaskFormer" -> "YuqingWang1029/VisTR" ["e"=1]
"facebookresearch/MaskFormer" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"facebookresearch/MaskFormer" -> "HRNet/HRNet-Semantic-Segmentation" ["e"=1]
"fudan-zvg/SETR" -> "facebookresearch/MaskFormer" ["e"=1]
"fudan-zvg/SETR" -> "NVlabs/SegFormer" ["e"=1]
"rstrudel/segmenter" -> "NVlabs/SegFormer" ["e"=1]
"rstrudel/segmenter" -> "facebookresearch/MaskFormer" ["e"=1]
"rstrudel/segmenter" -> "facebookresearch/Mask2Former" ["e"=1]
"ChenhongyiYang/QueryDet-PyTorch" -> "IDEA-Research/DN-DETR" ["e"=1]
"microsoft/SoftTeacher" -> "IDEA-Research/DINO" ["e"=1]
"CanPeng123/Faster-ILOD" -> "fcdl94/MMA"
"CanPeng123/Faster-ILOD" -> "Hi-FT/ERD"
"CanPeng123/Faster-ILOD" -> "JosephKJ/iOD"
"CanPeng123/Faster-ILOD" -> "FanZhichen/Awesome-Incremental-Few-Shot-Object-Detection"
"CanPeng123/Faster-ILOD" -> "CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation"
"CanPeng123/Faster-ILOD" -> "kshmelkov/incremental_detectors"
"hustvl/YOLOS" -> "naver-ai/vidt" ["e"=1]
"hustvl/YOLOS" -> "Atten4Vis/ConditionalDETR" ["e"=1]
"hustvl/YOLOS" -> "IDEA-Research/DN-DETR" ["e"=1]
"pytorch/data" -> "webdataset/webdataset" ["e"=1]
"haltakov/natural-language-youtube-search" -> "haltakov/natural-language-image-search" ["e"=1]
"dvlab-research/PanopticFCN" -> "facebookresearch/MaskFormer" ["e"=1]
"Meituan-AutoML/Twins" -> "facebookresearch/MaskFormer" ["e"=1]
"revantteotia/clip-training" -> "Zasder3/train-CLIP"
"revantteotia/clip-training" -> "Zasder3/train-CLIP-FT"
"ashkamath/mdetr" -> "microsoft/GLIP" ["e"=1]
"ashkamath/mdetr" -> "facebookresearch/Detic" ["e"=1]
"ashkamath/mdetr" -> "alirezazareian/ovr-cnn" ["e"=1]
"ashkamath/mdetr" -> "OFA-Sys/OFA" ["e"=1]
"ashkamath/mdetr" -> "mmaaz60/mvits_for_class_agnostic_od" ["e"=1]
"SegmentationBLWX/sssegmentation" -> "facebookresearch/MaskFormer" ["e"=1]
"SegmentationBLWX/sssegmentation" -> "czczup/ViT-Adapter" ["e"=1]
"SegmentationBLWX/sssegmentation" -> "NVlabs/SegFormer" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "Zasder3/train-CLIP"
"moein-shariatnia/OpenAI-CLIP" -> "mlfoundations/wise-ft"
"moein-shariatnia/OpenAI-CLIP" -> "rmokady/CLIP_prefix_caption"
"moein-shariatnia/OpenAI-CLIP" -> "clip-italian/clip-italian" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "rom1504/clip-retrieval"
"moein-shariatnia/OpenAI-CLIP" -> "mlfoundations/open_clip"
"moein-shariatnia/OpenAI-CLIP" -> "FreddeFrallan/Multilingual-CLIP"
"moein-shariatnia/OpenAI-CLIP" -> "yzhuoning/Awesome-CLIP" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "lucidrains/CoCa-pytorch"
"moein-shariatnia/OpenAI-CLIP" -> "lucidrains/video-diffusion-pytorch" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "cloneofsimo/minDiffusion" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "patrickjohncyh/fashion-clip" ["e"=1]
"moein-shariatnia/OpenAI-CLIP" -> "facebookresearch/SLIP"
"moein-shariatnia/OpenAI-CLIP" -> "lucidrains/x-clip"
"dddzg/up-detr" -> "megvii-research/AnchorDETR"
"dddzg/up-detr" -> "amirbar/DETReg" ["e"=1]
"dddzg/up-detr" -> "Atten4Vis/ConditionalDETR"
"dddzg/up-detr" -> "xieenze/DetCo" ["e"=1]
"dddzg/up-detr" -> "IDEA-Research/DN-DETR"
"dddzg/up-detr" -> "Megvii-BaseDetection/DeFCN" ["e"=1]
"dddzg/up-detr" -> "JosephKJ/OWOD"
"dddzg/up-detr" -> "gaopengcuhk/SMCA-DETR"
"dddzg/up-detr" -> "WXinlong/DenseCL" ["e"=1]
"dddzg/up-detr" -> "ZhangGongjie/SAM-DETR"
"dddzg/up-detr" -> "IDEA-Research/DAB-DETR"
"dddzg/up-detr" -> "limbo0000/InstanceLoc" ["e"=1]
"dddzg/up-detr" -> "PeizeSun/SparseR-CNN" ["e"=1]
"dddzg/up-detr" -> "megvii-model/YOLOF" ["e"=1]
"dddzg/up-detr" -> "implus/GFocalV2" ["e"=1]
"megvii-model/YOLOF" -> "JosephKJ/OWOD" ["e"=1]
"fcjian/TOOD" -> "Atten4Vis/ConditionalDETR" ["e"=1]
"chuhaojin/WenLan-api-document" -> "chuhaojin/BriVL-BUA-applications"
"chuhaojin/BriVL-BUA-applications" -> "chuhaojin/WenLan-api-document"
"chuhaojin/BriVL-BUA-applications" -> "BAAI-WuDao/BriVL"
"currentslab/awesome-vector-search" -> "criteo/autofaiss" ["e"=1]
"tfzhou/ContrastiveSeg" -> "facebookresearch/MaskFormer" ["e"=1]
"amirbar/DETReg" -> "mmaaz60/mvits_for_class_agnostic_od" ["e"=1]
"amirbar/DETReg" -> "dddzg/up-detr" ["e"=1]
"amirbar/DETReg" -> "akshitac8/OW-DETR" ["e"=1]
"amirbar/DETReg" -> "JosephKJ/OWOD" ["e"=1]
"xingyizhou/UniDet" -> "facebookresearch/Detic" ["e"=1]
"xingyizhou/UniDet" -> "JosephKJ/OWOD" ["e"=1]
"twangnh/pnp-detr" -> "VODKA312/IntroToSelf-control" ["e"=1]
"twangnh/pnp-detr" -> "kakaobrain/sparse-detr"
"twangnh/pnp-detr" -> "zhechen/Deformable-DETR-REGO"
"kingyiusuen/clip-image-search" -> "rkouye/es-clip-image-search"
"kingyiusuen/clip-image-search" -> "haltakov/natural-language-image-search"
"kingyiusuen/clip-image-search" -> "ManuelFay/ImageSearcher"
"kingyiusuen/clip-image-search" -> "atarss/clip-image-search"
"kingyiusuen/clip-image-search" -> "AkiRusProd/CLIP-search"
"stephanecharette/DarkPlate" -> "stephanecharette/MoveDetect"
"stephanecharette/DarkPlate" -> "stephanecharette/DarkHelp"
"xuefeng-cvr/BS-Net" -> "xuefeng-cvr/Tiny-Obstacle-Discovery-ROS"
"xuefeng-cvr/BS-Net" -> "xuefeng-cvr/Tiny-Obstacle-Discovery"
"stephanecharette/DarkHelp" -> "stephanecharette/DarkMark"
"stephanecharette/DarkHelp" -> "stephanecharette/DarkPlate"
"stephanecharette/DarkHelp" -> "hank-ai/darknet"
"stephanecharette/DarkHelp" -> "stephanecharette/MoveDetect"
"lucidrains/segformer-pytorch" -> "NVlabs/SegFormer" ["e"=1]
"gaopengcuhk/SMCA-DETR" -> "Atten4Vis/ConditionalDETR"
"gaopengcuhk/SMCA-DETR" -> "kakaobrain/sparse-detr"
"gaopengcuhk/SMCA-DETR" -> "megvii-research/AnchorDETR"
"gaopengcuhk/SMCA-DETR" -> "ZhangGongjie/SAM-DETR"
"gaopengcuhk/SMCA-DETR" -> "gaopengcuhk/Container"
"gaopengcuhk/SMCA-DETR" -> "zhechen/Deformable-DETR-REGO"
"gaopengcuhk/SMCA-DETR" -> "twangnh/pnp-detr"
"gaopengcuhk/SMCA-DETR" -> "abc403/SMCA-replication"
"t0efL/Cassava-Leaf-Disease-Classification" -> "t0efL/2nd-place-solution-Digital-Peter"
"joe-siyuan-qiao/ViP-DeepLab" -> "bytedance/kmax-deeplab" ["e"=1]
"kaist-dmlab/MDUAL" -> "kaist-dmlab/MORPH"
"kaist-dmlab/MDUAL" -> "kaist-dmlab/TensorSparkML"
"rom1504/laion-prepro" -> "LAION-AI/laion-datasets" ["e"=1]
"dzryk/antarctic-captions" -> "dzryk/clip-grams"
"kaist-dmlab/DF-TAR" -> "kaist-dmlab/MORPH"
"kaist-dmlab/DF-TAR" -> "kaist-dmlab/TensorSparkML"
"voxel51/fiftyone-examples" -> "voxel51/fiftyone-plugins"
"voxel51/fiftyone-examples" -> "voxel51/fiftyone-brain"
"voxel51/fiftyone-examples" -> "voxel51/voxelgpt"
"voxel51/fiftyone-examples" -> "voxel51/eta"
"voxel51/fiftyone-examples" -> "voxel51/papers-with-data"
"dzryk/clip-grams" -> "dzryk/cliptalk"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/CrossMatch"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/RECURVE"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/Prune4Rel"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/TCLP"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/DF-TAR"
"kaist-dmlab/MG-TAR" -> "kaist-dmlab/TensorSparkML"
"zmykevin/UC2" -> "e-bug/iglue"
"ai-forever/DigiTeller" -> "neverix/avengers-ensemble"
"encord-team/encord-client-python" -> "encord-team/encord-active"
"allenai/container" -> "gaopengcuhk/Container"
"neverix/avengers-ensemble" -> "NeuralPushkin/Dalle2-Decoder"
"neverix/avengers-ensemble" -> "KonderLip/data-fusion2022-open-solution"
"gaopengcuhk/Container" -> "allenai/container"
"facebookresearch/xformers" -> "mlfoundations/open_clip" ["e"=1]
"alibaba/EasyCV" -> "IDEA-Research/detrex" ["e"=1]
"alibaba/EasyCV" -> "IDEA-Research/DINO" ["e"=1]
"alibaba/EasyCV" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"yandex-research/ddpm-segmentation" -> "NVlabs/ODISE" ["e"=1]
"yandex-research/ddpm-segmentation" -> "ShoufaChen/DiffusionDet" ["e"=1]
"yandex-research/ddpm-segmentation" -> "NVlabs/GroupViT" ["e"=1]
"lucidrains/PaLM-pytorch" -> "lucidrains/flamingo-pytorch" ["e"=1]
"lucidrains/PaLM-pytorch" -> "lucidrains/CoCa-pytorch" ["e"=1]
"lucidrains/DALLE2-pytorch" -> "mlfoundations/open_clip" ["e"=1]
"salesforce/BLIP" -> "salesforce/LAVIS"
"salesforce/BLIP" -> "salesforce/ALBEF" ["e"=1]
"salesforce/BLIP" -> "mlfoundations/open_clip"
"salesforce/BLIP" -> "openai/CLIP" ["e"=1]
"salesforce/BLIP" -> "OFA-Sys/OFA"
"salesforce/BLIP" -> "microsoft/GLIP"
"salesforce/BLIP" -> "haotian-liu/LLaVA" ["e"=1]
"salesforce/BLIP" -> "QwenLM/Qwen-VL" ["e"=1]
"salesforce/BLIP" -> "IDEA-Research/GroundingDINO"
"salesforce/BLIP" -> "OFA-Sys/Chinese-CLIP"
"salesforce/BLIP" -> "rom1504/img2dataset"
"salesforce/BLIP" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"salesforce/BLIP" -> "mlfoundations/open_flamingo"
"salesforce/BLIP" -> "dandelin/ViLT" ["e"=1]
"salesforce/BLIP" -> "baaivision/EVA"
"OFA-Sys/OFA" -> "salesforce/BLIP"
"OFA-Sys/OFA" -> "salesforce/LAVIS"
"OFA-Sys/OFA" -> "salesforce/ALBEF" ["e"=1]
"OFA-Sys/OFA" -> "microsoft/GLIP"
"OFA-Sys/OFA" -> "alibaba/AliceMind" ["e"=1]
"OFA-Sys/OFA" -> "microsoft/Oscar" ["e"=1]
"OFA-Sys/OFA" -> "mlfoundations/open_flamingo"
"OFA-Sys/OFA" -> "lucidrains/flamingo-pytorch"
"OFA-Sys/OFA" -> "dandelin/ViLT" ["e"=1]
"OFA-Sys/OFA" -> "ashkamath/mdetr" ["e"=1]
"OFA-Sys/OFA" -> "KaiyangZhou/CoOp" ["e"=1]
"OFA-Sys/OFA" -> "yuewang-cuhk/awesome-vision-language-pretraining-papers" ["e"=1]
"OFA-Sys/OFA" -> "rmokady/CLIP_prefix_caption"
"OFA-Sys/OFA" -> "zengyan-97/X-VLM" ["e"=1]
"OFA-Sys/OFA" -> "X-PLUG/mPLUG-Owl" ["e"=1]
"facebookresearch/mae" -> "mlfoundations/open_clip" ["e"=1]
"facebookresearch/mae" -> "facebookresearch/dinov2" ["e"=1]
"Hi-FT/ERD" -> "CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation"
"Hi-FT/ERD" -> "JosephKJ/iOD"
"Hi-FT/ERD" -> "CanPeng123/Faster-ILOD"
"Hi-FT/ERD" -> "yaoyao-liu/CL-DETR"
"Hi-FT/ERD" -> "fcdl94/MMA"
"Hi-FT/ERD" -> "YuyangSunshine/ABR_IOD"
"Hi-FT/ERD" -> "kshmelkov/incremental_detectors"
"Hi-FT/ERD" -> "FanZhichen/Awesome-Incremental-Few-Shot-Object-Detection"
"XuJiacong/PIDNet" -> "NVlabs/SegFormer" ["e"=1]
"XuJiacong/PIDNet" -> "OpenGVLab/InternImage" ["e"=1]
"bubbliiiing/segformer-pytorch" -> "NVlabs/SegFormer" ["e"=1]
"Sanster/IOPaint" -> "geekyutao/Inpaint-Anything" ["e"=1]
"xuebinqin/DIS" -> "SysCV/sam-hq" ["e"=1]
"lucidrains/imagen-pytorch" -> "deep-floyd/IF" ["e"=1]
"microsoft/SimMIM" -> "facebookresearch/MaskFormer" ["e"=1]
"microsoft/SimMIM" -> "czczup/ViT-Adapter" ["e"=1]
"CompVis/latent-diffusion" -> "mlfoundations/open_clip" ["e"=1]
"isl-org/lang-seg" -> "NVlabs/GroupViT"
"isl-org/lang-seg" -> "raoyongming/DenseCLIP"
"isl-org/lang-seg" -> "chongzhou96/MaskCLIP"
"isl-org/lang-seg" -> "timojl/clipseg"
"isl-org/lang-seg" -> "vlmaps/vlmaps" ["e"=1]
"isl-org/lang-seg" -> "facebookresearch/ov-seg"
"isl-org/lang-seg" -> "DerrickWang005/CRIS.pytorch" ["e"=1]
"isl-org/lang-seg" -> "microsoft/GLIP"
"isl-org/lang-seg" -> "dvlab-research/LISA" ["e"=1]
"isl-org/lang-seg" -> "NVlabs/ODISE"
"isl-org/lang-seg" -> "ashkamath/mdetr" ["e"=1]
"isl-org/lang-seg" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"isl-org/lang-seg" -> "ZiqinZhou66/ZegCLIP"
"isl-org/lang-seg" -> "MendelXu/zsseg.baseline"
"isl-org/lang-seg" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"KaiyangZhou/CoOp" -> "raoyongming/DenseCLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "microsoft/GLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "mlfoundations/open_clip" ["e"=1]
"KaiyangZhou/CoOp" -> "salesforce/BLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "salesforce/LAVIS" ["e"=1]
"huggingface/diffusers" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"microsoft/GLIP" -> "IDEA-Research/GroundingDINO"
"microsoft/GLIP" -> "ashkamath/mdetr" ["e"=1]
"microsoft/GLIP" -> "microsoft/RegionCLIP"
"microsoft/GLIP" -> "facebookresearch/Detic"
"microsoft/GLIP" -> "IDEA-Research/DINO"
"microsoft/GLIP" -> "baaivision/EVA"
"microsoft/GLIP" -> "salesforce/BLIP"
"microsoft/GLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"microsoft/GLIP" -> "gligen/GLIGEN" ["e"=1]
"microsoft/GLIP" -> "salesforce/LAVIS"
"microsoft/GLIP" -> "OFA-Sys/OFA"
"microsoft/GLIP" -> "dvlab-research/LISA" ["e"=1]
"microsoft/GLIP" -> "TheShadow29/awesome-grounding" ["e"=1]
"microsoft/GLIP" -> "mlfoundations/open_clip"
"microsoft/GLIP" -> "UX-Decoder/Semantic-SAM"
"Alpha-VL/ConvMAE" -> "Sense-GVT/DeCLIP" ["e"=1]
"Alpha-VL/ConvMAE" -> "gaopengcuhk/SMCA-DETR" ["e"=1]
"wasi-master/13ft" -> "everywall/ladder" ["e"=1]
"DavidHuji/CapDec" -> "dhg-wei/DeCap"
"DavidHuji/CapDec" -> "FeiElysia/ViECap" ["e"=1]
"DavidHuji/CapDec" -> "allenai/close"
"DavidHuji/CapDec" -> "yxuansu/MAGIC"
"DavidHuji/CapDec" -> "YoadTew/zero-shot-image-to-text"
"IDEA-CCNL/Fengshenbang-LM" -> "OFA-Sys/Chinese-CLIP" ["e"=1]
"DingXiaoH/RepLKNet-pytorch" -> "OpenGVLab/InternImage" ["e"=1]
"VGVentures/slide_puzzle" -> "flutter/super_dash" ["e"=1]
"advimman/lama" -> "geekyutao/Inpaint-Anything" ["e"=1]
"advimman/lama" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"advimman/lama" -> "IDEA-Research/GroundingDINO" ["e"=1]
"cmhungsteve/Awesome-Transformer-Attention" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"cmhungsteve/Awesome-Transformer-Attention" -> "mlfoundations/open_clip" ["e"=1]
"microsoft/NUWA" -> "OFA-Sys/OFA" ["e"=1]
"lucidrains/CoCa-pytorch" -> "salesforce/ALBEF" ["e"=1]
"lucidrains/CoCa-pytorch" -> "salesforce/BLIP"
"lucidrains/CoCa-pytorch" -> "lucidrains/flamingo-pytorch"
"lucidrains/CoCa-pytorch" -> "facebookresearch/multimodal"
"lucidrains/CoCa-pytorch" -> "OFA-Sys/OFA"
"lucidrains/CoCa-pytorch" -> "baaivision/EVA"
"lucidrains/CoCa-pytorch" -> "facebookresearch/SLIP"
"lucidrains/CoCa-pytorch" -> "dandelin/ViLT" ["e"=1]
"lucidrains/CoCa-pytorch" -> "microsoft/GLIP"
"lucidrains/CoCa-pytorch" -> "zengyan-97/X-VLM" ["e"=1]
"lucidrains/CoCa-pytorch" -> "mlfoundations/open_clip"
"lucidrains/CoCa-pytorch" -> "rmokady/CLIP_prefix_caption"
"lucidrains/CoCa-pytorch" -> "Sense-GVT/DeCLIP"
"lucidrains/CoCa-pytorch" -> "KaiyangZhou/CoOp" ["e"=1]
"lucidrains/CoCa-pytorch" -> "salesforce/LAVIS"
"Deci-AI/super-gradients" -> "obss/sahi" ["e"=1]
"Deci-AI/super-gradients" -> "WongKinYiu/yolov9"
"Deci-AI/super-gradients" -> "AILab-CVC/YOLO-World"
"Deci-AI/super-gradients" -> "lyuwenyu/RT-DETR"
"Deci-AI/super-gradients" -> "meituan/YOLOv6" ["e"=1]
"Deci-AI/super-gradients" -> "autodistill/autodistill"
"Deci-AI/super-gradients" -> "WongKinYiu/yolov7" ["e"=1]
"Deci-AI/super-gradients" -> "mikel-brostrom/boxmot" ["e"=1]
"Deci-AI/super-gradients" -> "vietanhdev/anylabeling"
"Deci-AI/super-gradients" -> "ifzhang/ByteTrack" ["e"=1]
"Deci-AI/super-gradients" -> "Megvii-BaseDetection/YOLOX" ["e"=1]
"Deci-AI/super-gradients" -> "IDEA-Research/GroundingDINO"
"Deci-AI/super-gradients" -> "roboflow/notebooks" ["e"=1]
"Deci-AI/super-gradients" -> "lucasjinreal/yolov7_d2" ["e"=1]
"Deci-AI/super-gradients" -> "IDEA-Research/Grounded-Segment-Anything"
"libffcv/ffcv" -> "webdataset/webdataset" ["e"=1]
"libffcv/ffcv" -> "rom1504/img2dataset" ["e"=1]
"Timothyxxx/Chain-of-ThoughtsPapers" -> "amazon-science/mm-cot" ["e"=1]
"open-mmlab/mmengine" -> "open-mmlab/playground" ["e"=1]
"microsoft/RegionCLIP" -> "microsoft/GLIP"
"microsoft/RegionCLIP" -> "tgxs002/CORA"
"microsoft/RegionCLIP" -> "alirezazareian/ovr-cnn"
"microsoft/RegionCLIP" -> "zhenyuw16/UniDetector"
"microsoft/RegionCLIP" -> "hanoonaR/object-centric-ovd"
"microsoft/RegionCLIP" -> "fcjian/PromptDet"
"microsoft/RegionCLIP" -> "facebookresearch/Detic"
"microsoft/RegionCLIP" -> "dyabel/detpro"
"microsoft/RegionCLIP" -> "mlzxy/devit"
"microsoft/RegionCLIP" -> "clin1223/VLDet"
"microsoft/RegionCLIP" -> "wusize/ovdet"
"microsoft/RegionCLIP" -> "jianzongwu/Awesome-Open-Vocabulary"
"microsoft/RegionCLIP" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"microsoft/RegionCLIP" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"microsoft/RegionCLIP" -> "ashkamath/mdetr" ["e"=1]
"lucidrains/RETRO-pytorch" -> "lucidrains/flamingo-pytorch" ["e"=1]
"booydar/recurrent-memory-transformer" -> "allenai/mmc4" ["e"=1]
"facebookresearch/Mask2Former" -> "facebookresearch/MaskFormer"
"facebookresearch/Mask2Former" -> "IDEA-Research/MaskDINO"
"facebookresearch/Mask2Former" -> "czczup/ViT-Adapter"
"facebookresearch/Mask2Former" -> "SHI-Labs/OneFormer"
"facebookresearch/Mask2Former" -> "NVlabs/SegFormer"
"facebookresearch/Mask2Former" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"facebookresearch/Mask2Former" -> "UX-Decoder/Semantic-SAM"
"facebookresearch/Mask2Former" -> "open-mmlab/mmsegmentation" ["e"=1]
"facebookresearch/Mask2Former" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"facebookresearch/Mask2Former" -> "microsoft/X-Decoder"
"facebookresearch/Mask2Former" -> "IDEA-Research/DINO"
"facebookresearch/Mask2Former" -> "dvlab-research/LISA" ["e"=1]
"facebookresearch/Mask2Former" -> "NVlabs/ODISE"
"facebookresearch/Mask2Former" -> "facebookresearch/dinov2"
"facebookresearch/Mask2Former" -> "facebookresearch/ConvNeXt" ["e"=1]
"deeplearning-wisc/vos" -> "Went-Liang/UnSniffer" ["e"=1]
"NVlabs/FreeSOLO" -> "facebookresearch/Generic-Grouping" ["e"=1]
"kakaobrain/rq-vae-transformer" -> "kakaobrain/coyo-dataset" ["e"=1]
"facebookresearch/SLIP" -> "Sense-GVT/DeCLIP"
"facebookresearch/SLIP" -> "lucidrains/x-clip"
"facebookresearch/SLIP" -> "raoyongming/DenseCLIP"
"facebookresearch/SLIP" -> "salesforce/ALBEF" ["e"=1]
"facebookresearch/SLIP" -> "kakaobrain/coyo-dataset"
"facebookresearch/SLIP" -> "LAION-AI/CLIP_benchmark"
"facebookresearch/SLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"facebookresearch/SLIP" -> "facebookresearch/moco-v3" ["e"=1]
"facebookresearch/SLIP" -> "m-bain/frozen-in-time" ["e"=1]
"facebookresearch/SLIP" -> "jayleicn/ClipBERT" ["e"=1]
"facebookresearch/SLIP" -> "facebookresearch/Detic"
"facebookresearch/SLIP" -> "mlfoundations/wise-ft"
"facebookresearch/SLIP" -> "microsoft/GLIP"
"facebookresearch/SLIP" -> "ashkamath/mdetr" ["e"=1]
"facebookresearch/SLIP" -> "showlab/all-in-one" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "yangjianxin1/ClipCap-Chinese"
"rmokady/CLIP_prefix_caption" -> "aimagelab/meshed-memory-transformer" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "ruotianluo/ImageCaptioning.pytorch" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "OFA-Sys/OFA"
"rmokady/CLIP_prefix_caption" -> "YoadTew/zero-shot-image-to-text"
"rmokady/CLIP_prefix_caption" -> "DavidHuji/CapDec"
"rmokady/CLIP_prefix_caption" -> "j-min/CLIP-Caption-Reward"
"rmokady/CLIP_prefix_caption" -> "tylin/coco-caption" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "salesforce/BLIP"
"rmokady/CLIP_prefix_caption" -> "microsoft/Oscar" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "zhjohnchan/awesome-image-captioning" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "clip-vil/CLIP-ViL" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "peteanderson80/bottom-up-attention" ["e"=1]
"rmokady/CLIP_prefix_caption" -> "KaiyangZhou/CoOp" ["e"=1]
"lucidrains/x-clip" -> "Sense-GVT/DeCLIP"
"lucidrains/x-clip" -> "facebookresearch/SLIP"
"lucidrains/x-clip" -> "lucidrains/nuwa-pytorch" ["e"=1]
"lucidrains/x-clip" -> "MIMICLab/L-Verse"
"lucidrains/x-clip" -> "lucidrains/CoCa-pytorch"
"lucidrains/x-clip" -> "kakaobrain/coyo-dataset"
"lucidrains/x-clip" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"lucidrains/x-clip" -> "LAION-AI/CLIP_benchmark"
"lucidrains/x-clip" -> "facebookresearch/multimodal"
"lucidrains/x-clip" -> "FreddeFrallan/Multilingual-CLIP"
"lucidrains/x-clip" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"lucidrains/x-clip" -> "crowsonkb/v-diffusion-pytorch" ["e"=1]
"lucidrains/x-clip" -> "ml-jku/cloob"
"SHI-Labs/Neighborhood-Attention-Transformer" -> "SHI-Labs/OneFormer" ["e"=1]
"google-research/big_vision" -> "google-research/scenic" ["e"=1]
"google-research/big_vision" -> "baaivision/EVA"
"google-research/big_vision" -> "mlfoundations/open_clip"
"google-research/big_vision" -> "LLaVA-VL/LLaVA-NeXT" ["e"=1]
"google-research/big_vision" -> "rom1504/img2dataset"
"google-research/big_vision" -> "facebookresearch/MetaCLIP"
"google-research/big_vision" -> "salesforce/LAVIS"
"google-research/big_vision" -> "apple/ml-aim" ["e"=1]
"google-research/big_vision" -> "cambrian-mllm/cambrian" ["e"=1]
"google-research/big_vision" -> "rom1504/clip-retrieval"
"google-research/big_vision" -> "facebookresearch/vissl" ["e"=1]
"google-research/big_vision" -> "facebookresearch/dino" ["e"=1]
"google-research/big_vision" -> "google-research/vision_transformer" ["e"=1]
"google-research/big_vision" -> "facebookresearch/dinov2"
"google-research/big_vision" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"wkentaro/gdown" -> "rom1504/img2dataset" ["e"=1]
"wkentaro/gdown" -> "mlfoundations/open_clip" ["e"=1]
"cleanlab/cleanvision" -> "autodistill/autodistill" ["e"=1]
"cleanlab/cleanvision" -> "Deci-AI/super-gradients" ["e"=1]
"EdisonLeeeee/Awesome-Masked-Autoencoders" -> "lxtGH/Awesome-Segmentation-With-Transformer" ["e"=1]
"kakaobrain/mindall-e" -> "kakaobrain/coyo-dataset" ["e"=1]
"yoxu515/aot-benchmark" -> "z-x-yang/Segment-and-Track-Anything" ["e"=1]
"czczup/ViT-Adapter" -> "facebookresearch/Mask2Former"
"czczup/ViT-Adapter" -> "IDEA-Research/MaskDINO"
"czczup/ViT-Adapter" -> "OpenGVLab/InternImage"
"czczup/ViT-Adapter" -> "baaivision/EVA"
"czczup/ViT-Adapter" -> "facebookresearch/MaskFormer"
"czczup/ViT-Adapter" -> "microsoft/X-Decoder"
"czczup/ViT-Adapter" -> "IDEA-Research/DINO"
"czczup/ViT-Adapter" -> "NVlabs/SegFormer"
"czczup/ViT-Adapter" -> "tianrun-chen/SAM-Adapter-PyTorch"
"czczup/ViT-Adapter" -> "SHI-Labs/OneFormer"
"czczup/ViT-Adapter" -> "IDEA-Research/awesome-detection-transformer"
"czczup/ViT-Adapter" -> "ShoufaChen/AdaptFormer" ["e"=1]
"czczup/ViT-Adapter" -> "KMnP/vpt" ["e"=1]
"czczup/ViT-Adapter" -> "IDEA-Research/detrex"
"czczup/ViT-Adapter" -> "microsoft/SimMIM" ["e"=1]
"microsoft/FocalNet" -> "IDEA-Research/Stable-DINO" ["e"=1]
"microsoft/FocalNet" -> "IDEA-Research/DINO" ["e"=1]
"microsoft/FocalNet" -> "OpenGVLab/InternImage" ["e"=1]
"microsoft/FocalNet" -> "IDEA-Research/MaskDINO" ["e"=1]
"microsoft/FocalNet" -> "IDEA-Research/detrex" ["e"=1]
"CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation" -> "Hi-FT/ERD"
"CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation" -> "JosephKJ/iOD"
"CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation" -> "CanPeng123/Faster-ILOD"
"MCG-NKU/E2FGVI" -> "gaomingqi/Track-Anything" ["e"=1]
"visual-layer/fastdup" -> "Deci-AI/super-gradients" ["e"=1]
"visual-layer/fastdup" -> "rom1504/clip-retrieval" ["e"=1]
"visual-layer/fastdup" -> "autodistill/autodistill" ["e"=1]
"visual-layer/fastdup" -> "rom1504/img2dataset" ["e"=1]
"visual-layer/fastdup" -> "SysCV/sam-hq" ["e"=1]
"facebookresearch/Detic" -> "microsoft/GLIP"
"facebookresearch/Detic" -> "ashkamath/mdetr" ["e"=1]
"facebookresearch/Detic" -> "microsoft/RegionCLIP"
"facebookresearch/Detic" -> "xingyizhou/CenterNet2" ["e"=1]
"facebookresearch/Detic" -> "microsoft/X-Decoder"
"facebookresearch/Detic" -> "facebookresearch/Mask2Former"
"facebookresearch/Detic" -> "facebookresearch/ConvNeXt" ["e"=1]
"facebookresearch/Detic" -> "baaivision/EVA"
"facebookresearch/Detic" -> "xingyizhou/UniDet" ["e"=1]
"facebookresearch/Detic" -> "facebookresearch/SLIP"
"facebookresearch/Detic" -> "alirezazareian/ovr-cnn"
"facebookresearch/Detic" -> "IDEA-Research/DINO"
"facebookresearch/Detic" -> "facebookresearch/CutLER" ["e"=1]
"facebookresearch/Detic" -> "IDEA-Research/OpenSeeD"
"facebookresearch/Detic" -> "PeizeSun/SparseR-CNN" ["e"=1]
"timojl/clipseg" -> "isl-org/lang-seg"
"timojl/clipseg" -> "microsoft/X-Decoder"
"timojl/clipseg" -> "raoyongming/DenseCLIP"
"timojl/clipseg" -> "DerrickWang005/CRIS.pytorch" ["e"=1]
"timojl/clipseg" -> "microsoft/GLIP"
"timojl/clipseg" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"timojl/clipseg" -> "ThereforeGames/txt2mask" ["e"=1]
"timojl/clipseg" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"timojl/clipseg" -> "dvlab-research/LISA" ["e"=1]
"timojl/clipseg" -> "chongzhou96/MaskCLIP"
"timojl/clipseg" -> "UX-Decoder/Semantic-SAM"
"timojl/clipseg" -> "segments-ai/panoptic-segment-anything"
"timojl/clipseg" -> "ZrrSkywalker/Personalize-SAM"
"timojl/clipseg" -> "amrrs/stable-diffusion-prompt-inpainting" ["e"=1]
"timojl/clipseg" -> "czczup/ViT-Adapter"
"DerrickWang005/CRIS.pytorch" -> "chongzhou96/MaskCLIP" ["e"=1]
"DerrickWang005/CRIS.pytorch" -> "isl-org/lang-seg" ["e"=1]
"lucidrains/nuwa-pytorch" -> "lucidrains/x-clip" ["e"=1]
"lucidrains/nuwa-pytorch" -> "MIMICLab/L-Verse" ["e"=1]
"IDEA-Research/DN-DETR" -> "IDEA-Research/DAB-DETR"
"IDEA-Research/DN-DETR" -> "Atten4Vis/ConditionalDETR"
"IDEA-Research/DN-DETR" -> "IDEA-Research/DINO"
"IDEA-Research/DN-DETR" -> "IDEA-Research/awesome-detection-transformer"
"IDEA-Research/DN-DETR" -> "megvii-research/AnchorDETR"
"IDEA-Research/DN-DETR" -> "MCG-NJU/AdaMixer"
"IDEA-Research/DN-DETR" -> "IDEA-Research/detrex"
"IDEA-Research/DN-DETR" -> "jshilong/DDQ"
"IDEA-Research/DN-DETR" -> "HDETR/H-Deformable-DETR"
"IDEA-Research/DN-DETR" -> "IDEA-Research/MaskDINO"
"IDEA-Research/DN-DETR" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"IDEA-Research/DN-DETR" -> "ZhangGongjie/SAM-DETR"
"IDEA-Research/DN-DETR" -> "kakaobrain/sparse-detr"
"IDEA-Research/DN-DETR" -> "ShoufaChen/DiffusionDet"
"IDEA-Research/DN-DETR" -> "naver-ai/vidt"
"IDEA-Research/DINO" -> "IDEA-Research/detrex"
"IDEA-Research/DINO" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"IDEA-Research/DINO" -> "IDEA-Research/awesome-detection-transformer"
"IDEA-Research/DINO" -> "IDEA-Research/DN-DETR"
"IDEA-Research/DINO" -> "IDEA-Research/DAB-DETR"
"IDEA-Research/DINO" -> "IDEA-Research/MaskDINO"
"IDEA-Research/DINO" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/DINO" -> "Sense-X/Co-DETR" ["e"=1]
"IDEA-Research/DINO" -> "microsoft/GLIP"
"IDEA-Research/DINO" -> "OpenGVLab/InternImage"
"IDEA-Research/DINO" -> "facebookresearch/dino" ["e"=1]
"IDEA-Research/DINO" -> "lyuwenyu/RT-DETR"
"IDEA-Research/DINO" -> "baaivision/EVA"
"IDEA-Research/DINO" -> "facebookresearch/detr" ["e"=1]
"IDEA-Research/DINO" -> "facebookresearch/Mask2Former"
"tfzhou/ProtoSeg" -> "chongzhou96/MaskCLIP" ["e"=1]
"tfzhou/ProtoSeg" -> "facebookresearch/MaskFormer" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "raoyongming/DenseCLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "Sense-GVT/DeCLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "microsoft/GLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "ShoufaChen/DiffusionDet" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "mlfoundations/open_clip" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "facebookresearch/SLIP" ["e"=1]
"EPFL-VILAB/MultiMAE" -> "Sense-GVT/DeCLIP" ["e"=1]
"gaopengcuhk/Tip-Adapter" -> "raoyongming/DenseCLIP" ["e"=1]
"microsoft/UniCL" -> "microsoft/X-Decoder" ["e"=1]
"microsoft/UniCL" -> "facebookresearch/SLIP" ["e"=1]
"lucidrains/flamingo-pytorch" -> "mlfoundations/open_flamingo"
"lucidrains/flamingo-pytorch" -> "OFA-Sys/OFA"
"lucidrains/flamingo-pytorch" -> "lucidrains/CoCa-pytorch"
"lucidrains/flamingo-pytorch" -> "dhansmair/flamingo-mini"
"lucidrains/flamingo-pytorch" -> "allenai/mmc4"
"lucidrains/flamingo-pytorch" -> "kakaobrain/coyo-dataset"
"lucidrains/flamingo-pytorch" -> "microsoft/GLIP"
"lucidrains/flamingo-pytorch" -> "salesforce/ALBEF" ["e"=1]
"lucidrains/flamingo-pytorch" -> "salesforce/BLIP"
"lucidrains/flamingo-pytorch" -> "microsoft/Oscar" ["e"=1]
"lucidrains/flamingo-pytorch" -> "salesforce/LAVIS"
"lucidrains/flamingo-pytorch" -> "zengyan-97/X-VLM" ["e"=1]
"lucidrains/flamingo-pytorch" -> "facebookresearch/SLIP"
"lucidrains/flamingo-pytorch" -> "kohjingyu/fromage"
"lucidrains/flamingo-pytorch" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"sail-sg/poolformer" -> "facebookresearch/Mask2Former" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "ditejs/ditejs" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "gaoshaoye/Project-Kimi" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "WangTaoAs/PFD_Net" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "2401345934/vite-press-blog"
"ZhangGongjie/SAM-DETR" -> "wflin2020/KotlinExtensions" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "ZhangGongjie/Meta-DETR" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "wzongyu/OrderSystem" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "folospace/go-mysql-orm" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "MinerProxyBTC/GoMinerTool" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "Instance-Search/Instance-Search" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "retnullyu/Dirsearch4burp" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "retnullyu/scanner-front" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "VividLe/BackTAL" ["e"=1]
"ZhangGongjie/SAM-DETR" -> "gaopengcuhk/SMCA-DETR"
"google-research/pix2seq" -> "gaopengcuhk/Stable-Pix2Seq"
"google-research/pix2seq" -> "moein-shariatnia/Pix2Seq"
"google-research/pix2seq" -> "microsoft/X-Decoder"
"google-research/pix2seq" -> "microsoft/GLIP"
"google-research/pix2seq" -> "gaopengcuhk/Unofficial-Pix2Seq"
"google-research/pix2seq" -> "ShoufaChen/DiffusionDet"
"google-research/pix2seq" -> "OFA-Sys/OFA"
"google-research/pix2seq" -> "NVlabs/GroupViT"
"google-research/pix2seq" -> "IDEA-Research/DN-DETR"
"google-research/pix2seq" -> "IDEA-Research/DAB-DETR"
"google-research/pix2seq" -> "OpenGVLab/VisionLLM" ["e"=1]
"google-research/pix2seq" -> "amazon-science/polygon-transformer" ["e"=1]
"google-research/pix2seq" -> "facebookresearch/Detic"
"google-research/pix2seq" -> "gaopengcuhk/Pretrained-Pix2Seq"
"google-research/pix2seq" -> "IDEA-Research/awesome-detection-transformer"
"NVlabs/GroupViT" -> "isl-org/lang-seg"
"NVlabs/GroupViT" -> "chongzhou96/MaskCLIP"
"NVlabs/GroupViT" -> "raoyongming/DenseCLIP"
"NVlabs/GroupViT" -> "NVlabs/ODISE"
"NVlabs/GroupViT" -> "microsoft/GLIP"
"NVlabs/GroupViT" -> "facebookresearch/MaskFormer"
"NVlabs/GroupViT" -> "facebookresearch/ov-seg"
"NVlabs/GroupViT" -> "wjn922/ReferFormer" ["e"=1]
"NVlabs/GroupViT" -> "ashkamath/mdetr" ["e"=1]
"NVlabs/GroupViT" -> "tfzhou/ProtoSeg" ["e"=1]
"NVlabs/GroupViT" -> "Sense-GVT/DeCLIP"
"NVlabs/GroupViT" -> "yandex-research/ddpm-segmentation" ["e"=1]
"NVlabs/GroupViT" -> "google-research/pix2seq"
"NVlabs/GroupViT" -> "MendelXu/SAN"
"NVlabs/GroupViT" -> "bytedance/ibot" ["e"=1]
"MCG-NJU/AdaMixer" -> "IDEA-Research/DN-DETR"
"MCG-NJU/AdaMixer" -> "Atten4Vis/ConditionalDETR"
"MCG-NJU/AdaMixer" -> "jshilong/DDQ"
"MCG-NJU/AdaMixer" -> "MCG-NJU/STMixer" ["e"=1]
"MCG-NJU/AdaMixer" -> "Fangyi-Chen/SQR"
"MCG-NJU/AdaMixer" -> "jozhang97/DETA"
"MCG-NJU/AdaMixer" -> "hologerry/SoCo" ["e"=1]
"MCG-NJU/AdaMixer" -> "strongwolf/DW" ["e"=1]
"MCG-NJU/AdaMixer" -> "IDEA-Research/DAB-DETR"
"MCG-NJU/AdaMixer" -> "MCG-NJU/DEQDet"
"MCG-NJU/AdaMixer" -> "MCG-NJU/CamLiFlow" ["e"=1]
"dyabel/detpro" -> "clin1223/VLDet"
"dyabel/detpro" -> "alirezazareian/ovr-cnn"
"dyabel/detpro" -> "mengqiDyangge/HierKD"
"dyabel/detpro" -> "yuhangzang/OV-DETR"
"dyabel/detpro" -> "LutingWang/OADP"
"dyabel/detpro" -> "wusize/ovdet"
"dyabel/detpro" -> "llrtt/Zero-Shot-Detection-via-Vision-and-Language-Knowledge-Distillation"
"dyabel/detpro" -> "hanoonaR/object-centric-ovd"
"dyabel/detpro" -> "fcjian/PromptDet"
"dyabel/detpro" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"dyabel/detpro" -> "CVMI-Lab/CoDet"
"open-mmlab/OpenMMLabCourse" -> "open-mmlab/playground" ["e"=1]
"e-bug/iglue" -> "zmykevin/UC2"
"kakaobrain/sparse-detr" -> "Atten4Vis/ConditionalDETR"
"kakaobrain/sparse-detr" -> "gaopengcuhk/SMCA-DETR"
"kakaobrain/sparse-detr" -> "twangnh/pnp-detr"
"kakaobrain/sparse-detr" -> "megvii-research/AnchorDETR"
"kakaobrain/sparse-detr" -> "naver-ai/vidt"
"kakaobrain/sparse-detr" -> "kakaobrain/noc"
"kakaobrain/sparse-detr" -> "IDEA-Research/DAB-DETR"
"kakaobrain/sparse-detr" -> "IDEA-Research/DN-DETR"
"akshitac8/OW-DETR" -> "RE-OWOD/RE-OWOD"
"akshitac8/OW-DETR" -> "orrzohar/PROB"
"akshitac8/OW-DETR" -> "JosephKJ/OWOD"
"akshitac8/OW-DETR" -> "csuhan/opendet2"
"akshitac8/OW-DETR" -> "mmaaz60/mvits_for_class_agnostic_od"
"akshitac8/OW-DETR" -> "JosephKJ/iOD"
"akshitac8/OW-DETR" -> "Went-Liang/UnSniffer"
"akshitac8/OW-DETR" -> "orrzohar/FOMO"
"akshitac8/OW-DETR" -> "Vastlab/Elephant-of-object-detection"
"akshitac8/OW-DETR" -> "buxihuo/OW-YOLO"
"akshitac8/OW-DETR" -> "mcahny/object_localization_network"
"akshitac8/OW-DETR" -> "JohnWuzh/UC-OWOD"
"akshitac8/OW-DETR" -> "frh23333/mepu-owod"
"akshitac8/OW-DETR" -> "amirbar/DETReg" ["e"=1]
"IDEA-Research/awesome-detection-transformer" -> "IDEA-Research/detrex"
"IDEA-Research/awesome-detection-transformer" -> "IDEA-Research/DINO"
"IDEA-Research/awesome-detection-transformer" -> "IDEA-Research/DN-DETR"
"IDEA-Research/awesome-detection-transformer" -> "IDEA-Research/DAB-DETR"
"IDEA-Research/awesome-detection-transformer" -> "IDEA-Research/MaskDINO"
"IDEA-Research/awesome-detection-transformer" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"IDEA-Research/awesome-detection-transformer" -> "Atten4Vis/ConditionalDETR"
"IDEA-Research/awesome-detection-transformer" -> "dk-liang/Awesome-Visual-Transformer" ["e"=1]
"IDEA-Research/awesome-detection-transformer" -> "Sense-X/Co-DETR" ["e"=1]
"IDEA-Research/awesome-detection-transformer" -> "czczup/ViT-Adapter"
"IDEA-Research/awesome-detection-transformer" -> "MCG-NJU/AdaMixer"
"IDEA-Research/awesome-detection-transformer" -> "HDETR/H-Deformable-DETR"
"IDEA-Research/awesome-detection-transformer" -> "jshilong/DDQ"
"IDEA-Research/awesome-detection-transformer" -> "jianzongwu/Awesome-Open-Vocabulary"
"IDEA-Research/awesome-detection-transformer" -> "lxtGH/Awesome-Segmentation-With-Transformer"
"ZwwWayne/K-Net" -> "facebookresearch/MaskFormer" ["e"=1]
"ZwwWayne/K-Net" -> "IDEA-Research/DN-DETR" ["e"=1]
"EdVince/CLIP-ImageSearch-NCNN" -> "atarss/clip-image-search" ["e"=1]
"JosephKJ/iOD" -> "Hi-FT/ERD"
"JosephKJ/iOD" -> "CanPeng123/Faster-ILOD"
"JosephKJ/iOD" -> "CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation"
"JosephKJ/iOD" -> "kshmelkov/incremental_detectors"
"JosephKJ/iOD" -> "YuyangSunshine/ABR_IOD"
"JosephKJ/iOD" -> "fcdl94/MMA"
"JosephKJ/iOD" -> "JosephKJ/ELI" ["e"=1]
"JosephKJ/iOD" -> "Tongji-MIC-Lab/ML-iFSOD"
"JosephKJ/iOD" -> "akshitac8/OW-DETR"
"fcdl94/MMA" -> "YuyangSunshine/ABR_IOD"
"fcdl94/MMA" -> "CanPeng123/Faster-ILOD"
"mmaaz60/mvits_for_class_agnostic_od" -> "hanoonaR/object-centric-ovd"
"mmaaz60/mvits_for_class_agnostic_od" -> "akshitac8/OW-DETR"
"mmaaz60/mvits_for_class_agnostic_od" -> "amirbar/DETReg" ["e"=1]
"mmaaz60/mvits_for_class_agnostic_od" -> "orrzohar/PROB"
"mmaaz60/mvits_for_class_agnostic_od" -> "mcahny/object_localization_network"
"mmaaz60/mvits_for_class_agnostic_od" -> "JosephKJ/OWOD"
"mmaaz60/mvits_for_class_agnostic_od" -> "mmaaz60/EdgeNeXt" ["e"=1]
"mmaaz60/mvits_for_class_agnostic_od" -> "RE-OWOD/RE-OWOD"
"mmaaz60/mvits_for_class_agnostic_od" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"mmaaz60/mvits_for_class_agnostic_od" -> "abdohelmy/D-3Former"
"mmaaz60/mvits_for_class_agnostic_od" -> "ashkamath/mdetr" ["e"=1]
"mmaaz60/mvits_for_class_agnostic_od" -> "asif-hanif/vafa" ["e"=1]
"mmaaz60/mvits_for_class_agnostic_od" -> "clin1223/VLDet"
"mmaaz60/mvits_for_class_agnostic_od" -> "Muhammad-Huzaifaa/ObjectCompose" ["e"=1]
"yxuansu/SimCTG" -> "yxuansu/MAGIC" ["e"=1]
"Sense-X/UniFormer" -> "czczup/ViT-Adapter" ["e"=1]
"SysCV/transfiner" -> "IDEA-Research/MaskDINO" ["e"=1]
"SysCV/transfiner" -> "facebookresearch/Mask2Former" ["e"=1]
"SysCV/transfiner" -> "HDETR/H-Deformable-DETR" ["e"=1]
"chongzhou96/MaskCLIP" -> "raoyongming/DenseCLIP"
"chongzhou96/MaskCLIP" -> "ZiqinZhou66/ZegCLIP"
"chongzhou96/MaskCLIP" -> "isl-org/lang-seg"
"chongzhou96/MaskCLIP" -> "MendelXu/zsseg.baseline"
"chongzhou96/MaskCLIP" -> "NVlabs/ODISE"
"chongzhou96/MaskCLIP" -> "facebookresearch/ov-seg"
"chongzhou96/MaskCLIP" -> "NVlabs/GroupViT"
"chongzhou96/MaskCLIP" -> "xmed-lab/CLIP_Surgery"
"chongzhou96/MaskCLIP" -> "DerrickWang005/CRIS.pytorch" ["e"=1]
"chongzhou96/MaskCLIP" -> "wysoczanska/clip_dinoiser"
"chongzhou96/MaskCLIP" -> "MendelXu/SAN"
"chongzhou96/MaskCLIP" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"chongzhou96/MaskCLIP" -> "runnanchen/CLIP2Scene" ["e"=1]
"chongzhou96/MaskCLIP" -> "microsoft/X-Decoder"
"chongzhou96/MaskCLIP" -> "linyq2117/CLIP-ES" ["e"=1]
"ShoufaChen/AdaptFormer" -> "czczup/ViT-Adapter" ["e"=1]
"naver-ai/vidt" -> "kaist-dmlab/RecencyBias"
"naver-ai/vidt" -> "kakaobrain/sparse-detr"
"naver-ai/vidt" -> "kaist-dmlab/Ada-Boundary"
"naver-ai/vidt" -> "kaist-dmlab/TRAP"
"naver-ai/vidt" -> "kaist-dmlab/Hi-COVIDNet"
"naver-ai/vidt" -> "kaist-dmlab/STARE"
"naver-ai/vidt" -> "kaist-dmlab/TensorSparkML"
"naver-ai/vidt" -> "kaist-dmlab/NETS"
"naver-ai/vidt" -> "IDEA-Research/DN-DETR"
"naver-ai/vidt" -> "kaist-dmlab/FL-Sim"
"naver-ai/vidt" -> "kaist-dmlab/CrossMatch"
"naver-ai/vidt" -> "zhechen/Deformable-DETR-REGO"
"naver-ai/vidt" -> "kaist-dmlab/MG-TAR"
"Sense-GVT/DeCLIP" -> "facebookresearch/SLIP"
"Sense-GVT/DeCLIP" -> "raoyongming/DenseCLIP"
"Sense-GVT/DeCLIP" -> "lucidrains/x-clip"
"Sense-GVT/DeCLIP" -> "clip-vil/CLIP-ViL" ["e"=1]
"Sense-GVT/DeCLIP" -> "uta-smile/TCL" ["e"=1]
"Sense-GVT/DeCLIP" -> "salesforce/ALBEF" ["e"=1]
"Sense-GVT/DeCLIP" -> "microsoft/GLIP"
"Sense-GVT/DeCLIP" -> "ashkamath/mdetr" ["e"=1]
"Sense-GVT/DeCLIP" -> "yzhuoning/Awesome-CLIP" ["e"=1]
"Sense-GVT/DeCLIP" -> "OpenGVLab/gv-benchmark" ["e"=1]
"Sense-GVT/DeCLIP" -> "Alpha-VL/ConvMAE" ["e"=1]
"Sense-GVT/DeCLIP" -> "ChenRocks/UNITER" ["e"=1]
"Sense-GVT/DeCLIP" -> "NVlabs/GroupViT"
"Sense-GVT/DeCLIP" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"Sense-GVT/DeCLIP" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"zengyan-97/X-VLM" -> "OFA-Sys/OFA" ["e"=1]
"zengyan-97/X-VLM" -> "zengyan-97/CCLM" ["e"=1]
"MIMICLab/L-Verse" -> "tgisaturday/dalle-lightning"
"MIMICLab/L-Verse" -> "JiwanChung/tapm"
"raoyongming/DenseCLIP" -> "chongzhou96/MaskCLIP"
"raoyongming/DenseCLIP" -> "isl-org/lang-seg"
"raoyongming/DenseCLIP" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"raoyongming/DenseCLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"raoyongming/DenseCLIP" -> "Sense-GVT/DeCLIP"
"raoyongming/DenseCLIP" -> "gaopengcuhk/CLIP-Adapter" ["e"=1]
"raoyongming/DenseCLIP" -> "facebookresearch/SLIP"
"raoyongming/DenseCLIP" -> "NVlabs/GroupViT"
"raoyongming/DenseCLIP" -> "clip-vil/CLIP-ViL" ["e"=1]
"raoyongming/DenseCLIP" -> "MendelXu/zsseg.baseline"
"raoyongming/DenseCLIP" -> "microsoft/GLIP"
"raoyongming/DenseCLIP" -> "ashkamath/mdetr" ["e"=1]
"raoyongming/DenseCLIP" -> "ZiqinZhou66/ZegCLIP"
"raoyongming/DenseCLIP" -> "DerrickWang005/CRIS.pytorch" ["e"=1]
"raoyongming/DenseCLIP" -> "czczup/ViT-Adapter"
"facebookresearch/multimodal" -> "salesforce/ALBEF" ["e"=1]
"facebookresearch/multimodal" -> "lucidrains/CoCa-pytorch"
"facebookresearch/multimodal" -> "facebookresearch/mmf" ["e"=1]
"facebookresearch/multimodal" -> "pliang279/awesome-multimodal-ml" ["e"=1]
"facebookresearch/multimodal" -> "microsoft/GLIP"
"facebookresearch/multimodal" -> "salesforce/BLIP"
"facebookresearch/multimodal" -> "mlfoundations/open_flamingo"
"facebookresearch/multimodal" -> "salesforce/LAVIS"
"facebookresearch/multimodal" -> "open-mmlab/Multimodal-GPT" ["e"=1]
"facebookresearch/multimodal" -> "lucidrains/flamingo-pytorch"
"facebookresearch/multimodal" -> "rom1504/img2dataset"
"facebookresearch/multimodal" -> "google-research/big_vision"
"facebookresearch/multimodal" -> "baaivision/EVA"
"facebookresearch/multimodal" -> "OFA-Sys/OFA"
"facebookresearch/multimodal" -> "declare-lab/multimodal-deep-learning" ["e"=1]
"IDEA-Research/DAB-DETR" -> "IDEA-Research/DN-DETR"
"IDEA-Research/DAB-DETR" -> "Atten4Vis/ConditionalDETR"
"IDEA-Research/DAB-DETR" -> "megvii-research/AnchorDETR"
"IDEA-Research/DAB-DETR" -> "IDEA-Research/DINO"
"IDEA-Research/DAB-DETR" -> "IDEA-Research/awesome-detection-transformer"
"IDEA-Research/DAB-DETR" -> "HDETR/H-Deformable-DETR"
"IDEA-Research/DAB-DETR" -> "IDEA-Research/detrex"
"IDEA-Research/DAB-DETR" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"IDEA-Research/DAB-DETR" -> "ZhangGongjie/SAM-DETR"
"IDEA-Research/DAB-DETR" -> "kakaobrain/sparse-detr"
"IDEA-Research/DAB-DETR" -> "jshilong/DDQ"
"IDEA-Research/DAB-DETR" -> "MCG-NJU/AdaMixer"
"IDEA-Research/DAB-DETR" -> "Ixiaohuihuihui/AO2-DETR" ["e"=1]
"IDEA-Research/DAB-DETR" -> "IDEA-Research/MaskDINO"
"IDEA-Research/DAB-DETR" -> "gaopengcuhk/SMCA-DETR"
"encounter1997/FP-DETR" -> "zhechen/Deformable-DETR-REGO" ["e"=1]
"LAION-AI/CLIP_benchmark" -> "mlfoundations/datacomp"
"LAION-AI/CLIP_benchmark" -> "facebookresearch/MetaCLIP"
"LAION-AI/CLIP_benchmark" -> "mlfoundations/wise-ft"
"LAION-AI/CLIP_benchmark" -> "rom1504/img2dataset"
"LAION-AI/CLIP_benchmark" -> "rom1504/clip-retrieval"
"LAION-AI/CLIP_benchmark" -> "FreddeFrallan/Multilingual-CLIP"
"LAION-AI/CLIP_benchmark" -> "UCSC-VLAA/CLIPA"
"LAION-AI/CLIP_benchmark" -> "beichenzbc/Long-CLIP"
"LAION-AI/CLIP_benchmark" -> "facebookresearch/SLIP"
"LAION-AI/CLIP_benchmark" -> "mertyg/vision-language-models-are-bows" ["e"=1]
"LAION-AI/CLIP_benchmark" -> "kongds/E5-V" ["e"=1]
"LAION-AI/CLIP_benchmark" -> "LAION-AI/scaling-laws-openclip"
"LAION-AI/CLIP_benchmark" -> "mlfoundations/open_clip"
"LAION-AI/CLIP_benchmark" -> "microsoft/LLM2CLIP"
"LAION-AI/CLIP_benchmark" -> "LijieFan/LaCLIP"
"mlfoundations/model-soups" -> "mlfoundations/wise-ft" ["e"=1]
"mlfoundations/model-soups" -> "lucidrains/CoCa-pytorch" ["e"=1]
"iejMac/clip-video-encode" -> "rom1504/python-template" ["e"=1]
"dingjiansw101/ZegFormer" -> "MendelXu/zsseg.baseline"
"dingjiansw101/ZegFormer" -> "ZiqinZhou66/ZegCLIP"
"dingjiansw101/ZegFormer" -> "bytedance/fc-clip"
"TACJu/PartImageNet" -> "facebookresearch/paco"
"TACJu/PartImageNet" -> "bytedance/kmax-deeplab"
"mlfoundations/wise-ft" -> "Zasder3/train-CLIP"
"mlfoundations/wise-ft" -> "LAION-AI/CLIP_benchmark"
"mlfoundations/wise-ft" -> "rom1504/clip-retrieval"
"mlfoundations/wise-ft" -> "gaopengcuhk/CLIP-Adapter" ["e"=1]
"mlfoundations/wise-ft" -> "locuslab/FLYP" ["e"=1]
"mlfoundations/wise-ft" -> "mlfoundations/open_clip"
"mlfoundations/wise-ft" -> "mlfoundations/task_vectors" ["e"=1]
"mlfoundations/wise-ft" -> "LightDXY/FT-CLIP" ["e"=1]
"mlfoundations/wise-ft" -> "mlfoundations/model-soups" ["e"=1]
"mlfoundations/wise-ft" -> "facebookresearch/SLIP"
"mlfoundations/wise-ft" -> "KaiyangZhou/CoOp" ["e"=1]
"mlfoundations/wise-ft" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"mlfoundations/wise-ft" -> "UCSC-VLAA/CLIPA"
"mlfoundations/wise-ft" -> "facebookresearch/MetaCLIP"
"mlfoundations/wise-ft" -> "mlfoundations/datacomp"
"j-min/CLIP-Caption-Reward" -> "DavidHuji/CapDec"
"yangjianxin1/ClipCap-Chinese" -> "rmokady/CLIP_prefix_caption"
"yangjianxin1/ClipCap-Chinese" -> "DavidHuji/CapDec"
"yangjianxin1/ClipCap-Chinese" -> "li-xirong/cross-lingual-cap" ["e"=1]
"yangjianxin1/ClipCap-Chinese" -> "FeiElysia/ViECap" ["e"=1]
"yangjianxin1/ClipCap-Chinese" -> "foamliu/Image-Captioning-PyTorch" ["e"=1]
"yangjianxin1/ClipCap-Chinese" -> "davidnvq/grit" ["e"=1]
"yangjianxin1/ClipCap-Chinese" -> "ShemoonX/Chinese-image-caption"
"yangjianxin1/ClipCap-Chinese" -> "billjie1/Chinese-CLIP"
"LAION-AI/laion-datasets" -> "rom1504/laion-prepro" ["e"=1]
"xingyizhou/GTR" -> "jozhang97/DETA" ["e"=1]
"yxuansu/MAGIC" -> "YoadTew/zero-shot-image-to-text"
"yxuansu/MAGIC" -> "yxuansu/SimCTG" ["e"=1]
"yxuansu/MAGIC" -> "DavidHuji/CapDec"
"yxuansu/MAGIC" -> "yxuansu/TaCL" ["e"=1]
"mcahny/object_localization_network" -> "ksaito-ut/openworld_ldet"
"mcahny/object_localization_network" -> "mmaaz60/mvits_for_class_agnostic_od"
"mcahny/object_localization_network" -> "akshitac8/OW-DETR"
"mcahny/object_localization_network" -> "xiaofeng94/VL-PLM"
"mcahny/object_localization_network" -> "Vastlab/Elephant-of-object-detection"
"mcahny/object_localization_network" -> "facebookresearch/Generic-Grouping"
"mcahny/object_localization_network" -> "JosephKJ/OWOD"
"mcahny/object_localization_network" -> "dyabel/detpro"
"mcahny/object_localization_network" -> "csuhan/opendet2"
"mcahny/object_localization_network" -> "wusize/ovdet"
"mcahny/object_localization_network" -> "RE-OWOD/RE-OWOD"
"yuxie11/R2D2" -> "BAAI-WuDao/BriVL"
"yuxie11/R2D2" -> "billjie1/Chinese-CLIP"
"gaopengcuhk/CLIP-Adapter" -> "raoyongming/DenseCLIP" ["e"=1]
"gaopengcuhk/CLIP-Adapter" -> "mlfoundations/wise-ft" ["e"=1]
"YoadTew/zero-shot-image-to-text" -> "yxuansu/MAGIC"
"YoadTew/zero-shot-image-to-text" -> "YoadTew/zero-shot-video-to-text"
"YoadTew/zero-shot-image-to-text" -> "DavidHuji/CapDec"
"YoadTew/zero-shot-image-to-text" -> "joeyz0z/ConZIC"
"YoadTew/zero-shot-image-to-text" -> "dhg-wei/DeCap"
"YoadTew/zero-shot-image-to-text" -> "rmokady/CLIP_prefix_caption"
"zengyan-97/CCLM" -> "zmykevin/UC2"
"zengyan-97/CCLM" -> "adapter-hub/xGQA"
"megvii-research/AnchorDETR" -> "Atten4Vis/ConditionalDETR"
"megvii-research/AnchorDETR" -> "IDEA-Research/DAB-DETR"
"megvii-research/AnchorDETR" -> "IDEA-Research/DN-DETR"
"megvii-research/AnchorDETR" -> "gaopengcuhk/SMCA-DETR"
"megvii-research/AnchorDETR" -> "kakaobrain/sparse-detr"
"megvii-research/AnchorDETR" -> "ZhangGongjie/SAM-DETR"
"megvii-research/AnchorDETR" -> "dddzg/up-detr"
"megvii-research/AnchorDETR" -> "twangnh/pnp-detr"
"megvii-research/AnchorDETR" -> "MCG-NJU/AdaMixer"
"megvii-research/AnchorDETR" -> "jshilong/DDQ"
"megvii-research/AnchorDETR" -> "HDETR/H-Deformable-DETR"
"megvii-research/AnchorDETR" -> "tangjiuqi097/ATCAIS"
"megvii-research/AnchorDETR" -> "Megvii-BaseDetection/DeFCN" ["e"=1]
"megvii-research/AnchorDETR" -> "Megvii-BaseDetection/OTA" ["e"=1]
"megvii-research/AnchorDETR" -> "naver-ai/vidt"
"csuhan/opendet2" -> "RE-OWOD/RE-OWOD"
"csuhan/opendet2" -> "akshitac8/OW-DETR"
"csuhan/opendet2" -> "Vastlab/Elephant-of-object-detection"
"csuhan/opendet2" -> "buxihuo/OW-YOLO"
"bytedance/ibot" -> "NVlabs/GroupViT" ["e"=1]
"bytedance/ibot" -> "facebookresearch/SLIP" ["e"=1]
"bytedance/ibot" -> "Sense-GVT/DeCLIP" ["e"=1]
"wjn922/ReferFormer" -> "Surrey-UP-Lab/RegionSpot" ["e"=1]
"yuhangzang/OV-DETR" -> "dyabel/detpro"
"yuhangzang/OV-DETR" -> "alirezazareian/ovr-cnn"
"yuhangzang/OV-DETR" -> "tgxs002/CORA"
"yuhangzang/OV-DETR" -> "eternaldolphin/LaMI-DETR"
"yuhangzang/OV-DETR" -> "wusize/ovdet"
"yuhangzang/OV-DETR" -> "wusize/CLIPSelf"
"yuhangzang/OV-DETR" -> "mengqiDyangge/HierKD"
"Lednik7/CLIP-ONNX" -> "cene555/ruCLIP-SB"
"Lednik7/CLIP-ONNX" -> "t0efL/2nd-place-solution-Digital-Peter"
"Lednik7/CLIP-ONNX" -> "KonderLip/data-fusion2022-open-solution"
"Lednik7/CLIP-ONNX" -> "NeuralPushkin/Pushkin-Poems"
"Lednik7/CLIP-ONNX" -> "neverix/avengers-ensemble"
"jshilong/GroupRCNN" -> "jshilong/DDQ" ["e"=1]
"happy-hsy/BCNet" -> "happy-hsy/MotionMAE"
"MendelXu/zsseg.baseline" -> "dingjiansw101/ZegFormer"
"MendelXu/zsseg.baseline" -> "MendelXu/SAN"
"RE-OWOD/RE-OWOD" -> "akshitac8/OW-DETR"
"RE-OWOD/RE-OWOD" -> "csuhan/opendet2"
"buxihuo/OW-YOLO" -> "RE-OWOD/RE-OWOD"
"buxihuo/OW-YOLO" -> "csuhan/opendet2"
"jshilong/DDQ" -> "jshilong/GroupRCNN" ["e"=1]
"jshilong/DDQ" -> "jozhang97/DETA"
"jshilong/DDQ" -> "MCG-NJU/AdaMixer"
"jshilong/DDQ" -> "IDEA-Research/DN-DETR"
"jshilong/DDQ" -> "IDEA-Research/Lite-DETR"
"jshilong/DDQ" -> "Atten4Vis/ConditionalDETR"
"jshilong/DDQ" -> "jshilong/GPT4RoI" ["e"=1]
"jshilong/DDQ" -> "Fangyi-Chen/SQR"
"jshilong/DDQ" -> "strongwolf/DW" ["e"=1]
"jshilong/DDQ" -> "IDEA-Research/DAB-DETR"
"jshilong/DDQ" -> "megvii-research/Iter-E2EDET" ["e"=1]
"jshilong/DDQ" -> "FelixCaae/AlignDETR"
"fcjian/PromptDet" -> "alirezazareian/ovr-cnn"
"fcjian/PromptDet" -> "hanoonaR/object-centric-ovd"
"fcjian/PromptDet" -> "xiaofeng94/VL-PLM"
"fcjian/PromptDet" -> "dyabel/detpro"
"NVIDIA-AI-IOT/jetson_dla_tutorial" -> "NVIDIA-AI-IOT/jetson-intro-to-distillation" ["e"=1]
"xiaofeng94/VL-PLM" -> "samschulter/omnilabeltools"
"xiaofeng94/VL-PLM" -> "mengqiDyangge/HierKD"
"xiaofeng94/VL-PLM" -> "clin1223/VLDet"
"hologerry/SoCo" -> "MCG-NJU/AdaMixer" ["e"=1]
"cene555/ru-clip-tiny" -> "cene555/ruCLIP-SB"
"ytongbai/ViTs-vs-CNNs" -> "UCSC-VLAA/RobustCNN"
"ytongbai/ViTs-vs-CNNs" -> "meijieru/fast_advprop"
"gaopengcuhk/Stable-Pix2Seq" -> "gaopengcuhk/Pretrained-Pix2Seq"
"gaopengcuhk/Stable-Pix2Seq" -> "gaopengcuhk/Unofficial-Pix2Seq"
"gaopengcuhk/Stable-Pix2Seq" -> "moein-shariatnia/Pix2Seq"
"gaopengcuhk/Stable-Pix2Seq" -> "google-research/pix2seq"
"facebookresearch/sylph-few-shot-detection" -> "TMIU/iTFA"
"facebookresearch/sylph-few-shot-detection" -> "Ybowei/UNP"
"facebookresearch/sylph-few-shot-detection" -> "FanZhichen/Awesome-Incremental-Few-Shot-Object-Detection"
"kaist-dmlab/TCLP" -> "kaist-dmlab/MQNet"
"kaist-dmlab/TCLP" -> "kaist-dmlab/CrossMatch"
"rom1504/embedding-reader" -> "rom1504/python-template"
"YiLiM1/DANet" -> "xuefeng-cvr/Tiny-Obstacle-Discovery"
"YiLiM1/DANet" -> "xuefeng-cvr/Tiny-Obstacle-Discovery-ROS"
"NeuralPushkin/Pushkin-Poems" -> "NeuralPushkin/Dalle2-Decoder"
"Lednik7/nto-ai-text-recognition" -> "radmirkaz/MCS2022-Top-2-solution"
"gaopengcuhk/Unofficial-Pix2Seq" -> "gaopengcuhk/Stable-Pix2Seq"
"gaopengcuhk/Unofficial-Pix2Seq" -> "gaopengcuhk/Pretrained-Pix2Seq"
"gaopengcuhk/Unofficial-Pix2Seq" -> "JJJYmmm/Pix2SeqV2-Pytorch"
"gaopengcuhk/Pretrained-Pix2Seq" -> "gaopengcuhk/Stable-Pix2Seq"
"NeuralPushkin/Dalle2-Decoder" -> "NeuralPushkin/Pushkin-Poems"
"NeuralPushkin/Dalle2-Decoder" -> "neverix/avengers-ensemble"
"facebookresearch/ov-seg" -> "IDEA-Research/OpenSeeD"
"facebookresearch/ov-seg" -> "MendelXu/SAN"
"facebookresearch/ov-seg" -> "NVlabs/ODISE"
"facebookresearch/ov-seg" -> "HarborYuan/ovsam"
"facebookresearch/ov-seg" -> "chongzhou96/MaskCLIP"
"facebookresearch/ov-seg" -> "jianzongwu/Awesome-Open-Vocabulary"
"facebookresearch/ov-seg" -> "bytedance/fc-clip"
"facebookresearch/ov-seg" -> "microsoft/X-Decoder"
"facebookresearch/ov-seg" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"facebookresearch/ov-seg" -> "UX-Decoder/Semantic-SAM"
"facebookresearch/ov-seg" -> "amazon-science/prompt-pretraining"
"facebookresearch/ov-seg" -> "isl-org/lang-seg"
"facebookresearch/ov-seg" -> "ZiqinZhou66/ZegCLIP"
"facebookresearch/ov-seg" -> "berkeley-hipie/HIPIE"
"facebookresearch/ov-seg" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"facebookresearch/AnimatedDrawings" -> "facebookresearch/ImageBind" ["e"=1]
"mlfoundations/open_flamingo" -> "lucidrains/flamingo-pytorch"
"mlfoundations/open_flamingo" -> "salesforce/LAVIS"
"mlfoundations/open_flamingo" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"mlfoundations/open_flamingo" -> "open-mmlab/Multimodal-GPT" ["e"=1]
"mlfoundations/open_flamingo" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"mlfoundations/open_flamingo" -> "mlfoundations/open_clip"
"mlfoundations/open_flamingo" -> "allenai/mmc4"
"mlfoundations/open_flamingo" -> "X-PLUG/mPLUG-Owl" ["e"=1]
"mlfoundations/open_flamingo" -> "baaivision/Emu" ["e"=1]
"mlfoundations/open_flamingo" -> "haotian-liu/LLaVA" ["e"=1]
"mlfoundations/open_flamingo" -> "rom1504/img2dataset"
"mlfoundations/open_flamingo" -> "microsoft/GLIP"
"mlfoundations/open_flamingo" -> "OFA-Sys/OFA"
"mlfoundations/open_flamingo" -> "salesforce/BLIP"
"mlfoundations/open_flamingo" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"TommyZihao/Train_Custom_Dataset" -> "CVHub520/X-AnyLabeling" ["e"=1]
"microsoft/LMOps" -> "amazon-science/mm-cot" ["e"=1]
"amazon-science/mm-cot" -> "lupantech/ScienceQA" ["e"=1]
"amazon-science/mm-cot" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"amazon-science/mm-cot" -> "amazon-science/auto-cot" ["e"=1]
"amazon-science/mm-cot" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"amazon-science/mm-cot" -> "mlfoundations/open_flamingo"
"amazon-science/mm-cot" -> "salesforce/LAVIS"
"amazon-science/mm-cot" -> "FMInference/FlexLLMGen" ["e"=1]
"amazon-science/mm-cot" -> "CarperAI/trlx" ["e"=1]
"amazon-science/mm-cot" -> "Instruction-Tuning-with-GPT-4/GPT-4-LLM" ["e"=1]
"amazon-science/mm-cot" -> "microsoft/LMOps" ["e"=1]
"amazon-science/mm-cot" -> "FranxYao/chain-of-thought-hub" ["e"=1]
"amazon-science/mm-cot" -> "microsoft/unilm" ["e"=1]
"amazon-science/mm-cot" -> "lucidrains/toolformer-pytorch" ["e"=1]
"amazon-science/mm-cot" -> "OFA-Sys/OFA"
"amazon-science/mm-cot" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"ultralytics/ultralytics" -> "THU-MIG/yolov10" ["e"=1]
"ultralytics/ultralytics" -> "WongKinYiu/yolov9" ["e"=1]
"ultralytics/ultralytics" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"SHI-Labs/OneFormer" -> "facebookresearch/Mask2Former"
"SHI-Labs/OneFormer" -> "IDEA-Research/MaskDINO"
"SHI-Labs/OneFormer" -> "UX-Decoder/Semantic-SAM"
"SHI-Labs/OneFormer" -> "IDEA-Research/OpenSeeD"
"SHI-Labs/OneFormer" -> "microsoft/X-Decoder"
"SHI-Labs/OneFormer" -> "czczup/ViT-Adapter"
"SHI-Labs/OneFormer" -> "fudan-zvg/Semantic-Segment-Anything"
"SHI-Labs/OneFormer" -> "OpenGVLab/InternImage"
"SHI-Labs/OneFormer" -> "facebookresearch/MaskFormer"
"SHI-Labs/OneFormer" -> "baaivision/Painter"
"SHI-Labs/OneFormer" -> "NVlabs/SegFormer"
"SHI-Labs/OneFormer" -> "facebookresearch/ov-seg"
"SHI-Labs/OneFormer" -> "NVlabs/ODISE"
"SHI-Labs/OneFormer" -> "SHI-Labs/Neighborhood-Attention-Transformer" ["e"=1]
"SHI-Labs/OneFormer" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"timothybrooks/instruct-pix2pix" -> "salesforce/LAVIS" ["e"=1]
"timothybrooks/instruct-pix2pix" -> "deep-floyd/IF" ["e"=1]
"lllyasviel/ControlNet" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"open-mmlab/mmyolo" -> "lyuwenyu/RT-DETR" ["e"=1]
"open-mmlab/mmyolo" -> "AILab-CVC/YOLO-World" ["e"=1]
"runwayml/stable-diffusion" -> "deep-floyd/IF" ["e"=1]
"baaivision/Painter" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"baaivision/Painter" -> "ZrrSkywalker/Personalize-SAM"
"baaivision/Painter" -> "baaivision/EVA"
"baaivision/Painter" -> "UX-Decoder/Semantic-SAM"
"baaivision/Painter" -> "fudan-zvg/Semantic-Segment-Anything"
"baaivision/Painter" -> "microsoft/X-Decoder"
"baaivision/Painter" -> "microsoft/GLIP"
"baaivision/Painter" -> "dvlab-research/LISA" ["e"=1]
"baaivision/Painter" -> "baaivision/Emu" ["e"=1]
"baaivision/Painter" -> "SysCV/sam-hq"
"baaivision/Painter" -> "aim-uofa/Matcher"
"baaivision/Painter" -> "tianrun-chen/SAM-Adapter-PyTorch"
"baaivision/Painter" -> "VainF/Awesome-Anything"
"baaivision/Painter" -> "OpenGVLab/InternImage"
"baaivision/Painter" -> "IDEA-Research/Grounded-Segment-Anything"
"trungdq88/Awesome-Black-Friday-Cyber-Monday" -> "everywall/ladder" ["e"=1]
"zbwxp/SegVit" -> "ZiqinZhou66/ZegCLIP"
"zbwxp/SegVit" -> "ZhenZHAO/AugSeg" ["e"=1]
"zbwxp/SegVit" -> "maeve07/RCA" ["e"=1]
"roboflow/notebooks" -> "autodistill/autodistill" ["e"=1]
"roboflow/notebooks" -> "roboflow/maestro" ["e"=1]
"roboflow/notebooks" -> "IDEA-Research/GroundingDINO" ["e"=1]
"roboflow/notebooks" -> "Deci-AI/super-gradients" ["e"=1]
"roboflow/notebooks" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"deforum-art/deforum-stable-diffusion" -> "deep-floyd/IF" ["e"=1]
"cloneofsimo/lora" -> "deep-floyd/IF" ["e"=1]
"meituan/YOLOv6" -> "WongKinYiu/yolov9" ["e"=1]
"z1069614715/objectdetection_script" -> "lyuwenyu/RT-DETR" ["e"=1]
"z1069614715/objectdetection_script" -> "WongKinYiu/yolov9" ["e"=1]
"z1069614715/objectdetection_script" -> "CVHub520/X-AnyLabeling" ["e"=1]
"z1069614715/objectdetection_script" -> "THU-MIG/yolov10" ["e"=1]
"ZiqinZhou66/ZegCLIP" -> "chongzhou96/MaskCLIP"
"ZiqinZhou66/ZegCLIP" -> "dingjiansw101/ZegFormer"
"ZiqinZhou66/ZegCLIP" -> "HVision-NKU/Cascade-CLIP" ["e"=1]
"ZiqinZhou66/ZegCLIP" -> "linyq2117/CLIP-ES" ["e"=1]
"ZiqinZhou66/ZegCLIP" -> "zbwxp/SegVit"
"microsoft/GenerativeImage2Text" -> "OFA-Sys/OFA" ["e"=1]
"microsoft/GenerativeImage2Text" -> "lucidrains/CoCa-pytorch" ["e"=1]
"microsoft/BioGPT" -> "amazon-science/mm-cot" ["e"=1]
"atherosai/ui" -> "WongKinYiu/yolov9" ["e"=1]
"WongKinYiu/yolov7" -> "WongKinYiu/yolov9" ["e"=1]
"gligen/GLIGEN" -> "microsoft/GLIP" ["e"=1]
"gligen/GLIGEN" -> "IDEA-Research/GroundingDINO" ["e"=1]
"yangjianxin1/CLIP-Chinese" -> "OFA-Sys/Chinese-CLIP" ["e"=1]
"yangjianxin1/CLIP-Chinese" -> "yangjianxin1/ClipCap-Chinese" ["e"=1]
"augmentedstartups/AS-One" -> "Deci-AI/super-gradients" ["e"=1]
"stephansturges/WALDO" -> "stephansturges/OpenLander"
"stephansturges/WALDO" -> "stephansturges/NANO"
"stephansturges/WALDO" -> "opengeos/segment-geospatial" ["e"=1]
"stephansturges/WALDO" -> "kyegomez/swarms" ["e"=1]
"stephansturges/WALDO" -> "siyuanliii/masa"
"stephansturges/WALDO" -> "roboflow/maestro"
"stephansturges/WALDO" -> "Deci-AI/super-gradients"
"stephansturges/WALDO" -> "hkchengrex/Tracking-Anything-with-DEVA"
"stephansturges/WALDO" -> "intuitem/ciso-assistant-community" ["e"=1]
"stephansturges/WALDO" -> "microsoft/torchgeo" ["e"=1]
"stephansturges/WALDO" -> "opengeos/leafmap" ["e"=1]
"stephansturges/WALDO" -> "autodistill/autodistill"
"stephansturges/WALDO" -> "obss/sahi" ["e"=1]
"stephansturges/WALDO" -> "roboflow/supervision" ["e"=1]
"stephansturges/WALDO" -> "tryolabs/norfair" ["e"=1]
"microsoft/i-Code" -> "facebookresearch/ImageBind" ["e"=1]
"microsoft/i-Code" -> "mlfoundations/open_flamingo" ["e"=1]
"microsoft/i-Code" -> "salesforce/LAVIS" ["e"=1]
"lupantech/ScienceQA" -> "amazon-science/mm-cot" ["e"=1]
"jaymody/picoGPT" -> "amazon-science/mm-cot" ["e"=1]
"google-research/parti" -> "kakaobrain/coyo-dataset" ["e"=1]
"salesforce/LAVIS" -> "salesforce/BLIP"
"salesforce/LAVIS" -> "haotian-liu/LLaVA" ["e"=1]
"salesforce/LAVIS" -> "mlfoundations/open_clip"
"salesforce/LAVIS" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"salesforce/LAVIS" -> "openai/CLIP" ["e"=1]
"salesforce/LAVIS" -> "IDEA-Research/Grounded-Segment-Anything"
"salesforce/LAVIS" -> "mlfoundations/open_flamingo"
"salesforce/LAVIS" -> "microsoft/unilm" ["e"=1]
"salesforce/LAVIS" -> "IDEA-Research/GroundingDINO"
"salesforce/LAVIS" -> "Vision-CAIR/MiniGPT-4" ["e"=1]
"salesforce/LAVIS" -> "QwenLM/Qwen-VL" ["e"=1]
"salesforce/LAVIS" -> "OpenGVLab/InternVL" ["e"=1]
"salesforce/LAVIS" -> "facebookresearch/dinov2"
"salesforce/LAVIS" -> "huggingface/peft" ["e"=1]
"salesforce/LAVIS" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"LAION-AI/dalle2-laion" -> "kakaobrain/coyo-dataset" ["e"=1]
"btpf/Alexandria" -> "everywall/ladder" ["e"=1]
"deep-floyd/IF" -> "AIGC-Audio/AudioGPT" ["e"=1]
"deep-floyd/IF" -> "Stability-AI/StableLM" ["e"=1]
"deep-floyd/IF" -> "cloneofsimo/lora" ["e"=1]
"deep-floyd/IF" -> "openai/consistency_models" ["e"=1]
"deep-floyd/IF" -> "ashawkey/stable-dreamfusion" ["e"=1]
"deep-floyd/IF" -> "TencentARC/T2I-Adapter" ["e"=1]
"deep-floyd/IF" -> "lllyasviel/ControlNet" ["e"=1]
"deep-floyd/IF" -> "guoyww/AnimateDiff" ["e"=1]
"deep-floyd/IF" -> "lllyasviel/ControlNet-v1-1-nightly" ["e"=1]
"deep-floyd/IF" -> "huggingface/diffusers" ["e"=1]
"deep-floyd/IF" -> "threestudio-project/threestudio" ["e"=1]
"deep-floyd/IF" -> "facebookresearch/ImageBind"
"deep-floyd/IF" -> "tencent-ailab/IP-Adapter" ["e"=1]
"deep-floyd/IF" -> "gaomingqi/Track-Anything"
"deep-floyd/IF" -> "IDEA-Research/Grounded-Segment-Anything"
"openai/point-e" -> "deep-floyd/IF" ["e"=1]
"ShoufaChen/DiffusionDet" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"ShoufaChen/DiffusionDet" -> "IDEA-Research/DN-DETR"
"ShoufaChen/DiffusionDet" -> "IDEA-Research/DINO"
"ShoufaChen/DiffusionDet" -> "IDEA-Research/detrex"
"ShoufaChen/DiffusionDet" -> "facebookresearch/Mask2Former"
"ShoufaChen/DiffusionDet" -> "microsoft/GLIP"
"ShoufaChen/DiffusionDet" -> "baaivision/EVA"
"ShoufaChen/DiffusionDet" -> "yandex-research/ddpm-segmentation" ["e"=1]
"ShoufaChen/DiffusionDet" -> "PeizeSun/SparseR-CNN" ["e"=1]
"ShoufaChen/DiffusionDet" -> "IDEA-Research/awesome-detection-transformer"
"ShoufaChen/DiffusionDet" -> "microsoft/X-Decoder"
"ShoufaChen/DiffusionDet" -> "google-research/pix2seq"
"ShoufaChen/DiffusionDet" -> "KaiyangZhou/CoOp" ["e"=1]
"ShoufaChen/DiffusionDet" -> "dvlab-research/LISA" ["e"=1]
"ShoufaChen/DiffusionDet" -> "facebookresearch/MaskFormer"
"microsoft/X-Decoder" -> "IDEA-Research/OpenSeeD"
"microsoft/X-Decoder" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"microsoft/X-Decoder" -> "UX-Decoder/Semantic-SAM"
"microsoft/X-Decoder" -> "facebookresearch/Mask2Former"
"microsoft/X-Decoder" -> "baaivision/Painter"
"microsoft/X-Decoder" -> "IDEA-Research/MaskDINO"
"microsoft/X-Decoder" -> "microsoft/GLIP"
"microsoft/X-Decoder" -> "facebookresearch/ov-seg"
"microsoft/X-Decoder" -> "jshilong/GPT4RoI" ["e"=1]
"microsoft/X-Decoder" -> "czczup/ViT-Adapter"
"microsoft/X-Decoder" -> "NVlabs/ODISE"
"microsoft/X-Decoder" -> "SHI-Labs/OneFormer"
"microsoft/X-Decoder" -> "dvlab-research/LISA" ["e"=1]
"microsoft/X-Decoder" -> "chongzhou96/MaskCLIP"
"microsoft/X-Decoder" -> "baaivision/EVA"
"mpezeshki/pytorch_forward_forward" -> "google-research/pix2seq" ["e"=1]
"ai-forever/Kandinsky-2" -> "deep-floyd/IF" ["e"=1]
"pharmapsychotic/clip-interrogator" -> "salesforce/BLIP" ["e"=1]
"pharmapsychotic/clip-interrogator" -> "rom1504/clip-retrieval" ["e"=1]
"pharmapsychotic/clip-interrogator" -> "mlfoundations/open_clip" ["e"=1]
"pharmapsychotic/clip-interrogator" -> "salesforce/LAVIS" ["e"=1]
"microsoft/torchscale" -> "OFA-Sys/OFA" ["e"=1]
"IDEA-Research/detrex" -> "IDEA-Research/awesome-detection-transformer"
"IDEA-Research/detrex" -> "IDEA-Research/DINO"
"IDEA-Research/detrex" -> "IDEA-Research/MaskDINO"
"IDEA-Research/detrex" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"IDEA-Research/detrex" -> "IDEA-Research/DN-DETR"
"IDEA-Research/detrex" -> "Sense-X/Co-DETR" ["e"=1]
"IDEA-Research/detrex" -> "IDEA-Research/DAB-DETR"
"IDEA-Research/detrex" -> "microsoft/GLIP"
"IDEA-Research/detrex" -> "lyuwenyu/RT-DETR"
"IDEA-Research/detrex" -> "OpenGVLab/InternImage"
"IDEA-Research/detrex" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/detrex" -> "ShoufaChen/DiffusionDet"
"IDEA-Research/detrex" -> "facebookresearch/Mask2Former"
"IDEA-Research/detrex" -> "baaivision/EVA"
"IDEA-Research/detrex" -> "Atten4Vis/ConditionalDETR"
"facebookresearch/CutLER" -> "NVlabs/ODISE" ["e"=1]
"facebookresearch/CutLER" -> "facebookresearch/Detic" ["e"=1]
"facebookresearch/CutLER" -> "IDEA-Research/MaskDINO" ["e"=1]
"facebookresearch/CutLER" -> "facebookresearch/Mask2Former" ["e"=1]
"facebookresearch/CutLER" -> "IDEA-Research/OpenSeeD" ["e"=1]
"facebookresearch/CutLER" -> "chongzhou96/MaskCLIP" ["e"=1]
"facebookresearch/CutLER" -> "microsoft/X-Decoder" ["e"=1]
"facebookresearch/CutLER" -> "ShoufaChen/DiffusionDet" ["e"=1]
"facebookresearch/CutLER" -> "SHI-Labs/OneFormer" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "mlfoundations/open_clip"
"OFA-Sys/Chinese-CLIP" -> "salesforce/LAVIS"
"OFA-Sys/Chinese-CLIP" -> "salesforce/BLIP"
"OFA-Sys/Chinese-CLIP" -> "IDEA-CCNL/Fengshenbang-LM" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "QwenLM/Qwen-VL" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "openai/CLIP" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "THUDM/VisualGLM-6B" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "modelscope/ms-swift" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "rom1504/clip-retrieval"
"OFA-Sys/Chinese-CLIP" -> "OpenGVLab/InternVL" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "IDEA-Research/GroundingDINO"
"OFA-Sys/Chinese-CLIP" -> "FlagOpen/FlagEmbedding" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "LianjiaTech/BELLE" ["e"=1]
"OFA-Sys/Chinese-CLIP" -> "OFA-Sys/OFA"
"Sense-X/Co-DETR" -> "IDEA-Research/DINO" ["e"=1]
"JunweiLiang/awesome_lists" -> "VainF/Awesome-Anything" ["e"=1]
"IDEA-Research/MaskDINO" -> "IDEA-Research/OpenSeeD"
"IDEA-Research/MaskDINO" -> "IDEA-Research/DINO"
"IDEA-Research/MaskDINO" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/MaskDINO" -> "facebookresearch/Mask2Former"
"IDEA-Research/MaskDINO" -> "IDEA-Research/detrex"
"IDEA-Research/MaskDINO" -> "IDEA-Research/awesome-detection-transformer"
"IDEA-Research/MaskDINO" -> "czczup/ViT-Adapter"
"IDEA-Research/MaskDINO" -> "IDEA-Research/DN-DETR"
"IDEA-Research/MaskDINO" -> "SHI-Labs/OneFormer"
"IDEA-Research/MaskDINO" -> "microsoft/X-Decoder"
"IDEA-Research/MaskDINO" -> "facebookresearch/MaskFormer"
"IDEA-Research/MaskDINO" -> "OpenGVLab/InternImage"
"IDEA-Research/MaskDINO" -> "IDEA-Research/DAB-DETR"
"IDEA-Research/MaskDINO" -> "Sense-X/Co-DETR" ["e"=1]
"IDEA-Research/MaskDINO" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"mmaaz60/EdgeNeXt" -> "mmaaz60/mvits_for_class_agnostic_od" ["e"=1]
"mmaaz60/EdgeNeXt" -> "hanoonaR/object-centric-ovd" ["e"=1]
"hanoonaR/object-centric-ovd" -> "mmaaz60/mvits_for_class_agnostic_od"
"hanoonaR/object-centric-ovd" -> "fcjian/PromptDet"
"hanoonaR/object-centric-ovd" -> "dyabel/detpro"
"hanoonaR/object-centric-ovd" -> "alirezazareian/ovr-cnn"
"hanoonaR/object-centric-ovd" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"hanoonaR/object-centric-ovd" -> "wusize/ovdet"
"hanoonaR/object-centric-ovd" -> "muzairkhattak/ViFi-CLIP" ["e"=1]
"hanoonaR/object-centric-ovd" -> "Muhammad-Huzaifaa/ObjectCompose" ["e"=1]
"hanoonaR/object-centric-ovd" -> "clin1223/VLDet"
"hanoonaR/object-centric-ovd" -> "tgxs002/CORA"
"hanoonaR/object-centric-ovd" -> "microsoft/RegionCLIP"
"hanoonaR/object-centric-ovd" -> "mbzuai-oryx/CVRR-Evaluation-Suite" ["e"=1]
"hanoonaR/object-centric-ovd" -> "asif-hanif/vafa" ["e"=1]
"hanoonaR/object-centric-ovd" -> "yuhangzang/OV-DETR"
"hanoonaR/object-centric-ovd" -> "mmaaz60/EdgeNeXt" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "hanoonaR/object-centric-ovd" ["e"=1]
"PaddlePaddle/FastDeploy" -> "CVHub520/X-AnyLabeling" ["e"=1]
"encord-team/encord-active" -> "encord-team/encord-client-python"
"encord-team/encord-active" -> "encord-team/text-to-image-eval"
"encord-team/encord-active" -> "encord-team/encord-notebooks"
"encord-team/encord-active" -> "voxel51/fiftyone-plugins"
"OpenGVLab/InternImage" -> "czczup/ViT-Adapter"
"OpenGVLab/InternImage" -> "baaivision/EVA"
"OpenGVLab/InternImage" -> "IDEA-Research/DINO"
"OpenGVLab/InternImage" -> "Sense-X/Co-DETR" ["e"=1]
"OpenGVLab/InternImage" -> "OpenGVLab/DCNv4" ["e"=1]
"OpenGVLab/InternImage" -> "IDEA-Research/detrex"
"OpenGVLab/InternImage" -> "IDEA-Research/MaskDINO"
"OpenGVLab/InternImage" -> "baaivision/Painter"
"OpenGVLab/InternImage" -> "UX-Decoder/Semantic-SAM"
"OpenGVLab/InternImage" -> "fundamentalvision/BEVFormer" ["e"=1]
"OpenGVLab/InternImage" -> "IDEA-Research/GroundingDINO"
"OpenGVLab/InternImage" -> "facebookresearch/Mask2Former"
"OpenGVLab/InternImage" -> "open-mmlab/mmsegmentation" ["e"=1]
"OpenGVLab/InternImage" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"OpenGVLab/InternImage" -> "SHI-Labs/OneFormer"
"amazon-science/auto-cot" -> "amazon-science/mm-cot" ["e"=1]
"billjie1/Chinese-CLIP" -> "DtYXs/Chinese-CLIP"
"billjie1/Chinese-CLIP" -> "yuxie11/R2D2"
"sail-sg/Adan" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"apple/ml-mobileone" -> "apple/ml-mobileclip" ["e"=1]
"hkchengrex/XMem" -> "hkchengrex/Tracking-Anything-with-DEVA" ["e"=1]
"hkchengrex/XMem" -> "z-x-yang/Segment-and-Track-Anything" ["e"=1]
"hkchengrex/XMem" -> "gaomingqi/Track-Anything" ["e"=1]
"hkchengrex/XMem" -> "qianqianwang68/omnimotion" ["e"=1]
"hkchengrex/XMem" -> "SysCV/sam-pt" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "microsoft/GLIP" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "mlfoundations/open_flamingo" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "VainF/Awesome-Anything" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "microsoft/X-Decoder" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "salesforce/LAVIS" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "baaivision/Painter" ["e"=1]
"kakaobrain/coyo-dataset" -> "kakaobrain/mindall-e" ["e"=1]
"kakaobrain/coyo-dataset" -> "rom1504/img2dataset"
"kakaobrain/coyo-dataset" -> "allenai/mmc4"
"kakaobrain/coyo-dataset" -> "kakaobrain/kogpt" ["e"=1]
"kakaobrain/coyo-dataset" -> "facebookresearch/SLIP"
"kakaobrain/coyo-dataset" -> "kakaobrain/karlo" ["e"=1]
"kakaobrain/coyo-dataset" -> "lucidrains/flamingo-pytorch"
"kakaobrain/coyo-dataset" -> "KLUE-benchmark/KLUE" ["e"=1]
"kakaobrain/coyo-dataset" -> "mlfoundations/datacomp"
"kakaobrain/coyo-dataset" -> "EleutherAI/polyglot" ["e"=1]
"kakaobrain/coyo-dataset" -> "jungwoo-ha/WeeklyArxivTalk" ["e"=1]
"kakaobrain/coyo-dataset" -> "FreddeFrallan/Multilingual-CLIP"
"kakaobrain/coyo-dataset" -> "microsoft/GLIP"
"kakaobrain/coyo-dataset" -> "kakaobrain/rq-vae-transformer" ["e"=1]
"kakaobrain/coyo-dataset" -> "OFA-Sys/OFA"
"KMnP/vpt" -> "microsoft/GLIP" ["e"=1]
"bumble-tech/private-detector" -> "FreddeFrallan/Multilingual-CLIP" ["e"=1]
"google-deepmind/tapnet" -> "qianqianwang68/omnimotion" ["e"=1]
"google-deepmind/tapnet" -> "facebookresearch/co-tracker" ["e"=1]
"google-deepmind/tapnet" -> "SysCV/sam-pt" ["e"=1]
"Chasel-Tsui/mmdet-rfla" -> "jshilong/DDQ" ["e"=1]
"JialianW/GRiT" -> "showlab/Image2Paragraph" ["e"=1]
"mosaicml/streaming" -> "webdataset/webdataset" ["e"=1]
"HDETR/H-Deformable-DETR" -> "IDEA-Research/DAB-DETR"
"HDETR/H-Deformable-DETR" -> "Atten4Vis/ConditionalDETR"
"HDETR/H-Deformable-DETR" -> "LeapLabTHU/Rank-DETR" ["e"=1]
"HDETR/H-Deformable-DETR" -> "IDEA-Research/DN-DETR"
"HDETR/H-Deformable-DETR" -> "IDEA-Research/Lite-DETR"
"HDETR/H-Deformable-DETR" -> "IDEA-Research/Stable-DINO"
"HDETR/H-Deformable-DETR" -> "HDETR/H-Deformable-DETR-mmdet"
"HDETR/H-Deformable-DETR" -> "ZhangGongjie/SAM-DETR"
"HDETR/H-Deformable-DETR" -> "jozhang97/DETA"
"HDETR/H-Deformable-DETR" -> "kakaobrain/sparse-detr"
"HDETR/H-Deformable-DETR" -> "megvii-research/AnchorDETR"
"HDETR/H-Deformable-DETR" -> "MCG-NJU/AdaMixer"
"HDETR/H-Deformable-DETR" -> "gaopengcuhk/SMCA-DETR"
"HDETR/H-Deformable-DETR" -> "Sense-X/Co-DETR" ["e"=1]
"HDETR/H-Deformable-DETR" -> "Fangyi-Chen/SQR"
"baaivision/EVA" -> "microsoft/GLIP"
"baaivision/EVA" -> "OpenGVLab/InternImage"
"baaivision/EVA" -> "baaivision/Emu" ["e"=1]
"baaivision/EVA" -> "baaivision/Painter"
"baaivision/EVA" -> "mlfoundations/open_clip"
"baaivision/EVA" -> "salesforce/LAVIS"
"baaivision/EVA" -> "IDEA-Research/DINO"
"baaivision/EVA" -> "IDEA-Research/GroundingDINO"
"baaivision/EVA" -> "czczup/ViT-Adapter"
"baaivision/EVA" -> "UX-Decoder/Semantic-SAM"
"baaivision/EVA" -> "dvlab-research/LISA" ["e"=1]
"baaivision/EVA" -> "mlfoundations/open_flamingo"
"baaivision/EVA" -> "salesforce/BLIP"
"baaivision/EVA" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"baaivision/EVA" -> "google-research/big_vision"
"jozhang97/DETA" -> "jshilong/DDQ"
"jozhang97/DETA" -> "impiga/Plain-DETR"
"jozhang97/DETA" -> "IDEA-Research/Lite-DETR"
"jozhang97/DETA" -> "MCG-NJU/AdaMixer"
"jozhang97/DETA" -> "HDETR/H-Deformable-DETR"
"jozhang97/DETA" -> "IDEA-Research/Stable-DINO"
"jozhang97/DETA" -> "HDETR/H-Deformable-DETR-mmdet"
"jozhang97/DETA" -> "Atten4Vis/ConditionalDETR"
"clin1223/VLDet" -> "wusize/ovdet"
"clin1223/VLDet" -> "CVMI-Lab/CoDet"
"clin1223/VLDet" -> "dyabel/detpro"
"clin1223/VLDet" -> "xiaofeng94/VL-PLM"
"clin1223/VLDet" -> "FoundationVision/GenerateU"
"clin1223/VLDet" -> "mengqiDyangge/HierKD"
"clin1223/VLDet" -> "LutingWang/OADP"
"clin1223/VLDet" -> "mala-lab/SIC-CADS"
"clin1223/VLDet" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"clin1223/VLDet" -> "Surrey-UP-Lab/RegionSpot"
"TommyZihao/MMSegmentation_Tutorials" -> "yatengLG/ISAT_with_segment_anything" ["e"=1]
"glotlabs/gdrive" -> "IDEA-Research/Grounded-SAM-2" ["e"=1]
"GitGyun/visual_token_matching" -> "ZiqinZhou66/ZegCLIP" ["e"=1]
"iejMac/video2dataset" -> "allenai/mmc4" ["e"=1]
"iejMac/video2dataset" -> "rom1504/img2dataset" ["e"=1]
"Visual-Attention-Network/SegNeXt" -> "NVlabs/SegFormer" ["e"=1]
"Visual-Attention-Network/SegNeXt" -> "facebookresearch/Mask2Former" ["e"=1]
"Visual-Attention-Network/SegNeXt" -> "czczup/ViT-Adapter" ["e"=1]
"facebookresearch/ToMe" -> "czczup/ViT-Adapter" ["e"=1]
"facebookresearch/ToMe" -> "baaivision/EVA" ["e"=1]
"facebookresearch/ToMe" -> "NVlabs/GroupViT" ["e"=1]
"linyq2117/CLIP-ES" -> "xmed-lab/CLIP_Surgery" ["e"=1]
"linyq2117/CLIP-ES" -> "ZiqinZhou66/ZegCLIP" ["e"=1]
"mlfoundations/task_vectors" -> "mlfoundations/wise-ft" ["e"=1]
"moein-shariatnia/Pix2Seq" -> "gaopengcuhk/Stable-Pix2Seq"
"kakaobrain/karlo" -> "kakaobrain/coyo-dataset" ["e"=1]
"gaasher/I-JEPA" -> "LumenPallidium/jepa"
"gaasher/I-JEPA" -> "facebookresearch/ijepa"
"aharley/pips" -> "qianqianwang68/omnimotion" ["e"=1]
"aharley/pips" -> "SysCV/sam-pt" ["e"=1]
"aharley/pips" -> "facebookresearch/co-tracker" ["e"=1]
"kohjingyu/fromage" -> "kohjingyu/gill" ["e"=1]
"kohjingyu/fromage" -> "allenai/mmc4"
"kohjingyu/fromage" -> "Vision-CAIR/ChatCaptioner"
"kohjingyu/fromage" -> "om-ai-lab/VL-CheckList" ["e"=1]
"kohjingyu/fromage" -> "facebookresearch/diht"
"kohjingyu/fromage" -> "AILab-CVC/SEED" ["e"=1]
"kohjingyu/fromage" -> "ABaldrati/CLIP4Cir" ["e"=1]
"kohjingyu/fromage" -> "miccunifi/SEARLE" ["e"=1]
"facebookresearch/ConvNeXt-V2" -> "baaivision/EVA" ["e"=1]
"facebookresearch/ConvNeXt-V2" -> "OpenGVLab/InternImage" ["e"=1]
"facebookresearch/ConvNeXt-V2" -> "facebookresearch/Mask2Former" ["e"=1]
"facebookresearch/ConvNeXt-V2" -> "czczup/ViT-Adapter" ["e"=1]
"orrzohar/PROB" -> "orrzohar/FOMO"
"orrzohar/PROB" -> "akshitac8/OW-DETR"
"orrzohar/PROB" -> "frh23333/mepu-owod"
"orrzohar/PROB" -> "Went-Liang/UnSniffer"
"orrzohar/PROB" -> "DIG-Beihang/ALLOW"
"orrzohar/PROB" -> "feifeiobama/OrthogonalDet"
"orrzohar/PROB" -> "orrzohar/LOVM"
"orrzohar/PROB" -> "scuwyh2000/RandBox"
"lxn96/ICPE" -> "Ybowei/UNP" ["e"=1]
"krea-ai/open-prompts" -> "kakaobrain/coyo-dataset" ["e"=1]
"happy-hsy/MotionMAE" -> "happy-hsy/BCNet"
"happy-hsy/MotionMAE" -> "Surrey-UP-Lab/GS-LPM"
"khanrc/tcl" -> "kakaobrain/noc"
"facebookresearch/paco" -> "TACJu/PartImageNet"
"facebookresearch/paco" -> "facebookresearch/diht"
"facebookresearch/paco" -> "facebookresearch/VLPart"
"open-mmlab/mmeval" -> "jshilong/DDQ" ["e"=1]
"UCSC-VLAA/RobustCNN" -> "UCSC-VLAA/Image-Pretraining-for-Video"
"UCSC-VLAA/RobustCNN" -> "ytongbai/ViTs-vs-CNNs"
"HuKai97/detr-annotations" -> "HuKai97/deformable-detr-annotations"
"voxel51/fiftyone-plugins" -> "voxel51/papers-with-data"
"voxel51/fiftyone-plugins" -> "jacobmarks/ten-weeks-of-plugins"
"voxel51/fiftyone-plugins" -> "voxel51/fiftyone-brain"
"voxel51/fiftyone-plugins" -> "jacobmarks/zero-shot-prediction-plugin"
"voxel51/fiftyone-plugins" -> "voxel51/fiftyone-examples"
"voxel51/fiftyone-plugins" -> "allenleetc/model-comparison"
"voxel51/fiftyone-plugins" -> "voxel51/eta"
"voxel51/fiftyone-plugins" -> "jacobmarks/text-to-image"
"whwu95/Cap4Video" -> "YoadTew/zero-shot-video-to-text" ["e"=1]
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/Topical-Influence"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/BlackHole"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/PAS"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/TRAP"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/LetsPic-DL"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/MTA"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/revisit"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/FL-Sim"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/BioNER"
"kaist-dmlab/k-Medoid" -> "kaist-dmlab/RecencyBias"
"HuKai97/deformable-detr-annotations" -> "HuKai97/detr-annotations"
"vadimtimakin/end2end-HKR-research" -> "t0efL/2nd-place-solution-Digital-Peter"
"vadimtimakin/end2end-HKR-research" -> "radmirkaz/MCS2022-Top-2-solution"
"kaist-dmlab/MQNet" -> "kaist-dmlab/TCLP"
"kaist-dmlab/MQNet" -> "kaist-dmlab/CrossMatch"
"kaist-dmlab/MQNet" -> "kaist-dmlab/RECURVE"
"facebookresearch/diht" -> "facebookresearch/CiT"
"kakaobrain/noc" -> "khanrc/tcl"
"LutingWang/OADP" -> "wusize/ovdet"
"DeevsTheBest/TenderHack" -> "radmirkaz/MCS2022-Top-2-solution"
"binyisu/FSOSOD" -> "TMIU/iTFA"
"facebookresearch/ImageBind" -> "salesforce/LAVIS"
"facebookresearch/ImageBind" -> "facebookresearch/dinov2"
"facebookresearch/ImageBind" -> "IDEA-Research/Grounded-Segment-Anything"
"facebookresearch/ImageBind" -> "haotian-liu/LLaVA" ["e"=1]
"facebookresearch/ImageBind" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"facebookresearch/ImageBind" -> "Vision-CAIR/MiniGPT-4" ["e"=1]
"facebookresearch/ImageBind" -> "mlfoundations/open_clip"
"facebookresearch/ImageBind" -> "openai/consistency_models" ["e"=1]
"facebookresearch/ImageBind" -> "mlfoundations/open_flamingo"
"facebookresearch/ImageBind" -> "BradyFU/Awesome-Multimodal-Large-Language-Models" ["e"=1]
"facebookresearch/ImageBind" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"facebookresearch/ImageBind" -> "deep-floyd/IF"
"facebookresearch/ImageBind" -> "facebookresearch/segment-anything" ["e"=1]
"facebookresearch/ImageBind" -> "microsoft/unilm" ["e"=1]
"facebookresearch/ImageBind" -> "DAMO-NLP-SG/Video-LLaMA" ["e"=1]
"facebookresearch/segment-anything" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"facebookresearch/segment-anything" -> "facebookresearch/sam2" ["e"=1]
"facebookresearch/segment-anything" -> "facebookresearch/dinov2" ["e"=1]
"maxi-w/CLIP-SAM" -> "Usama3059/SAMtext"
"maxi-w/CLIP-SAM" -> "xmed-lab/CLIP_Surgery"
"maxi-w/CLIP-SAM" -> "ZhenZHAO/AugSeg" ["e"=1]
"maxi-w/CLIP-SAM" -> "PengtaoJiang/Segment-Anything-CLIP"
"maxi-w/CLIP-SAM" -> "RockeyCoss/Prompt-Segment-Anything"
"maxi-w/CLIP-SAM" -> "chongzhou96/MaskCLIP"
"maxi-w/CLIP-SAM" -> "Curt-Park/segment-anything-with-clip"
"maxi-w/CLIP-SAM" -> "MaybeShewill-CV/segment-anything-u-specify"
"maxi-w/CLIP-SAM" -> "HiLab-git/DTC" ["e"=1]
"IDEA-Research/Grounded-Segment-Anything" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/Grounded-Segment-Anything" -> "facebookresearch/segment-anything" ["e"=1]
"IDEA-Research/Grounded-Segment-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"IDEA-Research/Grounded-Segment-Anything" -> "facebookresearch/dinov2"
"IDEA-Research/Grounded-Segment-Anything" -> "facebookresearch/sam2"
"IDEA-Research/Grounded-Segment-Anything" -> "CASIA-IVA-Lab/FastSAM"
"IDEA-Research/Grounded-Segment-Anything" -> "haotian-liu/LLaVA" ["e"=1]
"IDEA-Research/Grounded-Segment-Anything" -> "salesforce/LAVIS"
"IDEA-Research/Grounded-Segment-Anything" -> "openai/CLIP" ["e"=1]
"IDEA-Research/Grounded-Segment-Anything" -> "geekyutao/Inpaint-Anything"
"IDEA-Research/Grounded-Segment-Anything" -> "lllyasviel/ControlNet" ["e"=1]
"IDEA-Research/Grounded-Segment-Anything" -> "mlfoundations/open_clip"
"IDEA-Research/Grounded-Segment-Anything" -> "SysCV/sam-hq"
"IDEA-Research/Grounded-Segment-Anything" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/Grounded-Segment-Anything" -> "huggingface/diffusers" ["e"=1]
"MiscellaneousStuff/meta-sam-demo" -> "haibingtown/segment-matting"
"MiscellaneousStuff/meta-sam-demo" -> "lujiazho/SegDrawer"
"MiscellaneousStuff/meta-sam-demo" -> "MizzleAa/segment-anything-demo-react-fastapi"
"Anything-of-anything/Anything-3D" -> "VainF/Awesome-Anything" ["e"=1]
"UX-Decoder/Semantic-SAM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"UX-Decoder/Semantic-SAM" -> "fudan-zvg/Semantic-Segment-Anything"
"UX-Decoder/Semantic-SAM" -> "SysCV/sam-hq"
"UX-Decoder/Semantic-SAM" -> "IDEA-Research/MaskDINO"
"UX-Decoder/Semantic-SAM" -> "IDEA-Research/OpenSeeD"
"UX-Decoder/Semantic-SAM" -> "IDEA-Research/GroundingDINO"
"UX-Decoder/Semantic-SAM" -> "IDEA-Research/Grounded-Segment-Anything"
"UX-Decoder/Semantic-SAM" -> "tianrun-chen/SAM-Adapter-PyTorch"
"UX-Decoder/Semantic-SAM" -> "ZrrSkywalker/Personalize-SAM"
"UX-Decoder/Semantic-SAM" -> "CASIA-IVA-Lab/FastSAM"
"UX-Decoder/Semantic-SAM" -> "xinyu1205/recognize-anything"
"UX-Decoder/Semantic-SAM" -> "ChaoningZhang/MobileSAM"
"UX-Decoder/Semantic-SAM" -> "facebookresearch/Mask2Former"
"UX-Decoder/Semantic-SAM" -> "dvlab-research/LISA" ["e"=1]
"UX-Decoder/Semantic-SAM" -> "yformer/EfficientSAM"
"unum-cloud/uform" -> "rom1504/clip-retrieval" ["e"=1]
"unum-cloud/uform" -> "microsoft/X-Decoder" ["e"=1]
"huawei-noah/VanillaNet" -> "OpenGVLab/InternImage" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "mlfoundations/open_flamingo" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "salesforce/LAVIS" ["e"=1]
"Vision-CAIR/MiniGPT-4" -> "salesforce/LAVIS" ["e"=1]
"IDEA-Research/GroundingDINO" -> "IDEA-Research/Grounded-Segment-Anything"
"IDEA-Research/GroundingDINO" -> "facebookresearch/dinov2"
"IDEA-Research/GroundingDINO" -> "AILab-CVC/YOLO-World"
"IDEA-Research/GroundingDINO" -> "microsoft/GLIP"
"IDEA-Research/GroundingDINO" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"IDEA-Research/GroundingDINO" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/GroundingDINO" -> "facebookresearch/sam2"
"IDEA-Research/GroundingDINO" -> "IDEA-Research/Grounded-SAM-2"
"IDEA-Research/GroundingDINO" -> "IDEA-Research/DINO"
"IDEA-Research/GroundingDINO" -> "salesforce/LAVIS"
"IDEA-Research/GroundingDINO" -> "mlfoundations/open_clip"
"IDEA-Research/GroundingDINO" -> "haotian-liu/LLaVA" ["e"=1]
"IDEA-Research/GroundingDINO" -> "facebookresearch/segment-anything" ["e"=1]
"IDEA-Research/GroundingDINO" -> "xinyu1205/recognize-anything"
"IDEA-Research/GroundingDINO" -> "CASIA-IVA-Lab/FastSAM"
"haotian-liu/LLaVA" -> "salesforce/LAVIS" ["e"=1]
"haotian-liu/LLaVA" -> "mlfoundations/open_clip" ["e"=1]
"haotian-liu/LLaVA" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "mlfoundations/open_flamingo" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "microsoft/X-Decoder" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "open-mmlab/playground" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "baaivision/Painter" ["e"=1]
"spotify/voyager" -> "criteo/autofaiss" ["e"=1]
"shyamsn97/mario-gpt" -> "amazon-science/mm-cot" ["e"=1]
"qianqianwang68/omnimotion" -> "google-deepmind/tapnet" ["e"=1]
"qianqianwang68/omnimotion" -> "facebookresearch/co-tracker"
"qianqianwang68/omnimotion" -> "JonathonLuiten/Dynamic3DGaussians" ["e"=1]
"qianqianwang68/omnimotion" -> "henry123-boy/SpaTracker" ["e"=1]
"qianqianwang68/omnimotion" -> "z-x-yang/Segment-and-Track-Anything"
"qianqianwang68/omnimotion" -> "gaomingqi/Track-Anything"
"qianqianwang68/omnimotion" -> "vye16/shape-of-motion" ["e"=1]
"qianqianwang68/omnimotion" -> "google/dynibar" ["e"=1]
"qianqianwang68/omnimotion" -> "princeton-vl/RAFT" ["e"=1]
"qianqianwang68/omnimotion" -> "hkchengrex/Tracking-Anything-with-DEVA"
"qianqianwang68/omnimotion" -> "hkchengrex/XMem" ["e"=1]
"qianqianwang68/omnimotion" -> "naver/dust3r" ["e"=1]
"qianqianwang68/omnimotion" -> "cvg/LightGlue" ["e"=1]
"qianqianwang68/omnimotion" -> "prs-eth/Marigold" ["e"=1]
"qianqianwang68/omnimotion" -> "autonomousvision/unimatch" ["e"=1]
"openai/consistency_models" -> "deep-floyd/IF" ["e"=1]
"openai/consistency_models" -> "facebookresearch/dinov2" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "SuperMedIntel/Medical-SAM-Adapter" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "ziqi-jin/finetune-anything"
"tianrun-chen/SAM-Adapter-PyTorch" -> "luca-medeiros/lightning-sam"
"tianrun-chen/SAM-Adapter-PyTorch" -> "hitachinsk/SAMed" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "ZrrSkywalker/Personalize-SAM"
"tianrun-chen/SAM-Adapter-PyTorch" -> "UX-Decoder/Semantic-SAM"
"tianrun-chen/SAM-Adapter-PyTorch" -> "liliu-avril/Awesome-Segment-Anything"
"tianrun-chen/SAM-Adapter-PyTorch" -> "KyanChen/RSPrompter" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "SysCV/sam-hq"
"tianrun-chen/SAM-Adapter-PyTorch" -> "fudan-zvg/Semantic-Segment-Anything"
"tianrun-chen/SAM-Adapter-PyTorch" -> "bowang-lab/MedSAM" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "OpenGVLab/SAM-Med2D" ["e"=1]
"tianrun-chen/SAM-Adapter-PyTorch" -> "baaivision/Painter"
"tianrun-chen/SAM-Adapter-PyTorch" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"tianrun-chen/SAM-Adapter-PyTorch" -> "Hedlen/awesome-segment-anything"
"AIGC-Audio/AudioGPT" -> "deep-floyd/IF" ["e"=1]
"AIGC-Audio/AudioGPT" -> "gaomingqi/Track-Anything" ["e"=1]
"Stability-AI/StableStudio" -> "deep-floyd/IF" ["e"=1]
"geekyutao/Inpaint-Anything" -> "advimman/lama" ["e"=1]
"geekyutao/Inpaint-Anything" -> "IDEA-Research/Grounded-Segment-Anything"
"geekyutao/Inpaint-Anything" -> "gaomingqi/Track-Anything"
"geekyutao/Inpaint-Anything" -> "sail-sg/EditAnything"
"geekyutao/Inpaint-Anything" -> "tencent-ailab/IP-Adapter" ["e"=1]
"geekyutao/Inpaint-Anything" -> "guoyww/AnimateDiff" ["e"=1]
"geekyutao/Inpaint-Anything" -> "IDEA-Research/GroundingDINO"
"geekyutao/Inpaint-Anything" -> "continue-revolution/sd-webui-segment-anything" ["e"=1]
"geekyutao/Inpaint-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"geekyutao/Inpaint-Anything" -> "CASIA-IVA-Lab/FastSAM"
"geekyutao/Inpaint-Anything" -> "facebookresearch/dinov2"
"geekyutao/Inpaint-Anything" -> "Sanster/IOPaint" ["e"=1]
"geekyutao/Inpaint-Anything" -> "facebookresearch/segment-anything" ["e"=1]
"geekyutao/Inpaint-Anything" -> "SysCV/sam-hq"
"geekyutao/Inpaint-Anything" -> "lllyasviel/ControlNet" ["e"=1]
"openai/shap-e" -> "deep-floyd/IF" ["e"=1]
"openai/shap-e" -> "facebookresearch/ImageBind" ["e"=1]
"openai/shap-e" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"luca-medeiros/lang-segment-anything" -> "IDEA-Research/GroundingDINO"
"luca-medeiros/lang-segment-anything" -> "UX-Decoder/Semantic-SAM"
"luca-medeiros/lang-segment-anything" -> "IDEA-Research/Grounded-Segment-Anything"
"luca-medeiros/lang-segment-anything" -> "IDEA-Research/Grounded-SAM-2"
"luca-medeiros/lang-segment-anything" -> "luca-medeiros/lightning-sam"
"luca-medeiros/lang-segment-anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"luca-medeiros/lang-segment-anything" -> "SysCV/sam-hq"
"luca-medeiros/lang-segment-anything" -> "fudan-zvg/Semantic-Segment-Anything"
"luca-medeiros/lang-segment-anything" -> "facebookresearch/sam2"
"luca-medeiros/lang-segment-anything" -> "ChaoningZhang/MobileSAM"
"luca-medeiros/lang-segment-anything" -> "CASIA-IVA-Lab/FastSAM"
"luca-medeiros/lang-segment-anything" -> "tianrun-chen/SAM-Adapter-PyTorch"
"luca-medeiros/lang-segment-anything" -> "ZrrSkywalker/Personalize-SAM"
"luca-medeiros/lang-segment-anything" -> "Hedlen/awesome-segment-anything"
"luca-medeiros/lang-segment-anything" -> "yformer/EfficientSAM"
"z-x-yang/Segment-and-Track-Anything" -> "gaomingqi/Track-Anything"
"z-x-yang/Segment-and-Track-Anything" -> "yoxu515/aot-benchmark" ["e"=1]
"z-x-yang/Segment-and-Track-Anything" -> "hkchengrex/XMem" ["e"=1]
"z-x-yang/Segment-and-Track-Anything" -> "hkchengrex/Tracking-Anything-with-DEVA"
"z-x-yang/Segment-and-Track-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"z-x-yang/Segment-and-Track-Anything" -> "qianqianwang68/omnimotion"
"z-x-yang/Segment-and-Track-Anything" -> "kadirnar/segment-anything-video"
"z-x-yang/Segment-and-Track-Anything" -> "IDEA-Research/Grounded-Segment-Anything"
"z-x-yang/Segment-and-Track-Anything" -> "UX-Decoder/Semantic-SAM"
"z-x-yang/Segment-and-Track-Anything" -> "IDEA-Research/GroundingDINO"
"z-x-yang/Segment-and-Track-Anything" -> "CASIA-IVA-Lab/FastSAM"
"z-x-yang/Segment-and-Track-Anything" -> "SysCV/sam-pt"
"z-x-yang/Segment-and-Track-Anything" -> "SysCV/sam-hq"
"z-x-yang/Segment-and-Track-Anything" -> "fudan-zvg/Semantic-Segment-Anything"
"z-x-yang/Segment-and-Track-Anything" -> "facebookresearch/co-tracker"
"hkchengrex/Tracking-Anything-with-DEVA" -> "hkchengrex/Cutie" ["e"=1]
"hkchengrex/Tracking-Anything-with-DEVA" -> "hkchengrex/XMem" ["e"=1]
"hkchengrex/Tracking-Anything-with-DEVA" -> "z-x-yang/Segment-and-Track-Anything"
"hkchengrex/Tracking-Anything-with-DEVA" -> "SysCV/sam-pt"
"hkchengrex/Tracking-Anything-with-DEVA" -> "lkeab/gaussian-grouping" ["e"=1]
"hkchengrex/Tracking-Anything-with-DEVA" -> "gaomingqi/Track-Anything"
"hkchengrex/Tracking-Anything-with-DEVA" -> "siyuanliii/masa"
"hkchengrex/Tracking-Anything-with-DEVA" -> "qianqianwang68/omnimotion"
"hkchengrex/Tracking-Anything-with-DEVA" -> "UX-Decoder/Semantic-SAM"
"hkchengrex/Tracking-Anything-with-DEVA" -> "SysCV/sam-hq"
"hkchengrex/Tracking-Anything-with-DEVA" -> "jiawen-zhu/HQTrack"
"hkchengrex/Tracking-Anything-with-DEVA" -> "FoundationVision/GLEE"
"hkchengrex/Tracking-Anything-with-DEVA" -> "mbzuai-metaverse/XMem2" ["e"=1]
"hkchengrex/Tracking-Anything-with-DEVA" -> "google-deepmind/tapnet" ["e"=1]
"hkchengrex/Tracking-Anything-with-DEVA" -> "facebookresearch/co-tracker"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "jianzongwu/Awesome-Open-Vocabulary"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "MendelXu/SAN"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "xb534/SED"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "wangf3014/SCLIP"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "xmed-lab/CLIP_Surgery"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "bytedance/fc-clip"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers" ["e"=1]
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "chongzhou96/MaskCLIP"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "HarborYuan/ovsam"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "wusize/CLIPSelf"
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" -> "facebookresearch/ov-seg"
"CASIA-IVA-Lab/FastSAM" -> "ChaoningZhang/MobileSAM"
"CASIA-IVA-Lab/FastSAM" -> "IDEA-Research/Grounded-Segment-Anything"
"CASIA-IVA-Lab/FastSAM" -> "SysCV/sam-hq"
"CASIA-IVA-Lab/FastSAM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"CASIA-IVA-Lab/FastSAM" -> "UX-Decoder/Semantic-SAM"
"CASIA-IVA-Lab/FastSAM" -> "IDEA-Research/GroundingDINO"
"CASIA-IVA-Lab/FastSAM" -> "facebookresearch/segment-anything" ["e"=1]
"CASIA-IVA-Lab/FastSAM" -> "facebookresearch/dinov2"
"CASIA-IVA-Lab/FastSAM" -> "facebookresearch/sam2"
"CASIA-IVA-Lab/FastSAM" -> "gaomingqi/Track-Anything"
"CASIA-IVA-Lab/FastSAM" -> "z-x-yang/Segment-and-Track-Anything"
"CASIA-IVA-Lab/FastSAM" -> "geekyutao/Inpaint-Anything"
"CASIA-IVA-Lab/FastSAM" -> "fudan-zvg/Semantic-Segment-Anything"
"CASIA-IVA-Lab/FastSAM" -> "LiheYoung/Depth-Anything" ["e"=1]
"CASIA-IVA-Lab/FastSAM" -> "yformer/EfficientSAM"
"ChaoningZhang/MobileSAM" -> "CASIA-IVA-Lab/FastSAM"
"ChaoningZhang/MobileSAM" -> "SysCV/sam-hq"
"ChaoningZhang/MobileSAM" -> "IDEA-Research/Grounded-Segment-Anything"
"ChaoningZhang/MobileSAM" -> "UX-Decoder/Semantic-SAM"
"ChaoningZhang/MobileSAM" -> "yformer/EfficientSAM"
"ChaoningZhang/MobileSAM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"ChaoningZhang/MobileSAM" -> "IDEA-Research/GroundingDINO"
"ChaoningZhang/MobileSAM" -> "facebookresearch/sam2"
"ChaoningZhang/MobileSAM" -> "mit-han-lab/efficientvit"
"ChaoningZhang/MobileSAM" -> "facebookresearch/dinov2"
"ChaoningZhang/MobileSAM" -> "z-x-yang/Segment-and-Track-Anything"
"ChaoningZhang/MobileSAM" -> "ZrrSkywalker/Personalize-SAM"
"ChaoningZhang/MobileSAM" -> "vietanhdev/anylabeling"
"ChaoningZhang/MobileSAM" -> "AILab-CVC/YOLO-World"
"ChaoningZhang/MobileSAM" -> "fudan-zvg/Semantic-Segment-Anything"
"THU-MIG/RepViT" -> "chongzhou96/EdgeSAM" ["e"=1]
"THU-MIG/RepViT" -> "mit-han-lab/efficientvit" ["e"=1]
"THU-MIG/RepViT" -> "lyuwenyu/RT-DETR" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "salesforce/LAVIS" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "mlfoundations/open_clip" ["e"=1]
"run-llama/chat-llamaindex" -> "run-llama/create_llama_projects" ["e"=1]
"yaoyao-liu/CL-DETR" -> "Hi-FT/ERD"
"yaoyao-liu/CL-DETR" -> "CanPeng123/Faster-ILOD"
"yaoyao-liu/CL-DETR" -> "YuyangSunshine/ABR_IOD"
"yaoyao-liu/CL-DETR" -> "chuxiuhong/DualTeacher"
"yaoyao-liu/CL-DETR" -> "CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation"
"CVHub520/X-AnyLabeling" -> "vietanhdev/anylabeling"
"CVHub520/X-AnyLabeling" -> "THU-MIG/yolov10"
"CVHub520/X-AnyLabeling" -> "AILab-CVC/YOLO-World"
"CVHub520/X-AnyLabeling" -> "lyuwenyu/RT-DETR"
"CVHub520/X-AnyLabeling" -> "yatengLG/ISAT_with_segment_anything"
"CVHub520/X-AnyLabeling" -> "wang-xinyu/tensorrtx" ["e"=1]
"CVHub520/X-AnyLabeling" -> "IDEA-Research/GroundingDINO"
"CVHub520/X-AnyLabeling" -> "WongKinYiu/yolov9"
"CVHub520/X-AnyLabeling" -> "IDEA-Research/Grounded-Segment-Anything"
"CVHub520/X-AnyLabeling" -> "ultralytics/ultralytics" ["e"=1]
"CVHub520/X-AnyLabeling" -> "mikel-brostrom/boxmot" ["e"=1]
"CVHub520/X-AnyLabeling" -> "obss/sahi" ["e"=1]
"CVHub520/X-AnyLabeling" -> "IDEA-Research/T-Rex"
"CVHub520/X-AnyLabeling" -> "shouxieai/tensorRT_Pro" ["e"=1]
"CVHub520/X-AnyLabeling" -> "CASIA-IVA-Lab/FastSAM"
"YavorGIvanov/sam.cpp" -> "dinglufe/segment-anything-cpp-wrapper" ["e"=1]
"YavorGIvanov/sam.cpp" -> "chongzhou96/EdgeSAM" ["e"=1]
"OpenGVLab/InternGPT" -> "facebookresearch/ImageBind" ["e"=1]
"OpenGVLab/InternGPT" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/InternGPT" -> "mlfoundations/open_flamingo" ["e"=1]
"OpenGVLab/InternGPT" -> "xinyu1205/recognize-anything" ["e"=1]
"OpenGVLab/InternGPT" -> "OpenGVLab/InternImage" ["e"=1]
"OpenGVLab/InternGPT" -> "baaivision/EVA" ["e"=1]
"OpenGVLab/DragGAN" -> "deep-floyd/IF" ["e"=1]
"OpenGVLab/DragGAN" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"OpenGVLab/DragGAN" -> "CASIA-IVA-Lab/FastSAM" ["e"=1]
"dvlab-research/LISA" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"dvlab-research/LISA" -> "microsoft/GLIP" ["e"=1]
"dvlab-research/LISA" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["e"=1]
"dvlab-research/LISA" -> "facebookresearch/Mask2Former" ["e"=1]
"dvlab-research/LISA" -> "baaivision/Painter" ["e"=1]
"dvlab-research/LISA" -> "baaivision/EVA" ["e"=1]
"dvlab-research/LISA" -> "NVlabs/ODISE" ["e"=1]
"microsoft/MM-REACT" -> "mlfoundations/open_flamingo" ["e"=1]
"microsoft/MM-REACT" -> "allenai/mmc4" ["e"=1]
"microsoft/MM-REACT" -> "microsoft/X-Decoder" ["e"=1]
"allenai/visprog" -> "cvlab-columbia/viper" ["e"=1]
"allenai/visprog" -> "NVlabs/ODISE" ["e"=1]
"allenai/visprog" -> "microsoft/X-Decoder" ["e"=1]
"allenai/visprog" -> "Vision-CAIR/ChatCaptioner" ["e"=1]
"Stability-AI/StableLM" -> "deep-floyd/IF" ["e"=1]
"Shiriluz/Word-As-Image" -> "NVlabs/prismer" ["e"=1]
"OpenGVLab/SAM-Med2D" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"lyuwenyu/RT-DETR" -> "Peterande/D-FINE"
"lyuwenyu/RT-DETR" -> "AILab-CVC/YOLO-World"
"lyuwenyu/RT-DETR" -> "ShihuaHuang95/DEIM"
"lyuwenyu/RT-DETR" -> "fundamentalvision/Deformable-DETR" ["e"=1]
"lyuwenyu/RT-DETR" -> "IDEA-Research/DINO"
"lyuwenyu/RT-DETR" -> "WongKinYiu/yolov9"
"lyuwenyu/RT-DETR" -> "facebookresearch/detr" ["e"=1]
"lyuwenyu/RT-DETR" -> "Sense-X/Co-DETR" ["e"=1]
"lyuwenyu/RT-DETR" -> "THU-MIG/yolov10"
"lyuwenyu/RT-DETR" -> "IDEA-Research/detrex"
"lyuwenyu/RT-DETR" -> "z1069614715/objectdetection_script" ["e"=1]
"lyuwenyu/RT-DETR" -> "CVHub520/X-AnyLabeling"
"lyuwenyu/RT-DETR" -> "IDEA-Research/GroundingDINO"
"lyuwenyu/RT-DETR" -> "sunsmarterjie/yolov12"
"lyuwenyu/RT-DETR" -> "open-mmlab/mmyolo" ["e"=1]
"baaivision/Emu" -> "baaivision/EVA" ["e"=1]
"baaivision/Emu" -> "mlfoundations/open_flamingo" ["e"=1]
"baaivision/Emu" -> "allenai/mmc4" ["e"=1]
"baaivision/Emu" -> "baaivision/Painter" ["e"=1]
"sail-sg/EditAnything" -> "geekyutao/Inpaint-Anything"
"sail-sg/EditAnything" -> "continue-revolution/sd-webui-segment-anything" ["e"=1]
"sail-sg/EditAnything" -> "IDEA-Research/Grounded-Segment-Anything"
"sail-sg/EditAnything" -> "TencentARC/T2I-Adapter" ["e"=1]
"sail-sg/EditAnything" -> "tencent-ailab/IP-Adapter" ["e"=1]
"sail-sg/EditAnything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"sail-sg/EditAnything" -> "VainF/Awesome-Anything"
"sail-sg/EditAnything" -> "SysCV/sam-hq"
"sail-sg/EditAnything" -> "PixArt-alpha/PixArt-alpha" ["e"=1]
"sail-sg/EditAnything" -> "lllyasviel/ControlNet-v1-1-nightly" ["e"=1]
"sail-sg/EditAnything" -> "AILab-CVC/VideoCrafter" ["e"=1]
"sail-sg/EditAnything" -> "Picsart-AI-Research/Text2Video-Zero" ["e"=1]
"sail-sg/EditAnything" -> "ali-vilab/AnyDoor" ["e"=1]
"sail-sg/EditAnything" -> "deep-floyd/IF"
"sail-sg/EditAnything" -> "kohya-ss/sd-scripts" ["e"=1]
"facebookresearch/Pearl" -> "facebookresearch/jepa" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "mlfoundations/open_flamingo" ["e"=1]
"yatengLG/ISAT_with_segment_anything" -> "CVHub520/X-AnyLabeling"
"yatengLG/ISAT_with_segment_anything" -> "vietanhdev/anylabeling"
"yatengLG/ISAT_with_segment_anything" -> "anuragxel/salt"
"yatengLG/ISAT_with_segment_anything" -> "SysCV/sam-hq"
"yatengLG/ISAT_with_segment_anything" -> "UX-Decoder/Semantic-SAM"
"yatengLG/ISAT_with_segment_anything" -> "ChaoningZhang/MobileSAM"
"yatengLG/ISAT_with_segment_anything" -> "open-mmlab/playground"
"yatengLG/ISAT_with_segment_anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"yatengLG/ISAT_with_segment_anything" -> "yformer/EfficientSAM"
"yatengLG/ISAT_with_segment_anything" -> "triple-Mu/YOLOv8-TensorRT" ["e"=1]
"yatengLG/ISAT_with_segment_anything" -> "ziqi-jin/finetune-anything"
"yatengLG/ISAT_with_segment_anything" -> "shouxieai/tensorRT_Pro" ["e"=1]
"yatengLG/ISAT_with_segment_anything" -> "fudan-zvg/Semantic-Segment-Anything"
"yatengLG/ISAT_with_segment_anything" -> "FeiYull/TensorRT-Alpha" ["e"=1]
"yatengLG/ISAT_with_segment_anything" -> "haochenheheda/segment-anything-annotator"
"OpenGVLab/LLaMA-Adapter" -> "mlfoundations/open_flamingo" ["e"=1]
"OpenGVLab/LLaMA-Adapter" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/LLaMA-Adapter" -> "facebookresearch/ImageBind" ["e"=1]
"pipeless-ai/pipeless" -> "jiawen-zhu/HQTrack" ["e"=1]
"zhouayi/SAM-Tool" -> "anuragxel/salt"
"zhouayi/SAM-Tool" -> "haochenheheda/segment-anything-annotator"
"zhouayi/SAM-Tool" -> "open-mmlab/playground"
"zhouayi/SAM-Tool" -> "George-Hotz/yolov8_seg_tensorRT"
"AILab-CVC/GPT4Tools" -> "allenai/mmc4" ["e"=1]
"facebookresearch/co-tracker" -> "google-deepmind/tapnet" ["e"=1]
"facebookresearch/co-tracker" -> "qianqianwang68/omnimotion"
"facebookresearch/co-tracker" -> "henry123-boy/SpaTracker" ["e"=1]
"facebookresearch/co-tracker" -> "naver/mast3r" ["e"=1]
"facebookresearch/co-tracker" -> "naver/dust3r" ["e"=1]
"facebookresearch/co-tracker" -> "gaomingqi/Track-Anything"
"facebookresearch/co-tracker" -> "z-x-yang/Segment-and-Track-Anything"
"facebookresearch/co-tracker" -> "facebookresearch/vggsfm" ["e"=1]
"facebookresearch/co-tracker" -> "facebookresearch/sam2"
"facebookresearch/co-tracker" -> "Junyi42/monst3r" ["e"=1]
"facebookresearch/co-tracker" -> "cvg/LightGlue" ["e"=1]
"facebookresearch/co-tracker" -> "prs-eth/Marigold" ["e"=1]
"facebookresearch/co-tracker" -> "facebookresearch/dinov2"
"facebookresearch/co-tracker" -> "LiheYoung/Depth-Anything" ["e"=1]
"facebookresearch/co-tracker" -> "JonathonLuiten/Dynamic3DGaussians" ["e"=1]
"lucidrains/lion-pytorch" -> "baaivision/EVA" ["e"=1]
"VainF/Awesome-Anything" -> "fudan-zvg/Semantic-Segment-Anything"
"VainF/Awesome-Anything" -> "Anything-of-anything/Anything-3D" ["e"=1]
"VainF/Awesome-Anything" -> "Hedlen/awesome-segment-anything"
"VainF/Awesome-Anything" -> "baaivision/Painter"
"VainF/Awesome-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"VainF/Awesome-Anything" -> "ttengwang/Caption-Anything"
"VainF/Awesome-Anything" -> "UX-Decoder/Semantic-SAM"
"VainF/Awesome-Anything" -> "kadirnar/segment-anything-video"
"VainF/Awesome-Anything" -> "microsoft/X-Decoder"
"VainF/Awesome-Anything" -> "geekyutao/Inpaint-Anything"
"VainF/Awesome-Anything" -> "showlab/Image2Paragraph"
"VainF/Awesome-Anything" -> "Adamdad/Awesome-ComposableAI" ["e"=1]
"VainF/Awesome-Anything" -> "sail-sg/EditAnything"
"VainF/Awesome-Anything" -> "IDEA-Research/Grounded-Segment-Anything"
"VainF/Awesome-Anything" -> "Computer-Vision-in-the-Wild/CVinW_Readings" ["e"=1]
"kevmo314/magic-copy" -> "sail-sg/EditAnything" ["e"=1]
"kevmo314/magic-copy" -> "anuragxel/salt" ["e"=1]
"gaomingqi/Track-Anything" -> "z-x-yang/Segment-and-Track-Anything"
"gaomingqi/Track-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"gaomingqi/Track-Anything" -> "hkchengrex/XMem" ["e"=1]
"gaomingqi/Track-Anything" -> "IDEA-Research/Grounded-Segment-Anything"
"gaomingqi/Track-Anything" -> "ttengwang/Caption-Anything"
"gaomingqi/Track-Anything" -> "geekyutao/Inpaint-Anything"
"gaomingqi/Track-Anything" -> "SysCV/sam-hq"
"gaomingqi/Track-Anything" -> "CASIA-IVA-Lab/FastSAM"
"gaomingqi/Track-Anything" -> "qianqianwang68/omnimotion"
"gaomingqi/Track-Anything" -> "facebookresearch/dinov2"
"gaomingqi/Track-Anything" -> "hkchengrex/Tracking-Anything-with-DEVA"
"gaomingqi/Track-Anything" -> "IDEA-Research/GroundingDINO"
"gaomingqi/Track-Anything" -> "facebookresearch/co-tracker"
"gaomingqi/Track-Anything" -> "deep-floyd/IF"
"gaomingqi/Track-Anything" -> "facebookresearch/segment-anything" ["e"=1]
"NExT-GPT/NExT-GPT" -> "facebookresearch/ImageBind" ["e"=1]
"NExT-GPT/NExT-GPT" -> "salesforce/LAVIS" ["e"=1]
"QwenLM/Qwen-VL" -> "salesforce/LAVIS" ["e"=1]
"QwenLM/Qwen-VL" -> "mlfoundations/open_clip" ["e"=1]
"QwenLM/Qwen-VL" -> "IDEA-Research/GroundingDINO" ["e"=1]
"QwenLM/Qwen-VL" -> "salesforce/BLIP" ["e"=1]
"NVlabs/FasterViT" -> "mit-han-lab/efficientvit" ["e"=1]
"DAMO-NLP-SG/Video-LLaMA" -> "salesforce/LAVIS" ["e"=1]
"DAMO-NLP-SG/Video-LLaMA" -> "mlfoundations/open_flamingo" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "mlfoundations/open_flamingo" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "salesforce/LAVIS" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "baaivision/EVA" ["e"=1]
"facebookresearch/dinov2" -> "facebookresearch/dino" ["e"=1]
"facebookresearch/dinov2" -> "IDEA-Research/Grounded-Segment-Anything"
"facebookresearch/dinov2" -> "IDEA-Research/GroundingDINO"
"facebookresearch/dinov2" -> "facebookresearch/sam2"
"facebookresearch/dinov2" -> "mlfoundations/open_clip"
"facebookresearch/dinov2" -> "facebookresearch/segment-anything" ["e"=1]
"facebookresearch/dinov2" -> "openai/CLIP" ["e"=1]
"facebookresearch/dinov2" -> "salesforce/LAVIS"
"facebookresearch/dinov2" -> "LiheYoung/Depth-Anything" ["e"=1]
"facebookresearch/dinov2" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"facebookresearch/dinov2" -> "haotian-liu/LLaVA" ["e"=1]
"facebookresearch/dinov2" -> "facebookresearch/mae" ["e"=1]
"facebookresearch/dinov2" -> "microsoft/Swin-Transformer" ["e"=1]
"facebookresearch/dinov2" -> "facebookresearch/ImageBind"
"facebookresearch/dinov2" -> "facebookresearch/DiT" ["e"=1]
"ttengwang/Caption-Anything" -> "showlab/Image2Paragraph"
"ttengwang/Caption-Anything" -> "gaomingqi/Track-Anything"
"ttengwang/Caption-Anything" -> "VainF/Awesome-Anything"
"ttengwang/Caption-Anything" -> "fudan-zvg/Semantic-Segment-Anything"
"ttengwang/Caption-Anything" -> "baaivision/Painter"
"ttengwang/Caption-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"ttengwang/Caption-Anything" -> "baaivision/Emu" ["e"=1]
"ttengwang/Caption-Anything" -> "UX-Decoder/Semantic-SAM"
"ttengwang/Caption-Anything" -> "salesforce/LAVIS"
"ttengwang/Caption-Anything" -> "X-PLUG/mPLUG-Owl" ["e"=1]
"ttengwang/Caption-Anything" -> "microsoft/GLIP"
"ttengwang/Caption-Anything" -> "mlfoundations/open_flamingo"
"ttengwang/Caption-Anything" -> "z-x-yang/Segment-and-Track-Anything"
"ttengwang/Caption-Anything" -> "baaivision/EVA"
"ttengwang/Caption-Anything" -> "shikras/shikra" ["e"=1]
"SysCV/sam-hq" -> "UX-Decoder/Semantic-SAM"
"SysCV/sam-hq" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"SysCV/sam-hq" -> "ChaoningZhang/MobileSAM"
"SysCV/sam-hq" -> "CASIA-IVA-Lab/FastSAM"
"SysCV/sam-hq" -> "IDEA-Research/Grounded-Segment-Anything"
"SysCV/sam-hq" -> "xinyu1205/recognize-anything"
"SysCV/sam-hq" -> "fudan-zvg/Semantic-Segment-Anything"
"SysCV/sam-hq" -> "IDEA-Research/GroundingDINO"
"SysCV/sam-hq" -> "ZrrSkywalker/Personalize-SAM"
"SysCV/sam-hq" -> "tianrun-chen/SAM-Adapter-PyTorch"
"SysCV/sam-hq" -> "yformer/EfficientSAM"
"SysCV/sam-hq" -> "gaomingqi/Track-Anything"
"SysCV/sam-hq" -> "Hedlen/awesome-segment-anything"
"SysCV/sam-hq" -> "ziqi-jin/finetune-anything"
"SysCV/sam-hq" -> "baaivision/Painter"
"OFA-Sys/ONE-PEACE" -> "baaivision/EVA"
"OFA-Sys/ONE-PEACE" -> "PKU-YuanGroup/LanguageBind" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "OFA-Sys/OFA"
"OFA-Sys/ONE-PEACE" -> "microsoft/X-Decoder"
"OFA-Sys/ONE-PEACE" -> "czczup/ViT-Adapter"
"OFA-Sys/ONE-PEACE" -> "IDEA-Research/MaskDINO"
"OFA-Sys/ONE-PEACE" -> "TXH-mercury/VALOR" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "LAION-AI/CLAP" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "OpenGVLab/InternImage"
"OFA-Sys/ONE-PEACE" -> "DAMO-NLP-SG/Video-LLaMA" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "baaivision/Painter"
"OFA-Sys/ONE-PEACE" -> "facebookresearch/AudioMAE" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "TXH-mercury/VAST" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "LAION-AI/audio-dataset" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "OpenGVLab/unmasked_teacher" ["e"=1]
"facebookresearch/ijepa" -> "facebookresearch/jepa"
"facebookresearch/ijepa" -> "facebookresearch/dinov2"
"facebookresearch/ijepa" -> "facebookresearch/ImageBind"
"facebookresearch/ijepa" -> "gaasher/I-JEPA"
"facebookresearch/ijepa" -> "facebookresearch/dino" ["e"=1]
"facebookresearch/ijepa" -> "facebookresearch/DiT" ["e"=1]
"facebookresearch/ijepa" -> "SysCV/sam-hq"
"facebookresearch/ijepa" -> "artidoro/qlora" ["e"=1]
"facebookresearch/ijepa" -> "facebookresearch/hiera" ["e"=1]
"facebookresearch/ijepa" -> "salesforce/LAVIS"
"facebookresearch/ijepa" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"facebookresearch/ijepa" -> "mlfoundations/open_clip"
"facebookresearch/ijepa" -> "facebookresearch/mae" ["e"=1]
"facebookresearch/ijepa" -> "xinyu1205/recognize-anything"
"facebookresearch/ijepa" -> "apple/ml-aim" ["e"=1]
"jiawen-zhu/HQTrack" -> "hkchengrex/Tracking-Anything-with-DEVA"
"jiawen-zhu/HQTrack" -> "SysCV/sam-pt"
"jiawen-zhu/HQTrack" -> "DavidZhangdw/Visual-Tracking-Development" ["e"=1]
"jiawen-zhu/HQTrack" -> "jiawen-zhu/TrackGPT"
"jiawen-zhu/HQTrack" -> "alaamaalouf/FollowAnything"
"jiawen-zhu/HQTrack" -> "botaoye/OSTrack" ["e"=1]
"jiawen-zhu/HQTrack" -> "MIV-XJTU/ARTrack" ["e"=1]
"jiawen-zhu/HQTrack" -> "google-deepmind/tapnet" ["e"=1]
"jiawen-zhu/HQTrack" -> "jiawen-zhu/ViPT" ["e"=1]
"jiawen-zhu/HQTrack" -> "hkchengrex/XMem" ["e"=1]
"jiawen-zhu/HQTrack" -> "SysCV/MaskFreeVIS" ["e"=1]
"jiawen-zhu/HQTrack" -> "Little-Podi/Transformer_Tracking" ["e"=1]
"jiawen-zhu/HQTrack" -> "kadirnar/segment-anything-video"
"jiawen-zhu/HQTrack" -> "qianqianwang68/omnimotion"
"jiawen-zhu/HQTrack" -> "gaomingqi/Awesome-Video-Object-Segmentation" ["e"=1]
"vietanhdev/anylabeling" -> "CVHub520/X-AnyLabeling"
"vietanhdev/anylabeling" -> "yatengLG/ISAT_with_segment_anything"
"vietanhdev/anylabeling" -> "ChaoningZhang/MobileSAM"
"vietanhdev/anylabeling" -> "SysCV/sam-hq"
"vietanhdev/anylabeling" -> "anuragxel/salt"
"vietanhdev/anylabeling" -> "open-mmlab/playground"
"vietanhdev/anylabeling" -> "CASIA-IVA-Lab/FastSAM"
"vietanhdev/anylabeling" -> "fudan-zvg/Semantic-Segment-Anything"
"vietanhdev/anylabeling" -> "UX-Decoder/Semantic-SAM"
"vietanhdev/anylabeling" -> "Hedlen/awesome-segment-anything"
"vietanhdev/anylabeling" -> "IDEA-Research/Grounded-Segment-Anything"
"vietanhdev/anylabeling" -> "obss/sahi" ["e"=1]
"vietanhdev/anylabeling" -> "Deci-AI/super-gradients"
"vietanhdev/anylabeling" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"vietanhdev/anylabeling" -> "autodistill/autodistill"
"THUDM/CogVLM" -> "salesforce/LAVIS" ["e"=1]
"THUDM/CogVLM" -> "IDEA-Research/GroundingDINO" ["e"=1]
"THUDM/CogVLM" -> "mlfoundations/open_clip" ["e"=1]
"roboflow/inference" -> "roboflow/maestro"
"roboflow/inference" -> "autodistill/autodistill"
"roboflow/inference" -> "roboflow/roboflow-python"
"roboflow/inference" -> "roboflow/rf-detr"
"roboflow/inference" -> "roboflow/notebooks" ["e"=1]
"roboflow/inference" -> "AILab-CVC/YOLO-World"
"roboflow/inference" -> "roboflow/supervision" ["e"=1]
"roboflow/inference" -> "roboflow/awesome-openai-vision-api-experiments"
"roboflow/inference" -> "IDEA-Research/T-Rex"
"roboflow/inference" -> "Deci-AI/super-gradients"
"roboflow/inference" -> "SkalskiP/top-cvpr-2024-papers"
"roboflow/inference" -> "roboflow/sports" ["e"=1]
"roboflow/inference" -> "pipeless-ai/pipeless" ["e"=1]
"roboflow/inference" -> "MultimediaTechLab/YOLO"
"roboflow/inference" -> "roboflow/trackers"
"Xatta-Trone/medium-parser-extension" -> "everywall/ladder" ["e"=1]
"xinyu1205/recognize-anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"xinyu1205/recognize-anything" -> "IDEA-Research/Grounded-Segment-Anything"
"xinyu1205/recognize-anything" -> "IDEA-Research/GroundingDINO"
"xinyu1205/recognize-anything" -> "SysCV/sam-hq"
"xinyu1205/recognize-anything" -> "UX-Decoder/Semantic-SAM"
"xinyu1205/recognize-anything" -> "salesforce/LAVIS"
"xinyu1205/recognize-anything" -> "microsoft/GLIP"
"xinyu1205/recognize-anything" -> "fudan-zvg/Semantic-Segment-Anything"
"xinyu1205/recognize-anything" -> "salesforce/BLIP"
"xinyu1205/recognize-anything" -> "OpenGVLab/Ask-Anything" ["e"=1]
"xinyu1205/recognize-anything" -> "dvlab-research/LISA" ["e"=1]
"xinyu1205/recognize-anything" -> "CASIA-IVA-Lab/FastSAM"
"xinyu1205/recognize-anything" -> "facebookresearch/dinov2"
"xinyu1205/recognize-anything" -> "mlfoundations/open_clip"
"xinyu1205/recognize-anything" -> "LLaVA-VL/LLaVA-NeXT" ["e"=1]
"invictus717/MetaTransformer" -> "facebookresearch/ImageBind" ["e"=1]
"invictus717/MetaTransformer" -> "baaivision/EVA" ["e"=1]
"invictus717/MetaTransformer" -> "mlfoundations/open_flamingo" ["e"=1]
"invictus717/MetaTransformer" -> "facebookresearch/multimodal" ["e"=1]
"mazzzystar/Queryable" -> "OFA-Sys/Chinese-CLIP" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "run-llama/create_llama_projects"
"Brendan-Kirtlan/Video-Encode" -> "flutter/games"
"Brendan-Kirtlan/Video-Encode" -> "protectai/ai-exploits"
"Brendan-Kirtlan/Video-Encode" -> "tldraw/make-real-starter"
"Brendan-Kirtlan/Video-Encode" -> "pytorch-labs/segment-anything-fast"
"Brendan-Kirtlan/Video-Encode" -> "everywall/ladder"
"Brendan-Kirtlan/Video-Encode" -> "twostraws/Inferno" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "0x90n/InfoSec-Black-Friday" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "google-deepmind/graphcast" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "Brendan-Kirtlan/Minecraft-file-encoder"
"Brendan-Kirtlan/Video-Encode" -> "microsoft/fluentui-blazor" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "disler/multi-agent-postgres-data-analytics" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "apache/incubator-xtable" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "dotnet/eShop" ["e"=1]
"Brendan-Kirtlan/Video-Encode" -> "BuilderIO/gpt-crawler" ["e"=1]
"alaamaalouf/FollowAnything" -> "jiawen-zhu/HQTrack"
"alaamaalouf/FollowAnything" -> "SysCV/sam-pt"
"impiga/Plain-DETR" -> "IDEA-Research/Lite-DETR"
"impiga/Plain-DETR" -> "jozhang97/DETA"
"impiga/Plain-DETR" -> "LeapLabTHU/Rank-DETR" ["e"=1]
"impiga/Plain-DETR" -> "IDEA-Research/Stable-DINO"
"impiga/Plain-DETR" -> "xiuqhou/Relation-DETR"
"impiga/Plain-DETR" -> "Atten4Vis/GroupDETR"
"impiga/Plain-DETR" -> "Atten4Vis/ConditionalDETR"
"impiga/Plain-DETR" -> "SIAnalytics/RHINO" ["e"=1]
"sczhou/ProPainter" -> "geekyutao/Inpaint-Anything" ["e"=1]
"mit-han-lab/efficientvit" -> "NVlabs/Sana" ["e"=1]
"mit-han-lab/efficientvit" -> "yformer/EfficientSAM"
"mit-han-lab/efficientvit" -> "LTH14/mar" ["e"=1]
"mit-han-lab/efficientvit" -> "ChaoningZhang/MobileSAM"
"mit-han-lab/efficientvit" -> "microsoft/Cream" ["e"=1]
"mit-han-lab/efficientvit" -> "THU-MIG/RepViT" ["e"=1]
"mit-han-lab/efficientvit" -> "SysCV/sam-hq"
"mit-han-lab/efficientvit" -> "FoundationVision/LlamaGen" ["e"=1]
"mit-han-lab/efficientvit" -> "sihyun-yu/REPA" ["e"=1]
"mit-han-lab/efficientvit" -> "UX-Decoder/Semantic-SAM"
"mit-han-lab/efficientvit" -> "hustvl/LightningDiT" ["e"=1]
"mit-han-lab/efficientvit" -> "bytedance/1d-tokenizer" ["e"=1]
"mit-han-lab/efficientvit" -> "facebookresearch/DiT" ["e"=1]
"mit-han-lab/efficientvit" -> "TencentARC/SEED-Voken" ["e"=1]
"mit-han-lab/efficientvit" -> "FoundationVision/Infinity" ["e"=1]
"liliu-avril/Awesome-Segment-Anything" -> "YichiZhang98/SAM4MIS" ["e"=1]
"liliu-avril/Awesome-Segment-Anything" -> "Hedlen/awesome-segment-anything"
"liliu-avril/Awesome-Segment-Anything" -> "tianrun-chen/SAM-Adapter-PyTorch"
"liliu-avril/Awesome-Segment-Anything" -> "Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything"
"liliu-avril/Awesome-Segment-Anything" -> "hitachinsk/SAMed" ["e"=1]
"liliu-avril/Awesome-Segment-Anything" -> "ZrrSkywalker/Personalize-SAM"
"liliu-avril/Awesome-Segment-Anything" -> "SuperMedIntel/Medical-SAM-Adapter" ["e"=1]
"liliu-avril/Awesome-Segment-Anything" -> "UX-Decoder/Semantic-SAM"
"liliu-avril/Awesome-Segment-Anything" -> "aim-uofa/Matcher"
"liliu-avril/Awesome-Segment-Anything" -> "KyanChen/RSPrompter" ["e"=1]
"liliu-avril/Awesome-Segment-Anything" -> "ziqi-jin/finetune-anything"
"liliu-avril/Awesome-Segment-Anything" -> "HarborYuan/ovsam"
"liliu-avril/Awesome-Segment-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"liliu-avril/Awesome-Segment-Anything" -> "yformer/EfficientSAM"
"liliu-avril/Awesome-Segment-Anything" -> "OpenGVLab/SAM-Med2D" ["e"=1]
"jbilcke-hf/ai-comic-factory" -> "sail-sg/EditAnything" ["e"=1]
"NVlabs/ODISE" -> "MendelXu/SAN"
"NVlabs/ODISE" -> "facebookresearch/ov-seg"
"NVlabs/ODISE" -> "IDEA-Research/OpenSeeD"
"NVlabs/ODISE" -> "chongzhou96/MaskCLIP"
"NVlabs/ODISE" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"NVlabs/ODISE" -> "bytedance/fc-clip"
"NVlabs/ODISE" -> "wl-zhao/VPD" ["e"=1]
"NVlabs/ODISE" -> "facebookresearch/Mask2Former"
"NVlabs/ODISE" -> "weijiawu/DiffuMask" ["e"=1]
"NVlabs/ODISE" -> "dvlab-research/LISA" ["e"=1]
"NVlabs/ODISE" -> "NVlabs/GroupViT"
"NVlabs/ODISE" -> "microsoft/X-Decoder"
"NVlabs/ODISE" -> "yandex-research/ddpm-segmentation" ["e"=1]
"NVlabs/ODISE" -> "jianzongwu/Awesome-Open-Vocabulary"
"NVlabs/ODISE" -> "baaivision/Painter"
"open-mmlab/playground" -> "open-mmlab/mmengine" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmyolo" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmfewshot" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmdeploy" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmpretrain" ["e"=1]
"open-mmlab/playground" -> "vietanhdev/anylabeling"
"open-mmlab/playground" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"open-mmlab/playground" -> "fudan-zvg/Semantic-Segment-Anything"
"open-mmlab/playground" -> "open-mmlab/mmrotate" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/Multimodal-GPT" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmeval" ["e"=1]
"open-mmlab/playground" -> "open-mmlab/mmrazor" ["e"=1]
"open-mmlab/playground" -> "VisionXLab/sam-mmrotate"
"open-mmlab/playground" -> "tianrun-chen/SAM-Adapter-PyTorch"
"open-mmlab/playground" -> "IDEA-Research/DINO"
"awaisrauf/Awesome-CV-Foundational-Models" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "xmed-lab/CLIP_Surgery" ["e"=1]
"daochenzha/data-centric-AI" -> "VainF/Awesome-Anything" ["e"=1]
"facebookresearch/MetaCLIP" -> "LAION-AI/CLIP_benchmark"
"facebookresearch/MetaCLIP" -> "beichenzbc/Long-CLIP"
"facebookresearch/MetaCLIP" -> "tsb0601/MMVP" ["e"=1]
"facebookresearch/MetaCLIP" -> "mlfoundations/datacomp"
"facebookresearch/MetaCLIP" -> "apple/ml-aim" ["e"=1]
"facebookresearch/MetaCLIP" -> "cambrian-mllm/cambrian" ["e"=1]
"facebookresearch/MetaCLIP" -> "baaivision/EVA"
"facebookresearch/MetaCLIP" -> "google-research/big_vision"
"facebookresearch/MetaCLIP" -> "rom1504/img2dataset"
"facebookresearch/MetaCLIP" -> "microsoft/GLIP"
"facebookresearch/MetaCLIP" -> "SunzeY/AlphaCLIP"
"facebookresearch/MetaCLIP" -> "mlfoundations/open_clip"
"facebookresearch/MetaCLIP" -> "apple/ml-mobileclip"
"facebookresearch/MetaCLIP" -> "mlfoundations/wise-ft"
"facebookresearch/MetaCLIP" -> "allenai/mmc4"
"YichiZhang98/SAM4MIS" -> "liliu-avril/Awesome-Segment-Anything" ["e"=1]
"voxel51/fiftyone-docs-search" -> "voxel51/voxelgpt"
"voxel51/fiftyone-docs-search" -> "voxel51/papers-with-data"
"voxel51/fiftyone-docs-search" -> "voxel51/fiftyone-plugins"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "UX-Decoder/Semantic-SAM"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "IDEA-Research/Grounded-Segment-Anything"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "IDEA-Research/GroundingDINO"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "SysCV/sam-hq"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "fudan-zvg/Semantic-Segment-Anything"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "microsoft/X-Decoder"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "baaivision/Painter"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "xinyu1205/recognize-anything"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "gaomingqi/Track-Anything"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "facebookresearch/dinov2"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "CASIA-IVA-Lab/FastSAM"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "z-x-yang/Segment-and-Track-Anything"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "ZrrSkywalker/Personalize-SAM"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "IDEA-Research/OpenSeeD"
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" -> "facebookresearch/Mask2Former"
"liunian-harold-li/DesCo" -> "samschulter/omnilabeltools"
"Hedlen/awesome-segment-anything" -> "ihub-pub/plugins" ["e"=1]
"Hedlen/awesome-segment-anything" -> "Raray-chuan/mini-spring" ["e"=1]
"Hedlen/awesome-segment-anything" -> "gqylpy/systempath" ["e"=1]
"Hedlen/awesome-segment-anything" -> "linkxzhou/LessDB" ["e"=1]
"Hedlen/awesome-segment-anything" -> "farseer-go/fs" ["e"=1]
"Hedlen/awesome-segment-anything" -> "ruixiaozi/rxz-ui" ["e"=1]
"Hedlen/awesome-segment-anything" -> "Western-OC2-Lab/AutoML-Implementation-for-Static-and-Dynamic-Data-Analytics" ["e"=1]
"Hedlen/awesome-segment-anything" -> "liliu-avril/Awesome-Segment-Anything"
"Hedlen/awesome-segment-anything" -> "Raray-chuan/xichuan_note" ["e"=1]
"Hedlen/awesome-segment-anything" -> "wewehao/flutter_chatgpt" ["e"=1]
"Hedlen/awesome-segment-anything" -> "dqzboy/DKube" ["e"=1]
"Hedlen/awesome-segment-anything" -> "1902756969/IKUN_Library" ["e"=1]
"Hedlen/awesome-segment-anything" -> "dqzboy/DevOps" ["e"=1]
"Hedlen/awesome-segment-anything" -> "Your7Maxx/FlowGod" ["e"=1]
"Hedlen/awesome-segment-anything" -> "Ruimve/resource-hint-webpack-plugin" ["e"=1]
"Farama-Foundation/chatarena" -> "allenai/mmc4" ["e"=1]
"apple/ml-fastvit" -> "mit-han-lab/efficientvit" ["e"=1]
"apple/ml-fastvit" -> "apple/ml-mobileclip" ["e"=1]
"apple/ml-fastvit" -> "facebookresearch/MetaCLIP" ["e"=1]
"apple/ml-fastvit" -> "google-research/big_vision" ["e"=1]
"apple/ml-fastvit" -> "lyuwenyu/RT-DETR" ["e"=1]
"apple/ml-fastvit" -> "ChaoningZhang/MobileSAM" ["e"=1]
"apple/ml-fastvit" -> "facebookresearch/dinov2" ["e"=1]
"jianzongwu/Awesome-Open-Vocabulary" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"jianzongwu/Awesome-Open-Vocabulary" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"jianzongwu/Awesome-Open-Vocabulary" -> "MendelXu/SAN"
"jianzongwu/Awesome-Open-Vocabulary" -> "HarborYuan/ovsam"
"jianzongwu/Awesome-Open-Vocabulary" -> "seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation"
"jianzongwu/Awesome-Open-Vocabulary" -> "Charles-Xie/awesome-described-object-detection"
"jianzongwu/Awesome-Open-Vocabulary" -> "facebookresearch/ov-seg"
"jianzongwu/Awesome-Open-Vocabulary" -> "IDEA-Research/OpenSeeD"
"jianzongwu/Awesome-Open-Vocabulary" -> "lxtGH/Awesome-Segmentation-With-Transformer"
"jianzongwu/Awesome-Open-Vocabulary" -> "wusize/CLIPSelf"
"jianzongwu/Awesome-Open-Vocabulary" -> "shenyunhang/APE"
"jianzongwu/Awesome-Open-Vocabulary" -> "TheShadow29/awesome-grounding" ["e"=1]
"jianzongwu/Awesome-Open-Vocabulary" -> "NVlabs/ODISE"
"jianzongwu/Awesome-Open-Vocabulary" -> "chongzhou96/MaskCLIP"
"jianzongwu/Awesome-Open-Vocabulary" -> "bytedance/fc-clip"
"OpenGVLab/VisionLLM" -> "microsoft/GLIP" ["e"=1]
"OpenGVLab/VisionLLM" -> "baaivision/EVA" ["e"=1]
"OpenGVLab/VisionLLM" -> "microsoft/X-Decoder" ["e"=1]
"OpenGVLab/VisionLLM" -> "google-research/pix2seq" ["e"=1]
"KyanChen/RSPrompter" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"KyanChen/RSPrompter" -> "ziqi-jin/finetune-anything" ["e"=1]
"huggingface/OBELICS" -> "LAION-AI/Big-Interleaved-Dataset" ["e"=1]
"Jun-CEN/SegmentAnyRGBD" -> "facebookresearch/ov-seg" ["e"=1]
"Jun-CEN/SegmentAnyRGBD" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"hitachinsk/SAMed" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"hitachinsk/SAMed" -> "ziqi-jin/finetune-anything" ["e"=1]
"hitachinsk/SAMed" -> "liliu-avril/Awesome-Segment-Anything" ["e"=1]
"PengtaoJiang/Segment-Anything-CLIP" -> "PengtaoJiang/OAA-PyTorch" ["e"=1]
"PengtaoJiang/Segment-Anything-CLIP" -> "helblazer811/RefSAM"
"PengtaoJiang/Segment-Anything-CLIP" -> "Seonghoon-Yu/Zero-shot-RIS" ["e"=1]
"fudan-zvg/Semantic-Segment-Anything" -> "UX-Decoder/Semantic-SAM"
"fudan-zvg/Semantic-Segment-Anything" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"fudan-zvg/Semantic-Segment-Anything" -> "SysCV/sam-hq"
"fudan-zvg/Semantic-Segment-Anything" -> "tianrun-chen/SAM-Adapter-PyTorch"
"fudan-zvg/Semantic-Segment-Anything" -> "Hedlen/awesome-segment-anything"
"fudan-zvg/Semantic-Segment-Anything" -> "VainF/Awesome-Anything"
"fudan-zvg/Semantic-Segment-Anything" -> "baaivision/Painter"
"fudan-zvg/Semantic-Segment-Anything" -> "IDEA-Research/Grounded-Segment-Anything"
"fudan-zvg/Semantic-Segment-Anything" -> "ZrrSkywalker/Personalize-SAM"
"fudan-zvg/Semantic-Segment-Anything" -> "ziqi-jin/finetune-anything"
"fudan-zvg/Semantic-Segment-Anything" -> "facebookresearch/Mask2Former"
"fudan-zvg/Semantic-Segment-Anything" -> "anuragxel/salt"
"fudan-zvg/Semantic-Segment-Anything" -> "SHI-Labs/OneFormer"
"fudan-zvg/Semantic-Segment-Anything" -> "CASIA-IVA-Lab/FastSAM"
"fudan-zvg/Semantic-Segment-Anything" -> "xinyu1205/recognize-anything"
"anuragxel/salt" -> "zhouayi/SAM-Tool"
"anuragxel/salt" -> "haochenheheda/segment-anything-annotator"
"anuragxel/salt" -> "fudan-zvg/Semantic-Segment-Anything"
"anuragxel/salt" -> "vietanhdev/anylabeling"
"anuragxel/salt" -> "yatengLG/ISAT_with_segment_anything"
"anuragxel/salt" -> "Hedlen/awesome-segment-anything"
"anuragxel/salt" -> "lujiazho/SegDrawer"
"anuragxel/salt" -> "SysCV/sam-hq"
"anuragxel/salt" -> "tianrun-chen/SAM-Adapter-PyTorch"
"anuragxel/salt" -> "kadirnar/segment-anything-video"
"anuragxel/salt" -> "ZrrSkywalker/Personalize-SAM"
"anuragxel/salt" -> "z-x-yang/Segment-and-Track-Anything"
"anuragxel/salt" -> "sail-sg/EditAnything"
"anuragxel/salt" -> "UX-Decoder/Semantic-SAM"
"anuragxel/salt" -> "Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything"
"NVIDIA-AI-IOT/nanosam" -> "NVIDIA-AI-IOT/jetson-intro-to-distillation"
"NVIDIA-AI-IOT/nanosam" -> "NVIDIA-AI-IOT/nanoowl"
"NVIDIA-AI-IOT/nanosam" -> "YuYue525/MobileSAM-pytorch"
"NVIDIA-AI-IOT/nanosam" -> "xinghaochen/TinySAM"
"NVIDIA-AI-IOT/nanosam" -> "chongzhou96/EdgeSAM"
"NVIDIA-AI-IOT/nanosam" -> "ChaoningZhang/MobileSAM"
"NVIDIA-AI-IOT/nanosam" -> "czg1225/SlimSAM"
"NVIDIA-AI-IOT/nanosam" -> "Aimol-l/OrtInference"
"NVIDIA-AI-IOT/nanosam" -> "spacewalk01/nanosam-cpp"
"NVIDIA-AI-IOT/nanosam" -> "ChuRuaNh0/FastSam_Awsome_TensorRT"
"NVIDIA-AI-IOT/nanosam" -> "yformer/EfficientSAM"
"NVIDIA-AI-IOT/nanosam" -> "NVIDIA-AI-IOT/jetson_dla_tutorial" ["e"=1]
"NVIDIA-AI-IOT/nanosam" -> "Gy920/segment-anything-2-real-time"
"NVIDIA-AI-IOT/nanosam" -> "mit-han-lab/efficientvit"
"NVIDIA-AI-IOT/nanosam" -> "zhudongwork/SAM_TensorRT"
"DmitryRyumin/ICCV-2023-Papers" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" ["e"=1]
"allenai/mmc4" -> "mlfoundations/open_flamingo"
"allenai/mmc4" -> "mlfoundations/datacomp"
"allenai/mmc4" -> "baaivision/Emu" ["e"=1]
"allenai/mmc4" -> "kakaobrain/coyo-dataset"
"allenai/mmc4" -> "kohjingyu/fromage"
"allenai/mmc4" -> "allenai/unified-io-2" ["e"=1]
"allenai/mmc4" -> "AILab-CVC/SEED" ["e"=1]
"allenai/mmc4" -> "AILab-CVC/SEED-Bench" ["e"=1]
"allenai/mmc4" -> "kohjingyu/gill" ["e"=1]
"allenai/mmc4" -> "lucidrains/flamingo-pytorch"
"allenai/mmc4" -> "huggingface/OBELICS"
"allenai/mmc4" -> "allenai/unified-io-inference" ["e"=1]
"allenai/mmc4" -> "HaozheZhao/MIC" ["e"=1]
"allenai/mmc4" -> "JialianW/GRiT" ["e"=1]
"allenai/mmc4" -> "showlab/Image2Paragraph"
"mlzxy/devit" -> "lovelyqian/CDFSOD-benchmark"
"mlzxy/devit" -> "ZhangGongjie/Meta-DETR" ["e"=1]
"mlzxy/devit" -> "gaobb/Few-Shot-Object-Detection-Papers" ["e"=1]
"mlzxy/devit" -> "csuhan/VFA" ["e"=1]
"mlzxy/devit" -> "GuangxingHan/Meta-Faster-R-CNN" ["e"=1]
"mlzxy/devit" -> "lxn96/awesome-few-shot-object-detection" ["e"=1]
"mlzxy/devit" -> "xavibou/ovdsat"
"mlzxy/devit" -> "microsoft/RegionCLIP"
"mlzxy/devit" -> "YifanXu74/MQ-Det" ["e"=1]
"mlzxy/devit" -> "open-mmlab/mmfewshot" ["e"=1]
"mlzxy/devit" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"mlzxy/devit" -> "er-muyue/DeFRCN" ["e"=1]
"mlzxy/devit" -> "lovelyqian/NTIRE2025_CDFSOD"
"mlzxy/devit" -> "fanq15/FewX" ["e"=1]
"mlzxy/devit" -> "tgxs002/CORA"
"ZrrSkywalker/Personalize-SAM" -> "aim-uofa/Matcher"
"ZrrSkywalker/Personalize-SAM" -> "tianrun-chen/SAM-Adapter-PyTorch"
"ZrrSkywalker/Personalize-SAM" -> "UX-Decoder/Semantic-SAM"
"ZrrSkywalker/Personalize-SAM" -> "SysCV/sam-hq"
"ZrrSkywalker/Personalize-SAM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"ZrrSkywalker/Personalize-SAM" -> "baaivision/Painter"
"ZrrSkywalker/Personalize-SAM" -> "ziqi-jin/finetune-anything"
"ZrrSkywalker/Personalize-SAM" -> "fudan-zvg/Semantic-Segment-Anything"
"ZrrSkywalker/Personalize-SAM" -> "liliu-avril/Awesome-Segment-Anything"
"ZrrSkywalker/Personalize-SAM" -> "Hedlen/awesome-segment-anything"
"ZrrSkywalker/Personalize-SAM" -> "microsoft/X-Decoder"
"ZrrSkywalker/Personalize-SAM" -> "HarborYuan/ovsam"
"ZrrSkywalker/Personalize-SAM" -> "ChaoningZhang/MobileSAM"
"ZrrSkywalker/Personalize-SAM" -> "luca-medeiros/lightning-sam"
"ZrrSkywalker/Personalize-SAM" -> "SuperMedIntel/Medical-SAM-Adapter" ["e"=1]
"JiauZhang/DragGAN" -> "gaomingqi/Track-Anything" ["e"=1]
"JiauZhang/DragGAN" -> "deep-floyd/IF" ["e"=1]
"autodistill/autodistill" -> "IDEA-Research/GroundingDINO"
"autodistill/autodistill" -> "AILab-CVC/YOLO-World"
"autodistill/autodistill" -> "roboflow/inference"
"autodistill/autodistill" -> "Deci-AI/super-gradients"
"autodistill/autodistill" -> "roboflow/notebooks" ["e"=1]
"autodistill/autodistill" -> "obss/sahi" ["e"=1]
"autodistill/autodistill" -> "IDEA-Research/T-Rex"
"autodistill/autodistill" -> "UX-Decoder/Semantic-SAM"
"autodistill/autodistill" -> "vietanhdev/anylabeling"
"autodistill/autodistill" -> "roboflow/maestro"
"autodistill/autodistill" -> "IDEA-Research/Grounded-Segment-Anything"
"autodistill/autodistill" -> "SysCV/sam-hq"
"autodistill/autodistill" -> "IDEA-Research/Grounded-SAM-2"
"autodistill/autodistill" -> "ChaoningZhang/MobileSAM"
"autodistill/autodistill" -> "IDEA-Research/Grounding-DINO-1.5-API"
"facebookresearch/hiera" -> "facebookresearch/MetaCLIP" ["e"=1]
"facebookresearch/hiera" -> "czczup/ViT-Adapter" ["e"=1]
"facebookresearch/hiera" -> "mit-han-lab/efficientvit" ["e"=1]
"hank-ai/darknet" -> "stephanecharette/DarkMark"
"hank-ai/darknet" -> "stephanecharette/DarkHelp"
"hank-ai/darknet" -> "MultimediaTechLab/YOLO"
"hank-ai/darknet" -> "stephanecharette/DarkPlate"
"chn-lee-yumi/MaterialSearch" -> "OFA-Sys/Chinese-CLIP" ["e"=1]
"lujiazho/SegDrawer" -> "MiscellaneousStuff/meta-sam-demo"
"lujiazho/SegDrawer" -> "Kingfish404/segment-anything-webui"
"lujiazho/SegDrawer" -> "Nomination-NRB/SAM-webui"
"lujiazho/SegDrawer" -> "anuragxel/salt"
"lujiazho/SegDrawer" -> "royerlab/napari-segment-anything" ["e"=1]
"lujiazho/SegDrawer" -> "vietanhdev/samexporter"
"JerryX1110/awesome-segment-anything-extensions" -> "Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything"
"JerryX1110/awesome-segment-anything-extensions" -> "Hedlen/awesome-segment-anything"
"JerryX1110/awesome-segment-anything-extensions" -> "feizc/IEA"
"JerryX1110/awesome-segment-anything-extensions" -> "dk-liang/Awesome-Segment-Anything"
"JerryX1110/awesome-segment-anything-extensions" -> "fudan-zvg/Semantic-Segment-Anything"
"JerryX1110/awesome-segment-anything-extensions" -> "wangsssky/SonarSAM" ["e"=1]
"pytorch-labs/segment-anything-fast" -> "run-llama/create_llama_projects"
"pytorch-labs/segment-anything-fast" -> "protectai/ai-exploits"
"pytorch-labs/segment-anything-fast" -> "flutter/games"
"pytorch-labs/segment-anything-fast" -> "tldraw/make-real-starter"
"pytorch-labs/segment-anything-fast" -> "yformer/EfficientSAM"
"pytorch-labs/segment-anything-fast" -> "Brendan-Kirtlan/Video-Encode"
"pytorch-labs/segment-anything-fast" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"pytorch-labs/segment-anything-fast" -> "SysCV/sam-hq"
"pytorch-labs/segment-anything-fast" -> "luca-medeiros/lightning-sam"
"pytorch-labs/segment-anything-fast" -> "UX-Decoder/Semantic-SAM"
"pytorch-labs/segment-anything-fast" -> "everywall/ladder"
"pytorch-labs/segment-anything-fast" -> "NVIDIA-AI-IOT/nanosam"
"pytorch-labs/segment-anything-fast" -> "ChaoningZhang/MobileSAM"
"pytorch-labs/segment-anything-fast" -> "twostraws/Inferno" ["e"=1]
"pytorch-labs/segment-anything-fast" -> "Hedlen/awesome-segment-anything"
"mlfoundations/datacomp" -> "allenai/mmc4"
"mlfoundations/datacomp" -> "LAION-AI/CLIP_benchmark"
"mlfoundations/datacomp" -> "facebookresearch/MetaCLIP"
"mlfoundations/datacomp" -> "huggingface/OBELICS"
"mlfoundations/datacomp" -> "UCSC-VLAA/CLIPA"
"mlfoundations/datacomp" -> "kakaobrain/coyo-dataset"
"mlfoundations/datacomp" -> "mlfoundations/wise-ft"
"mlfoundations/datacomp" -> "rom1504/img2dataset"
"mlfoundations/datacomp" -> "rom1504/laion-prepro"
"mlfoundations/datacomp" -> "baaivision/EVA"
"mlfoundations/datacomp" -> "RAIVNLab/sugar-crepe" ["e"=1]
"mlfoundations/datacomp" -> "showlab/Image2Paragraph"
"mlfoundations/datacomp" -> "rom1504/clip-retrieval"
"mlfoundations/datacomp" -> "google-research/big_vision"
"mlfoundations/datacomp" -> "mlfoundations/open_flamingo"
"LijieFan/LaCLIP" -> "baaivision/CapsFusion" ["e"=1]
"LijieFan/LaCLIP" -> "ant-research/DreamLIP"
"LijieFan/LaCLIP" -> "UCSC-VLAA/CLIPA"
"LijieFan/LaCLIP" -> "mertyg/vision-language-models-are-bows" ["e"=1]
"LijieFan/LaCLIP" -> "beichenzbc/Long-CLIP"
"IDEA-Research/Lite-DETR" -> "impiga/Plain-DETR"
"IDEA-Research/Lite-DETR" -> "jozhang97/DETA"
"IDEA-Research/Lite-DETR" -> "HDETR/H-Deformable-DETR"
"IDEA-Research/Lite-DETR" -> "ZhangGongjie/IMFA"
"IDEA-Research/Lite-DETR" -> "jshilong/DDQ"
"IDEA-Research/Lite-DETR" -> "linxid/Focus-DETR-mindspore"
"IDEA-Research/Lite-DETR" -> "IDEA-Research/Stable-DINO"
"showlab/Image2Paragraph" -> "JialianW/GRiT" ["e"=1]
"showlab/Image2Paragraph" -> "ttengwang/Caption-Anything"
"showlab/Image2Paragraph" -> "showlab/VLog"
"showlab/Image2Paragraph" -> "Vision-CAIR/ChatCaptioner"
"showlab/Image2Paragraph" -> "VainF/Awesome-Anything"
"showlab/Image2Paragraph" -> "allenai/mmc4"
"showlab/Image2Paragraph" -> "EvolvingLMMs-Lab/RelateAnything" ["e"=1]
"showlab/Image2Paragraph" -> "showlab/cosmo" ["e"=1]
"showlab/Image2Paragraph" -> "shikras/shikra" ["e"=1]
"showlab/Image2Paragraph" -> "showlab/all-in-one" ["e"=1]
"showlab/Image2Paragraph" -> "showlab/UniVTG" ["e"=1]
"showlab/Image2Paragraph" -> "facebookresearch/LaViLa" ["e"=1]
"showlab/Image2Paragraph" -> "fudan-zvg/Semantic-Segment-Anything"
"showlab/Image2Paragraph" -> "mlfoundations/datacomp"
"showlab/Image2Paragraph" -> "OFA-Sys/OFA"
"soulteary/docker-prompt-generator" -> "sail-sg/EditAnything" ["e"=1]
"lucidrains/toolformer-pytorch" -> "amazon-science/mm-cot" ["e"=1]
"HaozheZhao/MIC" -> "allenai/mmc4" ["e"=1]
"OpenGVLab/Ask-Anything" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/Ask-Anything" -> "xinyu1205/recognize-anything" ["e"=1]
"OpenGVLab/Ask-Anything" -> "mlfoundations/open_flamingo" ["e"=1]
"cvlab-columbia/viper" -> "allenai/visprog" ["e"=1]
"cvlab-columbia/viper" -> "mlfoundations/open_flamingo"
"cvlab-columbia/viper" -> "microsoft/GLIP"
"cvlab-columbia/viper" -> "mbzuai-oryx/Video-ChatGPT" ["e"=1]
"cvlab-columbia/viper" -> "facebookresearch/LaViLa" ["e"=1]
"cvlab-columbia/viper" -> "Vision-CAIR/ChatCaptioner"
"cvlab-columbia/viper" -> "dvlab-research/LISA" ["e"=1]
"cvlab-columbia/viper" -> "allenai/mmc4"
"cvlab-columbia/viper" -> "kohjingyu/fromage"
"cvlab-columbia/viper" -> "baaivision/Emu" ["e"=1]
"cvlab-columbia/viper" -> "lupantech/chameleon-llm" ["e"=1]
"cvlab-columbia/viper" -> "salesforce/LAVIS"
"cvlab-columbia/viper" -> "amazon-science/mm-cot"
"cvlab-columbia/viper" -> "microsoft/X-Decoder"
"cvlab-columbia/viper" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"lupantech/chameleon-llm" -> "allenai/mmc4" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "Vision-CAIR/ChatCaptioner" ["e"=1]
"OpenGVLab/all-seeing" -> "shikras/d-cube" ["e"=1]
"SkalskiP/awesome-chatgpt-code-interpreter-experiments" -> "SkalskiP/top-cvpr-2023-papers" ["e"=1]
"VITA-MLLM/Woodpecker" -> "shenyunhang/APE" ["e"=1]
"wusize/ovdet" -> "tgxs002/CORA"
"wusize/ovdet" -> "clin1223/VLDet"
"wusize/ovdet" -> "wusize/CLIM"
"wusize/ovdet" -> "CVMI-Lab/CoDet"
"wusize/ovdet" -> "LutingWang/OADP"
"wusize/ovdet" -> "dyabel/detpro"
"wusize/ovdet" -> "mala-lab/SIC-CADS"
"wusize/ovdet" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"wusize/ovdet" -> "VinAIResearch/LP-OVOD"
"wusize/ovdet" -> "YimingCuiCuiCui/awesome-open-vocabulary-object-detection"
"Charles-Xie/awesome-described-object-detection" -> "shikras/d-cube"
"Charles-Xie/awesome-described-object-detection" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"Charles-Xie/awesome-described-object-detection" -> "seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation"
"Charles-Xie/awesome-described-object-detection" -> "FoundationVision/GenerateU"
"Charles-Xie/awesome-described-object-detection" -> "CVMI-Lab/CoDet"
"Charles-Xie/awesome-described-object-detection" -> "jianzongwu/Awesome-Open-Vocabulary"
"Charles-Xie/awesome-described-object-detection" -> "Charles-Xie/CQL" ["e"=1]
"Charles-Xie/awesome-described-object-detection" -> "THU-MIG/YOLO-UniOW"
"Charles-Xie/awesome-described-object-detection" -> "iSEE-Laboratory/LLMDet"
"Went-Liang/UnSniffer" -> "xuefeng-cvr/Tiny-Obstacle-Discovery"
"Went-Liang/UnSniffer" -> "frh23333/mepu-owod"
"Went-Liang/UnSniffer" -> "orrzohar/PROB"
"Went-Liang/UnSniffer" -> "DIG-Beihang/ALLOW"
"kohjingyu/gill" -> "kohjingyu/fromage" ["e"=1]
"kohjingyu/gill" -> "allenai/mmc4" ["e"=1]
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "liliu-avril/Awesome-Segment-Anything"
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "JerryX1110/awesome-segment-anything-extensions"
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "Vision-Intelligence-and-Robots-Group/count-anything" ["e"=1]
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "PengtaoJiang/Segment-Anything-CLIP"
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "Vision-Intelligence-and-Robots-Group/awesome-micro-expression-recognition" ["e"=1]
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "Hedlen/awesome-segment-anything"
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "JamesQFreeman/Sam_LoRA" ["e"=1]
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "tianrun-chen/SAM-Adapter-PyTorch"
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" -> "ziqi-jin/finetune-anything"
"jshilong/GPT4RoI" -> "jshilong/DDQ" ["e"=1]
"jshilong/GPT4RoI" -> "microsoft/X-Decoder" ["e"=1]
"jshilong/GPT4RoI" -> "facebookresearch/VLPart" ["e"=1]
"shenyunhang/APE" -> "VITA-MLLM/Woodpecker" ["e"=1]
"shenyunhang/APE" -> "MME-Benchmarks/Video-MME" ["e"=1]
"shenyunhang/APE" -> "FoundationVision/GLEE"
"shenyunhang/APE" -> "YifanXu74/MQ-Det" ["e"=1]
"shenyunhang/APE" -> "jianzongwu/Awesome-Open-Vocabulary"
"shenyunhang/APE" -> "UX-Decoder/DINOv"
"shenyunhang/APE" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"shenyunhang/APE" -> "baaivision/tokenize-anything"
"shenyunhang/APE" -> "IDEA-Research/OpenSeeD"
"shenyunhang/APE" -> "CircleRadon/Osprey" ["e"=1]
"shenyunhang/APE" -> "FoundationVision/Groma" ["e"=1]
"shenyunhang/APE" -> "HarborYuan/ovsam"
"shenyunhang/APE" -> "lxtGH/OMG-Seg" ["e"=1]
"shenyunhang/APE" -> "BradyFU/DVG-Face"
"shenyunhang/APE" -> "Charles-Xie/awesome-described-object-detection"
"WangRongsheng/SAM-fine-tune" -> "ziqi-jin/finetune-anything"
"WangRongsheng/SAM-fine-tune" -> "mazurowski-lab/finetune-SAM"
"WangRongsheng/SAM-fine-tune" -> "MathieuNlp/Sam_LoRA" ["e"=1]
"YuyangSunshine/ABR_IOD" -> "fcdl94/MMA"
"NVlabs/prismer" -> "microsoft/X-Decoder"
"NVlabs/prismer" -> "mlfoundations/open_flamingo"
"NVlabs/prismer" -> "microsoft/MM-REACT" ["e"=1]
"NVlabs/prismer" -> "amazon-science/mm-cot"
"NVlabs/prismer" -> "autonomousvision/stylegan-t" ["e"=1]
"NVlabs/prismer" -> "ali-vilab/composer" ["e"=1]
"NVlabs/prismer" -> "Vision-CAIR/ChatCaptioner"
"NVlabs/prismer" -> "baaivision/Painter"
"NVlabs/prismer" -> "facebookresearch/Detic"
"NVlabs/prismer" -> "allenai/mmc4"
"NVlabs/prismer" -> "Shiriluz/Word-As-Image" ["e"=1]
"NVlabs/prismer" -> "lukasHoel/text2room" ["e"=1]
"NVlabs/prismer" -> "lucidrains/toolformer-pytorch" ["e"=1]
"NVlabs/prismer" -> "cvlab-columbia/viper"
"NVlabs/prismer" -> "kakaobrain/coyo-dataset"
"SuperMedIntel/Medical-SAM-Adapter" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"showlab/VLog" -> "showlab/Image2Paragraph"
"showlab/VLog" -> "showlab/UniVTG" ["e"=1]
"showlab/VLog" -> "Vision-CAIR/ChatCaptioner"
"showlab/VLog" -> "showlab/EgoVLP" ["e"=1]
"showlab/VLog" -> "showlab/cosmo" ["e"=1]
"showlab/VLog" -> "showlab/all-in-one" ["e"=1]
"showlab/VLog" -> "TencentARC/MCQ" ["e"=1]
"showlab/VLog" -> "mbzuai-oryx/Video-ChatGPT" ["e"=1]
"showlab/VLog" -> "JialianW/GRiT" ["e"=1]
"showlab/VLog" -> "AILab-CVC/SEED-Bench" ["e"=1]
"showlab/VLog" -> "microsoft/XPretrain" ["e"=1]
"showlab/VLog" -> "antoyang/VidChapters" ["e"=1]
"showlab/VLog" -> "facebookresearch/LaViLa" ["e"=1]
"showlab/VLog" -> "jayleicn/moment_detr" ["e"=1]
"showlab/VLog" -> "jayleicn/singularity" ["e"=1]
"SysCV/sam-pt" -> "hkchengrex/Tracking-Anything-with-DEVA"
"SysCV/sam-pt" -> "z-x-yang/Segment-and-Track-Anything"
"SysCV/sam-pt" -> "SysCV/sam-hq"
"SysCV/sam-pt" -> "hkchengrex/XMem" ["e"=1]
"SysCV/sam-pt" -> "google-deepmind/tapnet" ["e"=1]
"SysCV/sam-pt" -> "qianqianwang68/omnimotion"
"SysCV/sam-pt" -> "UX-Decoder/Semantic-SAM"
"SysCV/sam-pt" -> "jiawen-zhu/HQTrack"
"SysCV/sam-pt" -> "hkchengrex/Cutie" ["e"=1]
"SysCV/sam-pt" -> "aharley/pips" ["e"=1]
"SysCV/sam-pt" -> "kadirnar/segment-anything-video"
"SysCV/sam-pt" -> "yoxu515/aot-benchmark" ["e"=1]
"SysCV/sam-pt" -> "gaomingqi/Track-Anything"
"SysCV/sam-pt" -> "aim-uofa/Matcher"
"SysCV/sam-pt" -> "mbzuai-metaverse/XMem2" ["e"=1]
"IDEA-Research/OpenSeeD" -> "IDEA-Research/MaskDINO"
"IDEA-Research/OpenSeeD" -> "microsoft/X-Decoder"
"IDEA-Research/OpenSeeD" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/OpenSeeD" -> "facebookresearch/ov-seg"
"IDEA-Research/OpenSeeD" -> "facebookresearch/VLPart"
"IDEA-Research/OpenSeeD" -> "NVlabs/ODISE"
"IDEA-Research/OpenSeeD" -> "UX-Decoder/DINOv"
"IDEA-Research/OpenSeeD" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"IDEA-Research/OpenSeeD" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"IDEA-Research/OpenSeeD" -> "MendelXu/SAN"
"IDEA-Research/OpenSeeD" -> "bytedance/fc-clip"
"IDEA-Research/OpenSeeD" -> "IDEA-Research/Stable-DINO"
"IDEA-Research/OpenSeeD" -> "jianzongwu/Awesome-Open-Vocabulary"
"IDEA-Research/OpenSeeD" -> "SHI-Labs/OneFormer"
"IDEA-Research/OpenSeeD" -> "microsoft/GLIP"
"berkeley-hipie/HIPIE" -> "MendelXu/SAN"
"berkeley-hipie/HIPIE" -> "facebookresearch/ov-seg"
"berkeley-hipie/HIPIE" -> "NVlabs/ODISE"
"berkeley-hipie/HIPIE" -> "aimagelab/freeda" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"kadirnar/segment-anything-video" -> "z-x-yang/Segment-and-Track-Anything"
"kadirnar/segment-anything-video" -> "VainF/Awesome-Anything"
"kadirnar/segment-anything-video" -> "SysCV/sam-pt"
"kadirnar/segment-anything-video" -> "hkchengrex/Tracking-Anything-with-DEVA"
"kadirnar/segment-anything-video" -> "gaomingqi/Track-Anything"
"kadirnar/segment-anything-video" -> "fudan-zvg/Semantic-Segment-Anything"
"kadirnar/segment-anything-video" -> "Hedlen/awesome-segment-anything"
"kadirnar/segment-anything-video" -> "Curt-Park/segment-anything-with-clip"
"kadirnar/segment-anything-video" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"kadirnar/segment-anything-video" -> "anuragxel/salt"
"kadirnar/segment-anything-video" -> "hkchengrex/XMem" ["e"=1]
"kadirnar/segment-anything-video" -> "JerryX1110/awesome-segment-anything-extensions"
"kadirnar/segment-anything-video" -> "SysCV/sam-hq"
"kadirnar/segment-anything-video" -> "baaivision/Painter"
"kadirnar/segment-anything-video" -> "RockeyCoss/Prompt-Segment-Anything"
"SkalskiP/top-cvpr-2023-papers" -> "SkalskiP/top-cvpr-2024-papers"
"SkalskiP/top-cvpr-2023-papers" -> "voxel51/papers-with-data"
"SkalskiP/top-cvpr-2023-papers" -> "SkalskiP/awesome-foundation-and-multimodal-models"
"SkalskiP/top-cvpr-2023-papers" -> "SkalskiP/awesome-chatgpt-code-interpreter-experiments" ["e"=1]
"SkalskiP/top-cvpr-2023-papers" -> "VietnamAIHub/Vietnamese_LLMs" ["e"=1]
"facebookresearch/VLPart" -> "Saiyan-World/grounded-segment-any-parts"
"facebookresearch/VLPart" -> "IDEA-Research/OpenSeeD"
"facebookresearch/VLPart" -> "OpenRobotLab/OV_PARTS"
"facebookresearch/VLPart" -> "facebookresearch/paco"
"facebookresearch/VLPart" -> "TACJu/PartImageNet"
"facebookresearch/VLPart" -> "jshilong/GPT4RoI" ["e"=1]
"facebookresearch/VLPart" -> "UX-Decoder/Semantic-SAM"
"MendelXu/SAN" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"MendelXu/SAN" -> "MendelXu/zsseg.baseline"
"MendelXu/SAN" -> "bytedance/fc-clip"
"MendelXu/SAN" -> "facebookresearch/ov-seg"
"MendelXu/SAN" -> "NVlabs/ODISE"
"MendelXu/SAN" -> "jianzongwu/Awesome-Open-Vocabulary"
"MendelXu/SAN" -> "xb534/SED"
"MendelXu/SAN" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"MendelXu/SAN" -> "IDEA-Research/OpenSeeD"
"MendelXu/SAN" -> "dingjiansw101/ZegFormer"
"MendelXu/SAN" -> "wusize/CLIPSelf"
"MendelXu/SAN" -> "chongzhou96/MaskCLIP"
"MendelXu/SAN" -> "berkeley-hipie/HIPIE"
"MendelXu/SAN" -> "NiFangBaAGe/Explicit-Visual-Prompt" ["e"=1]
"MendelXu/SAN" -> "bytedance/FreeSeg"
"ytongbai/LVM" -> "baaivision/Painter" ["e"=1]
"ytongbai/LVM" -> "mlfoundations/open_flamingo" ["e"=1]
"gaomingqi/Awesome-Video-Object-Segmentation" -> "yformer/EfficientTAM" ["e"=1]
"Curt-Park/segment-anything-with-clip" -> "MaybeShewill-CV/segment-anything-u-specify"
"Curt-Park/segment-anything-with-clip" -> "PengtaoJiang/Segment-Anything-CLIP"
"Curt-Park/segment-anything-with-clip" -> "RockeyCoss/Prompt-Segment-Anything"
"Curt-Park/segment-anything-with-clip" -> "annotation-ai/technical-demo"
"Curt-Park/segment-anything-with-clip" -> "aim-uofa/Matcher"
"Curt-Park/segment-anything-with-clip" -> "maxi-w/CLIP-SAM"
"Curt-Park/segment-anything-with-clip" -> "kadirnar/segment-anything-video"
"Asad-Ismail/Grounding-Dino-FineTuning" -> "longzw1997/Open-GroundingDino"
"Asad-Ismail/Grounding-Dino-FineTuning" -> "Dongdong-d/GroundingDino-Finetuning"
"Vision-CAIR/ChatCaptioner" -> "showlab/Image2Paragraph"
"Vision-CAIR/ChatCaptioner" -> "showlab/VLog"
"Vision-CAIR/ChatCaptioner" -> "kohjingyu/fromage"
"Vision-CAIR/ChatCaptioner" -> "antoyang/FrozenBiLM" ["e"=1]
"Vision-CAIR/ChatCaptioner" -> "microsoft/LAVENDER" ["e"=1]
"Vision-CAIR/ChatCaptioner" -> "JialianW/GRiT" ["e"=1]
"Vision-CAIR/ChatCaptioner" -> "OpenGVLab/Multi-Modality-Arena" ["e"=1]
"Vision-CAIR/ChatCaptioner" -> "UARK-AICV/VLTinT" ["e"=1]
"luca-medeiros/lightning-sam" -> "ziqi-jin/finetune-anything"
"luca-medeiros/lightning-sam" -> "tianrun-chen/SAM-Adapter-PyTorch"
"luca-medeiros/lightning-sam" -> "bhpfelix/segment-anything-finetuner"
"luca-medeiros/lightning-sam" -> "hitachinsk/SAMed" ["e"=1]
"luca-medeiros/lightning-sam" -> "SuperMedIntel/Medical-SAM-Adapter" ["e"=1]
"luca-medeiros/lightning-sam" -> "ZrrSkywalker/Personalize-SAM"
"luca-medeiros/lightning-sam" -> "luca-medeiros/lang-segment-anything"
"luca-medeiros/lightning-sam" -> "UX-Decoder/Semantic-SAM"
"luca-medeiros/lightning-sam" -> "liliu-avril/Awesome-Segment-Anything"
"luca-medeiros/lightning-sam" -> "fudan-zvg/Semantic-Segment-Anything"
"luca-medeiros/lightning-sam" -> "WangRongsheng/SAM-fine-tune"
"luca-medeiros/lightning-sam" -> "HarborYuan/ovsam"
"luca-medeiros/lightning-sam" -> "xinghaochen/TinySAM"
"luca-medeiros/lightning-sam" -> "RockeyCoss/Prompt-Segment-Anything"
"luca-medeiros/lightning-sam" -> "SysCV/sam-hq"
"BooHwang/segment_anything_tensorrt" -> "mingj2021/segment-anything-tensorrt"
"BooHwang/segment_anything_tensorrt" -> "zhudongwork/SAM_TensorRT"
"BooHwang/segment_anything_tensorrt" -> "ChuRuaNh0/FastSam_Awsome_TensorRT"
"BooHwang/segment_anything_tensorrt" -> "ItayElam/SegmentAnything-TensorRT"
"ziqi-jin/finetune-anything" -> "luca-medeiros/lightning-sam"
"ziqi-jin/finetune-anything" -> "tianrun-chen/SAM-Adapter-PyTorch"
"ziqi-jin/finetune-anything" -> "hitachinsk/SAMed" ["e"=1]
"ziqi-jin/finetune-anything" -> "mazurowski-lab/finetune-SAM"
"ziqi-jin/finetune-anything" -> "UX-Decoder/Semantic-SAM"
"ziqi-jin/finetune-anything" -> "SuperMedIntel/Medical-SAM-Adapter" ["e"=1]
"ziqi-jin/finetune-anything" -> "KyanChen/RSPrompter" ["e"=1]
"ziqi-jin/finetune-anything" -> "ZrrSkywalker/Personalize-SAM"
"ziqi-jin/finetune-anything" -> "WangRongsheng/SAM-fine-tune"
"ziqi-jin/finetune-anything" -> "SysCV/sam-hq"
"ziqi-jin/finetune-anything" -> "fudan-zvg/Semantic-Segment-Anything"
"ziqi-jin/finetune-anything" -> "liliu-avril/Awesome-Segment-Anything"
"ziqi-jin/finetune-anything" -> "Hedlen/awesome-segment-anything"
"ziqi-jin/finetune-anything" -> "bhpfelix/segment-anything-finetuner"
"ziqi-jin/finetune-anything" -> "RockeyCoss/Prompt-Segment-Anything"
"voxel51/voxelgpt" -> "voxel51/fiftyone-docs-search"
"voxel51/voxelgpt" -> "voxel51/fiftyone-examples"
"voxel51/voxelgpt" -> "jacobmarks/zero-shot-prediction-plugin"
"voxel51/voxelgpt" -> "voxel51/fiftyone-plugins"
"voxel51/voxelgpt" -> "voxel51/papers-with-data"
"flutter/super_dash" -> "VGVentures/dash_ai_search"
"flutter/super_dash" -> "heroiclabs/nakama-dart"
"flutter/super_dash" -> "invertase/globe" ["e"=1]
"flutter/super_dash" -> "VGVentures/slide_puzzle" ["e"=1]
"zhenyuw16/UniDetector" -> "microsoft/RegionCLIP"
"zhenyuw16/UniDetector" -> "IDEA-Research/OpenSeeD"
"zhenyuw16/UniDetector" -> "zhenyuw16/Uni3DETR" ["e"=1]
"zhenyuw16/UniDetector" -> "mmaaz60/mvits_for_class_agnostic_od"
"zhenyuw16/UniDetector" -> "wusize/ovdet"
"zhenyuw16/UniDetector" -> "YifanXu74/MQ-Det" ["e"=1]
"zhenyuw16/UniDetector" -> "yuhangzang/OV-DETR"
"zhenyuw16/UniDetector" -> "orrzohar/PROB"
"zhenyuw16/UniDetector" -> "tgxs002/CORA"
"zhenyuw16/UniDetector" -> "fcjian/PromptDet"
"zhenyuw16/UniDetector" -> "akshitac8/OW-DETR"
"zhenyuw16/UniDetector" -> "microsoft/GLIP"
"zhenyuw16/UniDetector" -> "Sense-X/Co-DETR" ["e"=1]
"zhenyuw16/UniDetector" -> "facebookresearch/Detic"
"zhenyuw16/UniDetector" -> "longzw1997/Open-GroundingDino"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "jianzongwu/Awesome-Open-Vocabulary"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "IDEA-Research/awesome-detection-transformer"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "lxtGH/Tube-Link" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "lxtGH/OMG-Seg" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "liliu-avril/Awesome-Segment-Anything"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "facebookresearch/MaskFormer"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "Yangzhangcst/Transformer-in-Computer-Vision" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "lxtGH/Video-K-Net" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "SHI-Labs/OneFormer"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "facebookresearch/Mask2Former"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "czczup/ViT-Adapter"
"lxtGH/Awesome-Segmentation-With-Transformer" -> "magic-research/Sa2VA" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" ["e"=1]
"lxtGH/Awesome-Segmentation-With-Transformer" -> "LiheYoung/UniMatch" ["e"=1]
"segments-ai/panoptic-segment-anything" -> "berkeley-hipie/HIPIE"
"segments-ai/panoptic-segment-anything" -> "timojl/clipseg"
"segments-ai/panoptic-segment-anything" -> "fudan-zvg/Semantic-Segment-Anything"
"segments-ai/panoptic-segment-anything" -> "Saiyan-World/grounded-segment-any-parts"
"NiFangBaAGe/Explicit-Visual-Prompt" -> "MendelXu/SAN" ["e"=1]
"NVIDIA-AI-IOT/jetson-intro-to-distillation" -> "NVIDIA-AI-IOT/clip-distillation"
"NVIDIA-AI-IOT/jetson-intro-to-distillation" -> "NVIDIA-AI-IOT/nanosam"
"NVIDIA-AI-IOT/jetson-intro-to-distillation" -> "NVIDIA-AI-IOT/nanoowl"
"xmed-lab/CLIP_Surgery" -> "linyq2117/CLIP-ES" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "chongzhou96/MaskCLIP"
"xmed-lab/CLIP_Surgery" -> "xmed-lab/CLIPN" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"xmed-lab/CLIP_Surgery" -> "maxi-w/CLIP-SAM"
"xmed-lab/CLIP_Surgery" -> "MendelXu/zsseg.baseline"
"xmed-lab/CLIP_Surgery" -> "OpenGVLab/CaFo" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "ByChelsea/CLIP-AD" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "linyq2117/TagCLIP" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "WalBouss/GEM"
"xmed-lab/CLIP_Surgery" -> "wangf3014/SCLIP"
"xmed-lab/CLIP_Surgery" -> "azshue/TPT" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "MendelXu/SAN"
"xmed-lab/CLIP_Surgery" -> "muzairkhattak/PromptSRC" ["e"=1]
"xmed-lab/CLIP_Surgery" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"bytedance/fc-clip" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"bytedance/fc-clip" -> "MendelXu/SAN"
"bytedance/fc-clip" -> "xb534/SED"
"bytedance/fc-clip" -> "bytedance/FreeSeg"
"bytedance/fc-clip" -> "bytedance/OmniScient-Model"
"bytedance/fc-clip" -> "dingjiansw101/ZegFormer"
"bytedance/fc-clip" -> "IDEA-Research/OpenSeeD"
"bytedance/fc-clip" -> "wysoczanska/clip_dinoiser"
"bytedance/fc-clip" -> "jiaosiyu1999/MAFT-Plus"
"bytedance/fc-clip" -> "mlpc-ucsd/MaskCLIP"
"bytedance/fc-clip" -> "VIPSeg-Dataset/VIPSeg-Dataset" ["e"=1]
"bytedance/fc-clip" -> "Beckschen/ViTamin"
"bytedance/fc-clip" -> "facebookresearch/ov-seg"
"bytedance/fc-clip" -> "MendelXu/zsseg.baseline"
"bytedance/fc-clip" -> "bytedance/kmax-deeplab"
"jiaosiyu1999/MAFT" -> "jiaosiyu1999/MAFT-Plus"
"jiaosiyu1999/MAFT" -> "Xujxyang/OpenTrans"
"uncbiag/Awesome-Foundation-Models" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "liliu-avril/Awesome-Segment-Anything" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "Hedlen/awesome-segment-anything" ["e"=1]
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/nanosam"
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/ROS2-NanoOWL"
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/jetson-intro-to-distillation"
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/deepstream_parallel_inference_app" ["e"=1]
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/mmj_genai"
"NVIDIA-AI-IOT/nanoowl" -> "NVIDIA-AI-IOT/clip-distillation"
"NVIDIA-AI-IOT/nanoowl" -> "stevebottos/owl-vit-object-detection"
"AIDajiangtang/Superpoint-LightGlue-Image-Stiching" -> "OroChippw/SegmentAnything-OnnxRunner" ["e"=1]
"protectai/modelscan" -> "protectai/ai-exploits" ["e"=1]
"OptimalScale/DetGPT" -> "microsoft/GLIP" ["e"=1]
"OptimalScale/DetGPT" -> "IDEA-Research/OpenSeeD" ["e"=1]
"OptimalScale/DetGPT" -> "microsoft/X-Decoder" ["e"=1]
"OptimalScale/DetGPT" -> "microsoft/RegionCLIP" ["e"=1]
"OptimalScale/DetGPT" -> "IDEA-Research/GroundingDINO" ["e"=1]
"OptimalScale/DetGPT" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection" ["e"=1]
"OptimalScale/DetGPT" -> "Saiyan-World/grounded-segment-any-parts" ["e"=1]
"vietanhdev/samexporter" -> "ibaiGorordo/ONNX-SAM2-Segment-Anything"
"vietanhdev/samexporter" -> "axinc-ai/segment-anything-2"
"vietanhdev/samexporter" -> "OroChippw/SegmentAnything-OnnxRunner"
"vietanhdev/samexporter" -> "Aimol-l/SAM2Export"
"vietanhdev/samexporter" -> "Aimol-l/OrtInference"
"vietanhdev/samexporter" -> "ryouchinsa/sam-cpp-macos"
"vietanhdev/samexporter" -> "AndreyGermanov/sam_onnx_full_export"
"vietanhdev/samexporter" -> "dinglufe/segment-anything-cpp-wrapper"
"vietanhdev/samexporter" -> "chongzhou96/EdgeSAM"
"vietanhdev/samexporter" -> "AIDajiangtang/Segment-Anything-CPP"
"dinglufe/segment-anything-cpp-wrapper" -> "Aimol-l/OrtInference"
"dinglufe/segment-anything-cpp-wrapper" -> "ryouchinsa/sam-cpp-macos"
"dinglufe/segment-anything-cpp-wrapper" -> "AIDajiangtang/Segment-Anything-CPP"
"dinglufe/segment-anything-cpp-wrapper" -> "OroChippw/SegmentAnything-OnnxRunner"
"dinglufe/segment-anything-cpp-wrapper" -> "mingj2021/segment-anything-tensorrt"
"dinglufe/segment-anything-cpp-wrapper" -> "vietanhdev/samexporter"
"dinglufe/segment-anything-cpp-wrapper" -> "zhudongwork/SAM_TensorRT"
"dinglufe/segment-anything-cpp-wrapper" -> "chongzhou96/EdgeSAM"
"dinglufe/segment-anything-cpp-wrapper" -> "ChuRuaNh0/FastSam_Awsome_TensorRT"
"haibingtown/segment-matting" -> "MiscellaneousStuff/meta-sam-demo"
"5663015/segment_anything_webui" -> "dogeplusplus/sam-at-home"
"5663015/segment_anything_webui" -> "wx-chevalier/segment-anything-web-ui"
"bytedance/kmax-deeplab" -> "TACJu/Axial-VS"
"wusize/CLIPSelf" -> "wangf3014/SCLIP"
"wusize/CLIPSelf" -> "wusize/CLIM"
"wusize/CLIPSelf" -> "mala-lab/SIC-CADS"
"wusize/CLIPSelf" -> "mc-lan/ProxyCLIP"
"bhpfelix/segment-anything-finetuner" -> "luca-medeiros/lightning-sam"
"haochenheheda/segment-anything-annotator" -> "anuragxel/salt"
"haochenheheda/segment-anything-annotator" -> "zhouayi/SAM-Tool"
"haochenheheda/segment-anything-annotator" -> "yatengLG/ISAT_with_segment_anything"
"haochenheheda/segment-anything-annotator" -> "haochenheheda/LVVIS" ["e"=1]
"haochenheheda/segment-anything-annotator" -> "fudan-zvg/Semantic-Segment-Anything"
"haochenheheda/segment-anything-annotator" -> "KyanChen/RSPrompter" ["e"=1]
"haochenheheda/segment-anything-annotator" -> "royerlab/napari-segment-anything" ["e"=1]
"cvlab-kaist/CAT-Seg" -> "MendelXu/SAN" ["e"=1]
"cvlab-kaist/CAT-Seg" -> "xb534/SED" ["e"=1]
"cvlab-kaist/CAT-Seg" -> "bytedance/fc-clip" ["e"=1]
"bytedance/FreeSeg" -> "bytedance/fc-clip"
"bytedance/FreeSeg" -> "mlpc-ucsd/MaskCLIP"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "jianzongwu/Awesome-Open-Vocabulary"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "Charles-Xie/awesome-described-object-detection"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "wusize/ovdet"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "clin1223/VLDet"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "IDEA-Research/OpenSeeD"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "dyabel/detpro"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "FoundationVision/GenerateU"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "alirezazareian/ovr-cnn"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "tgxs002/CORA"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "CVMI-Lab/CoDet"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "YifanXu74/MQ-Det" ["e"=1]
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "mlzxy/devit"
"witnessai/Awesome-Open-Vocabulary-Object-Detection" -> "longzw1997/Open-GroundingDino"
"AIDajiangtang/Segment-Anything-CSharp" -> "AIDajiangtang/Segment-Anything-CPP"
"AIDajiangtang/Segment-Anything-CSharp" -> "thislookshard/SamSharp"
"Saiyan-World/grounded-segment-any-parts" -> "facebookresearch/VLPart"
"Saiyan-World/grounded-segment-any-parts" -> "OpenRobotLab/OV_PARTS"
"Saiyan-World/grounded-segment-any-parts" -> "jshilong/GPT4RoI" ["e"=1]
"Saiyan-World/grounded-segment-any-parts" -> "berkeley-hipie/HIPIE"
"Saiyan-World/grounded-segment-any-parts" -> "IDEA-Research/OpenSeeD"
"Saiyan-World/grounded-segment-any-parts" -> "RockeyCoss/Prompt-Segment-Anything"
"Kingfish404/segment-anything-webui" -> "5663015/segment_anything_webui"
"Kingfish404/segment-anything-webui" -> "lujiazho/SegDrawer"
"Kingfish404/segment-anything-webui" -> "MiscellaneousStuff/meta-sam-demo"
"Kingfish404/segment-anything-webui" -> "LarkMi/segment_anything_streamlit_webui"
"UCSC-VLAA/CLIPA" -> "UCSC-VLAA/Recap-DataComp-1B"
"UCSC-VLAA/CLIPA" -> "LijieFan/LaCLIP"
"UCSC-VLAA/CLIPA" -> "OliverRensu/D-iGPT"
"VisionXLab/sam-mmrotate" -> "liuyanyi/sam-with-mmdet"
"VisionXLab/sam-mmrotate" -> "VisionXLab/STAR-MMRotate" ["e"=1]
"aim-uofa/Matcher" -> "ZrrSkywalker/Personalize-SAM"
"aim-uofa/Matcher" -> "aim-uofa/SINE" ["e"=1]
"aim-uofa/Matcher" -> "syp2ysy/VRP-SAM" ["e"=1]
"aim-uofa/Matcher" -> "baaivision/Painter"
"aim-uofa/Matcher" -> "liliu-avril/Awesome-Segment-Anything"
"aim-uofa/Matcher" -> "UX-Decoder/Semantic-SAM"
"aim-uofa/Matcher" -> "MendelXu/SAN"
"aim-uofa/Matcher" -> "KyanChen/RSPrompter" ["e"=1]
"aim-uofa/Matcher" -> "SysCV/sam-hq"
"aim-uofa/Matcher" -> "UX-Decoder/DINOv"
"aim-uofa/Matcher" -> "hitachinsk/SAMed" ["e"=1]
"aim-uofa/Matcher" -> "aim-uofa/SegPrompt" ["e"=1]
"aim-uofa/Matcher" -> "IDEA-Research/OpenSeeD"
"aim-uofa/Matcher" -> "Hedlen/awesome-segment-anything"
"aim-uofa/Matcher" -> "Curt-Park/segment-anything-with-clip"
"OroChippw/SegmentAnything-OnnxRunner" -> "AIDajiangtang/Segment-Anything-CPP"
"shikras/d-cube" -> "Charles-Xie/awesome-described-object-detection"
"shikras/d-cube" -> "Charles-Xie/CQL" ["e"=1]
"tgxs002/CORA" -> "wusize/ovdet"
"tgxs002/CORA" -> "microsoft/RegionCLIP"
"tgxs002/CORA" -> "alirezazareian/ovr-cnn"
"tgxs002/CORA" -> "yuhangzang/OV-DETR"
"tgxs002/CORA" -> "rohit901/cooperative-foundational-models"
"tgxs002/CORA" -> "hanoonaR/object-centric-ovd"
"ChuRuaNh0/FastSam_Awsome_TensorRT" -> "BooHwang/segment_anything_tensorrt"
"ChuRuaNh0/FastSam_Awsome_TensorRT" -> "mingj2021/segment-anything-tensorrt"
"IDEA-Research/Stable-DINO" -> "Atten4Vis/MS-DETR"
"IDEA-Research/Stable-DINO" -> "HDETR/H-Deformable-DETR"
"IDEA-Research/Stable-DINO" -> "impiga/Plain-DETR"
"IDEA-Research/Stable-DINO" -> "FelixCaae/AlignDETR"
"IDEA-Research/Stable-DINO" -> "IDEA-Research/Lite-DETR"
"IDEA-Research/Stable-DINO" -> "Fangyi-Chen/SQR"
"IDEA-Research/Stable-DINO" -> "IDEA-Research/OpenSeeD"
"IDEA-Research/Stable-DINO" -> "jozhang97/DETA"
"IDEA-Research/Stable-DINO" -> "Atten4Vis/GroupDETR"
"IDEA-Research/Stable-DINO" -> "IDEA-Research/MP-Former" ["e"=1]
"MizzleAa/segment-anything-demo-react-fastapi" -> "wx-chevalier/segment-anything-web-ui"
"MaybeShewill-CV/segment-anything-u-specify" -> "Curt-Park/segment-anything-with-clip"
"RockeyCoss/Prompt-Segment-Anything" -> "liuyanyi/sam-with-mmdet"
"RockeyCoss/Prompt-Segment-Anything" -> "VisionXLab/sam-mmrotate"
"thislookshard/SamSharp" -> "UnaNancyOwen/MobileSAM-Unity"
"mingj2021/segment-anything-tensorrt" -> "BooHwang/segment_anything_tensorrt"
"mingj2021/segment-anything-tensorrt" -> "OroChippw/SegmentAnything-OnnxRunner"
"mingj2021/segment-anything-tensorrt" -> "ChuRuaNh0/FastSam_Awsome_TensorRT"
"dhg-wei/DeCap" -> "DavidHuji/CapDec"
"dhg-wei/DeCap" -> "YoadTew/zero-shot-video-to-text"
"dhg-wei/DeCap" -> "junyangwang0410/Knight"
"ryouchinsa/sam-cpp-macos" -> "Aimol-l/SAM2Export"
"ryouchinsa/sam-cpp-macos" -> "Aimol-l/OrtInference"
"ryouchinsa/sam-cpp-macos" -> "dinglufe/segment-anything-cpp-wrapper"
"dogeplusplus/sam-at-home" -> "5663015/segment_anything_webui"
"jacobmarks/text-to-image" -> "jacobmarks/ten-weeks-of-plugins"
"NVIDIA-AI-IOT/clip-distillation" -> "NVIDIA-AI-IOT/jetson-intro-to-distillation"
"voxel51/papers-with-data" -> "voxel51/fiftyone-plugins"
"voxel51/papers-with-data" -> "allenleetc/model-comparison"
"voxel51/papers-with-data" -> "jacobmarks/ten-weeks-of-plugins"
"voxel51/papers-with-data" -> "jacobmarks/zero-shot-prediction-plugin"
"kaist-dmlab/CrossMatch" -> "kaist-dmlab/RECURVE"
"stazizov/ViT_CIFAR100" -> "t0efL/2nd-place-solution-Digital-Peter"
"LumenPallidium/jepa" -> "FalsoMoralista/ijepa"
"jacobmarks/zero-shot-prediction-plugin" -> "jacobmarks/active-learning-plugin"
"jacobmarks/zero-shot-prediction-plugin" -> "allenleetc/model-comparison"
"jacobmarks/active-learning-plugin" -> "allenleetc/model-comparison"
"AIDajiangtang/Segment-Anything-CPP" -> "OroChippw/SegmentAnything-OnnxRunner"
"AIDajiangtang/Segment-Anything-CPP" -> "AIDajiangtang/Segment-Anything-CSharp"
"TMIU/iTFA" -> "binyisu/FSOSOD"
"bpc-clone/bpc_chrome_support" -> "everywall/ladder" ["e"=1]
"MultimediaTechLab/YOLO" -> "Peterande/D-FINE"
"MultimediaTechLab/YOLO" -> "hank-ai/darknet"
"MultimediaTechLab/YOLO" -> "lyuwenyu/RT-DETR"
"MultimediaTechLab/YOLO" -> "ShihuaHuang95/DEIM"
"MultimediaTechLab/YOLO" -> "WongKinYiu/yolov9"
"MultimediaTechLab/YOLO" -> "roboflow/rf-detr"
"MultimediaTechLab/YOLO" -> "Deci-AI/super-gradients"
"MultimediaTechLab/YOLO" -> "obss/sahi" ["e"=1]
"MultimediaTechLab/YOLO" -> "autodistill/autodistill"
"MultimediaTechLab/YOLO" -> "THU-MIG/yoloe"
"MultimediaTechLab/YOLO" -> "Megvii-BaseDetection/YOLOX" ["e"=1]
"MultimediaTechLab/YOLO" -> "sunsmarterjie/yolov12"
"MultimediaTechLab/YOLO" -> "Atten4Vis/LW-DETR"
"MultimediaTechLab/YOLO" -> "roboflow/trackers"
"MultimediaTechLab/YOLO" -> "PINTO0309/PINTO_model_zoo" ["e"=1]
"LargeWorldModel/LWM" -> "facebookresearch/jepa" ["e"=1]
"KindXiaoming/pykan" -> "facebookresearch/sam2" ["e"=1]
"OpenGVLab/InternVL" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/InternVL" -> "mlfoundations/open_clip" ["e"=1]
"WongKinYiu/yolov9" -> "THU-MIG/yolov10"
"WongKinYiu/yolov9" -> "WongKinYiu/yolov7" ["e"=1]
"WongKinYiu/yolov9" -> "AILab-CVC/YOLO-World"
"WongKinYiu/yolov9" -> "ultralytics/ultralytics" ["e"=1]
"WongKinYiu/yolov9" -> "lyuwenyu/RT-DETR"
"WongKinYiu/yolov9" -> "meituan/YOLOv6" ["e"=1]
"WongKinYiu/yolov9" -> "Megvii-BaseDetection/YOLOX" ["e"=1]
"WongKinYiu/yolov9" -> "CVHub520/X-AnyLabeling"
"WongKinYiu/yolov9" -> "z1069614715/objectdetection_script" ["e"=1]
"WongKinYiu/yolov9" -> "google/gemma.cpp" ["e"=1]
"WongKinYiu/yolov9" -> "mikel-brostrom/boxmot" ["e"=1]
"WongKinYiu/yolov9" -> "open-mmlab/mmyolo" ["e"=1]
"WongKinYiu/yolov9" -> "Deci-AI/super-gradients"
"WongKinYiu/yolov9" -> "IDEA-Research/GroundingDINO"
"WongKinYiu/yolov9" -> "obss/sahi" ["e"=1]
"google-deepmind/gemma" -> "facebookresearch/jepa" ["e"=1]
"Genesis-Embodied-AI/Genesis" -> "facebookresearch/sam2" ["e"=1]
"google/gemma_pytorch" -> "facebookresearch/jepa" ["e"=1]
"yformer/EfficientSAM" -> "UX-Decoder/Semantic-SAM"
"yformer/EfficientSAM" -> "ChaoningZhang/MobileSAM"
"yformer/EfficientSAM" -> "mit-han-lab/efficientvit"
"yformer/EfficientSAM" -> "SysCV/sam-hq"
"yformer/EfficientSAM" -> "chongzhou96/EdgeSAM"
"yformer/EfficientSAM" -> "AILab-CVC/YOLO-World"
"yformer/EfficientSAM" -> "tianrun-chen/SAM-Adapter-PyTorch"
"yformer/EfficientSAM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"yformer/EfficientSAM" -> "HarborYuan/ovsam"
"yformer/EfficientSAM" -> "CASIA-IVA-Lab/FastSAM"
"yformer/EfficientSAM" -> "IDEA-Research/T-Rex"
"yformer/EfficientSAM" -> "IDEA-Research/GroundingDINO"
"yformer/EfficientSAM" -> "siyuanliii/masa"
"yformer/EfficientSAM" -> "liliu-avril/Awesome-Segment-Anything"
"yformer/EfficientSAM" -> "IDEA-Research/Grounded-Segment-Anything"
"flutter/games" -> "pytorch-labs/segment-anything-fast"
"flutter/games" -> "run-llama/create_llama_projects"
"flutter/games" -> "protectai/ai-exploits"
"flutter/games" -> "Brendan-Kirtlan/Video-Encode"
"flutter/games" -> "flutter/super_dash"
"flutter/games" -> "tldraw/make-real-starter"
"flutter/games" -> "twostraws/Inferno" ["e"=1]
"flutter/games" -> "flutter/io_flip" ["e"=1]
"flutter/games" -> "flame-engine/awesome-flame" ["e"=1]
"flutter/games" -> "invertase/melos" ["e"=1]
"flutter/games" -> "shorebirdtech/shorebird" ["e"=1]
"flutter/games" -> "heroiclabs/nakama-dart"
"flutter/games" -> "everywall/ladder"
"flutter/games" -> "flutter/packages" ["e"=1]
"flutter/games" -> "flutter/news_toolkit" ["e"=1]
"everywall/ladder" -> "wasi-master/13ft" ["e"=1]
"everywall/ladder" -> "protectai/ai-exploits"
"everywall/ladder" -> "tldraw/make-real-starter"
"everywall/ladder" -> "Brendan-Kirtlan/Video-Encode"
"everywall/ladder" -> "pytorch-labs/segment-anything-fast"
"everywall/ladder" -> "linkwarden/linkwarden" ["e"=1]
"everywall/ladder" -> "Ftindy/IPTV-URL" ["e"=1]
"everywall/ladder" -> "chenxwh/insanely-fast-whisper" ["e"=1]
"everywall/ladder" -> "Xatta-Trone/medium-parser-extension" ["e"=1]
"everywall/ladder" -> "run-llama/create_llama_projects"
"everywall/ladder" -> "flutter/games"
"everywall/ladder" -> "BuilderIO/gpt-crawler" ["e"=1]
"everywall/ladder" -> "bpc-clone/bpc_chrome_support" ["e"=1]
"everywall/ladder" -> "yihong0618/bilingual_book_maker" ["e"=1]
"everywall/ladder" -> "vvbbnn00/WARP-Clash-API" ["e"=1]
"tldraw/make-real" -> "tldraw/make-real-starter" ["e"=1]
"roboflow/webcamGPT" -> "roboflow/awesome-openai-vision-api-experiments"
"ishan0102/vimGPT" -> "roboflow/awesome-openai-vision-api-experiments" ["e"=1]
"iyaja/llama-fs" -> "THU-MIG/yolov10" ["e"=1]
"roboflow/maestro" -> "roboflow/rf-detr"
"roboflow/maestro" -> "roboflow/inference"
"roboflow/maestro" -> "roboflow/awesome-openai-vision-api-experiments"
"roboflow/maestro" -> "merveenoyan/smol-vision" ["e"=1]
"roboflow/maestro" -> "SkalskiP/vlms-zero-to-hero" ["e"=1]
"roboflow/maestro" -> "roboflow/notebooks" ["e"=1]
"roboflow/maestro" -> "autodistill/autodistill"
"roboflow/maestro" -> "roboflow/trackers"
"roboflow/maestro" -> "neural-maze/ava-whatsapp-agent-course" ["e"=1]
"roboflow/maestro" -> "tjmlabs/ColiVara" ["e"=1]
"roboflow/maestro" -> "vikhyat/moondream" ["e"=1]
"roboflow/maestro" -> "THU-MIG/yoloe"
"roboflow/maestro" -> "roboflow/supervision" ["e"=1]
"roboflow/maestro" -> "AnswerDotAI/byaldi" ["e"=1]
"roboflow/maestro" -> "Lightning-AI/LitServe" ["e"=1]
"dvlab-research/MGM" -> "baaivision/EVA" ["e"=1]
"hkchengrex/Cutie" -> "hkchengrex/Tracking-Anything-with-DEVA" ["e"=1]
"hkchengrex/Cutie" -> "z-x-yang/Segment-and-Track-Anything" ["e"=1]
"hkchengrex/Cutie" -> "SysCV/sam-pt" ["e"=1]
"hkchengrex/Cutie" -> "siyuanliii/masa" ["e"=1]
"hkchengrex/Cutie" -> "yformer/EfficientTAM" ["e"=1]
"tldraw/draw-fast" -> "tldraw/make-real-starter" ["e"=1]
"merveenoyan/smol-vision" -> "roboflow/maestro" ["e"=1]
"merveenoyan/smol-vision" -> "google-research/big_vision" ["e"=1]
"LiheYoung/Depth-Anything" -> "facebookresearch/dinov2" ["e"=1]
"LiheYoung/Depth-Anything" -> "facebookresearch/sam2" ["e"=1]
"LiheYoung/Depth-Anything" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"LiheYoung/Depth-Anything" -> "IDEA-Research/GroundingDINO" ["e"=1]
"McGill-NLP/llm2vec" -> "microsoft/LLM2CLIP" ["e"=1]
"khanrc/honeybee" -> "kakaobrain/noc" ["e"=1]
"khanrc/honeybee" -> "kakaobrain/coyo-dataset" ["e"=1]
"google/gemma.cpp" -> "WongKinYiu/yolov9" ["e"=1]
"AILab-CVC/UniRepLKNet" -> "OpenGVLab/InternImage" ["e"=1]
"facebookresearch/jepa" -> "facebookresearch/ijepa"
"facebookresearch/jepa" -> "facebookresearch/DiT" ["e"=1]
"facebookresearch/jepa" -> "LargeWorldModel/LWM" ["e"=1]
"facebookresearch/jepa" -> "facebookresearch/dinov2"
"facebookresearch/jepa" -> "karpathy/minbpe" ["e"=1]
"facebookresearch/jepa" -> "google-research/big_vision"
"facebookresearch/jepa" -> "facebookresearch/schedule_free" ["e"=1]
"facebookresearch/jepa" -> "google/gemma_pytorch" ["e"=1]
"facebookresearch/jepa" -> "FoundationVision/VAR" ["e"=1]
"facebookresearch/jepa" -> "PKU-YuanGroup/Video-LLaVA" ["e"=1]
"facebookresearch/jepa" -> "Vchitect/Latte" ["e"=1]
"facebookresearch/jepa" -> "facebookresearch/ImageBind"
"facebookresearch/jepa" -> "PKU-YuanGroup/Open-Sora-Plan" ["e"=1]
"facebookresearch/jepa" -> "NVIDIA/Cosmos-Tokenizer" ["e"=1]
"facebookresearch/jepa" -> "Stability-AI/StableCascade" ["e"=1]
"czg1225/SlimSAM" -> "czg1225/Awesome-Efficient-Segment-Anything"
"czg1225/SlimSAM" -> "xinghaochen/TinySAM"
"czg1225/SlimSAM" -> "czg1225/CoDe" ["e"=1]
"czg1225/SlimSAM" -> "chongzhou96/EdgeSAM"
"czg1225/SlimSAM" -> "VainF/Isomorphic-Pruning" ["e"=1]
"czg1225/SlimSAM" -> "chengtao-lv/PTQ4SAM"
"czg1225/SlimSAM" -> "czg1225/AsyncDiff" ["e"=1]
"Meituan-AutoML/MobileVLM" -> "chongzhou96/EdgeSAM" ["e"=1]
"AILab-CVC/YOLO-World" -> "IDEA-Research/GroundingDINO"
"AILab-CVC/YOLO-World" -> "lyuwenyu/RT-DETR"
"AILab-CVC/YOLO-World" -> "WongKinYiu/yolov9"
"AILab-CVC/YOLO-World" -> "IDEA-Research/Grounded-Segment-Anything"
"AILab-CVC/YOLO-World" -> "IDEA-Research/T-Rex"
"AILab-CVC/YOLO-World" -> "facebookresearch/sam2"
"AILab-CVC/YOLO-World" -> "THU-MIG/yolov10"
"AILab-CVC/YOLO-World" -> "microsoft/GLIP"
"AILab-CVC/YOLO-World" -> "CVHub520/X-AnyLabeling"
"AILab-CVC/YOLO-World" -> "yformer/EfficientSAM"
"AILab-CVC/YOLO-World" -> "LiheYoung/Depth-Anything" ["e"=1]
"AILab-CVC/YOLO-World" -> "facebookresearch/dinov2"
"AILab-CVC/YOLO-World" -> "OpenGVLab/InternVL" ["e"=1]
"AILab-CVC/YOLO-World" -> "open-mmlab/mmyolo" ["e"=1]
"AILab-CVC/YOLO-World" -> "IDEA-Research/DINO"
"ntegrals/aura-voice" -> "roboflow/awesome-openai-vision-api-experiments" ["e"=1]
"OpenGVLab/Vision-RWKV" -> "HarborYuan/ovsam" ["e"=1]
"baaivision/tokenize-anything" -> "UX-Decoder/DINOv"
"baaivision/tokenize-anything" -> "HarborYuan/ovsam"
"baaivision/tokenize-anything" -> "CircleRadon/Osprey" ["e"=1]
"baaivision/tokenize-anything" -> "baaivision/Uni3D" ["e"=1]
"baaivision/tokenize-anything" -> "shenyunhang/APE"
"baaivision/tokenize-anything" -> "OPPOMKLab/recognize-anything"
"baaivision/tokenize-anything" -> "jianzongwu/Awesome-Open-Vocabulary"
"baaivision/tokenize-anything" -> "UX-Decoder/Semantic-SAM"
"baaivision/tokenize-anything" -> "baaivision/Emu" ["e"=1]
"baaivision/tokenize-anything" -> "FoundationVision/GLEE"
"baaivision/tokenize-anything" -> "UX-Decoder/FIND"
"baaivision/tokenize-anything" -> "PhyscalX/gradio-image-prompter"
"baaivision/tokenize-anything" -> "OpenGVLab/all-seeing" ["e"=1]
"baaivision/tokenize-anything" -> "baaivision/CapsFusion" ["e"=1]
"baaivision/tokenize-anything" -> "RunpeiDong/DreamLLM" ["e"=1]
"tldraw/make-real-starter" -> "tldraw/make-real" ["e"=1]
"tldraw/make-real-starter" -> "protectai/ai-exploits"
"tldraw/make-real-starter" -> "run-llama/create_llama_projects"
"tldraw/make-real-starter" -> "pytorch-labs/segment-anything-fast"
"tldraw/make-real-starter" -> "Brendan-Kirtlan/Video-Encode"
"tldraw/make-real-starter" -> "flutter/games"
"tldraw/make-real-starter" -> "everywall/ladder"
"tldraw/make-real-starter" -> "twostraws/Inferno" ["e"=1]
"tldraw/make-real-starter" -> "tldraw/draw-fast" ["e"=1]
"tldraw/make-real-starter" -> "BuilderIO/gpt-crawler" ["e"=1]
"tldraw/make-real-starter" -> "disler/multi-agent-postgres-data-analytics" ["e"=1]
"tldraw/make-real-starter" -> "google-deepmind/graphcast" ["e"=1]
"tldraw/make-real-starter" -> "SawyerHood/draw-a-ui" ["e"=1]
"tldraw/make-real-starter" -> "eylonmiz/react-agent" ["e"=1]
"tldraw/make-real-starter" -> "tldraw/tldraw-llm-starter" ["e"=1]
"FoundationVision/GLEE" -> "FoundationVision/Groma" ["e"=1]
"FoundationVision/GLEE" -> "lxtGH/OMG-Seg" ["e"=1]
"FoundationVision/GLEE" -> "IDEA-Research/T-Rex"
"FoundationVision/GLEE" -> "shenyunhang/APE"
"FoundationVision/GLEE" -> "HarborYuan/ovsam"
"FoundationVision/GLEE" -> "UX-Decoder/DINOv"
"FoundationVision/GLEE" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"FoundationVision/GLEE" -> "MinghanLi/UniVS" ["e"=1]
"FoundationVision/GLEE" -> "wanghao9610/OV-DINO"
"FoundationVision/GLEE" -> "dvlab-research/LISA" ["e"=1]
"FoundationVision/GLEE" -> "MasterBin-IIAU/UNINEXT" ["e"=1]
"FoundationVision/GLEE" -> "FoundationVision/GenerateU"
"FoundationVision/GLEE" -> "IDEA-Research/Grounding-DINO-1.5-API"
"FoundationVision/GLEE" -> "jianzongwu/Awesome-Open-Vocabulary"
"FoundationVision/GLEE" -> "FoundationVision/VNext" ["e"=1]
"lxtGH/OMG-Seg" -> "HarborYuan/ovsam" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "friedrichor/Awesome-Multimodal-Papers" ["e"=1]
"xiuqhou/Salience-DETR" -> "xiuqhou/Relation-DETR"
"xiuqhou/Salience-DETR" -> "Atten4Vis/MS-DETR"
"xiuqhou/Salience-DETR" -> "hoiliu-0801/DQ-DETR" ["e"=1]
"xiuqhou/Salience-DETR" -> "impiga/Plain-DETR"
"roboflow/awesome-openai-vision-api-experiments" -> "roboflow/maestro"
"roboflow/awesome-openai-vision-api-experiments" -> "roboflow/webcamGPT"
"roboflow/awesome-openai-vision-api-experiments" -> "SkalskiP/awesome-foundation-and-multimodal-models"
"roboflow/awesome-openai-vision-api-experiments" -> "langchain-ai/opengpts" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "microsoft/SoM" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "ishan0102/vimGPT" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "roboflow/notebooks" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "Vaibhavs10/insanely-fast-whisper" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "daveshap/OpenAI_Agent_Swarm" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "mshumer/gpt-llm-trainer" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "roboflow/inference"
"roboflow/awesome-openai-vision-api-experiments" -> "hkchengrex/Tracking-Anything-with-DEVA"
"roboflow/awesome-openai-vision-api-experiments" -> "xlang-ai/OpenAgents" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "superagent-ai/superagent" ["e"=1]
"roboflow/awesome-openai-vision-api-experiments" -> "openai/consistencydecoder" ["e"=1]
"w1oves/Rein" -> "xb534/SED" ["e"=1]
"google/diffseg" -> "NVlabs/ODISE" ["e"=1]
"protectai/ai-exploits" -> "pytorch-labs/segment-anything-fast"
"protectai/ai-exploits" -> "run-llama/create_llama_projects"
"protectai/ai-exploits" -> "tldraw/make-real-starter"
"protectai/ai-exploits" -> "flutter/games"
"protectai/ai-exploits" -> "Brendan-Kirtlan/Video-Encode"
"protectai/ai-exploits" -> "protectai/modelscan" ["e"=1]
"protectai/ai-exploits" -> "everywall/ladder"
"protectai/ai-exploits" -> "NVIDIA/garak" ["e"=1]
"protectai/ai-exploits" -> "protectai/vulnhuntr" ["e"=1]
"protectai/ai-exploits" -> "iknowjason/Awesome-CloudSec-Labs" ["e"=1]
"protectai/ai-exploits" -> "0x90n/InfoSec-Black-Friday" ["e"=1]
"protectai/ai-exploits" -> "fr0gger/Awesome-GPT-Agents" ["e"=1]
"protectai/ai-exploits" -> "netero1010/EDRSilencer" ["e"=1]
"protectai/ai-exploits" -> "twostraws/Inferno" ["e"=1]
"protectai/ai-exploits" -> "Pennyw0rth/NetExec" ["e"=1]
"mttaggart/I-S00N" -> "WongKinYiu/yolov9" ["e"=1]
"chongzhou96/EdgeSAM" -> "yformer/EfficientSAM"
"chongzhou96/EdgeSAM" -> "lxtGH/OMG-Seg" ["e"=1]
"chongzhou96/EdgeSAM" -> "HarborYuan/ovsam"
"chongzhou96/EdgeSAM" -> "THU-MIG/RepViT" ["e"=1]
"chongzhou96/EdgeSAM" -> "vietanhdev/samexporter"
"chongzhou96/EdgeSAM" -> "risesoft-y9/Data-Labeling" ["e"=1]
"chongzhou96/EdgeSAM" -> "ChaoningZhang/MobileSAM"
"chongzhou96/EdgeSAM" -> "czg1225/SlimSAM"
"chongzhou96/EdgeSAM" -> "gh0stintheshe11/Stats-SVG" ["e"=1]
"chongzhou96/EdgeSAM" -> "magic-research/Sa2VA" ["e"=1]
"chongzhou96/EdgeSAM" -> "NVIDIA-AI-IOT/nanosam"
"chongzhou96/EdgeSAM" -> "risesoft-y9/Network-Drive" ["e"=1]
"chongzhou96/EdgeSAM" -> "fudan-generative-vision/dynamicPDB" ["e"=1]
"chongzhou96/EdgeSAM" -> "dinglufe/segment-anything-cpp-wrapper"
"chongzhou96/EdgeSAM" -> "mit-han-lab/efficientvit"
"SunzeY/AlphaCLIP" -> "beichenzbc/Long-CLIP"
"SunzeY/AlphaCLIP" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"SunzeY/AlphaCLIP" -> "HarborYuan/ovsam"
"SunzeY/AlphaCLIP" -> "Liuziyu77/Visual-RFT" ["e"=1]
"SunzeY/AlphaCLIP" -> "jianzongwu/Awesome-Open-Vocabulary"
"SunzeY/AlphaCLIP" -> "gaopengcuhk/Tip-Adapter" ["e"=1]
"SunzeY/AlphaCLIP" -> "facebookresearch/MetaCLIP"
"SunzeY/AlphaCLIP" -> "Liuziyu77/RAR" ["e"=1]
"SunzeY/AlphaCLIP" -> "jshilong/GPT4RoI" ["e"=1]
"SunzeY/AlphaCLIP" -> "zhengli97/PromptKD" ["e"=1]
"SunzeY/AlphaCLIP" -> "KaiyangZhou/CoOp" ["e"=1]
"SunzeY/AlphaCLIP" -> "dvlab-research/LISA" ["e"=1]
"SunzeY/AlphaCLIP" -> "wysoczanska/clip_dinoiser"
"SunzeY/AlphaCLIP" -> "muzairkhattak/PromptSRC" ["e"=1]
"SunzeY/AlphaCLIP" -> "wangf3014/SCLIP"
"OpenGVLab/DCNv4" -> "OpenGVLab/InternImage" ["e"=1]
"SkyworkAI/Vitron" -> "FoundationVision/GLEE" ["e"=1]
"apple/ml-4m" -> "siyuanliii/masa" ["e"=1]
"apple/ml-4m" -> "google-research/big_vision" ["e"=1]
"AssafSinger94/dino-tracker" -> "siyuanliii/masa" ["e"=1]
"AssafSinger94/dino-tracker" -> "UX-Decoder/DINOv" ["e"=1]
"AssafSinger94/dino-tracker" -> "facebookresearch/co-tracker" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "SkalskiP/top-cvpr-2023-papers"
"SkalskiP/top-cvpr-2024-papers" -> "siyuanliii/masa"
"SkalskiP/top-cvpr-2024-papers" -> "SkalskiP/vlms-zero-to-hero" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "roboflow/maestro"
"SkalskiP/top-cvpr-2024-papers" -> "DmitryRyumin/CVPR-2023-24-Papers" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "frank-xwang/UnSAM" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "roboflow/trackers"
"SkalskiP/top-cvpr-2024-papers" -> "Kroery/DiffMOT" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "henry123-boy/SpaTracker" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "apple/ml-4m" ["e"=1]
"SkalskiP/top-cvpr-2024-papers" -> "SkalskiP/awesome-foundation-and-multimodal-models"
"IDEA-Research/T-Rex" -> "UX-Decoder/DINOv"
"IDEA-Research/T-Rex" -> "FoundationVision/GLEE"
"IDEA-Research/T-Rex" -> "AILab-CVC/YOLO-World"
"IDEA-Research/T-Rex" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/T-Rex" -> "IDEA-Research/Grounding-DINO-1.5-API"
"IDEA-Research/T-Rex" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once"
"IDEA-Research/T-Rex" -> "yformer/EfficientSAM"
"IDEA-Research/T-Rex" -> "IDEA-Research/DINO-X-API"
"IDEA-Research/T-Rex" -> "siyuanliii/masa"
"IDEA-Research/T-Rex" -> "CVHub520/X-AnyLabeling"
"IDEA-Research/T-Rex" -> "microsoft/GLIP"
"IDEA-Research/T-Rex" -> "SysCV/sam-hq"
"IDEA-Research/T-Rex" -> "IDEA-Research/detrex"
"IDEA-Research/T-Rex" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/T-Rex" -> "lyuwenyu/RT-DETR"
"Coframe/coffee" -> "roboflow/awesome-openai-vision-api-experiments" ["e"=1]
"NVlabs/RADIO" -> "HarborYuan/ovsam" ["e"=1]
"NVlabs/RADIO" -> "FoundationVision/GLEE" ["e"=1]
"NVlabs/RADIO" -> "siyuanliii/masa" ["e"=1]
"NVlabs/RADIO" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"apple/ml-aim" -> "facebookresearch/MetaCLIP" ["e"=1]
"apple/ml-aim" -> "google-research/big_vision" ["e"=1]
"apple/ml-mobileclip" -> "facebookresearch/MetaCLIP"
"apple/ml-mobileclip" -> "apple/ml-aim" ["e"=1]
"apple/ml-mobileclip" -> "apple/ml-tic-clip"
"apple/ml-mobileclip" -> "wkcn/TinyCLIP"
"apple/ml-mobileclip" -> "apple/ml-fastvit" ["e"=1]
"apple/ml-mobileclip" -> "apple/ml-mobileone" ["e"=1]
"apple/ml-mobileclip" -> "mlfoundations/wise-ft"
"apple/ml-mobileclip" -> "THU-MIG/yoloe"
"apple/ml-mobileclip" -> "google-ai-edge/ai-edge-torch" ["e"=1]
"apple/ml-mobileclip" -> "Meituan-AutoML/MobileVLM" ["e"=1]
"apple/ml-mobileclip" -> "IDEA-Research/Grounding-DINO-1.5-API"
"apple/ml-mobileclip" -> "NVIDIA-AI-IOT/clip-distillation"
"apple/ml-mobileclip" -> "chongzhou96/EdgeSAM"
"apple/ml-mobileclip" -> "mhamilton723/FeatUp" ["e"=1]
"apple/ml-mobileclip" -> "mit-han-lab/efficientvit"
"Ucas-HaoranWei/Vary-toy" -> "shenyunhang/APE" ["e"=1]
"microsoft/SoM" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"microsoft/SoM" -> "IDEA-Research/OpenSeeD" ["e"=1]
"microsoft/SoM" -> "microsoft/GLIP" ["e"=1]
"microsoft/SoM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["e"=1]
"microsoft/SoM" -> "IDEA-Research/Grounding-DINO-1.5-API" ["e"=1]
"run-llama/create_llama_projects" -> "pytorch-labs/segment-anything-fast"
"run-llama/create_llama_projects" -> "Brendan-Kirtlan/Video-Encode"
"run-llama/create_llama_projects" -> "protectai/ai-exploits"
"run-llama/create_llama_projects" -> "flutter/games"
"run-llama/create_llama_projects" -> "tldraw/make-real-starter"
"run-llama/create_llama_projects" -> "run-llama/chat-llamaindex" ["e"=1]
"run-llama/create_llama_projects" -> "run-llama/create-llama" ["e"=1]
"run-llama/create_llama_projects" -> "run-llama/sec-insights" ["e"=1]
"run-llama/create_llama_projects" -> "twostraws/Inferno" ["e"=1]
"run-llama/create_llama_projects" -> "everywall/ladder"
"run-llama/create_llama_projects" -> "run-llama/mongodb-demo" ["e"=1]
"run-llama/create_llama_projects" -> "run-llama/LlamaIndexTS" ["e"=1]
"run-llama/create_llama_projects" -> "disler/multi-agent-postgres-data-analytics" ["e"=1]
"longzw1997/Open-GroundingDino" -> "Asad-Ismail/Grounding-Dino-FineTuning"
"longzw1997/Open-GroundingDino" -> "YifanXu74/MQ-Det" ["e"=1]
"longzw1997/Open-GroundingDino" -> "microsoft/GLIP"
"longzw1997/Open-GroundingDino" -> "IDEA-Research/GroundingDINO"
"longzw1997/Open-GroundingDino" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"longzw1997/Open-GroundingDino" -> "IDEA-Research/Grounding-DINO-1.5-API"
"longzw1997/Open-GroundingDino" -> "wanghao9610/OV-DINO"
"longzw1997/Open-GroundingDino" -> "mlzxy/devit"
"longzw1997/Open-GroundingDino" -> "Charles-Xie/awesome-described-object-detection"
"longzw1997/Open-GroundingDino" -> "UX-Decoder/DINOv"
"longzw1997/Open-GroundingDino" -> "IDEA-Research/OpenSeeD"
"longzw1997/Open-GroundingDino" -> "IDEA-Research/Grounded-SAM-2"
"longzw1997/Open-GroundingDino" -> "microsoft/RegionCLIP"
"longzw1997/Open-GroundingDino" -> "jianzongwu/Awesome-Open-Vocabulary"
"longzw1997/Open-GroundingDino" -> "shenyunhang/APE"
"encord-team/text-to-image-eval" -> "encord-team/encord-notebooks"
"CVMI-Lab/CoDet" -> "clin1223/VLDet"
"CVMI-Lab/CoDet" -> "mala-lab/SIC-CADS"
"CVMI-Lab/CoDet" -> "VinAIResearch/LP-OVOD"
"CVMI-Lab/CoDet" -> "FoundationVision/GenerateU"
"CVMI-Lab/CoDet" -> "Surrey-UP-Lab/RegionSpot"
"CVMI-Lab/CoDet" -> "wusize/ovdet"
"CVMI-Lab/CoDet" -> "wusize/CLIM"
"CVMI-Lab/CoDet" -> "CVMI-Lab/ResKD" ["e"=1]
"FoundationVision/GenerateU" -> "CVMI-Lab/CoDet"
"FoundationVision/GenerateU" -> "clin1223/VLDet"
"FoundationVision/GenerateU" -> "xushilin1/dst-det"
"FoundationVision/GenerateU" -> "Charles-Xie/awesome-described-object-detection"
"FoundationVision/GenerateU" -> "Surrey-UP-Lab/RegionSpot"
"FoundationVision/GenerateU" -> "mala-lab/SIC-CADS"
"Atten4Vis/MS-DETR" -> "MonoFormer/MonoFormer"
"Atten4Vis/MS-DETR" -> "FelixCaae/AlignDETR"
"Atten4Vis/MS-DETR" -> "LeapLabTHU/Rank-DETR" ["e"=1]
"Atten4Vis/MS-DETR" -> "huzhengdongcs/DAC-DETR"
"Atten4Vis/MS-DETR" -> "IDEA-Research/Stable-DINO"
"Atten4Vis/MS-DETR" -> "xiuqhou/Relation-DETR"
"Atten4Vis/MS-DETR" -> "xiuqhou/Salience-DETR"
"mbzuai-oryx/groundingLMM" -> "HarborYuan/ovsam" ["e"=1]
"HarborYuan/ovsam" -> "lxtGH/OMG-Seg" ["e"=1]
"HarborYuan/ovsam" -> "jianzongwu/Awesome-Open-Vocabulary"
"HarborYuan/ovsam" -> "facebookresearch/ov-seg"
"HarborYuan/ovsam" -> "UX-Decoder/Semantic-SAM"
"HarborYuan/ovsam" -> "magic-research/Sa2VA" ["e"=1]
"HarborYuan/ovsam" -> "UX-Decoder/DINOv"
"HarborYuan/ovsam" -> "baaivision/tokenize-anything"
"HarborYuan/ovsam" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"HarborYuan/ovsam" -> "chongzhou96/EdgeSAM"
"HarborYuan/ovsam" -> "FoundationVision/GLEE"
"HarborYuan/ovsam" -> "IDEA-Research/OpenSeeD"
"HarborYuan/ovsam" -> "wusize/CLIPSelf"
"HarborYuan/ovsam" -> "yformer/EfficientSAM"
"HarborYuan/ovsam" -> "liliu-avril/Awesome-Segment-Anything"
"HarborYuan/ovsam" -> "dvlab-research/LISA" ["e"=1]
"PRIS-CV/DemoFusion" -> "yformer/EfficientSAM" ["e"=1]
"beichenzbc/Long-CLIP" -> "SunzeY/AlphaCLIP"
"beichenzbc/Long-CLIP" -> "ant-research/DreamLIP"
"beichenzbc/Long-CLIP" -> "LijieFan/LaCLIP"
"beichenzbc/Long-CLIP" -> "facebookresearch/MetaCLIP"
"beichenzbc/Long-CLIP" -> "SeaArtLab/ComfyUI-Long-CLIP"
"beichenzbc/Long-CLIP" -> "LAION-AI/CLIP_benchmark"
"beichenzbc/Long-CLIP" -> "FoundationVision/LlamaGen" ["e"=1]
"beichenzbc/Long-CLIP" -> "showlab/Show-o" ["e"=1]
"beichenzbc/Long-CLIP" -> "LPengYang/MotionClone" ["e"=1]
"beichenzbc/Long-CLIP" -> "ShareGPT4Omni/ShareGPT4V" ["e"=1]
"beichenzbc/Long-CLIP" -> "baaivision/DIVA" ["e"=1]
"beichenzbc/Long-CLIP" -> "TencentQQGYLab/ELLA" ["e"=1]
"beichenzbc/Long-CLIP" -> "shikiw/OPERA" ["e"=1]
"beichenzbc/Long-CLIP" -> "facebookresearch/DCI"
"beichenzbc/Long-CLIP" -> "Liuziyu77/Visual-RFT" ["e"=1]
"mhamilton723/FeatUp" -> "facebookresearch/dinov2" ["e"=1]
"mhamilton723/FeatUp" -> "mit-han-lab/efficientvit" ["e"=1]
"mhamilton723/FeatUp" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"mhamilton723/FeatUp" -> "chongzhou96/MaskCLIP" ["e"=1]
"mhamilton723/FeatUp" -> "czczup/ViT-Adapter" ["e"=1]
"syp2ysy/VRP-SAM" -> "UX-Decoder/DINOv" ["e"=1]
"wysoczanska/clip_dinoiser" -> "wysoczanska/clip-diy"
"wysoczanska/clip_dinoiser" -> "bytedance/fc-clip"
"wysoczanska/clip_dinoiser" -> "wangf3014/SCLIP"
"wysoczanska/clip_dinoiser" -> "chongzhou96/MaskCLIP"
"linyq2117/TagCLIP" -> "mc-lan/ProxyCLIP" ["e"=1]
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" -> "Charles-Xie/awesome-described-object-detection"
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" -> "jianzongwu/Awesome-Open-Vocabulary"
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" -> "jaychempan/LAE-DINO" ["e"=1]
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"siyuanliii/masa" -> "hkchengrex/Tracking-Anything-with-DEVA"
"siyuanliii/masa" -> "IDEA-Research/T-Rex"
"siyuanliii/masa" -> "MCG-NJU/MOTIP" ["e"=1]
"siyuanliii/masa" -> "yformer/EfficientSAM"
"siyuanliii/masa" -> "IDEA-Research/Grounded-SAM-2"
"siyuanliii/masa" -> "yformer/EfficientTAM"
"siyuanliii/masa" -> "IDEA-Research/Grounding-DINO-1.5-API"
"siyuanliii/masa" -> "zju3dv/MatchAnything" ["e"=1]
"siyuanliii/masa" -> "FoundationVision/GLEE"
"siyuanliii/masa" -> "AssafSinger94/dino-tracker" ["e"=1]
"siyuanliii/masa" -> "NVlabs/RADIO" ["e"=1]
"siyuanliii/masa" -> "HarborYuan/ovsam"
"siyuanliii/masa" -> "verlab/accelerated_features" ["e"=1]
"siyuanliii/masa" -> "AILab-CVC/YOLO-World"
"siyuanliii/masa" -> "luanshiyinyang/awesome-multiple-object-tracking" ["e"=1]
"google-research/syn-rep-learn" -> "LijieFan/LaCLIP"
"mazurowski-lab/finetune-SAM" -> "ziqi-jin/finetune-anything"
"mazurowski-lab/finetune-SAM" -> "WangRongsheng/SAM-fine-tune"
"mazurowski-lab/finetune-SAM" -> "YichiZhang98/SAM4MIS" ["e"=1]
"mazurowski-lab/finetune-SAM" -> "mazurowski-lab/SlicerSegmentWithSAM" ["e"=1]
"bytedance/coconut_cvpr2024" -> "zhang-tao-whu/DVIS_Plus" ["e"=1]
"bytedance/coconut_cvpr2024" -> "bytedance/OmniScient-Model"
"bytedance/coconut_cvpr2024" -> "bytedance/kmax-deeplab"
"CircleRadon/Osprey" -> "baaivision/tokenize-anything" ["e"=1]
"CircleRadon/Osprey" -> "shenyunhang/APE" ["e"=1]
"Beckschen/ViTamin" -> "bytedance/OmniScient-Model"
"Beckschen/ViTamin" -> "bytedance/kmax-deeplab"
"Beckschen/ViTamin" -> "TACJu/Axial-VS"
"Beckschen/ViTamin" -> "x-cls/superclass"
"FoundationVision/UniRef" -> "CVMI-Lab/CoDet" ["e"=1]
"FoundationVision/UniRef" -> "Surrey-UP-Lab/RegionSpot" ["e"=1]
"harpreetsahota204/awesome-cvpr-2024" -> "voxel51/zcore"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "SkalskiP/transformers"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "roboflow/awesome-openai-vision-api-experiments"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "awaisrauf/Awesome-CV-Foundational-Models" ["e"=1]
"SkalskiP/awesome-foundation-and-multimodal-models" -> "autodistill/autodistill"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "merveenoyan/awesome-osml-for-devs" ["e"=1]
"SkalskiP/awesome-foundation-and-multimodal-models" -> "merveenoyan/smol-vision" ["e"=1]
"SkalskiP/awesome-foundation-and-multimodal-models" -> "friedrichor/Awesome-Multimodal-Papers"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "SkalskiP/sketchy-vision"
"SkalskiP/awesome-foundation-and-multimodal-models" -> "facebookresearch/MetaCLIP"
"google-ai-edge/ai-edge-torch" -> "apple/ml-mobileclip" ["e"=1]
"Traffic-X/ViT-CoMer" -> "Traffic-X/Open-TransMind"
"Traffic-X/ViT-CoMer" -> "czczup/ViT-Adapter"
"xinghaochen/TinySAM" -> "czg1225/SlimSAM"
"xinghaochen/TinySAM" -> "NVIDIA-AI-IOT/nanosam"
"xinghaochen/TinySAM" -> "yformer/EfficientSAM"
"xinghaochen/TinySAM" -> "luca-medeiros/lightning-sam"
"xinghaochen/TinySAM" -> "11yxk/SAM-LST" ["e"=1]
"xinghaochen/TinySAM" -> "BooHwang/segment_anything_tensorrt"
"xinghaochen/TinySAM" -> "THU-MIG/RepViT" ["e"=1]
"baaivision/CapsFusion" -> "LijieFan/LaCLIP" ["e"=1]
"allenai/unified-io-2" -> "allenai/mmc4" ["e"=1]
"NVIDIA-AI-IOT/mmj_genai" -> "NVIDIA-AI-IOT/mmj_utils"
"NVIDIA-AI-IOT/mmj_genai" -> "NVIDIA-AI-IOT/jetson-platform-services"
"1hao-Liu/SM4Depth" -> "xuefeng-cvr/Tiny-Obstacle-Discovery"
"1hao-Liu/SM4Depth" -> "YiLiM1/DANet"
"orrzohar/FOMO" -> "orrzohar/PROB"
"orrzohar/FOMO" -> "feifeiobama/OrthogonalDet"
"orrzohar/FOMO" -> "frh23333/mepu-owod"
"orrzohar/FOMO" -> "orrzohar/LOVM"
"orrzohar/FOMO" -> "343gltysprk/ovow"
"WalBouss/GEM" -> "sinahmr/NACLIP"
"wangf3014/SCLIP" -> "mc-lan/ClearCLIP"
"wangf3014/SCLIP" -> "mc-lan/ProxyCLIP"
"wangf3014/SCLIP" -> "sinahmr/NACLIP"
"wangf3014/SCLIP" -> "wusize/CLIPSelf"
"wangf3014/SCLIP" -> "HVision-NKU/Cascade-CLIP" ["e"=1]
"czg1225/Awesome-Efficient-Segment-Anything" -> "czg1225/SlimSAM"
"yossigandelsman/clip_text_span" -> "ant-research/DreamLIP" ["e"=1]
"UX-Decoder/DINOv" -> "syp2ysy/VRP-SAM" ["e"=1]
"UX-Decoder/DINOv" -> "IDEA-Research/T-Rex"
"UX-Decoder/DINOv" -> "IDEA-Research/OpenSeeD"
"UX-Decoder/DINOv" -> "baaivision/tokenize-anything"
"UX-Decoder/DINOv" -> "HarborYuan/ovsam"
"UX-Decoder/DINOv" -> "shenyunhang/APE"
"UX-Decoder/DINOv" -> "FoundationVision/GLEE"
"UX-Decoder/DINOv" -> "UX-Decoder/Semantic-SAM"
"UX-Decoder/DINOv" -> "IDEA-Research/Grounding-DINO-1.5-API"
"UX-Decoder/DINOv" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"UX-Decoder/DINOv" -> "YifanXu74/MQ-Det" ["e"=1]
"UX-Decoder/DINOv" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"UX-Decoder/DINOv" -> "yongliu20/UniLSeg" ["e"=1]
"UX-Decoder/DINOv" -> "microsoft/X-Decoder"
"UX-Decoder/DINOv" -> "aim-uofa/Matcher"
"xushilin1/RMP-SAM" -> "xushilin1/dst-det"
"chengtao-lv/PTQ4SAM" -> "yifu-ding/BGEMM-CUDA"
"ouyanghaodong/DEYO" -> "ouyanghaodong/DEYOv1.5"
"mbzuai-oryx/MobiLlama" -> "hanoonaR/object-centric-ovd" ["e"=1]
"feifeiobama/OrthogonalDet" -> "orrzohar/FOMO"
"xb534/SED" -> "cvlab-kaist/CAT-Seg" ["e"=1]
"xb534/SED" -> "yongliu20/SCAN" ["e"=1]
"xb534/SED" -> "bytedance/fc-clip"
"xb534/SED" -> "jiaosiyu1999/MAFT-Plus"
"xb534/SED" -> "w1oves/Rein" ["e"=1]
"xb534/SED" -> "linsun449/cliper.code"
"xb534/SED" -> "MendelXu/SAN"
"xb534/SED" -> "Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation"
"xb534/SED" -> "mc-lan/ProxyCLIP"
"ant-research/DreamLIP" -> "wuw2019/LoTLIP" ["e"=1]
"hananshafi/llmblueprint" -> "rohit901/VANE-Bench" ["e"=1]
"Surrey-UP-Lab/RegionSpot" -> "happy-hsy/MotionMAE"
"Surrey-UP-Lab/RegionSpot" -> "CVMI-Lab/CoDet"
"Surrey-UP-Lab/RegionSpot" -> "Surrey-UP-Lab/GS-LPM"
"Surrey-UP-Lab/RegionSpot" -> "happy-hsy/BCNet"
"facebookresearch/DCI" -> "SivanDoveh/DAC"
"facebookresearch/DCI" -> "ant-research/DreamLIP"
"dusty-nv/NanoLLM" -> "asierarranz/Google_Gemma_DevDay"
"dusty-nv/NanoLLM" -> "NVIDIA-AI-IOT/jetson-intro-to-distillation"
"OliverRensu/D-iGPT" -> "lambert-x/ProLab"
"YutingLi0606/SURE" -> "LIYangggggg/SSB-OSR"
"YutingLi0606/SURE" -> "COCO-FP/COCO-FP"
"kaist-dmlab/Prune4Rel" -> "kaist-dmlab/RECURVE"
"kaist-dmlab/Prune4Rel" -> "kaist-dmlab/CrossMatch"
"stephansturges/NANO" -> "stephansturges/BAD"
"rohit901/cooperative-foundational-models" -> "rohit901/VANE-Bench"
"spacewalk01/nanosam-cpp" -> "Huntersdeng/CXX-DeepLearning-Inference"
"yangchris11/samurai" -> "facebookresearch/sam2"
"yangchris11/samurai" -> "Lightricks/LTX-Video" ["e"=1]
"yangchris11/samurai" -> "IDEA-Research/Grounded-SAM-2"
"yangchris11/samurai" -> "apple/ml-depth-pro" ["e"=1]
"yangchris11/samurai" -> "LiheYoung/Depth-Anything" ["e"=1]
"yangchris11/samurai" -> "bddicken/languages" ["e"=1]
"yangchris11/samurai" -> "black-forest-labs/flux" ["e"=1]
"yangchris11/samurai" -> "Genesis-Embodied-AI/Genesis" ["e"=1]
"yangchris11/samurai" -> "facebookresearch/co-tracker"
"yangchris11/samurai" -> "DepthAnything/Depth-Anything-V2" ["e"=1]
"yangchris11/samurai" -> "facebookresearch/sapiens" ["e"=1]
"yangchris11/samurai" -> "Tencent/HunyuanVideo" ["e"=1]
"yangchris11/samurai" -> "microsoft/TRELLIS" ["e"=1]
"yangchris11/samurai" -> "IDEA-Research/GroundingDINO"
"yangchris11/samurai" -> "NVIDIA/Cosmos" ["e"=1]
"meta-llama/llama-models" -> "facebookresearch/sam2" ["e"=1]
"THU-MIG/yolov10" -> "WongKinYiu/yolov9"
"THU-MIG/yolov10" -> "ultralytics/ultralytics" ["e"=1]
"THU-MIG/yolov10" -> "lyuwenyu/RT-DETR"
"THU-MIG/yolov10" -> "CVHub520/X-AnyLabeling"
"THU-MIG/yolov10" -> "AILab-CVC/YOLO-World"
"THU-MIG/yolov10" -> "WongKinYiu/yolov7" ["e"=1]
"THU-MIG/yolov10" -> "facebookresearch/sam2"
"THU-MIG/yolov10" -> "meituan/YOLOv6" ["e"=1]
"THU-MIG/yolov10" -> "Megvii-BaseDetection/YOLOX" ["e"=1]
"THU-MIG/yolov10" -> "IDEA-Research/GroundingDINO"
"THU-MIG/yolov10" -> "IDEA-Research/Grounded-Segment-Anything"
"THU-MIG/yolov10" -> "sunsmarterjie/yolov12"
"THU-MIG/yolov10" -> "ultralytics/yolov5" ["e"=1]
"THU-MIG/yolov10" -> "PaddlePaddle/PaddleDetection" ["e"=1]
"THU-MIG/yolov10" -> "CASIA-IVA-Lab/FastSAM"
"IDEA-Research/DINO-X-API" -> "IDEA-Research/Grounded-SAM-2"
"IDEA-Research/DINO-X-API" -> "IDEA-Research/Grounding-DINO-1.5-API"
"IDEA-Research/DINO-X-API" -> "THU-MIG/yoloe"
"IDEA-Research/DINO-X-API" -> "IDEA-Research/T-Rex"
"IDEA-Research/DINO-X-API" -> "xuxw98/ESAM" ["e"=1]
"IDEA-Research/DINO-X-API" -> "AILab-CVC/YOLO-World"
"IDEA-Research/DINO-X-API" -> "siyuanliii/masa"
"IDEA-Research/DINO-X-API" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/DINO-X-API" -> "UX-Decoder/DINOv"
"IDEA-Research/DINO-X-API" -> "HarborYuan/ovsam"
"IDEA-Research/DINO-X-API" -> "Peterande/D-FINE"
"IDEA-Research/DINO-X-API" -> "NVlabs/RADIO" ["e"=1]
"IDEA-Research/DINO-X-API" -> "yformer/EfficientTAM"
"IDEA-Research/DINO-X-API" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/DINO-X-API" -> "DepthAnything/PromptDA" ["e"=1]
"bddicken/languages" -> "yangchris11/samurai" ["e"=1]
"black-forest-labs/flux" -> "facebookresearch/sam2" ["e"=1]
"ai-dawang/PlugNPlay-Modules" -> "lyuwenyu/RT-DETR" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "salesforce/LAVIS" ["e"=1]
"facebookresearch/sam2" -> "facebookresearch/segment-anything" ["e"=1]
"facebookresearch/sam2" -> "IDEA-Research/Grounded-Segment-Anything"
"facebookresearch/sam2" -> "facebookresearch/dinov2"
"facebookresearch/sam2" -> "IDEA-Research/GroundingDINO"
"facebookresearch/sam2" -> "haotian-liu/LLaVA" ["e"=1]
"facebookresearch/sam2" -> "DepthAnything/Depth-Anything-V2" ["e"=1]
"facebookresearch/sam2" -> "IDEA-Research/Grounded-SAM-2"
"facebookresearch/sam2" -> "graphdeco-inria/gaussian-splatting" ["e"=1]
"facebookresearch/sam2" -> "openai/CLIP" ["e"=1]
"facebookresearch/sam2" -> "LiheYoung/Depth-Anything" ["e"=1]
"facebookresearch/sam2" -> "yangchris11/samurai"
"facebookresearch/sam2" -> "CASIA-IVA-Lab/FastSAM"
"facebookresearch/sam2" -> "black-forest-labs/flux" ["e"=1]
"facebookresearch/sam2" -> "Genesis-Embodied-AI/Genesis" ["e"=1]
"facebookresearch/sam2" -> "mlfoundations/open_clip"
"IDEA-Research/Grounded-SAM-2" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/Grounded-SAM-2" -> "IDEA-Research/DINO-X-API"
"IDEA-Research/Grounded-SAM-2" -> "facebookresearch/sam2"
"IDEA-Research/Grounded-SAM-2" -> "IDEA-Research/Grounded-Segment-Anything"
"IDEA-Research/Grounded-SAM-2" -> "UX-Decoder/Semantic-SAM"
"IDEA-Research/Grounded-SAM-2" -> "IDEA-Research/Grounding-DINO-1.5-API"
"IDEA-Research/Grounded-SAM-2" -> "Gy920/segment-anything-2-real-time"
"IDEA-Research/Grounded-SAM-2" -> "luca-medeiros/lang-segment-anything"
"IDEA-Research/Grounded-SAM-2" -> "naver/mast3r" ["e"=1]
"IDEA-Research/Grounded-SAM-2" -> "LLaVA-VL/LLaVA-NeXT" ["e"=1]
"IDEA-Research/Grounded-SAM-2" -> "NVlabs/FoundationPose" ["e"=1]
"IDEA-Research/Grounded-SAM-2" -> "z-x-yang/Segment-and-Track-Anything"
"IDEA-Research/Grounded-SAM-2" -> "siyuanliii/masa"
"IDEA-Research/Grounded-SAM-2" -> "hbb1/2d-gaussian-splatting" ["e"=1]
"IDEA-Research/Grounded-SAM-2" -> "AILab-CVC/YOLO-World"
"roboflow/sports" -> "roboflow/maestro" ["e"=1]
"roboflow/sports" -> "roboflow/rf-detr" ["e"=1]
"Peterande/D-FINE" -> "ShihuaHuang95/DEIM"
"Peterande/D-FINE" -> "jie200408/MyProject" ["e"=1]
"Peterande/D-FINE" -> "makeecat/Peng" ["e"=1]
"Peterande/D-FINE" -> "flymin/MagicDriveDiT" ["e"=1]
"Peterande/D-FINE" -> "lyuwenyu/RT-DETR"
"Peterande/D-FINE" -> "Lattice-zjj/On-Device-FinLLM" ["e"=1]
"Peterande/D-FINE" -> "Theo-Messi/lumen" ["e"=1]
"Peterande/D-FINE" -> "BizSpringSource/bizspring-vue3-opensource" ["e"=1]
"Peterande/D-FINE" -> "cure-lab/MagicDrive" ["e"=1]
"Peterande/D-FINE" -> "xhs996/xhs_spider" ["e"=1]
"Peterande/D-FINE" -> "javaKing-lgy/mini-mybatis" ["e"=1]
"Peterande/D-FINE" -> "tsinghua-fib-lab/ANeurIPS2024_SPV-MIA" ["e"=1]
"Peterande/D-FINE" -> "chaxus/ran" ["e"=1]
"Peterande/D-FINE" -> "fecommunity/reactpress" ["e"=1]
"Peterande/D-FINE" -> "outtable/confuse-9live" ["e"=1]
"WZH0120/SAM2-UNet" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"WZH0120/SAM2-UNet" -> "mazurowski-lab/finetune-SAM" ["e"=1]
"xiuqhou/Relation-DETR" -> "xiuqhou/Salience-DETR"
"xiuqhou/Relation-DETR" -> "Atten4Vis/MS-DETR"
"xiuqhou/Relation-DETR" -> "impiga/Plain-DETR"
"xiuqhou/Relation-DETR" -> "Atten4Vis/LW-DETR"
"xiuqhou/Relation-DETR" -> "clxia12/RT-DETRv3"
"xiuqhou/Relation-DETR" -> "LeapLabTHU/Rank-DETR" ["e"=1]
"NVlabs/Sana" -> "mit-han-lab/efficientvit" ["e"=1]
"DepthAnything/Depth-Anything-V2" -> "facebookresearch/sam2" ["e"=1]
"ShihuaHuang95/DEIM" -> "Peterande/D-FINE"
"ShihuaHuang95/DEIM" -> "lyuwenyu/RT-DETR"
"ShihuaHuang95/DEIM" -> "sunsmarterjie/yolov12"
"ShihuaHuang95/DEIM" -> "Atten4Vis/LW-DETR"
"ShihuaHuang95/DEIM" -> "clxia12/RT-DETRv3"
"ShihuaHuang95/DEIM" -> "dnth/DEIMKit"
"ShihuaHuang95/DEIM" -> "THU-MIG/yoloe"
"ShihuaHuang95/DEIM" -> "xiuqhou/Relation-DETR"
"ShihuaHuang95/DEIM" -> "Sense-X/Co-DETR" ["e"=1]
"ShihuaHuang95/DEIM" -> "ocean146/SimROD"
"ShihuaHuang95/DEIM" -> "roboflow/rf-detr"
"ShihuaHuang95/DEIM" -> "HZAI-ZJNU/Mamba-YOLO" ["e"=1]
"ShihuaHuang95/DEIM" -> "xiuqhou/Salience-DETR"
"ShihuaHuang95/DEIM" -> "iMoonLab/Hyper-YOLO" ["e"=1]
"ShihuaHuang95/DEIM" -> "YutingLi0606/SURE"
"tjmlabs/ColiVara" -> "roboflow/maestro" ["e"=1]
"facebookresearch/sapiens" -> "facebookresearch/sam2" ["e"=1]
"alimohammadiamirhossein/smite" -> "Mark12Ding/SAM2Long" ["e"=1]
"mlfoundations/MINT-1T" -> "UCSC-VLAA/Recap-DataComp-1B" ["e"=1]
"NVIDIA-AI-IOT/ros2_nanollm" -> "NVIDIA-AI-IOT/ROS2-NanoOWL" ["e"=1]
"Atten4Vis/LW-DETR" -> "ouyanghaodong/DEYO"
"Atten4Vis/LW-DETR" -> "xiuqhou/Relation-DETR"
"Atten4Vis/LW-DETR" -> "ShihuaHuang95/DEIM"
"Atten4Vis/LW-DETR" -> "HZAI-ZJNU/Mamba-YOLO" ["e"=1]
"Atten4Vis/LW-DETR" -> "Peterande/D-FINE"
"Atten4Vis/LW-DETR" -> "iMoonLab/Hyper-YOLO" ["e"=1]
"Atten4Vis/LW-DETR" -> "xiuqhou/Salience-DETR"
"Atten4Vis/LW-DETR" -> "jozhang97/DETA"
"Atten4Vis/LW-DETR" -> "ouyanghaodong/DEYOv1.5"
"Atten4Vis/LW-DETR" -> "clxia12/RT-DETRv3"
"Atten4Vis/LW-DETR" -> "lyuwenyu/RT-DETR"
"Atten4Vis/LW-DETR" -> "Sense-X/Co-DETR" ["e"=1]
"Atten4Vis/LW-DETR" -> "wanghao9610/OV-DINO"
"Atten4Vis/LW-DETR" -> "FishAndWasabi/YOLO-MS" ["e"=1]
"Atten4Vis/LW-DETR" -> "yang-0201/MAF-YOLO" ["e"=1]
"HZAI-ZJNU/Mamba-YOLO" -> "Atten4Vis/LW-DETR" ["e"=1]
"HZAI-ZJNU/Mamba-YOLO" -> "ouyanghaodong/DEYO" ["e"=1]
"lovelyqian/CDFSOD-benchmark" -> "mlzxy/devit"
"lovelyqian/CDFSOD-benchmark" -> "lovelyqian/NTIRE2025_CDFSOD"
"lovelyqian/CDFSOD-benchmark" -> "anishmadan23/foundational_fsod"
"lovelyqian/CDFSOD-benchmark" -> "binyisu/food"
"lovelyqian/CDFSOD-benchmark" -> "jaychempan/ETS" ["e"=1]
"lovelyqian/CDFSOD-benchmark" -> "gaobb/Few-Shot-Object-Detection-Papers" ["e"=1]
"lovelyqian/CDFSOD-benchmark" -> "csuhan/VFA" ["e"=1]
"sagieppel/fine-tune-train_segment_anything_2_in_60_lines_of_code" -> "tianrun-chen/SAM-Adapter-PyTorch" ["e"=1]
"IDEA-Research/Grounding-DINO-1.5-API" -> "IDEA-Research/Grounded-SAM-2"
"IDEA-Research/Grounding-DINO-1.5-API" -> "IDEA-Research/GroundingDINO"
"IDEA-Research/Grounding-DINO-1.5-API" -> "IDEA-Research/DINO-X-API"
"IDEA-Research/Grounding-DINO-1.5-API" -> "microsoft/GLIP"
"IDEA-Research/Grounding-DINO-1.5-API" -> "IDEA-Research/T-Rex"
"IDEA-Research/Grounding-DINO-1.5-API" -> "UX-Decoder/DINOv"
"IDEA-Research/Grounding-DINO-1.5-API" -> "wanghao9610/OV-DINO"
"IDEA-Research/Grounding-DINO-1.5-API" -> "longzw1997/Open-GroundingDino"
"IDEA-Research/Grounding-DINO-1.5-API" -> "FoundationVision/GLEE"
"IDEA-Research/Grounding-DINO-1.5-API" -> "AILab-CVC/YOLO-World"
"IDEA-Research/Grounding-DINO-1.5-API" -> "siyuanliii/masa"
"IDEA-Research/Grounding-DINO-1.5-API" -> "HarborYuan/ovsam"
"IDEA-Research/Grounding-DINO-1.5-API" -> "IDEA-Research/OpenSeeD"
"IDEA-Research/Grounding-DINO-1.5-API" -> "xinyu1205/recognize-anything"
"IDEA-Research/Grounding-DINO-1.5-API" -> "UX-Decoder/Semantic-SAM"
"x-cls/superclass" -> "Beckschen/ViTamin"
"linsun449/cliper.code" -> "linsun449/iseg.code"
"MME-Benchmarks/Video-MME" -> "shenyunhang/APE" ["e"=1]
"Gy920/segment-anything-2-real-time" -> "patrick-tssn/Streaming-Grounded-SAM-2"
"Gy920/segment-anything-2-real-time" -> "heyoeyo/muggled_sam"
"Gy920/segment-anything-2-real-time" -> "zdata-inc/sam2_realtime"
"Gy920/segment-anything-2-real-time" -> "yformer/EfficientTAM"
"Gy920/segment-anything-2-real-time" -> "IDEA-Research/Grounded-SAM-2"
"Gy920/segment-anything-2-real-time" -> "Aimol-l/OrtInference"
"Gy920/segment-anything-2-real-time" -> "Aimol-l/SAM2Export"
"Gy920/segment-anything-2-real-time" -> "axinc-ai/segment-anything-2"
"Gy920/segment-anything-2-real-time" -> "xuxw98/ESAM" ["e"=1]
"Gy920/segment-anything-2-real-time" -> "NVIDIA-AI-IOT/nanosam"
"Gy920/segment-anything-2-real-time" -> "gaomingqi/Awesome-Video-Object-Segmentation" ["e"=1]
"Gy920/segment-anything-2-real-time" -> "ibaiGorordo/ONNX-SAM2-Segment-Anything"
"mc-lan/ProxyCLIP" -> "mc-lan/ClearCLIP"
"mc-lan/ProxyCLIP" -> "leaves162/CLIPtrase"
"mc-lan/ProxyCLIP" -> "wangf3014/SCLIP"
"mc-lan/ProxyCLIP" -> "HVision-NKU/Cascade-CLIP" ["e"=1]
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "axinc-ai/segment-anything-2"
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "vietanhdev/samexporter"
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "Aimol-l/SAM2Export"
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "Aimol-l/OrtInference"
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "ryouchinsa/sam-cpp-macos"
"ibaiGorordo/ONNX-SAM2-Segment-Anything" -> "AliaChen/sam2TRT"
"wanghao9610/OV-DINO" -> "IDEA-Research/Grounding-DINO-1.5-API"
"wanghao9610/OV-DINO" -> "FoundationVision/GLEE"
"wanghao9610/OV-DINO" -> "iSEE-Laboratory/LLMDet"
"wanghao9610/OV-DINO" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection"
"wanghao9610/OV-DINO" -> "longzw1997/Open-GroundingDino"
"wanghao9610/OV-DINO" -> "HarborYuan/ovsam"
"wanghao9610/OV-DINO" -> "THU-MIG/YOLO-UniOW"
"wanghao9610/OV-DINO" -> "Atten4Vis/LW-DETR"
"wanghao9610/OV-DINO" -> "UX-Decoder/DINOv"
"wanghao9610/OV-DINO" -> "DongSky/MR-GDINO"
"clxia12/RT-DETRv3" -> "ShihuaHuang95/DEIM"
"clxia12/RT-DETRv3" -> "HuKai97/deformable-detr-annotations"
"clxia12/RT-DETRv3" -> "xiuqhou/Relation-DETR"
"frank-xwang/UnSAM" -> "HarborYuan/ovsam" ["e"=1]
"frank-xwang/UnSAM" -> "UX-Decoder/DINOv" ["e"=1]
"hustvl/MaskAdapter" -> "jiaosiyu1999/MAFT-Plus" ["e"=1]
"yformer/EfficientTAM" -> "jovanavidenovic/DAM4SAM"
"yformer/EfficientTAM" -> "Gy920/segment-anything-2-real-time"
"yformer/EfficientTAM" -> "gaomingqi/Awesome-Video-Object-Segmentation" ["e"=1]
"yformer/EfficientTAM" -> "Mark12Ding/SAM2Long" ["e"=1]
"yformer/EfficientTAM" -> "heyoeyo/muggled_sam"
"yformer/EfficientTAM" -> "siyuanliii/masa"
"yformer/EfficientTAM" -> "naver-ai/ZIM" ["e"=1]
"yformer/EfficientTAM" -> "yformer/EfficientSAM"
"yformer/EfficientTAM" -> "alimohammadiamirhossein/smite"
"yformer/EfficientTAM" -> "IDEA-Research/Grounded-SAM-2"
"yformer/EfficientTAM" -> "AssafSinger94/dino-tracker" ["e"=1]
"yformer/EfficientTAM" -> "prs-eth/RollingDepth" ["e"=1]
"yformer/EfficientTAM" -> "IDEA-Research/DINO-X-API"
"yformer/EfficientTAM" -> "hkchengrex/Cutie" ["e"=1]
"yformer/EfficientTAM" -> "MCG-NJU/MOTIP" ["e"=1]
"heyoeyo/muggled_sam" -> "patrick-tssn/Streaming-Grounded-SAM-2"
"heyoeyo/muggled_sam" -> "Aimol-l/SAM2Export"
"heyoeyo/muggled_sam" -> "Gy920/segment-anything-2-real-time"
"heyoeyo/muggled_sam" -> "zdata-inc/sam2_realtime"
"heyoeyo/muggled_sam" -> "heyoeyo/muggled_dpt" ["e"=1]
"wuw2019/LoTLIP" -> "ant-research/DreamLIP" ["e"=1]
"TIGER-AI-Lab/VLM2Vec" -> "microsoft/LLM2CLIP" ["e"=1]
"jiaosiyu1999/MAFT-Plus" -> "jiaosiyu1999/MAFT"
"jiaosiyu1999/MAFT-Plus" -> "Xujxyang/OpenTrans"
"UCSC-VLAA/Recap-DataComp-1B" -> "UCSC-VLAA/Image-Pretraining-for-Video"
"microsoft/LLM2CLIP" -> "TIGER-AI-Lab/VLM2Vec" ["e"=1]
"microsoft/LLM2CLIP" -> "x-cls/superclass"
"microsoft/LLM2CLIP" -> "ant-research/DreamLIP"
"microsoft/LLM2CLIP" -> "beichenzbc/Long-CLIP"
"microsoft/LLM2CLIP" -> "LAION-AI/CLIP_benchmark"
"microsoft/LLM2CLIP" -> "apple/ml-aim" ["e"=1]
"microsoft/LLM2CLIP" -> "baaivision/DIVA" ["e"=1]
"microsoft/LLM2CLIP" -> "SunzeY/AlphaCLIP"
"patrick-tssn/Streaming-Grounded-SAM-2" -> "Gy920/segment-anything-2-real-time"
"patrick-tssn/Streaming-Grounded-SAM-2" -> "heyoeyo/muggled_sam"
"patrick-tssn/Streaming-Grounded-SAM-2" -> "ShuoShenDe/Grounded-Sam2-Tracking"
"Aimol-l/OrtInference" -> "Aimol-l/SAM2Export"
"Aimol-l/OrtInference" -> "axinc-ai/segment-anything-2"
"Aimol-l/OrtInference" -> "lyxlplhy/Sam2Onnx_Inference"
"Aimol-l/OrtInference" -> "OroChippw/SegmentAnything-OnnxRunner"
"Aimol-l/OrtInference" -> "zhg-SZPT/FastSAM_Awsome_Openvino"
"Aimol-l/OrtInference" -> "dinglufe/segment-anything-cpp-wrapper"
"Aimol-l/OrtInference" -> "ryouchinsa/sam-cpp-macos"
"Aimol-l/OrtInference" -> "ibaiGorordo/ONNX-SAM2-Segment-Anything"
"Aimol-l/OrtInference" -> "vietanhdev/samexporter"
"axinc-ai/segment-anything-2" -> "Aimol-l/SAM2Export"
"axinc-ai/segment-anything-2" -> "ibaiGorordo/ONNX-SAM2-Segment-Anything"
"axinc-ai/segment-anything-2" -> "Aimol-l/OrtInference"
"Aimol-l/SAM2Export" -> "Aimol-l/OrtInference"
"Aimol-l/SAM2Export" -> "axinc-ai/segment-anything-2"
"voxel51/zcore" -> "jacobmarks/ten-weeks-of-plugins"
"jovanavidenovic/DAM4SAM" -> "XuM007/MITracker"
"jovanavidenovic/DAM4SAM" -> "Mark12Ding/SAM2Long" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "yformer/EfficientTAM"
"jovanavidenovic/DAM4SAM" -> "ClaudiaCuttano/SAMWISE" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "kangben258/MCITrack" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "chenxin-dlut/SUTrack" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "alimohammadiamirhossein/smite"
"jovanavidenovic/DAM4SAM" -> "Restricted-Memory/RMem" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "GuoleiSun/Awesome-SAM2"
"jovanavidenovic/DAM4SAM" -> "MIV-XJTU/ARTrack" ["e"=1]
"jovanavidenovic/DAM4SAM" -> "nnanhuang/SegAnyMo" ["e"=1]
"Surrey-UP-Lab/GS-LPM" -> "happy-hsy/MotionMAE"
"OliverRensu/MVG" -> "lambert-x/ProLab" ["e"=1]
"YutingLi0606/HTR-VT" -> "YutingLi0606/SURE"
"YutingLi0606/HTR-VT" -> "LIYangggggg/SSB-OSR"
"JarintotionDin/ZiRaGroundingDINO" -> "DongSky/MR-GDINO"
"DongSky/MR-GDINO" -> "JarintotionDin/ZiRaGroundingDINO"
"ouyanghaodong/DEYOv1.5" -> "ouyanghaodong/DEYO"
"linsun449/iseg.code" -> "linsun449/cliper.code"
"mc-lan/ClearCLIP" -> "mc-lan/ProxyCLIP"
"mc-lan/ClearCLIP" -> "wangf3014/SCLIP"
"lyxlplhy/Sam2Onnx_Inference" -> "lyxlplhy/Sam2-collection"
"lyxlplhy/Sam2-collection" -> "lyxlplhy/Sam2Onnx_Inference"
"MonoFormer/MonoFormer" -> "Atten4Vis/MS-DETR"
"COCO-FP/COCO-FP" -> "LIYangggggg/SSB-OSR"
"COCO-FP/COCO-FP" -> "YutingLi0606/SURE"
"LIYangggggg/SSB-OSR" -> "COCO-FP/COCO-FP"
"LIYangggggg/SSB-OSR" -> "YutingLi0606/SURE"
"kaist-dmlab/RECURVE" -> "kaist-dmlab/Prune4Rel"
"kaist-dmlab/RECURVE" -> "kaist-dmlab/CrossMatch"
"SkalskiP/vlms-zero-to-hero" -> "roboflow/maestro" ["e"=1]
"SkalskiP/vlms-zero-to-hero" -> "SkalskiP/top-cvpr-2024-papers" ["e"=1]
"sunsmarterjie/yolov12" -> "ShihuaHuang95/DEIM"
"sunsmarterjie/yolov12" -> "THU-MIG/yoloe"
"sunsmarterjie/yolov12" -> "Peterande/D-FINE"
"sunsmarterjie/yolov12" -> "lyuwenyu/RT-DETR"
"sunsmarterjie/yolov12" -> "roboflow/rf-detr"
"sunsmarterjie/yolov12" -> "THU-MIG/yolov10"
"sunsmarterjie/yolov12" -> "CVHub520/X-AnyLabeling"
"sunsmarterjie/yolov12" -> "WongKinYiu/yolov9"
"sunsmarterjie/yolov12" -> "AILab-CVC/YOLO-World"
"sunsmarterjie/yolov12" -> "Atten4Vis/LW-DETR"
"sunsmarterjie/yolov12" -> "laugh12321/TensorRT-YOLO" ["e"=1]
"sunsmarterjie/yolov12" -> "iscyy/ultralyticsPro" ["e"=1]
"sunsmarterjie/yolov12" -> "open-mmlab/mmyolo" ["e"=1]
"sunsmarterjie/yolov12" -> "HZAI-ZJNU/Mamba-YOLO" ["e"=1]
"sunsmarterjie/yolov12" -> "ifzhang/ByteTrack" ["e"=1]
"roboflow/trackers" -> "roboflow/rf-detr"
"roboflow/trackers" -> "roboflow/maestro"
"roboflow/trackers" -> "knmcguire/best-of-robot-simulators" ["e"=1]
"roboflow/trackers" -> "SkalskiP/vlms-zero-to-hero" ["e"=1]
"roboflow/trackers" -> "SkalskiP/top-cvpr-2024-papers"
"roboflow/trackers" -> "yformer/EfficientTAM"
"roboflow/trackers" -> "yangchris11/samurai"
"roboflow/trackers" -> "gtbook/robotics" ["e"=1]
"roboflow/trackers" -> "riscmaster/kinematic_arbiter" ["e"=1]
"roboflow/trackers" -> "Peterande/D-FINE"
"roboflow/trackers" -> "SoccerNet/sn-gamestate" ["e"=1]
"roboflow/trackers" -> "NVlabs/describe-anything" ["e"=1]
"roboflow/trackers" -> "PRBonn/kiss-icp" ["e"=1]
"roboflow/trackers" -> "rmurai0610/MASt3R-SLAM" ["e"=1]
"roboflow/trackers" -> "THU-MIG/yoloe"
"NVIDIA/Cosmos" -> "facebookresearch/sam2" ["e"=1]
"NVlabs/describe-anything" -> "THU-MIG/yoloe" ["e"=1]
"facebookresearch/perception_models" -> "THU-MIG/yoloe" ["e"=1]
"roboflow/rf-detr" -> "Peterande/D-FINE"
"roboflow/rf-detr" -> "roboflow/trackers"
"roboflow/rf-detr" -> "THU-MIG/yoloe"
"roboflow/rf-detr" -> "roboflow/maestro"
"roboflow/rf-detr" -> "lyuwenyu/RT-DETR"
"roboflow/rf-detr" -> "sunsmarterjie/yolov12"
"roboflow/rf-detr" -> "ShihuaHuang95/DEIM"
"roboflow/rf-detr" -> "roboflow/inference"
"roboflow/rf-detr" -> "MultimediaTechLab/YOLO"
"roboflow/rf-detr" -> "autodistill/autodistill"
"roboflow/rf-detr" -> "AILab-CVC/YOLO-World"
"roboflow/rf-detr" -> "Deci-AI/super-gradients"
"roboflow/rf-detr" -> "IDEA-Research/Grounded-SAM-2"
"roboflow/rf-detr" -> "yangchris11/samurai"
"roboflow/rf-detr" -> "roboflow/notebooks" ["e"=1]
"THU-MIG/YOLO-UniOW" -> "feifeiobama/OrthogonalDet"
"THU-MIG/YOLO-UniOW" -> "343gltysprk/ovow"
"THU-MIG/YOLO-UniOW" -> "D-Robotics-AI-Lab/DOSOD"
"THU-MIG/YOLO-UniOW" -> "Xuan-World/Mamba-YOLO-World"
"THU-MIG/YOLO-UniOW" -> "orrzohar/FOMO"
"THU-MIG/yoloe" -> "sunsmarterjie/yolov12"
"THU-MIG/yoloe" -> "IDEA-Research/DINO-X-API"
"THU-MIG/yoloe" -> "roboflow/rf-detr"
"THU-MIG/yoloe" -> "ShihuaHuang95/DEIM"
"THU-MIG/yoloe" -> "Peterande/D-FINE"
"THU-MIG/yoloe" -> "AILab-CVC/YOLO-World"
"THU-MIG/yoloe" -> "THU-MIG/YOLO-UniOW"
"THU-MIG/yoloe" -> "Atten4Vis/LW-DETR"
"THU-MIG/yoloe" -> "facebookresearch/perception_models" ["e"=1]
"THU-MIG/yoloe" -> "Westlake-AGI-Lab/Distill-Any-Depth" ["e"=1]
"THU-MIG/yoloe" -> "IDEA-Research/Grounding-DINO-1.5-API"
"THU-MIG/yoloe" -> "IDEA-Research/T-Rex"
"THU-MIG/yoloe" -> "iSEE-Laboratory/LLMDet"
"THU-MIG/yoloe" -> "lyuwenyu/RT-DETR"
"THU-MIG/yoloe" -> "NVlabs/describe-anything" ["e"=1]
"lil-lab/nlvr" -> "e-bug/iglue"
"lovelyqian/NTIRE2025_CDFSOD" -> "jaychempan/ETS" ["e"=1]
"iSEE-Laboratory/LLMDet" -> "THU-MIG/YOLO-UniOW"
"D-Robotics-AI-Lab/DOSOD" -> "THU-MIG/YOLO-UniOW"
"lucasjinreal/Namo-R1" -> "x-cls/superclass"
"ocean146/SimROD" -> "COCO-FP/COCO-FP"
"uber/petastorm" ["l"="-2.71,17.193", "c"=455]
"webdataset/webdataset" ["l"="49.092,30.307"]
"microsoft/unilm" ["l"="38.785,-0.95", "c"=39]
"salesforce/LAVIS" ["l"="49.008,30.194"]
"mlfoundations/open_clip" ["l"="48.974,30.216"]
"sgrvinod/a-PyTorch-Tutorial-to-Image-Captioning" ["l"="48.608,31.879", "c"=300]
"rmokady/CLIP_prefix_caption" ["l"="49.115,30.367"]
"katsura-jp/pytorch-cosine-annealing-with-warmup" ["l"="51.063,30.193", "c"=83]
"Zasder3/train-CLIP" ["l"="49.054,30.363"]
"idealo/imagededup" ["l"="51.052,29.696", "c"=83]
"rom1504/clip-retrieval" ["l"="49.021,30.321"]
"VainF/DeepLabV3Plus-Pytorch" ["l"="53.305,30.893", "c"=155]
"NVlabs/SegFormer" ["l"="48.864,30.228"]
"ultralytics/JSON2YOLO" ["l"="50.292,30.012", "c"=83]
"vietanhdev/anylabeling" ["l"="48.817,30.008"]
"AILab-CVC/YOLO-World" ["l"="48.743,30.053"]
"autodistill/autodistill" ["l"="48.728,30.002"]
"NVIDIA/aistore" ["l"="7.216,-11.471", "c"=515]
"matsui528/faiss_tips" ["l"="-1.166,3.916", "c"=576]
"criteo/autofaiss" ["l"="49.039,30.413"]
"facebookresearch/mmf" ["l"="48.638,32.057", "c"=300]
"facebookresearch/multimodal" ["l"="48.947,30.29"]
"pliang279/awesome-multimodal-ml" ["l"="48.592,32.051", "c"=300]
"SkalskiP/make-sense" ["l"="50.393,29.546", "c"=83]
"cvdfoundation/open-images-dataset" ["l"="50.717,30.179", "c"=83]
"raoyongming/DenseCLIP" ["l"="48.818,30.315"]
"kshmelkov/incremental_detectors" ["l"="48.307,30.438"]
"CanPeng123/Faster-ILOD" ["l"="48.312,30.42"]
"JosephKJ/iOD" ["l"="48.346,30.4"]
"Hi-FT/ERD" ["l"="48.301,30.416"]
"zhonhel/Incremental-Object-Detection-with-Feature-Pyramid-Network-and-Knowledge-Distillation" ["l"="48.292,30.459"]
"jinyu121/CIOD" ["l"="48.264,30.475"]
"DessiLBI2020/DessiLBI" ["l"="48.241,30.492"]
"TheShadow29/awesome-grounding" ["l"="48.847,31.967", "c"=300]
"microsoft/GLIP" ["l"="48.866,30.251"]
"jianzongwu/Awesome-Open-Vocabulary" ["l"="48.681,30.233"]
"MarkMoHR/Awesome-Referring-Image-Segmentation" ["l"="48.925,31.903", "c"=300]
"lxtGH/Awesome-Segmentation-With-Transformer" ["l"="48.757,30.228"]
"Qinying-Liu/Awesome-Open-Vocabulary-Semantic-Segmentation" ["l"="48.667,30.26"]
"li-xirong/coco-cn" ["l"="48.429,31.811", "c"=300]
"BAAI-WuDao/BriVL" ["l"="49.141,30.497"]
"kaist-dmlab/SELFIE" ["l"="48.63,30.558"]
"kaist-dmlab/LetsPic-DL" ["l"="48.608,30.541"]
"kaist-dmlab/MTA" ["l"="48.617,30.562"]
"kaist-dmlab/FL-Sim" ["l"="48.627,30.537"]
"kaist-dmlab/TRAP" ["l"="48.618,30.534"]
"kaist-dmlab/revisit" ["l"="48.603,30.548"]
"kaist-dmlab/BlackHole" ["l"="48.614,30.571"]
"kaist-dmlab/BioNER" ["l"="48.614,30.554"]
"kaist-dmlab/NETS" ["l"="48.633,30.547"]
"kaist-dmlab/Topical-Influence" ["l"="48.607,30.567"]
"kaist-dmlab/PAS" ["l"="48.624,30.57"]
"kaist-dmlab/RecencyBias" ["l"="48.638,30.537"]
"kaist-dmlab/Ada-Boundary" ["l"="48.642,30.526"]
"kaist-dmlab/RP-DBSCAN" ["l"="48.621,30.548"]
"kaist-dmlab/k-Medoid" ["l"="48.604,30.557"]
"kaist-dmlab/STARE" ["l"="48.657,30.532"]
"mhsamavatian/DAP" ["l"="48.614,30.76"]
"zzyy0929/AAAI2020-RiskOracle" ["l"="48.621,30.736"]
"NielsRogge/Transformers-Tutorials" ["l"="47.772,26.319", "c"=323]
"open-mmlab/mmsegmentation" ["l"="50.519,29.799", "c"=83]
"facebookresearch/Mask2Former" ["l"="48.83,30.207"]
"VisDrone/VisDrone-Dataset" ["l"="54.52,32.511", "c"=279]
"lyuwenyu/RT-DETR" ["l"="48.679,30.072"]
"voxel51/fiftyone" ["l"="50.554,29.627", "c"=83]
"IDEA-Research/Grounded-Segment-Anything" ["l"="48.915,30.081"]
"facebookresearch/dinov2" ["l"="48.971,30.114"]
"facebookresearch/sam2" ["l"="48.908,29.989"]
"PaddlePaddle/PaddleSeg" ["l"="50.315,29.679", "c"=83]
"unsplash/datasets" ["l"="-44.289,11.177", "c"=1049]
"haltakov/natural-language-image-search" ["l"="49.146,30.374"]
"rom1504/img2dataset" ["l"="48.99,30.304"]
"libffcv/ffcv" ["l"="50.953,29.6", "c"=83]
"arogozhnikov/einops" ["l"="50.9,29.579", "c"=83]
"facebookresearch/fairscale" ["l"="38.777,-0.604", "c"=39]
"facebookresearch/vissl" ["l"="52.961,29.524", "c"=547]
"facebookincubator/submitit" ["l"="21.614,14.08", "c"=267]
"mosaicml/streaming" ["l"="38.713,-0.353", "c"=39]
"pytorch/data" ["l"="21.583,14.144", "c"=267]
"kakaobrain/coyo-dataset" ["l"="49.003,30.342"]
"mlfoundations/open_flamingo" ["l"="49.028,30.256"]
"huggingface/accelerate" ["l"="38.719,-0.759", "c"=39]
"NVIDIA/DALI" ["l"="50.737,29.833", "c"=83]
"tryolabs/norfair" ["l"="54.552,32.486", "c"=279]
"Deci-AI/super-gradients" ["l"="48.722,29.975"]
"sebgao/LIP" ["l"="47.716,34.161", "c"=168]
"MCG-NJU/AdaMixer" ["l"="48.696,30.355"]
"google-research/kubric" ["l"="63.615,1.552", "c"=134]
"qianqianwang68/omnimotion" ["l"="48.96,29.972"]
"apple2373/MetaIRNet" ["l"="48.22,30.51"]
"nang-dev/hover-paywalls-browser-extension" ["l"="-51.138,13.049", "c"=200]
"everywall/ladder" ["l"="48.45,29.957"]
"bowenc0221/panoptic-deeplab" ["l"="53.241,30.94", "c"=155]
"facebookresearch/MaskFormer" ["l"="48.831,30.267"]
"HumanSignal/label-studio-ml-backend" ["l"="50.299,29.132", "c"=83]
"open-mmlab/playground" ["l"="48.845,30.051"]
"roboflow/roboflow-python" ["l"="48.58,29.85"]
"roboflow/inference" ["l"="48.652,29.953"]
"roboflow/roboflow-computer-vision-utilities" ["l"="48.555,29.82"]
"roboflow/dji-aerial-georeferencing" ["l"="48.538,29.785"]
"roboflow/polygonzone" ["l"="48.565,29.804"]
"dbolya/tide" ["l"="50.765,30.234", "c"=83]
"IDEA-Research/awesome-detection-transformer" ["l"="48.75,30.304"]
"alirezazareian/ovr-cnn" ["l"="48.586,30.298"]
"dyabel/detpro" ["l"="48.548,30.295"]
"fcjian/PromptDet" ["l"="48.563,30.306"]
"yuhangzang/OV-DETR" ["l"="48.573,30.317"]
"salesforce/PB-OVD" ["l"="48.548,30.342"]
"hanoonaR/object-centric-ovd" ["l"="48.546,30.31"]
"tgxs002/CORA" ["l"="48.572,30.289"]
"microsoft/RegionCLIP" ["l"="48.631,30.276"]
"wusize/ovdet" ["l"="48.55,30.282"]
"xiaofeng94/VL-PLM" ["l"="48.516,30.32"]
"witnessai/Awesome-Open-Vocabulary-Object-Detection" ["l"="48.608,30.245"]
"JosephKJ/OWOD" ["l"="48.467,30.367"]
"akshitac8/OW-DETR" ["l"="48.43,30.338"]
"mmaaz60/mvits_for_class_agnostic_od" ["l"="48.479,30.325"]
"mcahny/object_localization_network" ["l"="48.46,30.343"]
"orrzohar/PROB" ["l"="48.438,30.305"]
"amirbar/DETReg" ["l"="49.386,29.431", "c"=1525]
"megvii-model/YOLOF" ["l"="50.723,30.244", "c"=83]
"ucbdrive/few-shot-object-detection" ["l"="49.416,29.395", "c"=1525]
"xieenze/DetCo" ["l"="52.987,29.388", "c"=547]
"xingyizhou/CenterNet2" ["l"="50.729,30.212", "c"=83]
"RE-OWOD/RE-OWOD" ["l"="48.436,30.354"]
"implus/GFocalV2" ["l"="50.768,30.262", "c"=83]
"PeizeSun/OneNet" ["l"="50.741,30.275", "c"=83]
"dddzg/up-detr" ["l"="48.63,30.387"]
"csuhan/opendet2" ["l"="48.419,30.358"]
"vahidk/tfrecord" ["l"="50.58,30.164", "c"=83]
"georgian-io/Multimodal-Toolkit" ["l"="45.988,24.742", "c"=1262]
"microsoft/M3P" ["l"="49.14,30.474"]
"zmykevin/UC2" ["l"="49.232,30.541"]
"shruti-jadon/Semantic-Segmentation-Loss-Functions" ["l"="61.912,36.863", "c"=178]
"voxel51/fiftyone-brain" ["l"="48.324,29.655"]
"voxel51/fiftyone-plugins" ["l"="48.329,29.632"]
"voxel51/fiftyone-examples" ["l"="48.341,29.644"]
"voxel51/papers-with-data" ["l"="48.362,29.665"]
"valeoai/ZS3" ["l"="46.486,31.433", "c"=580]
"MendelXu/zsseg.baseline" ["l"="48.725,30.298"]
"kaist-dmlab/Hi-COVIDNet" ["l"="48.671,30.518"]
"kaist-dmlab/TensorSparkML" ["l"="48.66,30.557"]
"yule-BUAA/DSTGCN" ["l"="48.645,30.656"]
"Echohhhhhh/GSNet" ["l"="48.631,30.702"]
"kaist-dmlab/MG-TAR" ["l"="48.665,30.581"]
"yule-BUAA/DNNTSP" ["l"="48.641,30.679"]
"tingxueronghua/pytorch-classification-advprop" ["l"="49.219,30.796"]
"meijieru/fast_advprop" ["l"="49.2,30.767"]
"AI-secure/Big-but-Invisible-Adversarial-Attack" ["l"="49.234,30.816"]
"BradyFU/DVG" ["l"="48.474,30.154"]
"BradyFU/DVG-Face" ["l"="48.519,30.163"]
"xuefeng-cvr/Tiny-Obstacle-Discovery" ["l"="48.305,30.322"]
"xuefeng-cvr/Tiny-Obstacle-Discovery-ROS" ["l"="48.287,30.32"]
"CompVis/taming-transformers" ["l"="45.914,31.524", "c"=605]
"google-research/vision_transformer" ["l"="50.739,29.626", "c"=83]
"openai/CLIP" ["l"="50.642,29.547", "c"=83]
"SwinTransformer/Swin-Transformer-Semantic-Segmentation" ["l"="53.203,31.048", "c"=155]
"Alibaba-MIIL/ImageNet21K" ["l"="51.117,30.299", "c"=83]
"mlfoundations/wise-ft" ["l"="48.956,30.334"]
"UCSC-VLAA/CLIPA" ["l"="48.984,30.44"]
"haotian-liu/LLaVA" ["l"="47.375,29.865", "c"=254]
"salesforce/BLIP" ["l"="48.991,30.249"]
"IDEA-Research/GroundingDINO" ["l"="48.845,30.11"]
"BradyFU/Awesome-Multimodal-Large-Language-Models" ["l"="47.423,29.9", "c"=254]
"OFA-Sys/Chinese-CLIP" ["l"="49.065,30.217"]
"facebookresearch/mae" ["l"="50.721,29.589", "c"=83]
"CompVis/latent-diffusion" ["l"="45.862,31.511", "c"=605]
"huggingface/diffusers" ["l"="45.89,31.459", "c"=605]
"YuqingWang1029/VisTR" ["l"="50.673,30.529", "c"=83]
"microsoft/Cream" ["l"="48.983,33.05", "c"=401]
"mit-han-lab/efficientvit" ["l"="48.711,30.03"]
"whai362/PVT" ["l"="50.757,29.87", "c"=83]
"fudan-zvg/SETR" ["l"="53.247,31.058", "c"=155]
"HRNet/HRNet-Semantic-Segmentation" ["l"="53.339,30.954", "c"=155]
"lucidrains/segformer-pytorch" ["l"="53.18,31.092", "c"=155]
"bubbliiiing/segformer-pytorch" ["l"="50.203,30.161", "c"=83]
"Beckschen/TransUNet" ["l"="61.845,36.92", "c"=178]
"czczup/ViT-Adapter" ["l"="48.832,30.241"]
"rstrudel/segmenter" ["l"="53.236,31.041", "c"=155]
"HuCaoFighting/Swin-Unet" ["l"="61.818,36.933", "c"=178]
"SHI-Labs/OneFormer" ["l"="48.81,30.192"]
"nadermx/backgroundremover" ["l"="38.619,0.965", "c"=54]
"geekyutao/Inpaint-Anything" ["l"="48.981,30.072"]
"lucidrains/DALLE-pytorch" ["l"="46.018,31.525", "c"=605]
"haltakov/natural-language-youtube-search" ["l"="-22.286,6.68", "c"=633]
"haofanwang/natural-language-joint-query-search" ["l"="32.712,30.649", "c"=109]
"kingyiusuen/clip-image-search" ["l"="49.228,30.367"]
"rkouye/es-clip-image-search" ["l"="49.201,30.369"]
"EdVince/CLIP-ImageSearch-NCNN" ["l"="49.652,30.812", "c"=1055]
"FreddeFrallan/Multilingual-CLIP" ["l"="49.042,30.389"]
"nerdyrodent/CLIP-Guided-Diffusion" ["l"="44.7,31.439", "c"=1003]
"AndreyGuzhov/AudioCLIP" ["l"="39.6,5.488", "c"=593]
"yzhuoning/Awesome-CLIP" ["l"="50.366,38.215", "c"=684]
"eps696/stylegan2" ["l"="44.825,31.497", "c"=1003]
"ABaldrati/CLIP4Cir" ["l"="32.783,30.705", "c"=109]
"LAION-AI/CLIP_benchmark" ["l"="48.96,30.365"]
"facebookresearch/SLIP" ["l"="48.929,30.344"]
"google-research-datasets/wit" ["l"="48.743,31.945", "c"=300]
"LAION-AI/CLIP-based-NSFW-Detector" ["l"="38.29,-7.084", "c"=448]
"Lednik7/CLIP-ONNX" ["l"="49.116,30.553"]
"lucidrains/x-clip" ["l"="48.971,30.385"]
"OFA-Sys/OFA" ["l"="49.008,30.282"]
"billjie1/Chinese-CLIP" ["l"="49.143,30.452"]
"rom1504/laion-prepro" ["l"="49.014,30.409"]
"google-research/big_vision" ["l"="48.957,30.256"]
"rinongal/textual_inversion" ["l"="32.103,31.96", "c"=88]
"baaivision/EVA" ["l"="48.906,30.24"]
"pharmapsychotic/clip-interrogator" ["l"="32.104,31.839", "c"=88]
"facebookresearch/DiT" ["l"="45.849,31.545", "c"=605]
"obss/sahi" ["l"="50.456,29.951", "c"=83]
"CVHub520/X-AnyLabeling" ["l"="48.763,30.008"]
"WongKinYiu/yolov9" ["l"="48.681,29.992"]
"salesforce/ALBEF" ["l"="48.761,31.992", "c"=300]
"luo3300612/Visualizer" ["l"="50.875,29.609", "c"=83]
"IDEA-Research/detrex" ["l"="48.774,30.252"]
"google-research/scenic" ["l"="48.018,33.755", "c"=168]
"amusi/ICCV2023-Papers-with-Code" ["l"="50.838,29.727", "c"=83]
"facebookresearch/distributed-faiss" ["l"="-1.192,3.951", "c"=576]
"rom1504/embedding-reader" ["l"="49.079,30.465"]
"lucidrains/RETRO-pytorch" ["l"="-5.216,-23.353", "c"=164]
"dzryk/antarctic-captions" ["l"="49.063,30.486"]
"KarelDO/xmc.dspy" ["l"="41.235,0.914", "c"=7]
"currentslab/awesome-vector-search" ["l"="-1.148,3.943", "c"=576]
"songhwanjun/Awesome-Noisy-Labels" ["l"="51.507,30.423", "c"=83]
"fundamentalvision/Deformable-DETR" ["l"="50.74,29.892", "c"=83]
"IDEA-Research/DINO" ["l"="48.79,30.224"]
"IDEA-Research/DN-DETR" ["l"="48.73,30.349"]
"IDEA-Research/DAB-DETR" ["l"="48.719,30.337"]
"ShoufaChen/DiffusionDet" ["l"="48.83,30.299"]
"dk-liang/Awesome-Visual-Transformer" ["l"="50.812,29.72", "c"=83]
"facebookresearch/dino" ["l"="50.773,29.606", "c"=83]
"SwinTransformer/Swin-Transformer-Object-Detection" ["l"="50.687,30.088", "c"=83]
"ZhangGongjie/Meta-DETR" ["l"="49.393,29.414", "c"=1525]
"ZhangGongjie/SAM-DETR" ["l"="48.696,30.394"]
"THUDM/CogView" ["l"="46.01,31.588", "c"=605]
"Atten4Vis/ConditionalDETR" ["l"="48.682,30.361"]
"megvii-research/AnchorDETR" ["l"="48.678,30.387"]
"gaopengcuhk/SMCA-DETR" ["l"="48.665,30.405"]
"kakaobrain/sparse-detr" ["l"="48.685,30.405"]
"twangnh/pnp-detr" ["l"="48.671,30.425"]
"HDETR/H-Deformable-DETR" ["l"="48.669,30.354"]
"jshilong/DDQ" ["l"="48.679,30.342"]
"impiga/Plain-DETR" ["l"="48.617,30.292"]
"PeizeSun/SparseR-CNN" ["l"="50.754,30.202", "c"=83]
"MichaelFan01/STDC-Seg" ["l"="53.25,31.015", "c"=155]
"rafaelpadilla/review_object_detection_metrics" ["l"="50.625,30.104", "c"=83]
"Yangzhangcst/Transformer-in-Computer-Vision" ["l"="50.858,29.642", "c"=83]
"liliu-avril/Awesome-Segment-Anything" ["l"="48.774,30.116"]
"sithu31296/semantic-segmentation" ["l"="53.231,30.993", "c"=155]
"allenai/mmc4" ["l"="49.046,30.301"]
"johanmodin/clifs" ["l"="47.861,32.938", "c"=373]
"chuhaojin/BriVL-BUA-applications" ["l"="49.157,30.518"]
"chuhaojin/WenLan-api-document" ["l"="49.157,30.531"]
"yuxie11/R2D2" ["l"="49.164,30.484"]
"neilfei/brivl-nmi" ["l"="49.181,30.523"]
"uta-smile/TCL" ["l"="48.806,32.003", "c"=300]
"neuralmagic/deepsparse" ["l"="38.731,-0.469", "c"=39]
"dandelin/ViLT" ["l"="48.751,32.016", "c"=300]
"lucidrains/perceiver-pytorch" ["l"="48.859,33.923", "c"=556]
"lucidrains/flamingo-pytorch" ["l"="49.022,30.299"]
"NVlabs/GroupViT" ["l"="48.79,30.31"]
"alibaba/AliceMind" ["l"="53.359,27.127", "c"=60]
"hila-chefer/Transformer-MM-Explainability" ["l"="50.91,29.608", "c"=83]
"Sense-GVT/DeCLIP" ["l"="48.883,30.342"]
"google-research/deeplab2" ["l"="53.16,30.962", "c"=155]
"IDEA-Research/MaskDINO" ["l"="48.8,30.247"]
"bytedance/kmax-deeplab" ["l"="48.74,30.41"]
"stephanecharette/DarkMark" ["l"="48.445,29.882"]
"stephanecharette/DarkHelp" ["l"="48.462,29.875"]
"hank-ai/darknet" ["l"="48.492,29.904"]
"stephanecharette/DarkPlate" ["l"="48.451,29.861"]
"stephanecharette/MoveDetect" ["l"="48.433,29.862"]
"yurijmikhalevich/rclip" ["l"="-51.29,10.081", "c"=19]
"facebookresearch/xcit" ["l"="49.042,33.133", "c"=401]
"heroiclabs/nakama-dart" ["l"="48.342,29.978"]
"Allan-Nava/nakama-flutter" ["l"="48.288,29.973"]
"revantteotia/clip-training" ["l"="49.086,30.394"]
"Zasder3/train-CLIP-FT" ["l"="49.092,30.41"]
"moein-shariatnia/OpenAI-CLIP" ["l"="49.017,30.363"]
"clip-italian/clip-italian" ["l"="44.796,25.486", "c"=68]
"gaopengcuhk/Tip-Adapter" ["l"="50.332,38.271", "c"=684]
"KaiyangZhou/CoOp" ["l"="50.344,38.24", "c"=684]
"gaopengcuhk/CLIP-Adapter" ["l"="50.337,38.258", "c"=684]
"arampacha/CLIP-rsicd" ["l"="41.697,25.141", "c"=525]
"microsoft/DynamicHead" ["l"="50.811,30.232", "c"=83]
"ZwwWayne/K-Net" ["l"="50.751,30.441", "c"=83]
"dvlab-research/PanopticFCN" ["l"="53.209,30.951", "c"=155]
"openseg-group/openseg.pytorch" ["l"="53.345,30.977", "c"=155]
"tfzhou/ContrastiveSeg" ["l"="53.025,29.394", "c"=547]
"ChenhongyiYang/QueryDet-PyTorch" ["l"="53.89,31.966", "c"=2290]
"microsoft/SoftTeacher" ["l"="51.008,30.242", "c"=83]
"fcdl94/MMA" ["l"="48.328,30.416"]
"FanZhichen/Awesome-Incremental-Few-Shot-Object-Detection" ["l"="48.264,30.427"]
"CtCCtV/Amazing-Incremental-Object-Detection-with-Knowledge-Distillation" ["l"="48.312,30.405"]
"hustvl/YOLOS" ["l"="50.648,30.201", "c"=83]
"naver-ai/vidt" ["l"="48.668,30.488"]
"Meituan-AutoML/Twins" ["l"="49.122,33.112", "c"=401]
"ashkamath/mdetr" ["l"="48.833,31.941", "c"=300]
"facebookresearch/Detic" ["l"="48.797,30.285"]
"SegmentationBLWX/sssegmentation" ["l"="53.26,30.996", "c"=155]
"lucidrains/CoCa-pytorch" ["l"="48.961,30.31"]
"lucidrains/video-diffusion-pytorch" ["l"="33.669,31.317", "c"=109]
"cloneofsimo/minDiffusion" ["l"="45.71,31.647", "c"=605]
"patrickjohncyh/fashion-clip" ["l"="43.483,30.651", "c"=318]
"Megvii-BaseDetection/DeFCN" ["l"="50.773,30.294", "c"=83]
"WXinlong/DenseCL" ["l"="52.996,29.449", "c"=547]
"limbo0000/InstanceLoc" ["l"="52.999,29.373", "c"=547]
"fcjian/TOOD" ["l"="50.777,30.322", "c"=83]
"xingyizhou/UniDet" ["l"="50.941,30.289", "c"=83]
"VODKA312/IntroToSelf-control" ["l"="49.873,3.435", "c"=941]
"zhechen/Deformable-DETR-REGO" ["l"="48.664,30.454"]
"ManuelFay/ImageSearcher" ["l"="49.27,30.376"]
"atarss/clip-image-search" ["l"="49.28,30.359"]
"AkiRusProd/CLIP-search" ["l"="49.256,30.36"]
"xuefeng-cvr/BS-Net" ["l"="48.268,30.329"]
"gaopengcuhk/Container" ["l"="48.634,30.464"]
"abc403/SMCA-replication" ["l"="48.642,30.438"]
"t0efL/Cassava-Leaf-Disease-Classification" ["l"="49.154,30.632"]
"t0efL/2nd-place-solution-Digital-Peter" ["l"="49.134,30.619"]
"joe-siyuan-qiao/ViP-DeepLab" ["l"="53.182,30.947", "c"=155]
"kaist-dmlab/MDUAL" ["l"="48.642,30.589"]
"kaist-dmlab/MORPH" ["l"="48.64,30.608"]
"LAION-AI/laion-datasets" ["l"="33.439,31.53", "c"=109]
"dzryk/clip-grams" ["l"="49.076,30.524"]
"kaist-dmlab/DF-TAR" ["l"="48.652,30.595"]
"voxel51/voxelgpt" ["l"="48.353,29.627"]
"voxel51/eta" ["l"="48.352,29.611"]
"dzryk/cliptalk" ["l"="49.082,30.546"]
"kaist-dmlab/CrossMatch" ["l"="48.681,30.569"]
"kaist-dmlab/RECURVE" ["l"="48.682,30.589"]
"kaist-dmlab/Prune4Rel" ["l"="48.674,30.6"]
"kaist-dmlab/TCLP" ["l"="48.694,30.586"]
"e-bug/iglue" ["l"="49.27,30.558"]
"ai-forever/DigiTeller" ["l"="49.161,30.604"]
"neverix/avengers-ensemble" ["l"="49.141,30.585"]
"encord-team/encord-client-python" ["l"="48.282,29.541"]
"encord-team/encord-active" ["l"="48.282,29.566"]
"allenai/container" ["l"="48.62,30.488"]
"NeuralPushkin/Dalle2-Decoder" ["l"="49.158,30.585"]
"KonderLip/data-fusion2022-open-solution" ["l"="49.127,30.575"]
"facebookresearch/xformers" ["l"="38.829,-0.716", "c"=39]
"alibaba/EasyCV" ["l"="50.391,29.908", "c"=83]
"yandex-research/ddpm-segmentation" ["l"="61.794,36.52", "c"=178]
"NVlabs/ODISE" ["l"="48.752,30.251"]
"lucidrains/PaLM-pytorch" ["l"="-5.186,-23.312", "c"=164]
"lucidrains/DALLE2-pytorch" ["l"="45.993,31.488", "c"=605]
"QwenLM/Qwen-VL" ["l"="47.411,29.954", "c"=254]
"microsoft/Oscar" ["l"="48.709,31.976", "c"=300]
"yuewang-cuhk/awesome-vision-language-pretraining-papers" ["l"="48.733,31.999", "c"=300]
"zengyan-97/X-VLM" ["l"="48.801,32.022", "c"=300]
"X-PLUG/mPLUG-Owl" ["l"="47.444,29.996", "c"=254]
"yaoyao-liu/CL-DETR" ["l"="48.287,30.427"]
"YuyangSunshine/ABR_IOD" ["l"="48.322,30.43"]
"XuJiacong/PIDNet" ["l"="53.187,31.025", "c"=155]
"OpenGVLab/InternImage" ["l"="48.854,30.198"]
"Sanster/IOPaint" ["l"="38.492,0.994", "c"=54]
"xuebinqin/DIS" ["l"="44.782,30.973", "c"=243]
"SysCV/sam-hq" ["l"="48.851,30.076"]
"lucidrains/imagen-pytorch" ["l"="45.967,31.512", "c"=605]
"deep-floyd/IF" ["l"="49.092,30.021"]
"microsoft/SimMIM" ["l"="52.893,29.408", "c"=547]
"isl-org/lang-seg" ["l"="48.77,30.285"]
"chongzhou96/MaskCLIP" ["l"="48.735,30.277"]
"timojl/clipseg" ["l"="48.781,30.205"]
"vlmaps/vlmaps" ["l"="60.195,17.587", "c"=363]
"facebookresearch/ov-seg" ["l"="48.732,30.243"]
"DerrickWang005/CRIS.pytorch" ["l"="48.962,31.89", "c"=300]
"dvlab-research/LISA" ["l"="47.454,30.124", "c"=254]
"ZiqinZhou66/ZegCLIP" ["l"="48.753,30.329"]
"gligen/GLIGEN" ["l"="33.379,31.323", "c"=109]
"UX-Decoder/Semantic-SAM" ["l"="48.814,30.127"]
"Alpha-VL/ConvMAE" ["l"="52.866,29.376", "c"=547]
"wasi-master/13ft" ["l"="12.488,-8.751", "c"=18]
"DavidHuji/CapDec" ["l"="49.215,30.426"]
"dhg-wei/DeCap" ["l"="49.252,30.442"]
"FeiElysia/ViECap" ["l"="60.47,17.653", "c"=363]
"allenai/close" ["l"="49.241,30.463"]
"yxuansu/MAGIC" ["l"="49.249,30.421"]
"YoadTew/zero-shot-image-to-text" ["l"="49.222,30.408"]
"IDEA-CCNL/Fengshenbang-LM" ["l"="39.065,-2.107", "c"=202]
"DingXiaoH/RepLKNet-pytorch" ["l"="49.015,33.038", "c"=401]
"VGVentures/slide_puzzle" ["l"="59.903,-22.485", "c"=17]
"flutter/super_dash" ["l"="48.342,29.951"]
"advimman/lama" ["l"="44.749,30.927", "c"=243]
"cmhungsteve/Awesome-Transformer-Attention" ["l"="50.774,29.648", "c"=83]
"microsoft/NUWA" ["l"="45.955,31.58", "c"=605]
"meituan/YOLOv6" ["l"="50.363,29.926", "c"=83]
"WongKinYiu/yolov7" ["l"="50.383,29.816", "c"=83]
"mikel-brostrom/boxmot" ["l"="54.558,32.535", "c"=279]
"ifzhang/ByteTrack" ["l"="54.517,32.538", "c"=279]
"Megvii-BaseDetection/YOLOX" ["l"="50.432,29.878", "c"=83]
"roboflow/notebooks" ["l"="47.729,26.311", "c"=323]
"lucasjinreal/yolov7_d2" ["l"="50.381,29.973", "c"=83]
"Timothyxxx/Chain-of-ThoughtsPapers" ["l"="36.759,-2.46", "c"=797]
"amazon-science/mm-cot" ["l"="49.134,30.261"]
"open-mmlab/mmengine" ["l"="50.421,29.903", "c"=83]
"zhenyuw16/UniDetector" ["l"="48.6,30.278"]
"mlzxy/devit" ["l"="48.566,30.245"]
"clin1223/VLDet" ["l"="48.535,30.281"]
"booydar/recurrent-memory-transformer" ["l"="38.077,-1.555", "c"=1218]
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["l"="48.865,30.127"]
"microsoft/X-Decoder" ["l"="48.821,30.224"]
"facebookresearch/ConvNeXt" ["l"="50.707,29.721", "c"=83]
"deeplearning-wisc/vos" ["l"="52.532,14.172", "c"=1208]
"Went-Liang/UnSniffer" ["l"="48.389,30.317"]
"NVlabs/FreeSOLO" ["l"="53.097,29.37", "c"=547]
"facebookresearch/Generic-Grouping" ["l"="48.4,30.385"]
"kakaobrain/rq-vae-transformer" ["l"="46.537,30.551", "c"=367]
"facebookresearch/moco-v3" ["l"="52.975,29.48", "c"=547]
"m-bain/frozen-in-time" ["l"="47.892,32.958", "c"=373]
"jayleicn/ClipBERT" ["l"="48.738,31.975", "c"=300]
"showlab/all-in-one" ["l"="47.833,32.976", "c"=373]
"yangjianxin1/ClipCap-Chinese" ["l"="49.163,30.419"]
"aimagelab/meshed-memory-transformer" ["l"="48.618,31.937", "c"=300]
"ruotianluo/ImageCaptioning.pytorch" ["l"="48.568,31.903", "c"=300]
"j-min/CLIP-Caption-Reward" ["l"="49.19,30.402"]
"tylin/coco-caption" ["l"="48.589,31.901", "c"=300]
"zhjohnchan/awesome-image-captioning" ["l"="48.605,31.919", "c"=300]
"clip-vil/CLIP-ViL" ["l"="48.758,31.969", "c"=300]
"peteanderson80/bottom-up-attention" ["l"="48.645,31.994", "c"=300]
"lucidrains/nuwa-pytorch" ["l"="33.738,31.321", "c"=109]
"MIMICLab/L-Verse" ["l"="48.988,30.484"]
"crowsonkb/v-diffusion-pytorch" ["l"="44.723,31.427", "c"=1003]
"ml-jku/cloob" ["l"="49.011,30.451"]
"SHI-Labs/Neighborhood-Attention-Transformer" ["l"="49.082,33.057", "c"=401]
"LLaVA-VL/LLaVA-NeXT" ["l"="47.414,30.029", "c"=254]
"facebookresearch/MetaCLIP" ["l"="48.898,30.287"]
"apple/ml-aim" ["l"="46.514,30.627", "c"=367]
"cambrian-mllm/cambrian" ["l"="47.383,30.081", "c"=254]
"EvolvingLMMs-Lab/lmms-eval" ["l"="51.076,2.828", "c"=85]
"wkentaro/gdown" ["l"="-14.223,-1.895", "c"=152]
"cleanlab/cleanvision" ["l"="44.905,25.861", "c"=68]
"EdisonLeeeee/Awesome-Masked-Autoencoders" ["l"="52.811,29.38", "c"=547]
"kakaobrain/mindall-e" ["l"="-5.138,-23.218", "c"=164]
"yoxu515/aot-benchmark" ["l"="47.732,34.615", "c"=1004]
"z-x-yang/Segment-and-Track-Anything" ["l"="48.917,30.042"]
"tianrun-chen/SAM-Adapter-PyTorch" ["l"="48.82,30.098"]
"ShoufaChen/AdaptFormer" ["l"="50.241,38.231", "c"=684]
"KMnP/vpt" ["l"="50.273,38.24", "c"=684]
"microsoft/FocalNet" ["l"="49.058,33.074", "c"=401]
"IDEA-Research/Stable-DINO" ["l"="48.64,30.296"]
"MCG-NKU/E2FGVI" ["l"="44.816,29.355", "c"=912]
"gaomingqi/Track-Anything" ["l"="48.96,30.035"]
"visual-layer/fastdup" ["l"="44.969,25.894", "c"=68]
"facebookresearch/CutLER" ["l"="53.148,29.31", "c"=547]
"IDEA-Research/OpenSeeD" ["l"="48.733,30.218"]
"ThereforeGames/txt2mask" ["l"="31.908,31.928", "c"=88]
"segments-ai/panoptic-segment-anything" ["l"="48.75,30.191"]
"ZrrSkywalker/Personalize-SAM" ["l"="48.803,30.113"]
"amrrs/stable-diffusion-prompt-inpainting" ["l"="31.933,31.999", "c"=88]
"Sense-X/Co-DETR" ["l"="60.459,17.685", "c"=363]
"facebookresearch/detr" ["l"="50.658,29.739", "c"=83]
"tfzhou/ProtoSeg" ["l"="54.017,31.448", "c"=938]
"EPFL-VILAB/MultiMAE" ["l"="52.887,29.334", "c"=547]
"microsoft/UniCL" ["l"="48.798,31.955", "c"=300]
"dhansmair/flamingo-mini" ["l"="49.134,30.32"]
"kohjingyu/fromage" ["l"="49.065,30.322"]
"EvolvingLMMs-Lab/Otter" ["l"="50.99,2.78", "c"=85]
"sail-sg/poolformer" ["l"="49.031,33.08", "c"=401]
"ditejs/ditejs" ["l"="-54.629,-14.751", "c"=301]
"gaoshaoye/Project-Kimi" ["l"="-54.646,-14.744", "c"=301]
"WangTaoAs/PFD_Net" ["l"="-54.629,-14.764", "c"=301]
"2401345934/vite-press-blog" ["l"="48.695,30.442"]
"wflin2020/KotlinExtensions" ["l"="-54.604,-14.723", "c"=301]
"wzongyu/OrderSystem" ["l"="-54.643,-14.799", "c"=301]
"folospace/go-mysql-orm" ["l"="-54.07,-12.492", "c"=252]
"MinerProxyBTC/GoMinerTool" ["l"="49.938,3.278", "c"=941]
"Instance-Search/Instance-Search" ["l"="-53.897,-12.377", "c"=252]
"retnullyu/Dirsearch4burp" ["l"="-54.879,-13.714", "c"=219]
"retnullyu/scanner-front" ["l"="-54.876,-13.704", "c"=219]
"VividLe/BackTAL" ["l"="50.059,3.338", "c"=941]
"google-research/pix2seq" ["l"="48.825,30.345"]
"gaopengcuhk/Stable-Pix2Seq" ["l"="48.827,30.4"]
"moein-shariatnia/Pix2Seq" ["l"="48.842,30.41"]
"gaopengcuhk/Unofficial-Pix2Seq" ["l"="48.821,30.426"]
"OpenGVLab/VisionLLM" ["l"="47.46,30.162", "c"=254]
"amazon-science/polygon-transformer" ["l"="49.006,31.88", "c"=300]
"gaopengcuhk/Pretrained-Pix2Seq" ["l"="48.81,30.408"]
"wjn922/ReferFormer" ["l"="48.95,31.87", "c"=300]
"MendelXu/SAN" ["l"="48.706,30.267"]
"bytedance/ibot" ["l"="52.924,29.41", "c"=547]
"MCG-NJU/STMixer" ["l"="47.675,33.955", "c"=168]
"Fangyi-Chen/SQR" ["l"="48.65,30.35"]
"jozhang97/DETA" ["l"="48.647,30.325"]
"hologerry/SoCo" ["l"="49.352,29.458", "c"=1525]
"strongwolf/DW" ["l"="53.145,32.051", "c"=731]
"MCG-NJU/DEQDet" ["l"="48.658,30.389"]
"MCG-NJU/CamLiFlow" ["l"="65.214,4.293", "c"=263]
"mengqiDyangge/HierKD" ["l"="48.525,30.307"]
"LutingWang/OADP" ["l"="48.515,30.29"]
"llrtt/Zero-Shot-Detection-via-Vision-and-Language-Knowledge-Distillation" ["l"="48.508,30.337"]
"CVMI-Lab/CoDet" ["l"="48.536,30.261"]
"open-mmlab/OpenMMLabCourse" ["l"="50.424,29.934", "c"=83]
"kakaobrain/noc" ["l"="48.616,30.462"]
"orrzohar/FOMO" ["l"="48.443,30.274"]
"Vastlab/Elephant-of-object-detection" ["l"="48.428,30.367"]
"buxihuo/OW-YOLO" ["l"="48.396,30.359"]
"JohnWuzh/UC-OWOD" ["l"="48.392,30.34"]
"frh23333/mepu-owod" ["l"="48.416,30.307"]
"JosephKJ/ELI" ["l"="33.99,31.968", "c"=520]
"Tongji-MIC-Lab/ML-iFSOD" ["l"="48.322,30.389"]
"mmaaz60/EdgeNeXt" ["l"="48.956,33.056", "c"=401]
"mbzuai-oryx/ClimateGPT" ["l"="48.882,33.03", "c"=401]
"abdohelmy/D-3Former" ["l"="48.445,30.322"]
"asif-hanif/vafa" ["l"="50.483,38.279", "c"=684]
"Muhammad-Huzaifaa/ObjectCompose" ["l"="50.527,38.312", "c"=684]
"yxuansu/SimCTG" ["l"="53.445,26.109", "c"=172]
"Sense-X/UniFormer" ["l"="48.062,33.826", "c"=168]
"SysCV/transfiner" ["l"="50.653,30.483", "c"=83]
"xmed-lab/CLIP_Surgery" ["l"="48.678,30.279"]
"wysoczanska/clip_dinoiser" ["l"="48.701,30.326"]
"runnanchen/CLIP2Scene" ["l"="65.274,11.803", "c"=203]
"linyq2117/CLIP-ES" ["l"="53.999,31.503", "c"=938]
"OpenGVLab/gv-benchmark" ["l"="49.376,29.551", "c"=1525]
"ChenRocks/UNITER" ["l"="48.714,31.993", "c"=300]
"ArrowLuo/CLIP4Clip" ["l"="47.909,32.98", "c"=373]
"zengyan-97/CCLM" ["l"="49.259,30.579"]
"tgisaturday/dalle-lightning" ["l"="48.993,30.527"]
"JiwanChung/tapm" ["l"="48.987,30.508"]
"open-mmlab/Multimodal-GPT" ["l"="47.499,30.148", "c"=254]
"declare-lab/multimodal-deep-learning" ["l"="56.62,28.026", "c"=940]
"Ixiaohuihuihui/AO2-DETR" ["l"="53.255,31.956", "c"=731]
"encounter1997/FP-DETR" ["l"="51.865,30.22", "c"=83]
"mlfoundations/datacomp" ["l"="48.986,30.327"]
"beichenzbc/Long-CLIP" ["l"="48.896,30.398"]
"mertyg/vision-language-models-are-bows" ["l"="38.248,-0.115", "c"=39]
"kongds/E5-V" ["l"="32.878,30.741", "c"=109]
"LAION-AI/scaling-laws-openclip" ["l"="48.963,30.427"]
"microsoft/LLM2CLIP" ["l"="48.879,30.422"]
"LijieFan/LaCLIP" ["l"="48.937,30.444"]
"mlfoundations/model-soups" ["l"="38.238,-0.409", "c"=39]
"iejMac/clip-video-encode" ["l"="33.727,31.475", "c"=109]
"rom1504/python-template" ["l"="49.096,30.496"]
"dingjiansw101/ZegFormer" ["l"="48.722,30.317"]
"bytedance/fc-clip" ["l"="48.703,30.305"]
"TACJu/PartImageNet" ["l"="48.771,30.374"]
"facebookresearch/paco" ["l"="48.803,30.369"]
"locuslab/FLYP" ["l"="50.83,37.704", "c"=1182]
"mlfoundations/task_vectors" ["l"="38.295,-0.394", "c"=39]
"LightDXY/FT-CLIP" ["l"="50.333,38.337", "c"=684]
"li-xirong/cross-lingual-cap" ["l"="48.408,31.798", "c"=300]
"foamliu/Image-Captioning-PyTorch" ["l"="48.402,31.826", "c"=300]
"davidnvq/grit" ["l"="48.639,31.933", "c"=300]
"ShemoonX/Chinese-image-caption" ["l"="49.184,30.44"]
"xingyizhou/GTR" ["l"="54.388,32.502", "c"=279]
"yxuansu/TaCL" ["l"="53.498,26.165", "c"=172]
"ksaito-ut/openworld_ldet" ["l"="48.427,30.386"]
"YoadTew/zero-shot-video-to-text" ["l"="49.275,30.432"]
"joeyz0z/ConZIC" ["l"="49.282,30.408"]
"adapter-hub/xGQA" ["l"="49.275,30.601"]
"tangjiuqi097/ATCAIS" ["l"="48.65,30.421"]
"Megvii-BaseDetection/OTA" ["l"="50.746,30.325", "c"=83]
"Surrey-UP-Lab/RegionSpot" ["l"="48.485,30.261"]
"eternaldolphin/LaMI-DETR" ["l"="48.538,30.371"]
"wusize/CLIPSelf" ["l"="48.633,30.26"]
"cene555/ruCLIP-SB" ["l"="49.115,30.586"]
"NeuralPushkin/Pushkin-Poems" ["l"="49.146,30.571"]
"jshilong/GroupRCNN" ["l"="49.461,29.481", "c"=1525]
"happy-hsy/BCNet" ["l"="48.454,30.265"]
"happy-hsy/MotionMAE" ["l"="48.438,30.258"]
"IDEA-Research/Lite-DETR" ["l"="48.63,30.343"]
"jshilong/GPT4RoI" ["l"="47.44,30.215", "c"=254]
"megvii-research/Iter-E2EDET" ["l"="50.85,30.512", "c"=83]
"FelixCaae/AlignDETR" ["l"="48.608,30.304"]
"NVIDIA-AI-IOT/jetson_dla_tutorial" ["l"="53.343,32.587", "c"=251]
"NVIDIA-AI-IOT/jetson-intro-to-distillation" ["l"="48.746,29.849"]
"samschulter/omnilabeltools" ["l"="48.496,30.372"]
"cene555/ru-clip-tiny" ["l"="49.116,30.61"]
"ytongbai/ViTs-vs-CNNs" ["l"="49.177,30.731"]
"UCSC-VLAA/RobustCNN" ["l"="49.154,30.7"]
"facebookresearch/sylph-few-shot-detection" ["l"="48.212,30.443"]
"TMIU/iTFA" ["l"="48.179,30.447"]
"Ybowei/UNP" ["l"="48.195,30.457"]
"kaist-dmlab/MQNet" ["l"="48.696,30.6"]
"YiLiM1/DANet" ["l"="48.282,30.331"]
"Lednik7/nto-ai-text-recognition" ["l"="49.133,30.723"]
"radmirkaz/MCS2022-Top-2-solution" ["l"="49.126,30.698"]
"JJJYmmm/Pix2SeqV2-Pytorch" ["l"="48.825,30.46"]
"HarborYuan/ovsam" ["l"="48.712,30.143"]
"cvlab-kaist/CAT-Seg" ["l"="32.295,30.678", "c"=297]
"amazon-science/prompt-pretraining" ["l"="48.631,30.31"]
"berkeley-hipie/HIPIE" ["l"="48.703,30.247"]
"facebookresearch/AnimatedDrawings" ["l"="38.516,1.159", "c"=54]
"facebookresearch/ImageBind" ["l"="49.068,30.103"]
"OpenGVLab/LLaMA-Adapter" ["l"="39.851,0.706", "c"=7]
"baaivision/Emu" ["l"="46.521,30.662", "c"=367]
"TommyZihao/Train_Custom_Dataset" ["l"="50.394,29.87", "c"=83]
"microsoft/LMOps" ["l"="38.618,-0.732", "c"=39]
"lupantech/ScienceQA" ["l"="47.248,30.316", "c"=254]
"amazon-science/auto-cot" ["l"="36.741,-2.4", "c"=797]
"FMInference/FlexLLMGen" ["l"="38.831,-0.771", "c"=39]
"CarperAI/trlx" ["l"="37.133,-0.204", "c"=126]
"Instruction-Tuning-with-GPT-4/GPT-4-LLM" ["l"="39.064,-2.245", "c"=202]
"FranxYao/chain-of-thought-hub" ["l"="37.241,-0.207", "c"=126]
"lucidrains/toolformer-pytorch" ["l"="36.685,-2.24", "c"=797]
"ultralytics/ultralytics" ["l"="50.35,29.629", "c"=83]
"THU-MIG/yolov10" ["l"="48.776,29.972"]
"fudan-zvg/Semantic-Segment-Anything" ["l"="48.866,30.098"]
"baaivision/Painter" ["l"="48.864,30.163"]
"timothybrooks/instruct-pix2pix" ["l"="32.237,31.989", "c"=88]
"lllyasviel/ControlNet" ["l"="38.358,1.011", "c"=54]
"open-mmlab/mmyolo" ["l"="50.361,29.892", "c"=83]
"runwayml/stable-diffusion" ["l"="32.178,31.943", "c"=88]
"aim-uofa/Matcher" ["l"="48.791,30.148"]
"VainF/Awesome-Anything" ["l"="48.929,30.125"]
"trungdq88/Awesome-Black-Friday-Cyber-Monday" ["l"="40.373,-0.221", "c"=7]
"zbwxp/SegVit" ["l"="48.75,30.387"]
"ZhenZHAO/AugSeg" ["l"="51.341,37.281", "c"=1244]
"maeve07/RCA" ["l"="54.064,31.518", "c"=938]
"roboflow/maestro" ["l"="48.652,29.93"]
"deforum-art/deforum-stable-diffusion" ["l"="32.091,31.62", "c"=88]
"cloneofsimo/lora" ["l"="32.196,31.881", "c"=88]
"z1069614715/objectdetection_script" ["l"="50.441,29.706", "c"=83]
"HVision-NKU/Cascade-CLIP" ["l"="47.746,35.584", "c"=695]
"microsoft/GenerativeImage2Text" ["l"="48.772,31.949", "c"=300]
"microsoft/BioGPT" ["l"="24.232,13.302", "c"=281]
"atherosai/ui" ["l"="40.383,-0.291", "c"=7]
"yangjianxin1/CLIP-Chinese" ["l"="50.06,30.469", "c"=83]
"augmentedstartups/AS-One" ["l"="54.54,32.414", "c"=279]
"stephansturges/WALDO" ["l"="48.779,29.909"]
"stephansturges/OpenLander" ["l"="48.832,29.851"]
"stephansturges/NANO" ["l"="48.835,29.824"]
"opengeos/segment-geospatial" ["l"="41.682,24.232", "c"=76]
"kyegomez/swarms" ["l"="41.065,0.15", "c"=7]
"siyuanliii/masa" ["l"="48.739,30.027"]
"hkchengrex/Tracking-Anything-with-DEVA" ["l"="48.868,29.995"]
"intuitem/ciso-assistant-community" ["l"="-42.547,-33.282", "c"=79]
"microsoft/torchgeo" ["l"="41.683,24.205", "c"=76]
"opengeos/leafmap" ["l"="41.646,24.202", "c"=76]
"roboflow/supervision" ["l"="40.654,-0.062", "c"=7]
"microsoft/i-Code" ["l"="47.583,29.952", "c"=254]
"jaymody/picoGPT" ["l"="40.005,0.723", "c"=7]
"google-research/parti" ["l"="46.016,31.618", "c"=605]
"Vision-CAIR/MiniGPT-4" ["l"="39.832,0.405", "c"=7]
"OpenGVLab/InternVL" ["l"="47.362,29.955", "c"=254]
"huggingface/peft" ["l"="40.04,0.52", "c"=7]
"LAION-AI/dalle2-laion" ["l"="44.725,31.284", "c"=1003]
"btpf/Alexandria" ["l"="11.629,-7.056", "c"=1221]
"AIGC-Audio/AudioGPT" ["l"="41.005,-3.675", "c"=146]
"Stability-AI/StableLM" ["l"="39.941,0.547", "c"=7]
"openai/consistency_models" ["l"="45.813,31.6", "c"=605]
"ashawkey/stable-dreamfusion" ["l"="64.401,3.296", "c"=49]
"TencentARC/T2I-Adapter" ["l"="33.446,31.264", "c"=109]
"guoyww/AnimateDiff" ["l"="33.564,31.071", "c"=109]
"lllyasviel/ControlNet-v1-1-nightly" ["l"="32.181,31.753", "c"=88]
"threestudio-project/threestudio" ["l"="64.334,3.3", "c"=49]
"tencent-ailab/IP-Adapter" ["l"="33.503,31.093", "c"=109]
"openai/point-e" ["l"="63.376,1.707", "c"=134]
"mpezeshki/pytorch_forward_forward" ["l"="60.928,33.601", "c"=607]
"ai-forever/Kandinsky-2" ["l"="33.443,31.218", "c"=109]
"microsoft/torchscale" ["l"="38.755,-0.718", "c"=39]
"THUDM/VisualGLM-6B" ["l"="39.161,-2.048", "c"=202]
"modelscope/ms-swift" ["l"="38.867,-1.929", "c"=202]
"FlagOpen/FlagEmbedding" ["l"="38.963,-1.98", "c"=202]
"LianjiaTech/BELLE" ["l"="39.054,-2.075", "c"=202]
"JunweiLiang/awesome_lists" ["l"="-3.978,23.512", "c"=827]
"muzairkhattak/ViFi-CLIP" ["l"="50.438,38.277", "c"=684]
"mbzuai-oryx/CVRR-Evaluation-Suite" ["l"="50.472,38.302", "c"=684]
"PaddlePaddle/FastDeploy" ["l"="50.118,29.663", "c"=83]
"encord-team/text-to-image-eval" ["l"="48.256,29.543"]
"encord-team/encord-notebooks" ["l"="48.258,29.558"]
"OpenGVLab/DCNv4" ["l"="49.086,32.955", "c"=401]
"fundamentalvision/BEVFormer" ["l"="64.517,11.258", "c"=61]
"DtYXs/Chinese-CLIP" ["l"="49.178,30.466"]
"sail-sg/Adan" ["l"="48.905,33.002", "c"=401]
"apple/ml-mobileone" ["l"="48.97,32.964", "c"=401]
"apple/ml-mobileclip" ["l"="48.747,30.132"]
"hkchengrex/XMem" ["l"="47.736,34.586", "c"=1004]
"SysCV/sam-pt" ["l"="48.916,30.016"]
"Computer-Vision-in-the-Wild/CVinW_Readings" ["l"="47.472,30.142", "c"=254]
"kakaobrain/kogpt" ["l"="-5.146,-23.168", "c"=164]
"kakaobrain/karlo" ["l"="31.87,31.971", "c"=88]
"KLUE-benchmark/KLUE" ["l"="-5.126,-23.17", "c"=164]
"EleutherAI/polyglot" ["l"="-5.22,-23.204", "c"=164]
"jungwoo-ha/WeeklyArxivTalk" ["l"="-5.068,-23.217", "c"=164]
"bumble-tech/private-detector" ["l"="-10.129,-8.056", "c"=5]
"google-deepmind/tapnet" ["l"="64.231,3.033", "c"=49]
"facebookresearch/co-tracker" ["l"="48.995,29.976"]
"Chasel-Tsui/mmdet-rfla" ["l"="53.855,31.976", "c"=2290]
"JialianW/GRiT" ["l"="47.45,30.28", "c"=254]
"showlab/Image2Paragraph" ["l"="49.024,30.224"]
"LeapLabTHU/Rank-DETR" ["l"="49.279,32.968", "c"=401]
"HDETR/H-Deformable-DETR-mmdet" ["l"="48.642,30.367"]
"FoundationVision/GenerateU" ["l"="48.548,30.245"]
"mala-lab/SIC-CADS" ["l"="48.56,30.265"]
"TommyZihao/MMSegmentation_Tutorials" ["l"="50.313,30.001", "c"=83]
"yatengLG/ISAT_with_segment_anything" ["l"="48.84,30.024"]
"glotlabs/gdrive" ["l"="-14.249,-1.749", "c"=152]
"IDEA-Research/Grounded-SAM-2" ["l"="48.784,30.026"]
"GitGyun/visual_token_matching" ["l"="57.926,19.159", "c"=433]
"iejMac/video2dataset" ["l"="33.639,31.396", "c"=109]
"Visual-Attention-Network/SegNeXt" ["l"="48.929,33.076", "c"=401]
"facebookresearch/ToMe" ["l"="48.99,33.157", "c"=401]
"gaasher/I-JEPA" ["l"="49.156,30.118"]
"LumenPallidium/jepa" ["l"="49.214,30.107"]
"facebookresearch/ijepa" ["l"="49.063,30.141"]
"aharley/pips" ["l"="64.276,2.968", "c"=49]
"kohjingyu/gill" ["l"="46.547,30.714", "c"=367]
"Vision-CAIR/ChatCaptioner" ["l"="49.086,30.262"]
"om-ai-lab/VL-CheckList" ["l"="38.181,-0.107", "c"=39]
"facebookresearch/diht" ["l"="48.94,30.405"]
"AILab-CVC/SEED" ["l"="46.508,30.691", "c"=367]
"miccunifi/SEARLE" ["l"="32.804,30.689", "c"=109]
"facebookresearch/ConvNeXt-V2" ["l"="48.976,33.022", "c"=401]
"DIG-Beihang/ALLOW" ["l"="48.402,30.305"]
"feifeiobama/OrthogonalDet" ["l"="48.454,30.251"]
"orrzohar/LOVM" ["l"="48.417,30.287"]
"scuwyh2000/RandBox" ["l"="48.384,30.295"]
"lxn96/ICPE" ["l"="49.313,29.394", "c"=1525]
"krea-ai/open-prompts" ["l"="31.815,31.96", "c"=88]
"Surrey-UP-Lab/GS-LPM" ["l"="48.421,30.257"]
"khanrc/tcl" ["l"="48.587,30.485"]
"facebookresearch/VLPart" ["l"="48.75,30.278"]
"open-mmlab/mmeval" ["l"="49.474,29.465", "c"=1525]
"UCSC-VLAA/Image-Pretraining-for-Video" ["l"="49.099,30.632"]
"HuKai97/detr-annotations" ["l"="48.421,30.119"]
"HuKai97/deformable-detr-annotations" ["l"="48.457,30.12"]
"jacobmarks/ten-weeks-of-plugins" ["l"="48.305,29.642"]
"jacobmarks/zero-shot-prediction-plugin" ["l"="48.365,29.641"]
"allenleetc/model-comparison" ["l"="48.358,29.649"]
"jacobmarks/text-to-image" ["l"="48.298,29.626"]
"whwu95/Cap4Video" ["l"="47.871,33.007", "c"=373]
"vadimtimakin/end2end-HKR-research" ["l"="49.132,30.663"]
"facebookresearch/CiT" ["l"="48.953,30.465"]
"DeevsTheBest/TenderHack" ["l"="49.113,30.717"]
"binyisu/FSOSOD" ["l"="48.162,30.453"]
"facebookresearch/segment-anything" ["l"="50.506,29.519", "c"=83]
"DAMO-NLP-SG/Video-LLaMA" ["l"="47.525,30.006", "c"=254]
"maxi-w/CLIP-SAM" ["l"="48.702,30.208"]
"Usama3059/SAMtext" ["l"="48.642,30.213"]
"PengtaoJiang/Segment-Anything-CLIP" ["l"="48.725,30.163"]
"RockeyCoss/Prompt-Segment-Anything" ["l"="48.759,30.149"]
"Curt-Park/segment-anything-with-clip" ["l"="48.763,30.165"]
"MaybeShewill-CV/segment-anything-u-specify" ["l"="48.709,30.184"]
"HiLab-git/DTC" ["l"="61.937,36.735", "c"=178]
"CASIA-IVA-Lab/FastSAM" ["l"="48.883,30.048"]
"MiscellaneousStuff/meta-sam-demo" ["l"="48.917,29.788"]
"haibingtown/segment-matting" ["l"="48.922,29.761"]
"lujiazho/SegDrawer" ["l"="48.892,29.849"]
"MizzleAa/segment-anything-demo-react-fastapi" ["l"="48.942,29.747"]
"Anything-of-anything/Anything-3D" ["l"="64.238,3.51", "c"=49]
"xinyu1205/recognize-anything" ["l"="48.905,30.145"]
"ChaoningZhang/MobileSAM" ["l"="48.811,30.039"]
"yformer/EfficientSAM" ["l"="48.774,30.049"]
"unum-cloud/uform" ["l"="-1.226,4.146", "c"=576]
"huawei-noah/VanillaNet" ["l"="48.98,32.943", "c"=401]
"Alpha-VLLM/LLaMA2-Accessory" ["l"="47.478,29.969", "c"=254]
"spotify/voyager" ["l"="41.19,0.965", "c"=7]
"shyamsn97/mario-gpt" ["l"="59.144,17.472", "c"=169]
"JonathonLuiten/Dynamic3DGaussians" ["l"="64.086,3.208", "c"=49]
"henry123-boy/SpaTracker" ["l"="64.198,3.086", "c"=49]
"vye16/shape-of-motion" ["l"="64.18,3.178", "c"=49]
"google/dynibar" ["l"="63.764,1.785", "c"=134]
"princeton-vl/RAFT" ["l"="65.014,4.136", "c"=263]
"naver/dust3r" ["l"="64.222,3.099", "c"=49]
"cvg/LightGlue" ["l"="59.489,9.235", "c"=274]
"prs-eth/Marigold" ["l"="64.18,3.052", "c"=49]
"autonomousvision/unimatch" ["l"="65.28,5.133", "c"=415]
"SuperMedIntel/Medical-SAM-Adapter" ["l"="62.48,37.755", "c"=284]
"ziqi-jin/finetune-anything" ["l"="48.784,30.096"]
"luca-medeiros/lightning-sam" ["l"="48.762,30.078"]
"hitachinsk/SAMed" ["l"="62.464,37.771", "c"=284]
"KyanChen/RSPrompter" ["l"="41.83,25.176", "c"=525]
"bowang-lab/MedSAM" ["l"="61.767,36.827", "c"=178]
"OpenGVLab/SAM-Med2D" ["l"="62.449,37.732", "c"=284]
"Hedlen/awesome-segment-anything" ["l"="48.803,30.077"]
"Stability-AI/StableStudio" ["l"="38.511,1.082", "c"=54]
"sail-sg/EditAnything" ["l"="49.011,30.048"]
"continue-revolution/sd-webui-segment-anything" ["l"="32.091,31.688", "c"=88]
"openai/shap-e" ["l"="38.594,1.097", "c"=54]
"luca-medeiros/lang-segment-anything" ["l"="48.824,30.066"]
"kadirnar/segment-anything-video" ["l"="48.878,30.072"]
"hkchengrex/Cutie" ["l"="47.704,34.585", "c"=1004]
"lkeab/gaussian-grouping" ["l"="64.073,3.317", "c"=49]
"jiawen-zhu/HQTrack" ["l"="48.936,29.948"]
"FoundationVision/GLEE" ["l"="48.677,30.134"]
"mbzuai-metaverse/XMem2" ["l"="47.681,34.558", "c"=1004]
"xb534/SED" ["l"="48.662,30.304"]
"seanzhuh/Awesome-Open-Vocabulary-Detection-and-Segmentation" ["l"="48.631,30.235"]
"wangf3014/SCLIP" ["l"="48.651,30.311"]
"PengtaoJiang/Awesome-Weakly-Supervised-Semantic-Segmentation-Papers" ["l"="54.016,31.531", "c"=938]
"LiheYoung/Depth-Anything" ["l"="64.231,2.986", "c"=49]
"THU-MIG/RepViT" ["l"="49.028,32.958", "c"=401]
"chongzhou96/EdgeSAM" ["l"="48.723,29.949"]
"run-llama/chat-llamaindex" ["l"="41.099,0.655", "c"=7]
"run-llama/create_llama_projects" ["l"="48.498,29.991"]
"chuxiuhong/DualTeacher" ["l"="48.263,30.442"]
"wang-xinyu/tensorrtx" ["l"="50.315,29.877", "c"=83]
"IDEA-Research/T-Rex" ["l"="48.732,30.089"]
"shouxieai/tensorRT_Pro" ["l"="53.346,32.653", "c"=251]
"YavorGIvanov/sam.cpp" ["l"="40.223,1.022", "c"=7]
"dinglufe/segment-anything-cpp-wrapper" ["l"="48.706,29.831"]
"OpenGVLab/InternGPT" ["l"="40.967,-3.607", "c"=146]
"OpenGVLab/DragGAN" ["l"="38.564,1.035", "c"=54]
"microsoft/MM-REACT" ["l"="47.433,30.256", "c"=254]
"allenai/visprog" ["l"="47.462,30.218", "c"=254]
"cvlab-columbia/viper" ["l"="49.056,30.267"]
"Shiriluz/Word-As-Image" ["l"="33.318,31.297", "c"=109]
"NVlabs/prismer" ["l"="48.976,30.277"]
"Peterande/D-FINE" ["l"="48.599,30.048"]
"ShihuaHuang95/DEIM" ["l"="48.587,30.078"]
"sunsmarterjie/yolov12" ["l"="48.65,30.037"]
"PixArt-alpha/PixArt-alpha" ["l"="33.472,31.192", "c"=109]
"AILab-CVC/VideoCrafter" ["l"="33.589,31.197", "c"=109]
"Picsart-AI-Research/Text2Video-Zero" ["l"="33.618,31.229", "c"=109]
"ali-vilab/AnyDoor" ["l"="33.606,31.054", "c"=109]
"kohya-ss/sd-scripts" ["l"="32.155,31.778", "c"=88]
"facebookresearch/Pearl" ["l"="57.842,18.061", "c"=45]
"facebookresearch/jepa" ["l"="49.119,30.148"]
"lyuchenyang/Macaw-LLM" ["l"="47.559,29.998", "c"=254]
"anuragxel/salt" ["l"="48.866,30.018"]
"triple-Mu/YOLOv8-TensorRT" ["l"="53.406,32.663", "c"=251]
"FeiYull/TensorRT-Alpha" ["l"="53.43,32.679", "c"=251]
"haochenheheda/segment-anything-annotator" ["l"="48.858,29.976"]
"pipeless-ai/pipeless" ["l"="52.975,32.473", "c"=251]
"zhouayi/SAM-Tool" ["l"="48.879,29.958"]
"George-Hotz/yolov8_seg_tensorRT" ["l"="48.919,29.902"]
"AILab-CVC/GPT4Tools" ["l"="36.959,-1.189", "c"=795]
"naver/mast3r" ["l"="64.13,3.123", "c"=49]
"facebookresearch/vggsfm" ["l"="64.102,3.123", "c"=49]
"Junyi42/monst3r" ["l"="64.151,3.146", "c"=49]
"lucidrains/lion-pytorch" ["l"="48.881,32.963", "c"=401]
"ttengwang/Caption-Anything" ["l"="48.949,30.157"]
"Adamdad/Awesome-ComposableAI" ["l"="-53.135,-12.66", "c"=686]
"kevmo314/magic-copy" ["l"="-5.392,17.453", "c"=316]
"NExT-GPT/NExT-GPT" ["l"="47.491,29.926", "c"=254]
"NVlabs/FasterViT" ["l"="49.017,32.999", "c"=401]
"microsoft/Swin-Transformer" ["l"="50.669,29.705", "c"=83]
"shikras/shikra" ["l"="47.418,30.229", "c"=254]
"OFA-Sys/ONE-PEACE" ["l"="48.896,30.217"]
"PKU-YuanGroup/LanguageBind" ["l"="47.504,30.049", "c"=254]
"TXH-mercury/VALOR" ["l"="47.778,32.932", "c"=373]
"LAION-AI/CLAP" ["l"="38.633,1.997", "c"=54]
"facebookresearch/AudioMAE" ["l"="39.624,5.481", "c"=593]
"TXH-mercury/VAST" ["l"="47.793,32.925", "c"=373]
"LAION-AI/audio-dataset" ["l"="39.597,5.515", "c"=593]
"OpenGVLab/unmasked_teacher" ["l"="47.778,32.957", "c"=373]
"artidoro/qlora" ["l"="39.956,0.604", "c"=7]
"facebookresearch/hiera" ["l"="48.119,33.775", "c"=168]
"DavidZhangdw/Visual-Tracking-Development" ["l"="54.511,33.793", "c"=298]
"jiawen-zhu/TrackGPT" ["l"="48.978,29.892"]
"alaamaalouf/FollowAnything" ["l"="48.97,29.921"]
"botaoye/OSTrack" ["l"="54.501,33.779", "c"=298]
"MIV-XJTU/ARTrack" ["l"="54.467,33.783", "c"=298]
"jiawen-zhu/ViPT" ["l"="54.474,33.817", "c"=298]
"SysCV/MaskFreeVIS" ["l"="50.717,30.68", "c"=83]
"Little-Podi/Transformer_Tracking" ["l"="54.482,33.787", "c"=298]
"gaomingqi/Awesome-Video-Object-Segmentation" ["l"="47.663,34.581", "c"=1004]
"THUDM/CogVLM" ["l"="47.384,29.926", "c"=254]
"roboflow/rf-detr" ["l"="48.645,30.003"]
"roboflow/awesome-openai-vision-api-experiments" ["l"="48.644,29.895"]
"SkalskiP/top-cvpr-2024-papers" ["l"="48.593,29.913"]
"roboflow/sports" ["l"="49.013,25.81", "c"=584]
"MultimediaTechLab/YOLO" ["l"="48.608,29.997"]
"roboflow/trackers" ["l"="48.625,29.962"]
"Xatta-Trone/medium-parser-extension" ["l"="-52.119,11.954", "c"=266]
"OpenGVLab/Ask-Anything" ["l"="47.522,30.03", "c"=254]
"invictus717/MetaTransformer" ["l"="47.494,30.005", "c"=254]
"mazzzystar/Queryable" ["l"="49.763,30.778", "c"=1055]
"Brendan-Kirtlan/Video-Encode" ["l"="48.471,29.984"]
"flutter/games" ["l"="48.444,29.99"]
"protectai/ai-exploits" ["l"="48.494,29.965"]
"tldraw/make-real-starter" ["l"="48.474,30.008"]
"pytorch-labs/segment-anything-fast" ["l"="48.587,30.013"]
"twostraws/Inferno" ["l"="41.831,-28.021", "c"=174]
"0x90n/InfoSec-Black-Friday" ["l"="-45.3,-31.848", "c"=53]
"google-deepmind/graphcast" ["l"="41.793,25.911", "c"=537]
"Brendan-Kirtlan/Minecraft-file-encoder" ["l"="48.4,29.978"]
"microsoft/fluentui-blazor" ["l"="-36.651,-0.985", "c"=260]
"disler/multi-agent-postgres-data-analytics" ["l"="41.316,0.639", "c"=7]
"apache/incubator-xtable" ["l"="-0.284,14.892", "c"=729]
"dotnet/eShop" ["l"="-34.111,-1.06", "c"=8]
"BuilderIO/gpt-crawler" ["l"="40.494,-0.011", "c"=7]
"xiuqhou/Relation-DETR" ["l"="48.577,30.178"]
"Atten4Vis/GroupDETR" ["l"="48.597,30.32"]
"SIAnalytics/RHINO" ["l"="53.293,31.948", "c"=731]
"sczhou/ProPainter" ["l"="33.749,31.098", "c"=109]
"NVlabs/Sana" ["l"="33.172,32.969", "c"=81]
"LTH14/mar" ["l"="46.402,30.601", "c"=367]
"FoundationVision/LlamaGen" ["l"="46.44,30.619", "c"=367]
"sihyun-yu/REPA" ["l"="46.361,30.587", "c"=367]
"hustvl/LightningDiT" ["l"="46.365,30.634", "c"=367]
"bytedance/1d-tokenizer" ["l"="46.433,30.63", "c"=367]
"TencentARC/SEED-Voken" ["l"="46.452,30.635", "c"=367]
"FoundationVision/Infinity" ["l"="46.396,30.64", "c"=367]
"YichiZhang98/SAM4MIS" ["l"="62.439,37.716", "c"=284]
"Vision-Intelligence-and-Robots-Group/Awesome-Segment-Anything" ["l"="48.786,30.069"]
"jbilcke-hf/ai-comic-factory" ["l"="45.711,-1.868", "c"=410]
"wl-zhao/VPD" ["l"="60.46,17.662", "c"=363]
"weijiawu/DiffuMask" ["l"="61.726,36.437", "c"=178]
"open-mmlab/mmfewshot" ["l"="49.426,29.431", "c"=1525]
"open-mmlab/mmdeploy" ["l"="50.347,29.856", "c"=83]
"open-mmlab/mmpretrain" ["l"="50.465,29.896", "c"=83]
"open-mmlab/mmrotate" ["l"="53.111,31.954", "c"=731]
"open-mmlab/mmrazor" ["l"="53.517,33.522", "c"=1263]
"VisionXLab/sam-mmrotate" ["l"="48.777,30.136"]
"awaisrauf/Awesome-CV-Foundational-Models" ["l"="50.424,38.221", "c"=684]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" ["l"="50.339,38.212", "c"=684]
"daochenzha/data-centric-AI" ["l"="44.769,25.817", "c"=68]
"tsb0601/MMVP" ["l"="47.341,30.208", "c"=254]
"SunzeY/AlphaCLIP" ["l"="48.796,30.337"]
"voxel51/fiftyone-docs-search" ["l"="48.333,29.61"]
"liunian-harold-li/DesCo" ["l"="48.481,30.407"]
"ihub-pub/plugins" ["l"="-54.382,-12.654", "c"=252]
"Raray-chuan/mini-spring" ["l"="-54.379,-12.563", "c"=252]
"gqylpy/systempath" ["l"="-54.476,-12.651", "c"=252]
"linkxzhou/LessDB" ["l"="-54.468,-12.597", "c"=252]
"farseer-go/fs" ["l"="-54.389,-12.61", "c"=252]
"ruixiaozi/rxz-ui" ["l"="-54.498,-12.485", "c"=252]
"Western-OC2-Lab/AutoML-Implementation-for-Static-and-Dynamic-Data-Analytics" ["l"="-54.376,-12.628", "c"=252]
"Raray-chuan/xichuan_note" ["l"="-54.389,-12.593", "c"=252]
"wewehao/flutter_chatgpt" ["l"="-54.456,-12.521", "c"=252]
"dqzboy/DKube" ["l"="-54.446,-12.664", "c"=252]
"1902756969/IKUN_Library" ["l"="-54.544,-12.476", "c"=252]
"dqzboy/DevOps" ["l"="-54.436,-12.673", "c"=252]
"Your7Maxx/FlowGod" ["l"="-54.468,-12.564", "c"=252]
"Ruimve/resource-hint-webpack-plugin" ["l"="-54.398,-12.52", "c"=252]
"Farama-Foundation/chatarena" ["l"="41.12,-3.795", "c"=146]
"apple/ml-fastvit" ["l"="48.949,32.981", "c"=401]
"Charles-Xie/awesome-described-object-detection" ["l"="48.593,30.218"]
"shenyunhang/APE" ["l"="48.647,30.18"]
"huggingface/OBELICS" ["l"="49.078,30.348"]
"LAION-AI/Big-Interleaved-Dataset" ["l"="44.594,31.23", "c"=1003]
"Jun-CEN/SegmentAnyRGBD" ["l"="65.108,11.631", "c"=203]
"PengtaoJiang/OAA-PyTorch" ["l"="54.101,31.578", "c"=938]
"helblazer811/RefSAM" ["l"="48.681,30.169"]
"Seonghoon-Yu/Zero-shot-RIS" ["l"="48.992,31.869", "c"=300]
"NVIDIA-AI-IOT/nanosam" ["l"="48.719,29.897"]
"NVIDIA-AI-IOT/nanoowl" ["l"="48.763,29.822"]
"YuYue525/MobileSAM-pytorch" ["l"="48.706,29.857"]
"xinghaochen/TinySAM" ["l"="48.709,29.931"]
"czg1225/SlimSAM" ["l"="48.685,29.884"]
"Aimol-l/OrtInference" ["l"="48.725,29.814"]
"spacewalk01/nanosam-cpp" ["l"="48.674,29.851"]
"ChuRuaNh0/FastSam_Awsome_TensorRT" ["l"="48.685,29.822"]
"Gy920/segment-anything-2-real-time" ["l"="48.754,29.878"]
"zhudongwork/SAM_TensorRT" ["l"="48.691,29.847"]
"DmitryRyumin/ICCV-2023-Papers" ["l"="38.218,2.355", "c"=54]
"allenai/unified-io-2" ["l"="46.539,30.684", "c"=367]
"AILab-CVC/SEED-Bench" ["l"="47.282,30.295", "c"=254]
"allenai/unified-io-inference" ["l"="47.462,30.349", "c"=254]
"HaozheZhao/MIC" ["l"="47.396,30.311", "c"=254]
"lovelyqian/CDFSOD-benchmark" ["l"="48.485,30.233"]
"gaobb/Few-Shot-Object-Detection-Papers" ["l"="49.324,29.383", "c"=1525]
"csuhan/VFA" ["l"="49.342,29.399", "c"=1525]
"GuangxingHan/Meta-Faster-R-CNN" ["l"="49.339,29.409", "c"=1525]
"lxn96/awesome-few-shot-object-detection" ["l"="49.355,29.407", "c"=1525]
"xavibou/ovdsat" ["l"="48.518,30.245"]
"YifanXu74/MQ-Det" ["l"="-55.332,-10.634", "c"=845]
"er-muyue/DeFRCN" ["l"="49.371,29.388", "c"=1525]
"lovelyqian/NTIRE2025_CDFSOD" ["l"="48.506,30.238"]
"fanq15/FewX" ["l"="49.4,29.388", "c"=1525]
"JiauZhang/DragGAN" ["l"="40.989,-3.636", "c"=146]
"IDEA-Research/Grounding-DINO-1.5-API" ["l"="48.72,30.116"]
"chn-lee-yumi/MaterialSearch" ["l"="32.611,33.059", "c"=81]
"Kingfish404/segment-anything-webui" ["l"="48.943,29.79"]
"Nomination-NRB/SAM-webui" ["l"="48.913,29.822"]
"royerlab/napari-segment-anything" ["l"="41.788,26.496", "c"=712]
"vietanhdev/samexporter" ["l"="48.733,29.83"]
"JerryX1110/awesome-segment-anything-extensions" ["l"="48.842,29.999"]
"feizc/IEA" ["l"="48.896,29.921"]
"dk-liang/Awesome-Segment-Anything" ["l"="48.883,29.904"]
"wangsssky/SonarSAM" ["l"="48.39,33.069", "c"=373]
"RAIVNLab/sugar-crepe" ["l"="52.226,25.45", "c"=172]
"baaivision/CapsFusion" ["l"="46.532,30.74", "c"=367]
"ant-research/DreamLIP" ["l"="48.898,30.452"]
"ZhangGongjie/IMFA" ["l"="48.589,30.382"]
"linxid/Focus-DETR-mindspore" ["l"="48.582,30.403"]
"showlab/VLog" ["l"="49.116,30.228"]
"EvolvingLMMs-Lab/RelateAnything" ["l"="50.117,38.365", "c"=684]
"showlab/cosmo" ["l"="33.402,31.665", "c"=109]
"showlab/UniVTG" ["l"="60.48,17.581", "c"=363]
"facebookresearch/LaViLa" ["l"="47.738,32.967", "c"=373]
"soulteary/docker-prompt-generator" ["l"="43.675,1", "c"=135]
"mbzuai-oryx/Video-ChatGPT" ["l"="47.532,30.076", "c"=254]
"lupantech/chameleon-llm" ["l"="36.795,-2.439", "c"=797]
"OpenGVLab/Multi-Modality-Arena" ["l"="47.363,30.271", "c"=254]
"OpenGVLab/all-seeing" ["l"="47.38,30.222", "c"=254]
"shikras/d-cube" ["l"="48.549,30.21"]
"SkalskiP/awesome-chatgpt-code-interpreter-experiments" ["l"="40.984,-3.834", "c"=146]
"SkalskiP/top-cvpr-2023-papers" ["l"="48.515,29.834"]
"VITA-MLLM/Woodpecker" ["l"="47.384,30.268", "c"=254]
"wusize/CLIM" ["l"="48.573,30.266"]
"VinAIResearch/LP-OVOD" ["l"="48.512,30.271"]
"YimingCuiCuiCui/awesome-open-vocabulary-object-detection" ["l"="48.488,30.29"]
"Charles-Xie/CQL" ["l"="47.322,33.749", "c"=168]
"THU-MIG/YOLO-UniOW" ["l"="48.515,30.187"]
"iSEE-Laboratory/LLMDet" ["l"="48.572,30.148"]
"Vision-Intelligence-and-Robots-Group/count-anything" ["l"="33.386,28.32", "c"=1028]
"Vision-Intelligence-and-Robots-Group/awesome-micro-expression-recognition" ["l"="56.31,27.296", "c"=486]
"JamesQFreeman/Sam_LoRA" ["l"="62.517,37.809", "c"=284]
"MME-Benchmarks/Video-MME" ["l"="47.549,30.151", "c"=254]
"UX-Decoder/DINOv" ["l"="48.702,30.159"]
"mbzuai-oryx/groundingLMM" ["l"="47.465,30.182", "c"=254]
"baaivision/tokenize-anything" ["l"="48.655,30.158"]
"CircleRadon/Osprey" ["l"="64.134,11.38", "c"=61]
"FoundationVision/Groma" ["l"="50.752,3.019", "c"=85]
"lxtGH/OMG-Seg" ["l"="51.008,2.867", "c"=85]
"WangRongsheng/SAM-fine-tune" ["l"="48.754,30.1"]
"mazurowski-lab/finetune-SAM" ["l"="48.742,30.111"]
"MathieuNlp/Sam_LoRA" ["l"="62.547,37.829", "c"=284]
"autonomousvision/stylegan-t" ["l"="44.914,30.441", "c"=243]
"ali-vilab/composer" ["l"="33.391,31.387", "c"=109]
"lukasHoel/text2room" ["l"="64.282,3.494", "c"=49]
"showlab/EgoVLP" ["l"="47.697,32.969", "c"=373]
"TencentARC/MCQ" ["l"="47.871,32.98", "c"=373]
"microsoft/XPretrain" ["l"="47.83,32.958", "c"=373]
"antoyang/VidChapters" ["l"="47.765,33.039", "c"=373]
"jayleicn/moment_detr" ["l"="48.026,33.09", "c"=373]
"jayleicn/singularity" ["l"="47.846,32.965", "c"=373]
"aimagelab/freeda" ["l"="47.927,30.282", "c"=254]
"DirtyHarryLYL/LLM-in-Vision" ["l"="47.427,30.163", "c"=254]
"SkalskiP/awesome-foundation-and-multimodal-models" ["l"="48.61,29.938"]
"VietnamAIHub/Vietnamese_LLMs" ["l"="52.703,-0.115", "c"=810]
"Saiyan-World/grounded-segment-any-parts" ["l"="48.712,30.23"]
"OpenRobotLab/OV_PARTS" ["l"="48.702,30.282"]
"NiFangBaAGe/Explicit-Visual-Prompt" ["l"="31.287,30.058", "c"=836]
"bytedance/FreeSeg" ["l"="48.681,30.311"]
"ytongbai/LVM" ["l"="46.493,30.613", "c"=367]
"yformer/EfficientTAM" ["l"="48.752,29.94"]
"annotation-ai/technical-demo" ["l"="48.729,30.181"]
"Asad-Ismail/Grounding-Dino-FineTuning" ["l"="48.618,30.195"]
"longzw1997/Open-GroundingDino" ["l"="48.671,30.192"]
"Dongdong-d/GroundingDino-Finetuning" ["l"="48.59,30.195"]
"antoyang/FrozenBiLM" ["l"="47.853,32.988", "c"=373]
"microsoft/LAVENDER" ["l"="47.81,32.97", "c"=373]
"UARK-AICV/VLTinT" ["l"="47.676,33.11", "c"=373]
"bhpfelix/segment-anything-finetuner" ["l"="48.711,30.093"]
"BooHwang/segment_anything_tensorrt" ["l"="48.669,29.829"]
"mingj2021/segment-anything-tensorrt" ["l"="48.675,29.803"]
"ItayElam/SegmentAnything-TensorRT" ["l"="48.648,29.788"]
"VGVentures/dash_ai_search" ["l"="48.299,29.931"]
"invertase/globe" ["l"="59.741,-22.511", "c"=17]
"zhenyuw16/Uni3DETR" ["l"="65.12,11.89", "c"=203]
"lxtGH/Tube-Link" ["l"="50.704,30.664", "c"=83]
"lxtGH/Video-K-Net" ["l"="50.72,30.612", "c"=83]
"magic-research/Sa2VA" ["l"="50.832,3.039", "c"=85]
"zhenyingfang/Awesome-Temporal-Action-Detection-Temporal-Action-Proposal-Generation" ["l"="47.969,34.009", "c"=168]
"LiheYoung/UniMatch" ["l"="51.346,37.269", "c"=1244]
"NVIDIA-AI-IOT/clip-distillation" ["l"="48.749,29.904"]
"xmed-lab/CLIPN" ["l"="52.515,14.268", "c"=1208]
"OpenGVLab/CaFo" ["l"="50.366,38.284", "c"=684]
"ByChelsea/CLIP-AD" ["l"="53.223,14.258", "c"=669]
"linyq2117/TagCLIP" ["l"="53.973,31.478", "c"=938]
"WalBouss/GEM" ["l"="48.61,30.353"]
"azshue/TPT" ["l"="50.443,38.248", "c"=684]
"muzairkhattak/PromptSRC" ["l"="50.408,38.267", "c"=684]
"bytedance/OmniScient-Model" ["l"="48.723,30.418"]
"jiaosiyu1999/MAFT-Plus" ["l"="48.628,30.367"]
"mlpc-ucsd/MaskCLIP" ["l"="48.671,30.327"]
"VIPSeg-Dataset/VIPSeg-Dataset" ["l"="50.695,30.669", "c"=83]
"Beckschen/ViTamin" ["l"="48.757,30.433"]
"jiaosiyu1999/MAFT" ["l"="48.606,30.397"]
"Xujxyang/OpenTrans" ["l"="48.608,30.41"]
"uncbiag/Awesome-Foundation-Models" ["l"="50.381,38.189", "c"=684]
"NVIDIA-AI-IOT/ROS2-NanoOWL" ["l"="48.779,29.787"]
"NVIDIA-AI-IOT/deepstream_parallel_inference_app" ["l"="53.163,32.583", "c"=251]
"NVIDIA-AI-IOT/mmj_genai" ["l"="48.757,29.74"]
"stevebottos/owl-vit-object-detection" ["l"="48.776,29.77"]
"AIDajiangtang/Superpoint-LightGlue-Image-Stiching" ["l"="59.907,11.301", "c"=87]
"OroChippw/SegmentAnything-OnnxRunner" ["l"="48.699,29.795"]
"protectai/modelscan" ["l"="38.031,-7.537", "c"=448]
"OptimalScale/DetGPT" ["l"="47.468,30.2", "c"=254]
"ibaiGorordo/ONNX-SAM2-Segment-Anything" ["l"="48.746,29.798"]
"axinc-ai/segment-anything-2" ["l"="48.745,29.813"]
"Aimol-l/SAM2Export" ["l"="48.747,29.825"]
"ryouchinsa/sam-cpp-macos" ["l"="48.72,29.8"]
"AndreyGermanov/sam_onnx_full_export" ["l"="48.733,29.775"]
"AIDajiangtang/Segment-Anything-CPP" ["l"="48.698,29.777"]
"5663015/segment_anything_webui" ["l"="48.978,29.733"]
"dogeplusplus/sam-at-home" ["l"="48.994,29.711"]
"wx-chevalier/segment-anything-web-ui" ["l"="48.959,29.724"]
"TACJu/Axial-VS" ["l"="48.745,30.446"]
"mc-lan/ProxyCLIP" ["l"="48.616,30.322"]
"haochenheheda/LVVIS" ["l"="50.678,30.691", "c"=83]
"AIDajiangtang/Segment-Anything-CSharp" ["l"="48.685,29.736"]
"thislookshard/SamSharp" ["l"="48.674,29.692"]
"LarkMi/segment_anything_streamlit_webui" ["l"="48.969,29.766"]
"UCSC-VLAA/Recap-DataComp-1B" ["l"="49.046,30.556"]
"OliverRensu/D-iGPT" ["l"="49.012,30.507"]
"liuyanyi/sam-with-mmdet" ["l"="48.743,30.159"]
"VisionXLab/STAR-MMRotate" ["l"="53.279,31.922", "c"=731]
"aim-uofa/SINE" ["l"="-35.205,20.05", "c"=1031]
"syp2ysy/VRP-SAM" ["l"="62.447,36.449", "c"=178]
"aim-uofa/SegPrompt" ["l"="62.501,36.501", "c"=178]
"rohit901/cooperative-foundational-models" ["l"="48.523,30.354"]
"Atten4Vis/MS-DETR" ["l"="48.572,30.229"]
"IDEA-Research/MP-Former" ["l"="50.581,30.627", "c"=83]
"UnaNancyOwen/MobileSAM-Unity" ["l"="48.668,29.667"]
"junyangwang0410/Knight" ["l"="49.28,30.459"]
"stazizov/ViT_CIFAR100" ["l"="49.14,30.64"]
"FalsoMoralista/ijepa" ["l"="49.242,30.102"]
"jacobmarks/active-learning-plugin" ["l"="48.382,29.638"]
"bpc-clone/bpc_chrome_support" ["l"="-51.149,13.099", "c"=200]
"THU-MIG/yoloe" ["l"="48.635,30.066"]
"Atten4Vis/LW-DETR" ["l"="48.593,30.118"]
"PINTO0309/PINTO_model_zoo" ["l"="49.966,29.931", "c"=83]
"LargeWorldModel/LWM" ["l"="47.44,29.845", "c"=254]
"KindXiaoming/pykan" ["l"="49.316,34.271", "c"=556]
"google/gemma.cpp" ["l"="39.121,-0.579", "c"=39]
"google-deepmind/gemma" ["l"="38.97,-0.712", "c"=39]
"Genesis-Embodied-AI/Genesis" ["l"="59.161,16.789", "c"=234]
"google/gemma_pytorch" ["l"="38.988,-0.572", "c"=39]
"flutter/io_flip" ["l"="59.852,-22.5", "c"=17]
"flame-engine/awesome-flame" ["l"="60.479,-24.383", "c"=870]
"invertase/melos" ["l"="59.933,-22.523", "c"=17]
"shorebirdtech/shorebird" ["l"="59.948,-22.534", "c"=17]
"flutter/packages" ["l"="60.127,-22.58", "c"=17]
"flutter/news_toolkit" ["l"="59.913,-22.561", "c"=17]
"linkwarden/linkwarden" ["l"="12.524,-8.925", "c"=18]
"Ftindy/IPTV-URL" ["l"="-49.905,14.946", "c"=131]
"chenxwh/insanely-fast-whisper" ["l"="45.413,-1.949", "c"=410]
"yihong0618/bilingual_book_maker" ["l"="43.699,0.94", "c"=135]
"vvbbnn00/WARP-Clash-API" ["l"="45.484,0.775", "c"=99]
"tldraw/make-real" ["l"="40.611,0.335", "c"=7]
"roboflow/webcamGPT" ["l"="48.616,29.849"]
"ishan0102/vimGPT" ["l"="40.932,0.648", "c"=7]
"iyaja/llama-fs" ["l"="41.015,0.354", "c"=7]
"merveenoyan/smol-vision" ["l"="41.317,0.69", "c"=7]
"SkalskiP/vlms-zero-to-hero" ["l"="-14.367,-23.124", "c"=1101]
"neural-maze/ava-whatsapp-agent-course" ["l"="41.392,0.451", "c"=7]
"tjmlabs/ColiVara" ["l"="41.443,0.391", "c"=7]
"vikhyat/moondream" ["l"="40.74,0.374", "c"=7]
"AnswerDotAI/byaldi" ["l"="41.331,0.719", "c"=7]
"Lightning-AI/LitServe" ["l"="41.093,0.577", "c"=7]
"dvlab-research/MGM" ["l"="47.407,29.986", "c"=254]
"tldraw/draw-fast" ["l"="-5.084,-30.517", "c"=4]
"McGill-NLP/llm2vec" ["l"="54.627,25.653", "c"=439]
"khanrc/honeybee" ["l"="-5.315,-23.192", "c"=164]
"AILab-CVC/UniRepLKNet" ["l"="49.061,32.948", "c"=401]
"karpathy/minbpe" ["l"="40.261,0.682", "c"=7]
"facebookresearch/schedule_free" ["l"="38.814,-0.246", "c"=39]
"FoundationVision/VAR" ["l"="51.232,2.921", "c"=85]
"PKU-YuanGroup/Video-LLaVA" ["l"="47.477,30.025", "c"=254]
"Vchitect/Latte" ["l"="33.561,31.229", "c"=109]
"PKU-YuanGroup/Open-Sora-Plan" ["l"="33.524,31.053", "c"=109]
"NVIDIA/Cosmos-Tokenizer" ["l"="46.423,30.602", "c"=367]
"Stability-AI/StableCascade" ["l"="33.544,30.971", "c"=109]
"czg1225/Awesome-Efficient-Segment-Anything" ["l"="48.655,29.855"]
"czg1225/CoDe" ["l"="39.012,0.214", "c"=39]
"VainF/Isomorphic-Pruning" ["l"="38.926,0.175", "c"=39]
"chengtao-lv/PTQ4SAM" ["l"="48.637,29.814"]
"czg1225/AsyncDiff" ["l"="39.032,0.147", "c"=39]
"Meituan-AutoML/MobileVLM" ["l"="47.409,30.083", "c"=254]
"ntegrals/aura-voice" ["l"="40.977,0.543", "c"=7]
"OpenGVLab/Vision-RWKV" ["l"="49.245,34.144", "c"=556]
"baaivision/Uni3D" ["l"="65.179,11.71", "c"=203]
"OPPOMKLab/recognize-anything" ["l"="48.6,30.163"]
"UX-Decoder/FIND" ["l"="48.557,30.159"]
"PhyscalX/gradio-image-prompter" ["l"="48.594,30.143"]
"RunpeiDong/DreamLLM" ["l"="46.515,30.707", "c"=367]
"SawyerHood/draw-a-ui" ["l"="40.437,0.152", "c"=7]
"eylonmiz/react-agent" ["l"="-12.674,-7.391", "c"=86]
"tldraw/tldraw-llm-starter" ["l"="-5.19,-30.58", "c"=4]
"MinghanLi/UniVS" ["l"="50.697,30.739", "c"=83]
"wanghao9610/OV-DINO" ["l"="48.628,30.153"]
"MasterBin-IIAU/UNINEXT" ["l"="50.896,2.808", "c"=85]
"FoundationVision/VNext" ["l"="50.689,30.608", "c"=83]
"gokayfem/awesome-vlm-architectures" ["l"="47.373,30.036", "c"=254]
"friedrichor/Awesome-Multimodal-Papers" ["l"="48.543,29.881"]
"xiuqhou/Salience-DETR" ["l"="48.566,30.19"]
"hoiliu-0801/DQ-DETR" ["l"="53.773,32.018", "c"=2290]
"langchain-ai/opengpts" ["l"="40.767,0.456", "c"=7]
"microsoft/SoM" ["l"="47.404,30.19", "c"=254]
"Vaibhavs10/insanely-fast-whisper" ["l"="40.594,3.192", "c"=908]
"daveshap/OpenAI_Agent_Swarm" ["l"="40.773,0.625", "c"=7]
"mshumer/gpt-llm-trainer" ["l"="41.05,-4.021", "c"=146]
"xlang-ai/OpenAgents" ["l"="36.761,-2.216", "c"=797]
"superagent-ai/superagent" ["l"="41.136,-3.874", "c"=146]
"openai/consistencydecoder" ["l"="45.816,31.64", "c"=605]
"w1oves/Rein" ["l"="64.304,4.171", "c"=49]
"google/diffseg" ["l"="61.734,36.495", "c"=178]
"NVIDIA/garak" ["l"="38.051,-7.488", "c"=448]
"protectai/vulnhuntr" ["l"="-44.125,-29.58", "c"=3]
"iknowjason/Awesome-CloudSec-Labs" ["l"="11.375,-4.595", "c"=147]
"fr0gger/Awesome-GPT-Agents" ["l"="-45.518,-31.854", "c"=53]
"netero1010/EDRSilencer" ["l"="-47.46,-32.451", "c"=41]
"Pennyw0rth/NetExec" ["l"="-45.372,-31.988", "c"=53]
"mttaggart/I-S00N" ["l"="40.539,-0.503", "c"=7]
"risesoft-y9/Data-Labeling" ["l"="50.881,2.931", "c"=85]
"gh0stintheshe11/Stats-SVG" ["l"="50.879,2.896", "c"=85]
"risesoft-y9/Network-Drive" ["l"="50.839,3.063", "c"=85]
"fudan-generative-vision/dynamicPDB" ["l"="50.899,2.863", "c"=85]
"Liuziyu77/Visual-RFT" ["l"="47.336,30.087", "c"=254]
"Liuziyu77/RAR" ["l"="38.975,0.562", "c"=39]
"zhengli97/PromptKD" ["l"="50.397,38.279", "c"=684]
"SkyworkAI/Vitron" ["l"="47.494,30.173", "c"=254]
"apple/ml-4m" ["l"="46.544,30.64", "c"=367]
"AssafSinger94/dino-tracker" ["l"="64.253,3.014", "c"=49]
"DmitryRyumin/CVPR-2023-24-Papers" ["l"="38.282,2.309", "c"=54]
"frank-xwang/UnSAM" ["l"="53.167,29.27", "c"=547]
"Kroery/DiffMOT" ["l"="54.353,32.424", "c"=279]
"IDEA-Research/DINO-X-API" ["l"="48.711,30.066"]
"Coframe/coffee" ["l"="41.269,-4.062", "c"=146]
"NVlabs/RADIO" ["l"="64.088,2.918", "c"=49]
"apple/ml-tic-clip" ["l"="48.661,30.111"]
"wkcn/TinyCLIP" ["l"="48.647,30.125"]
"google-ai-edge/ai-edge-torch" ["l"="49.817,29.931", "c"=83]
"mhamilton723/FeatUp" ["l"="64.136,3.037", "c"=49]
"Ucas-HaoranWei/Vary-toy" ["l"="47.285,30.125", "c"=254]
"run-llama/create-llama" ["l"="41.249,0.55", "c"=7]
"run-llama/sec-insights" ["l"="41.049,0.692", "c"=7]
"run-llama/mongodb-demo" ["l"="41.078,0.907", "c"=7]
"run-llama/LlamaIndexTS" ["l"="40.977,0.513", "c"=7]
"CVMI-Lab/ResKD" ["l"="64.217,11.559", "c"=61]
"xushilin1/dst-det" ["l"="48.488,30.339"]
"MonoFormer/MonoFormer" ["l"="48.531,30.224"]
"huzhengdongcs/DAC-DETR" ["l"="48.511,30.214"]
"PRIS-CV/DemoFusion" ["l"="33.496,31.134", "c"=109]
"SeaArtLab/ComfyUI-Long-CLIP" ["l"="48.913,30.47"]
"showlab/Show-o" ["l"="46.437,30.648", "c"=367]
"LPengYang/MotionClone" ["l"="33.47,31.294", "c"=109]
"ShareGPT4Omni/ShareGPT4V" ["l"="38.94,0.575", "c"=39]
"baaivision/DIVA" ["l"="47.261,30.211", "c"=254]
"TencentQQGYLab/ELLA" ["l"="33.384,31.23", "c"=109]
"shikiw/OPERA" ["l"="47.362,30.288", "c"=254]
"facebookresearch/DCI" ["l"="48.888,30.482"]
"wysoczanska/clip-diy" ["l"="48.662,30.371"]
"jaychempan/LAE-DINO" ["l"="41.672,25.148", "c"=525]
"MCG-NJU/MOTIP" ["l"="54.387,32.432", "c"=279]
"zju3dv/MatchAnything" ["l"="59.551,9.261", "c"=274]
"verlab/accelerated_features" ["l"="59.528,9.27", "c"=274]
"luanshiyinyang/awesome-multiple-object-tracking" ["l"="54.46,32.51", "c"=279]
"google-research/syn-rep-learn" ["l"="48.94,30.526"]
"mazurowski-lab/SlicerSegmentWithSAM" ["l"="61.692,36.559", "c"=178]
"bytedance/coconut_cvpr2024" ["l"="48.728,30.46"]
"zhang-tao-whu/DVIS_Plus" ["l"="50.695,30.708", "c"=83]
"x-cls/superclass" ["l"="48.8,30.475"]
"FoundationVision/UniRef" ["l"="48.989,31.891", "c"=300]
"harpreetsahota204/awesome-cvpr-2024" ["l"="48.221,29.612"]
"voxel51/zcore" ["l"="48.257,29.626"]
"SkalskiP/transformers" ["l"="48.569,29.888"]
"merveenoyan/awesome-osml-for-devs" ["l"="41.394,0.865", "c"=7]
"SkalskiP/sketchy-vision" ["l"="48.546,29.911"]
"Traffic-X/ViT-CoMer" ["l"="48.922,30.207"]
"Traffic-X/Open-TransMind" ["l"="48.94,30.19"]
"11yxk/SAM-LST" ["l"="62.436,37.846", "c"=284]
"NVIDIA-AI-IOT/mmj_utils" ["l"="48.752,29.716"]
"NVIDIA-AI-IOT/jetson-platform-services" ["l"="48.759,29.701"]
"1hao-Liu/SM4Depth" ["l"="48.271,30.314"]
"343gltysprk/ovow" ["l"="48.462,30.227"]
"sinahmr/NACLIP" ["l"="48.591,30.349"]
"mc-lan/ClearCLIP" ["l"="48.61,30.336"]
"yossigandelsman/clip_text_span" ["l"="47.854,33.434", "c"=373]
"yongliu20/UniLSeg" ["l"="47.832,30.236", "c"=254]
"xushilin1/RMP-SAM" ["l"="48.443,30.411"]
"yifu-ding/BGEMM-CUDA" ["l"="48.62,29.787"]
"ouyanghaodong/DEYO" ["l"="48.526,30.107"]
"ouyanghaodong/DEYOv1.5" ["l"="48.546,30.105"]
"mbzuai-oryx/MobiLlama" ["l"="39.001,-0.027", "c"=39]
"yongliu20/SCAN" ["l"="47.817,30.224", "c"=254]
"linsun449/cliper.code" ["l"="48.594,30.367"]
"wuw2019/LoTLIP" ["l"="-35.277,20.035", "c"=1031]
"hananshafi/llmblueprint" ["l"="50.534,38.33", "c"=684]
"rohit901/VANE-Bench" ["l"="48.509,30.383"]
"SivanDoveh/DAC" ["l"="48.886,30.518"]
"dusty-nv/NanoLLM" ["l"="48.786,29.743"]
"asierarranz/Google_Gemma_DevDay" ["l"="48.797,29.705"]
"lambert-x/ProLab" ["l"="49.018,30.543"]
"YutingLi0606/SURE" ["l"="48.485,30.073"]
"LIYangggggg/SSB-OSR" ["l"="48.457,30.075"]
"COCO-FP/COCO-FP" ["l"="48.472,30.082"]
"stephansturges/BAD" ["l"="48.855,29.793"]
"Huntersdeng/CXX-DeepLearning-Inference" ["l"="48.65,29.828"]
"yangchris11/samurai" ["l"="48.841,29.926"]
"Lightricks/LTX-Video" ["l"="33.166,32.998", "c"=81]
"apple/ml-depth-pro" ["l"="64.201,3.024", "c"=49]
"bddicken/languages" ["l"="-22.288,-25.498", "c"=101]
"black-forest-labs/flux" ["l"="33.314,33.013", "c"=81]
"DepthAnything/Depth-Anything-V2" ["l"="64.246,3.057", "c"=49]
"facebookresearch/sapiens" ["l"="64.252,2.925", "c"=49]
"Tencent/HunyuanVideo" ["l"="33.22,32.974", "c"=81]
"microsoft/TRELLIS" ["l"="64.404,3.185", "c"=49]
"NVIDIA/Cosmos" ["l"="59.173,16.723", "c"=234]
"meta-llama/llama-models" ["l"="40.506,0.452", "c"=7]
"ultralytics/yolov5" ["l"="50.386,29.716", "c"=83]
"PaddlePaddle/PaddleDetection" ["l"="50.235,29.715", "c"=83]
"xuxw98/ESAM" ["l"="65.06,11.71", "c"=203]
"DepthAnything/PromptDA" ["l"="64.147,3.099", "c"=49]
"ai-dawang/PlugNPlay-Modules" ["l"="50.541,29.574", "c"=83]
"QwenLM/Qwen2.5-VL" ["l"="47.318,29.932", "c"=254]
"graphdeco-inria/gaussian-splatting" ["l"="63.433,1.708", "c"=134]
"NVlabs/FoundationPose" ["l"="59.358,15.555", "c"=536]
"hbb1/2d-gaussian-splatting" ["l"="64.103,3.227", "c"=49]
"jie200408/MyProject" ["l"="-55.172,-11.181", "c"=365]
"makeecat/Peng" ["l"="-55.179,-11.206", "c"=365]
"flymin/MagicDriveDiT" ["l"="-55.145,-11.17", "c"=365]
"Lattice-zjj/On-Device-FinLLM" ["l"="-55.165,-11.304", "c"=365]
"Theo-Messi/lumen" ["l"="-55.192,-11.227", "c"=365]
"BizSpringSource/bizspring-vue3-opensource" ["l"="-54.427,-12.903", "c"=252]
"cure-lab/MagicDrive" ["l"="-55.145,-11.137", "c"=365]
"xhs996/xhs_spider" ["l"="-55.114,-11.18", "c"=365]
"javaKing-lgy/mini-mybatis" ["l"="-55.093,-11.187", "c"=365]
"tsinghua-fib-lab/ANeurIPS2024_SPV-MIA" ["l"="-55.173,-11.322", "c"=365]
"chaxus/ran" ["l"="-55.22,-11.222", "c"=365]
"fecommunity/reactpress" ["l"="-55.169,-11.28", "c"=365]
"outtable/confuse-9live" ["l"="-55.162,-11.155", "c"=365]
"WZH0120/SAM2-UNet" ["l"="62.388,37.772", "c"=284]
"clxia12/RT-DETRv3" ["l"="48.548,30.124"]
"dnth/DEIMKit" ["l"="48.538,30.07"]
"ocean146/SimROD" ["l"="48.516,30.078"]
"HZAI-ZJNU/Mamba-YOLO" ["l"="49.099,34.242", "c"=556]
"iMoonLab/Hyper-YOLO" ["l"="51.355,16.271", "c"=1152]
"alimohammadiamirhossein/smite" ["l"="48.8,29.87"]
"Mark12Ding/SAM2Long" ["l"="50.78,3.05", "c"=85]
"mlfoundations/MINT-1T" ["l"="47.362,30.186", "c"=254]
"NVIDIA-AI-IOT/ros2_nanollm" ["l"="58.95,12.942", "c"=299]
"FishAndWasabi/YOLO-MS" ["l"="47.729,35.619", "c"=695]
"yang-0201/MAF-YOLO" ["l"="51.351,16.316", "c"=1152]
"anishmadan23/foundational_fsod" ["l"="48.423,30.224"]
"binyisu/food" ["l"="48.444,30.224"]
"jaychempan/ETS" ["l"="41.626,25.113", "c"=525]
"sagieppel/fine-tune-train_segment_anything_2_in_60_lines_of_code" ["l"="62.361,37.771", "c"=284]
"linsun449/iseg.code" ["l"="48.567,30.388"]
"patrick-tssn/Streaming-Grounded-SAM-2" ["l"="48.776,29.838"]
"heyoeyo/muggled_sam" ["l"="48.766,29.86"]
"zdata-inc/sam2_realtime" ["l"="48.777,29.85"]
"leaves162/CLIPtrase" ["l"="48.572,30.356"]
"AliaChen/sam2TRT" ["l"="48.749,29.763"]
"DongSky/MR-GDINO" ["l"="48.54,30.143"]
"hustvl/MaskAdapter" ["l"="63.43,12", "c"=693]
"jovanavidenovic/DAM4SAM" ["l"="48.8,29.847"]
"naver-ai/ZIM" ["l"="49.533,32.967", "c"=401]
"prs-eth/RollingDepth" ["l"="64.15,3.084", "c"=49]
"heyoeyo/muggled_dpt" ["l"="64.215,2.737", "c"=49]
"TIGER-AI-Lab/VLM2Vec" ["l"="32.902,30.738", "c"=109]
"ShuoShenDe/Grounded-Sam2-Tracking" ["l"="48.791,29.807"]
"lyxlplhy/Sam2Onnx_Inference" ["l"="48.72,29.759"]
"zhg-SZPT/FastSAM_Awsome_Openvino" ["l"="48.711,29.768"]
"XuM007/MITracker" ["l"="48.831,29.798"]
"ClaudiaCuttano/SAMWISE" ["l"="33.876,32.433", "c"=520]
"kangben258/MCITrack" ["l"="54.399,33.831", "c"=298]
"chenxin-dlut/SUTrack" ["l"="54.376,33.856", "c"=298]
"Restricted-Memory/RMem" ["l"="62.41,37.946", "c"=284]
"GuoleiSun/Awesome-SAM2" ["l"="48.814,29.79"]
"nnanhuang/SegAnyMo" ["l"="64.289,3.122", "c"=49]
"OliverRensu/MVG" ["l"="62.463,37.63", "c"=284]
"YutingLi0606/HTR-VT" ["l"="48.436,30.073"]
"JarintotionDin/ZiRaGroundingDINO" ["l"="48.511,30.138"]
"lyxlplhy/Sam2-collection" ["l"="48.718,29.739"]
"laugh12321/TensorRT-YOLO" ["l"="-55.268,-11.238", "c"=365]
"iscyy/ultralyticsPro" ["l"="53.492,3.653", "c"=1032]
"knmcguire/best-of-robot-simulators" ["l"="58.967,12.782", "c"=299]
"gtbook/robotics" ["l"="58.919,12.758", "c"=299]
"riscmaster/kinematic_arbiter" ["l"="58.963,12.86", "c"=299]
"SoccerNet/sn-gamestate" ["l"="49.079,25.881", "c"=584]
"NVlabs/describe-anything" ["l"="64.089,2.969", "c"=49]
"PRBonn/kiss-icp" ["l"="58.243,9.939", "c"=142]
"rmurai0610/MASt3R-SLAM" ["l"="64.086,3.075", "c"=49]
"facebookresearch/perception_models" ["l"="64.107,3.01", "c"=49]
"D-Robotics-AI-Lab/DOSOD" ["l"="48.478,30.185"]
"Xuan-World/Mamba-YOLO-World" ["l"="48.447,30.183"]
"Westlake-AGI-Lab/Distill-Any-Depth" ["l"="64.112,3.065", "c"=49]
"lil-lab/nlvr" ["l"="49.317,30.584"]
"lucasjinreal/Namo-R1" ["l"="48.8,30.534"]
}