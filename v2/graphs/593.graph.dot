digraph G {
"qiuqiangkong/audioset_tagging_cnn" -> "YuanGongND/ast"
"qiuqiangkong/audioset_tagging_cnn" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" -> "qiuqiangkong/panns_inference"
"qiuqiangkong/audioset_tagging_cnn" -> "kkoutini/PaSST"
"qiuqiangkong/audioset_tagging_cnn" -> "RetroCirce/HTS-Audio-Transformer"
"qiuqiangkong/audioset_tagging_cnn" -> "LAION-AI/CLAP" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" -> "qiuqiangkong/audioset_classification"
"qiuqiangkong/audioset_tagging_cnn" -> "karolpiczak/ESC-50"
"qiuqiangkong/audioset_tagging_cnn" -> "iver56/audiomentations" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" -> "qiuqiangkong/panns_transfer_to_gtzan"
"qiuqiangkong/audioset_tagging_cnn" -> "yinkalario/General-Purpose-Sound-Recognition-Demo"
"qiuqiangkong/audioset_tagging_cnn" -> "s3prl/s3prl" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" -> "asteroid-team/torch-audiomentations" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" -> "fschmid56/EfficientAT"
"qiuqiangkong/audioset_tagging_cnn" -> "facebookresearch/AudioMAE"
"NVIDIA/nvvl" -> "cvondrick/soundnet" ["e"=1]
"iver56/audiomentations" -> "YuanGongND/ast" ["e"=1]
"iver56/audiomentations" -> "qiuqiangkong/audioset_tagging_cnn" ["e"=1]
"YapengTian/AVE-ECCV18" -> "YapengTian/AVVP-ECCV20"
"YapengTian/AVE-ECCV18" -> "jasongief/PSP_CVPR_2021"
"YapengTian/AVE-ECCV18" -> "FloretCat/CMRAN"
"YapengTian/AVE-ECCV18" -> "ardasnck/learning_to_localize_sound_source"
"YapengTian/AVE-ECCV18" -> "krantiparida/awesome-audio-visual"
"YapengTian/AVE-ECCV18" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"YapengTian/AVE-ECCV18" -> "marmot-xy/CMBS"
"YapengTian/AVE-ECCV18" -> "hche11/VGGSound"
"YapengTian/AVE-ECCV18" -> "Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing"
"YapengTian/AVE-ECCV18" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"YapengTian/AVE-ECCV18" -> "GenjiB/LAVISH"
"YapengTian/AVE-ECCV18" -> "ttgeng233/UnAV"
"YapengTian/AVE-ECCV18" -> "hangzhaomit/Sound-of-Pixels"
"YapengTian/AVE-ECCV18" -> "GeWu-Lab/awesome-audiovisual-learning"
"YapengTian/AVE-ECCV18" -> "GeWu-Lab/MUSIC-AVQA"
"krantiparida/awesome-audio-visual" -> "GeWu-Lab/awesome-audiovisual-learning"
"krantiparida/awesome-audio-visual" -> "YapengTian/AVE-ECCV18"
"krantiparida/awesome-audio-visual" -> "danmic/av-se" ["e"=1]
"krantiparida/awesome-audio-visual" -> "hche11/VGGSound"
"krantiparida/awesome-audio-visual" -> "YapengTian/AVVP-ECCV20"
"krantiparida/awesome-audio-visual" -> "facebookresearch/av_hubert" ["e"=1]
"krantiparida/awesome-audio-visual" -> "afourast/avobjects"
"krantiparida/awesome-audio-visual" -> "smeetrs/deep_avsr" ["e"=1]
"krantiparida/awesome-audio-visual" -> "rhgao/co-separation"
"krantiparida/awesome-audio-visual" -> "YuanGongND/cav-mae"
"krantiparida/awesome-audio-visual" -> "pedro-morgado/spatialaudiogen"
"krantiparida/awesome-audio-visual" -> "joonson/syncnet_python" ["e"=1]
"krantiparida/awesome-audio-visual" -> "facebookresearch/2.5D-Visual-Sound"
"krantiparida/awesome-audio-visual" -> "GenjiB/LAVISH"
"krantiparida/awesome-audio-visual" -> "facebookresearch/EasyComDataset"
"jim-schwoebel/voicebook" -> "jim-schwoebel/voice_gender_detection"
"jim-schwoebel/voicebook" -> "jim-schwoebel/voice_datasets" ["e"=1]
"jim-schwoebel/voicebook" -> "jim-schwoebel/allie"
"jim-schwoebel/voicebook" -> "jim-schwoebel/download_audioset"
"jim-schwoebel/voicebook" -> "edufonseca/icassp19"
"jim-schwoebel/voicebook" -> "jim-schwoebel/audioset_models"
"Renovamen/Speech-Emotion-Recognition" -> "yeyupiaoling/SpeechEmotionRecognition-Pytorch" ["e"=1]
"Renovamen/Speech-Emotion-Recognition" -> "yingdajun/SpeechEmotionAndPeopleAnalyse" ["e"=1]
"jim-schwoebel/download_audioset" -> "jim-schwoebel/audioset_models"
"jim-schwoebel/download_audioset" -> "unixpickle/audioset"
"IBM/MAX-Audio-Classifier" -> "IBM/audioset-classification"
"IBM/MAX-Audio-Classifier" -> "qiuqiangkong/audioset_classification"
"seth814/Audio-Classification" -> "keunwoochoi/kapre" ["e"=1]
"seth814/Audio-Classification" -> "ksanjeevan/crnn-audio-classification"
"seth814/Audio-Classification" -> "imfing/audio-classification"
"seth814/Audio-Classification" -> "marcogdepinto/emotion-classification-from-audio-files" ["e"=1]
"seth814/Audio-Classification" -> "aqibsaeed/Urban-Sound-Classification"
"seth814/Audio-Classification" -> "musikalkemist/DeepLearningForAudioWithPython"
"seth814/Audio-Classification" -> "qiuqiangkong/audioset_classification"
"seth814/Audio-Classification" -> "jonnor/machinehearing"
"seth814/Audio-Classification" -> "jaron/deep-listening"
"seth814/Audio-Classification" -> "karolpiczak/ESC-50"
"seth814/Audio-Classification" -> "luuil/Tensorflow-Audio-Classification"
"seth814/Audio-Classification" -> "despoisj/DeepAudioClassification" ["e"=1]
"seth814/Audio-Classification" -> "qiuqiangkong/audioset_tagging_cnn"
"seth814/Audio-Classification" -> "marl/openl3"
"seth814/Audio-Classification" -> "musikalkemist/AudioSignalProcessingForML"
"ardasnck/learning_to_localize_sound_source" -> "shvdiwnkozbw/Multi-Source-Sound-Localization"
"ardasnck/learning_to_localize_sound_source" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"ardasnck/learning_to_localize_sound_source" -> "zjsong/SSPL"
"ardasnck/learning_to_localize_sound_source" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"ardasnck/learning_to_localize_sound_source" -> "YapengTian/AVE-ECCV18"
"ardasnck/learning_to_localize_sound_source" -> "rhgao/co-separation"
"ardasnck/learning_to_localize_sound_source" -> "FloretCat/CMRAN"
"ardasnck/learning_to_localize_sound_source" -> "stoneMo/EZ-VSL"
"ardasnck/learning_to_localize_sound_source" -> "liyidi/soundnet_localize_sound_source"
"ardasnck/learning_to_localize_sound_source" -> "stoneMo/SLAVC"
"jonnor/ESC-CNN-microcontroller" -> "jonnor/machinehearing"
"jonnor/ESC-CNN-microcontroller" -> "araobp/acoustic-features"
"yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model" -> "PALMJJ/Multimodal-short-video-classification"
"yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model" -> "yt1120948918/short-video-classification"
"yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model" -> "Luka0612/ChineseVLBert"
"kadoufall/Urban-Sound-Classification-VS" -> "yeyupiaoling/AudioClassification-Tensorflow"
"kadoufall/Urban-Sound-Classification-VS" -> "nitinvwaran/UrbanSound8K-audio-classification-with-ResNet"
"imfing/audio-classification" -> "micah5/pyAudioClassification"
"imfing/audio-classification" -> "drscotthawley/panotti"
"imfing/audio-classification" -> "qiuqiangkong/audioset_classification"
"imfing/audio-classification" -> "vishalshar/Audio-Classification-using-CNN-MLP"
"imfing/audio-classification" -> "ksanjeevan/crnn-audio-classification"
"imfing/audio-classification" -> "jaron/deep-listening"
"imfing/audio-classification" -> "luuil/Tensorflow-Audio-Classification"
"imfing/audio-classification" -> "aqibsaeed/Urban-Sound-Classification"
"imfing/audio-classification" -> "CVxTz/audio_classification"
"imfing/audio-classification" -> "kadoufall/Urban-Sound-Classification-VS"
"imfing/audio-classification" -> "daisukelab/ml-sound-classifier"
"imfing/audio-classification" -> "karolpiczak/ESC-50"
"lRomul/argus-freesound" -> "qrfaction/2nd-Freesound-Audio-Tagging-2019"
"lRomul/argus-freesound" -> "ebouteillon/freesound-audio-tagging-2019"
"lRomul/argus-freesound" -> "ex4sperans/freesound-classification"
"lRomul/argus-freesound" -> "lRomul/argus" ["e"=1]
"lRomul/argus-freesound" -> "ryanwongsa/kaggle-birdsong-recognition"
"lRomul/argus-freesound" -> "sainathadapa/kaggle-freesound-audio-tagging"
"lRomul/argus-freesound" -> "edufonseca/icassp19"
"lRomul/argus-freesound" -> "mnpinto/audiotagging2019" ["e"=1]
"lRomul/argus-freesound" -> "ksanjeevan/crnn-audio-classification"
"lRomul/argus-freesound" -> "Cocoxili/DCASE2018Task2"
"lRomul/argus-freesound" -> "qiuqiangkong/audioset_tagging_cnn"
"lRomul/argus-freesound" -> "MyLtYkRiTiK/ComputerVision_Tutorials_in_Russian" ["e"=1]
"lRomul/argus-freesound" -> "zcaceres/spec_augment" ["e"=1]
"bastibe/python-soundfile" -> "justinsalamon/scaper" ["e"=1]
"facebookresearch/FAIR-Play" -> "facebookresearch/2.5D-Visual-Sound"
"facebookresearch/FAIR-Play" -> "SheldonTsui/SepStereo_ECCV2020"
"facebookresearch/FAIR-Play" -> "pedro-morgado/spatialaudiogen"
"facebookresearch/FAIR-Play" -> "rhgao/co-separation"
"facebookresearch/FAIR-Play" -> "SheldonTsui/PseudoBinaural_CVPR2021"
"facebookresearch/2.5D-Visual-Sound" -> "facebookresearch/FAIR-Play"
"facebookresearch/2.5D-Visual-Sound" -> "SheldonTsui/SepStereo_ECCV2020"
"facebookresearch/2.5D-Visual-Sound" -> "SheldonTsui/PseudoBinaural_CVPR2021"
"facebookresearch/2.5D-Visual-Sound" -> "pedro-morgado/spatialaudiogen"
"facebookresearch/2.5D-Visual-Sound" -> "rhgao/co-separation"
"facebookresearch/2.5D-Visual-Sound" -> "facebookresearch/learning-audio-visual-dereverberation"
"soerenab/AudioMNIST" -> "microsoft/CLAP" ["e"=1]
"csteinmetz1/pyloudnorm" -> "justinsalamon/scaper" ["e"=1]
"harritaylor/torchvggish" -> "tcvrick/audioset-vggish-tensorflow-to-pytorch"
"harritaylor/torchvggish" -> "DTaoo/VGGish"
"harritaylor/torchvggish" -> "ksanjeevan/crnn-audio-classification"
"harritaylor/torchvggish" -> "qiuqiangkong/audioset_classification"
"harritaylor/torchvggish" -> "hche11/VGGSound"
"harritaylor/torchvggish" -> "qiuqiangkong/audioset_tagging_cnn"
"harritaylor/torchvggish" -> "YapengTian/AVE-ECCV18"
"harritaylor/torchvggish" -> "marl/openl3"
"harritaylor/torchvggish" -> "YuanGongND/ast"
"harritaylor/torchvggish" -> "luuil/Tensorflow-Audio-Classification"
"harritaylor/torchvggish" -> "linrongc/youtube-8m" ["e"=1]
"harritaylor/torchvggish" -> "balavenkatesh3322/audio-pretrained-model" ["e"=1]
"harritaylor/torchvggish" -> "v-iashin/video_features" ["e"=1]
"harritaylor/torchvggish" -> "yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model"
"harritaylor/torchvggish" -> "lyakaap/NetVLAD-pytorch" ["e"=1]
"jordipons/musicnn" -> "audioset/ontology" ["e"=1]
"osai-ai/tensor-stream" -> "lRomul/argus-freesound" ["e"=1]
"mir-dataset-loaders/mirdata" -> "marl/openl3" ["e"=1]
"rohitrango/objects-that-sound" -> "Kajiyu/LLLNet"
"rohitrango/objects-that-sound" -> "kyuyeonpooh/objects-that-sound"
"rohitrango/objects-that-sound" -> "marl/l3embedding"
"rohitrango/objects-that-sound" -> "auroracramer/flickr-soundnet-dl"
"marcogdepinto/emotion-classification-from-audio-files" -> "seth814/Audio-Classification" ["e"=1]
"sharathadavanne/seld-net" -> "sharathadavanne/sed-crnn"
"sharathadavanne/seld-net" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"sharathadavanne/seld-net" -> "yinkalario/EIN-SELD"
"sharathadavanne/seld-net" -> "Audio-WestlakeU/FN-SSL" ["e"=1]
"sharathadavanne/seld-net" -> "sharathadavanne/seld-dcase2019"
"sharathadavanne/seld-net" -> "sharathadavanne/seld-dcase2022"
"sharathadavanne/seld-net" -> "sharathadavanne/seld-dcase2020"
"sharathadavanne/seld-net" -> "thomeou/SALSA"
"sharathadavanne/seld-net" -> "MaigoAkisame/cmu-thesis"
"sharathadavanne/seld-net" -> "DavidDiazGuerra/gpuRIR" ["e"=1]
"sharathadavanne/seld-net" -> "shvdiwnkozbw/Multi-Source-Sound-Localization"
"sharathadavanne/seld-net" -> "Soumitro-Chakrabarty/Single-speaker-localization" ["e"=1]
"sharathadavanne/seld-net" -> "DavidDiazGuerra/Cross3D"
"sharathadavanne/seld-net" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" ["e"=1]
"sharathadavanne/seld-net" -> "giusenso/seld-tcn"
"cdjkim/audiocaps" -> "XinhaoMei/WavCaps"
"cdjkim/audiocaps" -> "JishengBai/AudioSetCaps"
"cdjkim/audiocaps" -> "XinhaoMei/ACT"
"cdjkim/audiocaps" -> "wsntxxn/AudioCaption"
"cdjkim/audiocaps" -> "audio-captioning/clotho-dataset"
"cdjkim/audiocaps" -> "audio-captioning/audio-captioning-resources"
"jonnor/machinehearing" -> "jonnor/ESC-CNN-microcontroller"
"jonnor/machinehearing" -> "fastaudio/fastaudio" ["e"=1]
"andrewowens/multisensory" -> "avivga/audio-visual-speech-enhancement" ["e"=1]
"andrewowens/multisensory" -> "afourast/avobjects"
"andrewowens/multisensory" -> "hangzhaomit/Sound-of-Pixels"
"andrewowens/multisensory" -> "rohitrango/objects-that-sound"
"andrewowens/multisensory" -> "bill9800/speech_separation" ["e"=1]
"andrewowens/multisensory" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"andrewowens/multisensory" -> "facebookresearch/FAIR-Play"
"andrewowens/multisensory" -> "ardasnck/learning_to_localize_sound_source"
"andrewowens/multisensory" -> "ajinkyaT/Lip_Reading_in_the_Wild_AVSR" ["e"=1]
"andrewowens/multisensory" -> "mayurnewase/looking-to-listen-at-cocktail-party" ["e"=1]
"andrewowens/multisensory" -> "YapengTian/AVE-ECCV18"
"andrewowens/multisensory" -> "rhgao/co-separation"
"marl/l3embedding" -> "marl/openl3"
"marl/l3embedding" -> "rohitrango/objects-that-sound"
"micah5/pyAudioClassification" -> "drscotthawley/panotti"
"micah5/pyAudioClassification" -> "imfing/audio-classification"
"micah5/pyAudioClassification" -> "sainathadapa/kaggle-freesound-audio-tagging"
"bill9800/speech_separation" -> "afourast/avobjects" ["e"=1]
"jhartquist/fastai_audio" -> "drscotthawley/panotti" ["e"=1]
"marl/openl3" -> "marl/l3embedding"
"marl/openl3" -> "mir-dataset-loaders/mirdata" ["e"=1]
"marl/openl3" -> "KinWaiCheuk/nnAudio" ["e"=1]
"marl/openl3" -> "justinsalamon/scaper"
"marl/openl3" -> "MaigoAkisame/cmu-thesis"
"marl/openl3" -> "keunwoochoi/kapre" ["e"=1]
"marl/openl3" -> "jordipons/sklearn-audio-transfer-learning" ["e"=1]
"marl/openl3" -> "MTG/freesound-datasets" ["e"=1]
"marl/openl3" -> "qiuqiangkong/audioset_classification"
"marl/openl3" -> "bmcfee/muda" ["e"=1]
"marl/openl3" -> "microsoft/CLAP"
"marl/openl3" -> "Spijkervet/CLMR" ["e"=1]
"marl/openl3" -> "mir-evaluation/mir_eval" ["e"=1]
"marl/openl3" -> "keunwoochoi/torchaudio-contrib" ["e"=1]
"marl/openl3" -> "soundata/soundata" ["e"=1]
"MaigoAkisame/cmu-thesis" -> "TUT-ARG/sed_eval"
"MaigoAkisame/cmu-thesis" -> "sharathadavanne/sed-crnn"
"MaigoAkisame/cmu-thesis" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"MaigoAkisame/cmu-thesis" -> "DCASE-REPO/DESED_task"
"MaigoAkisame/cmu-thesis" -> "DCASE-REPO/dcase2018_baseline"
"MaigoAkisame/cmu-thesis" -> "Kikyo-16/Sound_event_detection"
"MaigoAkisame/cmu-thesis" -> "sharathadavanne/seld-dcase2019"
"MaigoAkisame/cmu-thesis" -> "qiuqiangkong/sed_time_freq_segmentation"
"MaigoAkisame/cmu-thesis" -> "ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars"
"MaigoAkisame/cmu-thesis" -> "dr-costas/dnd-sed"
"MaigoAkisame/cmu-thesis" -> "qiuqiangkong/sound_event_detection_dcase2017_task4"
"MaigoAkisame/cmu-thesis" -> "turpaultn/DESED"
"MaigoAkisame/cmu-thesis" -> "qiuqiangkong/audioset_classification"
"MaigoAkisame/cmu-thesis" -> "TUT-ARG/DCASE2017-baseline-system"
"MaigoAkisame/cmu-thesis" -> "marl/audiosetdl"
"speedyseal/audiosetdl" -> "hche11/VGGSound"
"qiuqiangkong/torchlibrosa" -> "qiuqiangkong/audioset_tagging_cnn" ["e"=1]
"qiuqiangkong/torchlibrosa" -> "kkoutini/PaSST" ["e"=1]
"qiuqiangkong/torchlibrosa" -> "qiuqiangkong/panns_inference" ["e"=1]
"qiuqiangkong/torchlibrosa" -> "YuanGongND/ssast" ["e"=1]
"qiuqiangkong/torchlibrosa" -> "LAION-AI/audio-dataset" ["e"=1]
"qiuqiangkong/torchlibrosa" -> "microsoft/CLAP" ["e"=1]
"hangzhaomit/Sound-of-Pixels" -> "roudimit/MUSIC_dataset"
"hangzhaomit/Sound-of-Pixels" -> "rhgao/co-separation"
"hangzhaomit/Sound-of-Pixels" -> "andrewowens/multisensory"
"hangzhaomit/Sound-of-Pixels" -> "afourast/avobjects"
"hangzhaomit/Sound-of-Pixels" -> "YapengTian/AVE-ECCV18"
"hangzhaomit/Sound-of-Pixels" -> "rohitrango/objects-that-sound"
"hangzhaomit/Sound-of-Pixels" -> "facebookresearch/2.5D-Visual-Sound"
"hangzhaomit/Sound-of-Pixels" -> "ardasnck/learning_to_localize_sound_source"
"hangzhaomit/Sound-of-Pixels" -> "rhgao/Deep-MIML-Network"
"hangzhaomit/Sound-of-Pixels" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"hangzhaomit/Sound-of-Pixels" -> "SheldonTsui/SepStereo_ECCV2020"
"hangzhaomit/Sound-of-Pixels" -> "pedro-morgado/spatialaudiogen"
"hangzhaomit/Sound-of-Pixels" -> "krantiparida/awesome-audio-visual"
"hangzhaomit/Sound-of-Pixels" -> "YapengTian/CCOL-CVPR21"
"hangzhaomit/Sound-of-Pixels" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"sharathadavanne/sed-crnn" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"sharathadavanne/sed-crnn" -> "MaigoAkisame/cmu-thesis"
"sharathadavanne/sed-crnn" -> "yongxuUSTC/dcase2017_task4_cvssp"
"sharathadavanne/sed-crnn" -> "TUT-ARG/sed_eval"
"sharathadavanne/sed-crnn" -> "sharathadavanne/seld-net"
"sharathadavanne/sed-crnn" -> "Kikyo-16/Sound_event_detection"
"sharathadavanne/sed-crnn" -> "sharathadavanne/seld-dcase2019"
"sharathadavanne/sed-crnn" -> "TUT-ARG/sed_vis"
"sharathadavanne/sed-crnn" -> "TUT-ARG/DCASE2017-baseline-system"
"sharathadavanne/sed-crnn" -> "justinsalamon/scaper"
"sharathadavanne/sed-crnn" -> "ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars"
"sharathadavanne/sed-crnn" -> "turpaultn/DESED"
"sharathadavanne/sed-crnn" -> "DCASE-REPO/dcase2018_baseline"
"sharathadavanne/sed-crnn" -> "DCASE-REPO/dcase_util"
"sharathadavanne/sed-crnn" -> "TUT-ARG/DCASE2016-baseline-system-python"
"turpaultn/DCASE2019_task4" -> "turpaultn/dcase20_task4"
"turpaultn/DCASE2019_task4" -> "qiuqiangkong/dcase2019_task4"
"turpaultn/DCASE2019_task4" -> "DCASE-REPO/dcase2018_baseline"
"lihanghang/CASR-DEMO" -> "lihanghang/Deep-learning-And-Paper"
"ksanjeevan/crnn-audio-classification" -> "seth814/Audio-Classification"
"ksanjeevan/crnn-audio-classification" -> "qiuqiangkong/audioset_classification"
"ksanjeevan/crnn-audio-classification" -> "kamalesh0406/Audio-Classification"
"ksanjeevan/crnn-audio-classification" -> "imfing/audio-classification"
"ksanjeevan/crnn-audio-classification" -> "aqibsaeed/Urban-Sound-Classification"
"ksanjeevan/crnn-audio-classification" -> "sarthak268/Audio_Classification_using_LSTM"
"ksanjeevan/crnn-audio-classification" -> "harritaylor/torchvggish"
"ksanjeevan/crnn-audio-classification" -> "nitinvwaran/UrbanSound8K-audio-classification-with-ResNet"
"ksanjeevan/crnn-audio-classification" -> "lRomul/argus-freesound"
"ksanjeevan/crnn-audio-classification" -> "yeyupiaoling/AudioClassification-Pytorch"
"ksanjeevan/crnn-audio-classification" -> "luuil/Tensorflow-Audio-Classification"
"ksanjeevan/crnn-audio-classification" -> "RetroCirce/HTS-Audio-Transformer"
"ksanjeevan/crnn-audio-classification" -> "karolpiczak/ESC-50"
"ksanjeevan/crnn-audio-classification" -> "jaron/deep-listening"
"ksanjeevan/crnn-audio-classification" -> "DCASE-REPO/dcase2018_baseline"
"DCASE-REPO/dcase_util" -> "DCASE-REPO/dcase2018_baseline"
"DCASE-REPO/dcase_util" -> "toni-heittola/icassp2019-tutorial"
"DCASE-REPO/dcase_util" -> "TUT-ARG/sed_eval"
"DCASE-REPO/dcase_util" -> "MihawkHu/DCASE2020_task1"
"DCASE-REPO/dcase_util" -> "TUT-ARG/sed_vis"
"DCASE-REPO/dcase2018_baseline" -> "DCASE-REPO/dcase_util"
"DCASE-REPO/dcase2018_baseline" -> "turpaultn/DCASE2019_task4"
"DCASE-REPO/dcase2018_baseline" -> "yongxuUSTC/dcase2017_task4_cvssp"
"DCASE-REPO/dcase2018_baseline" -> "TUT-ARG/DCASE2017-baseline-system"
"DCASE-REPO/dcase2018_baseline" -> "MaigoAkisame/cmu-thesis"
"DCASE-REPO/dcase2018_baseline" -> "CPJKU/dcase_task2"
"DCASE-REPO/dcase2018_baseline" -> "TUT-ARG/sed_eval"
"pedro-morgado/spatialaudiogen" -> "facebookresearch/2.5D-Visual-Sound"
"pedro-morgado/spatialaudiogen" -> "SheldonTsui/SepStereo_ECCV2020"
"pedro-morgado/spatialaudiogen" -> "facebookresearch/FAIR-Play"
"pedro-morgado/spatialaudiogen" -> "SheldonTsui/PseudoBinaural_CVPR2021"
"pedro-morgado/spatialaudiogen" -> "pedro-morgado/AVSpatialAlignment"
"h2oai/pystacknet" -> "Cocoxili/DCASE2018Task2" ["e"=1]
"luuil/Tensorflow-Audio-Classification" -> "IBM/audioset-classification"
"luuil/Tensorflow-Audio-Classification" -> "DTaoo/VGGish"
"luuil/Tensorflow-Audio-Classification" -> "qiuqiangkong/audioset_classification"
"edufonseca/icassp19" -> "ebouteillon/freesound-audio-tagging-2019"
"tcvrick/audioset-vggish-tensorflow-to-pytorch" -> "harritaylor/torchvggish"
"DTaoo/VGGish" -> "luuil/Tensorflow-Audio-Classification"
"DTaoo/VGGish" -> "jordipons/sklearn-audio-transfer-learning" ["e"=1]
"DTaoo/VGGish" -> "qiuqiangkong/audioset_classification"
"DTaoo/VGGish" -> "harritaylor/torchvggish"
"aoifemcdonagh/audioset-processing" -> "MorenoLaQuatra/audioset-download"
"aoifemcdonagh/audioset-processing" -> "jim-schwoebel/download_audioset"
"IBM/audioset-classification" -> "qiuqiangkong/audioset_classification"
"IBM/audioset-classification" -> "IBM/MAX-Audio-Classifier"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "yinkalario/EIN-SELD"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "qiuqiangkong/dcase2019_task3"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "danielkrause/DCASE2022-data-generator"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "sharathadavanne/seld-dcase2019"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "sharathadavanne/sed-crnn"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "thomeou/SALSA"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "MaigoAkisame/cmu-thesis"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "sharathadavanne/seld-net"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "yinkalario/DCASE2019-TASK3"
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" -> "Jinbo-Hu/DCASE2022-TASK3"
"kkoutini/cpjku_dcase19" -> "kkoutini/cpjku_dcase20"
"kkoutini/cpjku_dcase19" -> "McDonnell-Lab/DCASE2019-Task1"
"kkoutini/cpjku_dcase19" -> "toni-heittola/dcase2020_task1_baseline"
"kkoutini/cpjku_dcase19" -> "MihawkHu/DCASE2020_task1"
"pudae/kaggle-humpback" -> "qrfaction/2nd-Freesound-Audio-Tagging-2019" ["e"=1]
"vishalshar/Audio-Classification-using-CNN-MLP" -> "CVxTz/audio_classification"
"Cocoxili/DCASE2018Task2" -> "sainathadapa/kaggle-freesound-audio-tagging"
"Cocoxili/DCASE2018Task2" -> "qrfaction/2nd-Freesound-Audio-Tagging-2019"
"CVxTz/audio_classification" -> "vishalshar/Audio-Classification-using-CNN-MLP"
"qiuqiangkong/audioset_classification" -> "IBM/audioset-classification"
"qiuqiangkong/audioset_classification" -> "marl/audiosetdl"
"qiuqiangkong/audioset_classification" -> "yongxuUSTC/dcase2017_task4_cvssp"
"qiuqiangkong/audioset_classification" -> "qiuqiangkong/ICASSP2018_audioset"
"qiuqiangkong/audioset_classification" -> "imfing/audio-classification"
"qiuqiangkong/audioset_classification" -> "ksanjeevan/crnn-audio-classification"
"qiuqiangkong/audioset_classification" -> "MaigoAkisame/cmu-thesis"
"qiuqiangkong/audioset_classification" -> "qiuqiangkong/audioset_tagging_cnn"
"qiuqiangkong/audioset_classification" -> "qiuqiangkong/sound_event_detection_dcase2017_task4"
"qiuqiangkong/audioset_classification" -> "ChangsongYu/Eusipco2018_Google_AudioSet"
"qiuqiangkong/audioset_classification" -> "IBM/MAX-Audio-Classifier"
"qiuqiangkong/audioset_classification" -> "luuil/Tensorflow-Audio-Classification"
"qiuqiangkong/audioset_classification" -> "audioset/ontology"
"qiuqiangkong/audioset_classification" -> "DTaoo/VGGish"
"qiuqiangkong/audioset_classification" -> "jim-schwoebel/download_audioset"
"qrfaction/2nd-Freesound-Audio-Tagging-2019" -> "lRomul/argus-freesound"
"toni-heittola/icassp2019-tutorial" -> "qiuqiangkong/ICASSP2018_audioset"
"RicherMans/AudioCaption" -> "audio-captioning/audio-captioning-resources"
"RicherMans/AudioCaption" -> "audio-captioning/audio-captioning-papers"
"RicherMans/AudioCaption" -> "microsoft/WavText5K"
"ebouteillon/freesound-audio-tagging-2019" -> "daisukelab/freesound-audio-tagging-2019"
"ebouteillon/freesound-audio-tagging-2019" -> "lRomul/argus-freesound"
"ebouteillon/freesound-audio-tagging-2019" -> "edufonseca/icassp19"
"Kikyo-16/Sound_event_detection" -> "sharathadavanne/sed-crnn"
"Kikyo-16/Sound_event_detection" -> "fgnt/pb_sed"
"Kikyo-16/Sound_event_detection" -> "turpaultn/dcase20_task4"
"Kikyo-16/Sound_event_detection" -> "qiuqiangkong/sound_event_detection_dcase2017_task4"
"Kikyo-16/Sound_event_detection" -> "turpaultn/DCASE2019_task4"
"Kikyo-16/Sound_event_detection" -> "MaigoAkisame/cmu-thesis"
"Kikyo-16/Sound_event_detection" -> "turpaultn/DESED"
"Kikyo-16/Sound_event_detection" -> "DCASE-REPO/DESED_task"
"Kikyo-16/Sound_event_detection" -> "TUT-ARG/sed_eval"
"Kikyo-16/Sound_event_detection" -> "TUT-ARG/sed_vis"
"Kikyo-16/Sound_event_detection" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"Kikyo-16/Sound_event_detection" -> "edufonseca/FSD50K_baseline"
"Kikyo-16/Sound_event_detection" -> "dr-costas/dnd-sed"
"sainathadapa/kaggle-freesound-audio-tagging" -> "Cocoxili/DCASE2018Task2"
"sainathadapa/kaggle-freesound-audio-tagging" -> "micah5/pyAudioClassification"
"marl/audiosetdl" -> "unixpickle/audioset"
"marl/audiosetdl" -> "qiuqiangkong/audioset_classification"
"marl/audiosetdl" -> "MaigoAkisame/cmu-thesis"
"marl/audiosetdl" -> "toni-heittola/icassp2019-tutorial"
"marl/audiosetdl" -> "qiuqiangkong/ICASSP2018_audioset"
"araobp/acoustic-features" -> "araobp/image-features"
"araobp/acoustic-features" -> "araobp/stm32-mcu"
"kingfengji/DeepMIML" -> "rhgao/Deep-MIML-Network" ["e"=1]
"roudimit/MUSIC_dataset" -> "hangzhaomit/Sound-of-Pixels"
"roudimit/MUSIC_dataset" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"roudimit/MUSIC_dataset" -> "sony/CLIPSep" ["e"=1]
"CPJKU/dcase_task2" -> "tqbl/dcase2018_task2"
"CPJKU/dcase_task2" -> "finejuly/dcase2018_task2_cochlearai"
"sharathadavanne/seld-dcase2019" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"sharathadavanne/seld-dcase2019" -> "sharathadavanne/seld-dcase2020"
"sharathadavanne/seld-dcase2019" -> "sharathadavanne/sed-crnn"
"yongxuUSTC/dcase2017_task4_cvssp" -> "DCASE-REPO/dcase2018_baseline"
"yongxuUSTC/dcase2017_task4_cvssp" -> "ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars"
"yongxuUSTC/dcase2017_task4_cvssp" -> "sharathadavanne/sed-crnn"
"yongxuUSTC/dcase2017_task4_cvssp" -> "CPJKU/dcase_task2"
"yongxuUSTC/dcase2017_task4_cvssp" -> "qiuqiangkong/audioset_classification"
"yongxuUSTC/dcase2017_task4_cvssp" -> "TUT-ARG/DCASE2017-baseline-system"
"yongxuUSTC/dcase2017_task4_cvssp" -> "qiuqiangkong/ICASSP2018_audioset"
"yongxuUSTC/dcase2017_task4_cvssp" -> "TUT-ARG/DCASE2016-baseline-system-python"
"yongxuUSTC/dcase2017_task4_cvssp" -> "TUT-ARG/sed_eval"
"yongxuUSTC/dcase2017_task4_cvssp" -> "qiuqiangkong/dcase2018_task4"
"yongxuUSTC/dcase2017_task4_cvssp" -> "qiuqiangkong/sound_event_detection_dcase2017_task4"
"yongxuUSTC/dcase2017_task4_cvssp" -> "turpaultn/DCASE2019_task4"
"yongxuUSTC/dcase2017_task4_cvssp" -> "MaigoAkisame/cmu-thesis"
"araobp/image-features" -> "araobp/acoustic-features"
"McDonnell-Lab/DCASE2019-Task1" -> "MihawkHu/Acoustic_Lottery"
"rhgao/Deep-MIML-Network" -> "rhgao/co-separation"
"tqbl/gccaps" -> "tqbl/dcase2018_task2"
"tqbl/dcase2018_task2" -> "CPJKU/dcase_task2"
"tqbl/dcase2018_task2" -> "finejuly/dcase2018_task2_cochlearai"
"finejuly/dcase2018_task2_cochlearai" -> "tqbl/dcase2018_task2"
"koukyo1994/kaggle-birdcall-resnet-baseline-training" -> "fkubota/spectrogram-tree"
"koukyo1994/kaggle-birdcall-resnet-baseline-training" -> "koukyo1994/kaggle-birdcall-6th-place"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "yeyupiaoling/AudioClassification-Tensorflow" ["e"=1]
"turpaultn/DESED" -> "DCASE-REPO/DESED_task"
"turpaultn/DESED" -> "frednam93/FDY-SED"
"turpaultn/DESED" -> "turpaultn/dcase20_task4"
"turpaultn/DESED" -> "Audio-WestlakeU/ATST-SED"
"turpaultn/DESED" -> "TUT-ARG/sed_vis"
"turpaultn/DESED" -> "cai525/Transformer4SED"
"turpaultn/DESED" -> "justinsalamon/scaper"
"turpaultn/DESED" -> "fgnt/sed_scores_eval"
"turpaultn/DESED" -> "turpaultn/DCASE2019_task4"
"tyiannak/pyAudioAnalysis" -> "karolpiczak/ESC-50" ["e"=1]
"ryanwongsa/kaggle-birdsong-recognition" -> "vlomme/Birdcall-Identification-competition"
"ryanwongsa/kaggle-birdsong-recognition" -> "TheoViel/kaggle_birdcall_identification"
"ryanwongsa/kaggle-birdsong-recognition" -> "koukyo1994/kaggle-birdcall-6th-place"
"ryanwongsa/kaggle-birdsong-recognition" -> "tattaka/birdclef-2021"
"ryanwongsa/kaggle-birdsong-recognition" -> "jfpuget/STFT_Transformer"
"ryanwongsa/kaggle-birdsong-recognition" -> "lRomul/argus-freesound"
"musikalkemist/AudioSignalProcessingForML" -> "musikalkemist/DeepLearningForAudioWithPython"
"musikalkemist/AudioSignalProcessingForML" -> "musikalkemist/pytorchforaudio"
"musikalkemist/AudioSignalProcessingForML" -> "musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment"
"musikalkemist/AudioSignalProcessingForML" -> "musikalkemist/generating-sound-with-neural-networks"
"musikalkemist/AudioSignalProcessingForML" -> "iver56/audiomentations" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "seth814/Audio-Classification"
"musikalkemist/AudioSignalProcessingForML" -> "iranroman/musicinformationretrieval.com" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "csteinmetz1/ai-audio-startups" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "wenet-e2e/speech-synthesis-paper" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "YuanGongND/ast"
"musikalkemist/AudioSignalProcessingForML" -> "pytorch/audio" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "jim-schwoebel/voice_datasets" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "musikalkemist/audioDataAugmentationTutorial"
"musikalkemist/AudioSignalProcessingForML" -> "magenta/ddsp" ["e"=1]
"musikalkemist/AudioSignalProcessingForML" -> "qiuqiangkong/audioset_tagging_cnn"
"lucidrains/linear-attention-transformer" -> "OpenNLPLab/cosFormer" ["e"=1]
"hche11/VGGSound" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"hche11/VGGSound" -> "speedyseal/audiosetdl"
"hche11/VGGSound" -> "YapengTian/AVVP-ECCV20"
"hche11/VGGSound" -> "YapengTian/AVE-ECCV18"
"hche11/VGGSound" -> "ardasnck/learning_to_localize_sound_source"
"hche11/VGGSound" -> "GenjiB/LAVISH"
"hche11/VGGSound" -> "krantiparida/awesome-audio-visual"
"hche11/VGGSound" -> "YuanGongND/cav-mae"
"hche11/VGGSound" -> "microsoft/CLAP"
"hche11/VGGSound" -> "XinhaoMei/WavCaps"
"hche11/VGGSound" -> "liuxubo717/LASS"
"hche11/VGGSound" -> "JishengBai/AudioSetCaps"
"hche11/VGGSound" -> "LAION-AI/audio-dataset"
"hche11/VGGSound" -> "GeWu-Lab/awesome-audiovisual-learning"
"hche11/VGGSound" -> "microsoft/WavText5K"
"musikalkemist/generating-melodies-with-rnn-lstm" -> "musikalkemist/generativemusicaicourse"
"musikalkemist/generating-melodies-with-rnn-lstm" -> "musikalkemist/generating-sound-with-neural-networks"
"musikalkemist/generating-melodies-with-rnn-lstm" -> "musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment"
"fgnt/pb_sed" -> "frednam93/FilterAugSED"
"fgnt/pb_sed" -> "DCASE-REPO/DESED_task"
"fgnt/pb_sed" -> "frednam93/FDY-SED"
"fgnt/pb_sed" -> "965694547/Hybrid-system-of-frame-wise-model-and-SEDT"
"fgnt/pb_sed" -> "fgnt/sed_scores_eval"
"fgnt/pb_sed" -> "TUT-ARG/sed_vis"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/AudioSignalProcessingForML"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/pytorchforaudio"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/generating-sound-with-neural-networks"
"musikalkemist/DeepLearningForAudioWithPython" -> "seth814/Audio-Classification"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/generating-melodies-with-rnn-lstm"
"musikalkemist/DeepLearningForAudioWithPython" -> "vbelz/Speech-enhancement" ["e"=1]
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/spotifyplaylistgenerator"
"musikalkemist/DeepLearningForAudioWithPython" -> "iranroman/musicinformationretrieval.com" ["e"=1]
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/audioDataAugmentationTutorial"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/generativemusicaicourse"
"musikalkemist/DeepLearningForAudioWithPython" -> "musikalkemist/praudio"
"musikalkemist/DeepLearningForAudioWithPython" -> "AI-Guru/music-generation-research" ["e"=1]
"musikalkemist/DeepLearningForAudioWithPython" -> "jonnor/machinehearing"
"musikalkemist/DeepLearningForAudioWithPython" -> "iver56/audiomentations" ["e"=1]
"aiXander/Realtime_PyAudio_FFT" -> "justinsalamon/scaper" ["e"=1]
"asteroid-team/torch-audiomentations" -> "facebookresearch/AudioMAE" ["e"=1]
"asteroid-team/torch-audiomentations" -> "YuanGongND/ast" ["e"=1]
"facebookresearch/sound-spaces" -> "pedro-morgado/spatialaudiogen" ["e"=1]
"facebookresearch/sound-spaces" -> "facebookresearch/visual-acoustic-matching" ["e"=1]
"facebookresearch/sound-spaces" -> "facebookresearch/learning-audio-visual-dereverberation" ["e"=1]
"facebookresearch/sound-spaces" -> "SheldonTsui/SepStereo_ECCV2020" ["e"=1]
"spotify/klio" -> "justinsalamon/scaper" ["e"=1]
"rhgao/co-separation" -> "YapengTian/CCOL-CVPR21"
"rhgao/co-separation" -> "rhgao/Deep-MIML-Network"
"rhgao/co-separation" -> "facebookresearch/2.5D-Visual-Sound"
"rhgao/co-separation" -> "ubc-vision/TriBERT"
"rhgao/co-separation" -> "facebookresearch/FAIR-Play"
"rhgao/co-separation" -> "SheldonTsui/SepStereo_ECCV2020"
"rhgao/co-separation" -> "ardasnck/learning_to_localize_sound_source"
"rhgao/co-separation" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"rhgao/co-separation" -> "shvdiwnkozbw/Multi-Source-Sound-Localization"
"facebookresearch/Listen-to-Look" -> "rhgao/co-separation" ["e"=1]
"facebookresearch/Listen-to-Look" -> "facebookresearch/2.5D-Visual-Sound" ["e"=1]
"kamalesh0406/Audio-Classification" -> "mariostrbac/environmental-sound-classification"
"kamalesh0406/Audio-Classification" -> "geekysethi/audio_classification"
"kamalesh0406/Audio-Classification" -> "AndreyGuzhov/ESResNet"
"kamalesh0406/Audio-Classification" -> "ksanjeevan/crnn-audio-classification"
"kamalesh0406/Audio-Classification" -> "sarthak268/Audio_Classification_using_LSTM"
"afourast/avobjects" -> "danmic/av-se" ["e"=1]
"afourast/avobjects" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"afourast/avobjects" -> "ardasnck/learning_to_localize_sound_source"
"afourast/avobjects" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"afourast/avobjects" -> "rhgao/co-separation"
"afourast/avobjects" -> "facebookresearch/2.5D-Visual-Sound"
"afourast/avobjects" -> "facebookresearch/VisualVoice" ["e"=1]
"afourast/avobjects" -> "andrewowens/multisensory"
"joonson/syncnet_trainer" -> "afourast/avobjects" ["e"=1]
"danmic/av-se" -> "afourast/avobjects" ["e"=1]
"YapengTian/AVVP-ECCV20" -> "Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing"
"YapengTian/AVVP-ECCV20" -> "marmot-xy/CMBS"
"YapengTian/AVVP-ECCV20" -> "MCG-NJU/JoMoLD" ["e"=1]
"YapengTian/AVVP-ECCV20" -> "jasongief/PSP_CVPR_2021"
"YapengTian/AVVP-ECCV20" -> "YapengTian/AVE-ECCV18"
"YapengTian/AVVP-ECCV20" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"YapengTian/AVVP-ECCV20" -> "FloretCat/CMRAN"
"YapengTian/AVVP-ECCV20" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"YapengTian/AVVP-ECCV20" -> "ttgeng233/UnAV"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/DeepLearningForAudioWithPython"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/generating-sound-with-neural-networks"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/generating-melodies-with-rnn-lstm"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/pytorchforaudio"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/praudio"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/spotifyplaylistgenerator"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/AudioSignalProcessingForML"
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" -> "musikalkemist/audioDataAugmentationTutorial"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "yinkalario/Sound-Event-Detection-AudioSet"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "qiuqiangkong/panns_inference"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "microsoft/WavText5K"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "DCASE-REPO/DESED_task"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "etzinis/heterogeneous_separation"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "frednam93/FDY-SED"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "haoheliu/diffres-python"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "qiuqiangkong/audioset_tagging_cnn"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "akoepke/audio-retrieval-benchmark"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "Kikyo-16/Sound_event_detection"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "FishMaster93/AFFIA3K"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "qiuqiangkong/panns_transfer_to_gtzan"
"yinkalario/General-Purpose-Sound-Recognition-Demo" -> "turpaultn/DESED"
"SheldonTsui/SepStereo_ECCV2020" -> "SheldonTsui/PseudoBinaural_CVPR2021"
"SheldonTsui/SepStereo_ECCV2020" -> "facebookresearch/2.5D-Visual-Sound"
"SheldonTsui/SepStereo_ECCV2020" -> "pedro-morgado/spatialaudiogen"
"SheldonTsui/SepStereo_ECCV2020" -> "facebookresearch/FAIR-Play"
"shvdiwnkozbw/Multi-Source-Sound-Localization" -> "ardasnck/learning_to_localize_sound_source"
"shvdiwnkozbw/Multi-Source-Sound-Localization" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"shvdiwnkozbw/Multi-Source-Sound-Localization" -> "idiap/nnsslm"
"GAMMA-UMD/doa-release" -> "DavidDiazGuerra/icoDOA" ["e"=1]
"kkoutini/cpjku_dcase20" -> "kkoutini/cpjku_dcase19"
"kkoutini/cpjku_dcase20" -> "MihawkHu/DCASE2020_task1"
"qiuqiangkong/panns_inference" -> "qiuqiangkong/audioset_tagging_cnn"
"qiuqiangkong/panns_inference" -> "yinkalario/General-Purpose-Sound-Recognition-Demo"
"qiuqiangkong/panns_inference" -> "qiuqiangkong/panns_transfer_to_gtzan"
"qiuqiangkong/panns_inference" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"qiuqiangkong/panns_inference" -> "RetroCirce/HTS-Audio-Transformer"
"dr-costas/dnd-sed" -> "dr-costas/SEDLM"
"DavidDiazGuerra/Cross3D" -> "DavidDiazGuerra/icoDOA"
"DavidDiazGuerra/Cross3D" -> "cevers/sap_locata_io"
"emilywg/DCASE2020-Task1" -> "MihawkHu/DCASE2020_task1"
"sharathadavanne/seld-dcase2020" -> "yinkalario/EIN-SELD"
"sharathadavanne/seld-dcase2020" -> "sharathadavanne/seld-dcase2021"
"sharathadavanne/seld-dcase2020" -> "sharathadavanne/seld-dcase2019"
"edufonseca/FSD50K_baseline" -> "SarthakYadav/fsd50k-pytorch"
"yinkalario/Sound-Event-Detection-AudioSet" -> "yinkalario/General-Purpose-Sound-Recognition-Demo"
"cevers/sap_locata_io" -> "cevers/sap_locata_eval"
"cevers/sap_locata_eval" -> "cevers/sap_locata_io"
"bmcfee/muda" -> "MaigoAkisame/cmu-thesis" ["e"=1]
"MihawkHu/DCASE2020_task1" -> "emilywg/DCASE2020-Task1"
"MihawkHu/DCASE2020_task1" -> "toni-heittola/dcase2020_task1_baseline"
"MihawkHu/DCASE2020_task1" -> "kkoutini/cpjku_dcase20"
"MihawkHu/DCASE2020_task1" -> "McDonnell-Lab/DCASE2019-Task1"
"MihawkHu/DCASE2020_task1" -> "MihawkHu/Acoustic_Lottery"
"MihawkHu/DCASE2020_task1" -> "kkoutini/cpjku_dcase19"
"yinkalario/EIN-SELD" -> "sharathadavanne/seld-dcase2021"
"yinkalario/EIN-SELD" -> "danielkrause/DCASE2022-data-generator"
"yinkalario/EIN-SELD" -> "thomeou/SALSA"
"yinkalario/EIN-SELD" -> "sharathadavanne/seld-dcase2022"
"yinkalario/EIN-SELD" -> "Jinbo-Hu/DCASE2022-TASK3"
"yinkalario/EIN-SELD" -> "yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization"
"yinkalario/EIN-SELD" -> "sharathadavanne/seld-dcase2020"
"qiuqiangkong/panns_transfer_to_gtzan" -> "qiuqiangkong/panns_inference"
"qiuqiangkong/panns_transfer_to_gtzan" -> "fgnt/pb_sed"
"qiuqiangkong/panns_transfer_to_gtzan" -> "qiuqiangkong/audioset_tagging_cnn"
"AgaMiko/bird-recognition-review" -> "ryanwongsa/kaggle-birdsong-recognition" ["e"=1]
"turpaultn/dcase20_task4" -> "turpaultn/DESED"
"turpaultn/dcase20_task4" -> "turpaultn/DCASE2019_task4"
"koukyo1994/kaggle-birdcall-6th-place" -> "tattaka/birdclef-2021"
"yeyupiaoling/AudioClassification-Tensorflow" -> "kadoufall/Urban-Sound-Classification-VS"
"TheoViel/kaggle_birdcall_identification" -> "ryanwongsa/kaggle-birdsong-recognition"
"TheoViel/kaggle_birdcall_identification" -> "vlomme/Birdcall-Identification-competition"
"kyuyeonpooh/objects-that-sound" -> "FishMaster93/AFFIA3K"
"audioanalytic/psds_eval" -> "frednam93/FDY-SED"
"audio-captioning/audio-captioning-papers" -> "audio-captioning/audio-captioning-resources"
"audio-captioning/audio-captioning-papers" -> "audio-captioning/dcase-2020-baseline"
"audio-captioning/audio-captioning-papers" -> "XinhaoMei/DCASE2021_task6_v2"
"audio-captioning/audio-captioning-papers" -> "lukewys/dcase_2020_T6"
"audio-captioning/audio-captioning-papers" -> "wsntxxn/AudioCaption"
"vlomme/Birdcall-Identification-competition" -> "ryanwongsa/kaggle-birdsong-recognition"
"DTaoo/Discriminative-Sounding-Objects-Localization" -> "hche11/Localizing-Visual-Sounds-the-Hard-Way"
"DTaoo/Discriminative-Sounding-Objects-Localization" -> "shvdiwnkozbw/Multi-Source-Sound-Localization"
"DTaoo/Discriminative-Sounding-Objects-Localization" -> "YapengTian/AVVP-ECCV20"
"qiuqiangkong/sound_event_detection_dcase2017_task4" -> "qiuqiangkong/autoth"
"Luka0612/ChineseVLBert" -> "wavewangyue/mae"
"fkubota/anima" -> "fkubota/kagglelike-leaderboard"
"fkubota/spectrogram-tree" -> "fkubota/anima"
"fkubota/spectrogram-tree" -> "koukyo1994/kaggle-birdcall-resnet-baseline-training"
"audio-captioning/dcase-2020-baseline" -> "audio-captioning/audio-captioning-papers"
"haltakov/natural-language-image-search" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/AudioClassification-Pytorch" ["e"=1]
"facebookresearch/dora" -> "facebookresearch/flashy"
"facebookresearch/dora" -> "nttcslab/eval-audio-repr"
"karolpiczak/ESC-50" -> "YuanGongND/ast"
"karolpiczak/ESC-50" -> "qiuqiangkong/audioset_tagging_cnn"
"karolpiczak/ESC-50" -> "aqibsaeed/Urban-Sound-Classification"
"karolpiczak/ESC-50" -> "audioset/ontology"
"karolpiczak/ESC-50" -> "RetroCirce/HTS-Audio-Transformer"
"karolpiczak/ESC-50" -> "imfing/audio-classification"
"karolpiczak/ESC-50" -> "microsoft/DNS-Challenge" ["e"=1]
"karolpiczak/ESC-50" -> "iver56/audiomentations" ["e"=1]
"karolpiczak/ESC-50" -> "ksanjeevan/crnn-audio-classification"
"karolpiczak/ESC-50" -> "WenzheLiu-Speech/awesome-speech-enhancement" ["e"=1]
"karolpiczak/ESC-50" -> "karolpiczak/paper-2015-esc-dataset"
"karolpiczak/ESC-50" -> "LCAV/pyroomacoustics" ["e"=1]
"karolpiczak/ESC-50" -> "microsoft/CLAP"
"karolpiczak/ESC-50" -> "yeyupiaoling/AudioClassification-Pytorch"
"karolpiczak/ESC-50" -> "s3prl/s3prl" ["e"=1]
"YuanGongND/ast" -> "YuanGongND/ssast"
"YuanGongND/ast" -> "qiuqiangkong/audioset_tagging_cnn"
"YuanGongND/ast" -> "RetroCirce/HTS-Audio-Transformer"
"YuanGongND/ast" -> "kkoutini/PaSST"
"YuanGongND/ast" -> "facebookresearch/AudioMAE"
"YuanGongND/ast" -> "karolpiczak/ESC-50"
"YuanGongND/ast" -> "iver56/audiomentations" ["e"=1]
"YuanGongND/ast" -> "YuanGongND/psla"
"YuanGongND/ast" -> "asteroid-team/torch-audiomentations" ["e"=1]
"YuanGongND/ast" -> "LAION-AI/CLAP" ["e"=1]
"YuanGongND/ast" -> "YuanGongND/cav-mae"
"YuanGongND/ast" -> "AndreyGuzhov/AudioCLIP"
"YuanGongND/ast" -> "microsoft/CLAP"
"YuanGongND/ast" -> "YuanGongND/ltu" ["e"=1]
"YuanGongND/ast" -> "s3prl/s3prl" ["e"=1]
"facebookresearch/VisualVoice" -> "afourast/avobjects" ["e"=1]
"facebookresearch/VisualVoice" -> "facebookresearch/2.5D-Visual-Sound" ["e"=1]
"TaoRuijie/TalkNet-ASD" -> "afourast/avobjects" ["e"=1]
"google-research/leaf-audio" -> "YuanGongND/ast" ["e"=1]
"google-research/leaf-audio" -> "kkoutini/PaSST" ["e"=1]
"google-research/leaf-audio" -> "qiuqiangkong/audioset_tagging_cnn" ["e"=1]
"SheldonTsui/PseudoBinaural_CVPR2021" -> "SheldonTsui/SepStereo_ECCV2020"
"SheldonTsui/PseudoBinaural_CVPR2021" -> "facebookresearch/2.5D-Visual-Sound"
"SheldonTsui/PseudoBinaural_CVPR2021" -> "facebookresearch/learning-audio-visual-dereverberation"
"Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing" -> "jasongief/PSP_CVPR_2021"
"Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing" -> "YapengTian/AVVP-ECCV20"
"jasongief/PSP_CVPR_2021" -> "FloretCat/CMRAN"
"jasongief/PSP_CVPR_2021" -> "Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing"
"jasongief/PSP_CVPR_2021" -> "marmot-xy/CMBS"
"jasongief/PSP_CVPR_2021" -> "JustinYuu/MM_Pyramid"
"jasongief/PSP_CVPR_2021" -> "YapengTian/AVVP-ECCV20"
"musikalkemist/pytorchforaudio" -> "musikalkemist/DeepLearningForAudioWithPython"
"musikalkemist/pytorchforaudio" -> "musikalkemist/AudioSignalProcessingForML"
"musikalkemist/pytorchforaudio" -> "musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment"
"musikalkemist/pytorchforaudio" -> "kamalesh0406/Audio-Classification"
"xiaobai1217/Awesome-Video-Datasets" -> "krantiparida/awesome-audio-visual" ["e"=1]
"csukuangfj/kaldifeat" -> "RicherMans/Dasheng" ["e"=1]
"AndreyGuzhov/AudioCLIP" -> "descriptinc/lyrebird-wav2clip"
"AndreyGuzhov/AudioCLIP" -> "LAION-AI/CLAP" ["e"=1]
"AndreyGuzhov/AudioCLIP" -> "LAION-AI/audio-dataset"
"AndreyGuzhov/AudioCLIP" -> "microsoft/CLAP"
"AndreyGuzhov/AudioCLIP" -> "YuanGongND/ast"
"AndreyGuzhov/AudioCLIP" -> "researchmm/MM-Diffusion" ["e"=1]
"AndreyGuzhov/AudioCLIP" -> "cdjkim/audiocaps"
"AndreyGuzhov/AudioCLIP" -> "facebookresearch/AudioMAE"
"AndreyGuzhov/AudioCLIP" -> "RetroCirce/HTS-Audio-Transformer"
"AndreyGuzhov/AudioCLIP" -> "YuanGongND/cav-mae"
"AndreyGuzhov/AudioCLIP" -> "v-iashin/SpecVQGAN" ["e"=1]
"AndreyGuzhov/AudioCLIP" -> "hche11/VGGSound"
"AndreyGuzhov/AudioCLIP" -> "microsoft/Pengi" ["e"=1]
"AndreyGuzhov/AudioCLIP" -> "qiuqiangkong/audioset_tagging_cnn"
"AndreyGuzhov/AudioCLIP" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"DCASE-REPO/DESED_task" -> "frednam93/FDY-SED"
"DCASE-REPO/DESED_task" -> "turpaultn/DESED"
"DCASE-REPO/DESED_task" -> "fgnt/pb_sed"
"DCASE-REPO/DESED_task" -> "frednam93/FilterAugSED"
"DCASE-REPO/DESED_task" -> "Audio-WestlakeU/ATST-SED"
"DCASE-REPO/DESED_task" -> "fgnt/sed_scores_eval"
"DCASE-REPO/DESED_task" -> "TUT-ARG/sed_vis"
"DCASE-REPO/DESED_task" -> "cai525/Transformer4SED"
"DCASE-REPO/DESED_task" -> "TUT-ARG/sed_eval"
"DCASE-REPO/DESED_task" -> "MaigoAkisame/cmu-thesis"
"sooftware/conformer" -> "YuanGongND/ast" ["e"=1]
"yingdajun/SpeechEmotionAndPeopleAnalyse" -> "vince9515/SER"
"yeyupiaoling/AudioClassification-Pytorch" -> "yeyupiaoling/VoiceprintRecognition-Pytorch" ["e"=1]
"yeyupiaoling/AudioClassification-Pytorch" -> "yeyupiaoling/AudioClassification-PaddlePaddle" ["e"=1]
"yeyupiaoling/AudioClassification-Pytorch" -> "ksanjeevan/crnn-audio-classification"
"yeyupiaoling/AudioClassification-Pytorch" -> "yeyupiaoling/SpeechEmotionRecognition-Pytorch"
"yeyupiaoling/AudioClassification-Pytorch" -> "TaoRuijie/ECAPA-TDNN" ["e"=1]
"yeyupiaoling/AudioClassification-Pytorch" -> "qiuqiangkong/audioset_tagging_cnn"
"yeyupiaoling/AudioClassification-Pytorch" -> "KingH12138/Pytorch-AudioClassification-master"
"yeyupiaoling/AudioClassification-Pytorch" -> "karolpiczak/ESC-50"
"yeyupiaoling/AudioClassification-Pytorch" -> "kadoufall/Urban-Sound-Classification-VS"
"yeyupiaoling/AudioClassification-Pytorch" -> "YuanGongND/ast"
"yeyupiaoling/AudioClassification-Pytorch" -> "RetroCirce/HTS-Audio-Transformer"
"yeyupiaoling/AudioClassification-Pytorch" -> "yeyupiaoling/AudioClassification-Tensorflow"
"yeyupiaoling/AudioClassification-Pytorch" -> "kamalesh0406/Audio-Classification"
"yeyupiaoling/AudioClassification-Pytorch" -> "harritaylor/torchvggish"
"yeyupiaoling/AudioClassification-Pytorch" -> "Alibaba-MIIL/AudioClassfication"
"karolpiczak/paper-2015-esc-dataset" -> "karolpiczak/paper-2015-esc-convnet"
"pliang279/MultiBench" -> "GeWu-Lab/OGM-GE_CVPR2022" ["e"=1]
"soham97/awesome-sound_event_detection" -> "Audio-WestlakeU/ATST-SED"
"soham97/awesome-sound_event_detection" -> "RetroCirce/HTS-Audio-Transformer"
"soham97/awesome-sound_event_detection" -> "fgnt/pb_sed"
"soham97/awesome-sound_event_detection" -> "robertanto/Real-Time-Sound-Event-Detection"
"soham97/awesome-sound_event_detection" -> "DCASE-REPO/DESED_task"
"soham97/awesome-sound_event_detection" -> "frednam93/FDY-SED"
"soham97/awesome-sound_event_detection" -> "kkoutini/PaSST"
"soham97/awesome-sound_event_detection" -> "turpaultn/DESED"
"soham97/awesome-sound_event_detection" -> "fschmid56/EfficientAT"
"hche11/Localizing-Visual-Sounds-the-Hard-Way" -> "DTaoo/Discriminative-Sounding-Objects-Localization"
"hche11/Localizing-Visual-Sounds-the-Hard-Way" -> "ardasnck/learning_to_localize_sound_source"
"hche11/Localizing-Visual-Sounds-the-Hard-Way" -> "stoneMo/EZ-VSL"
"liuxubo717/cl4ac" -> "liuxubo717/V-ACT"
"liuxubo717/cl4ac" -> "liuxubo717/SimPFs"
"liuxubo717/cl4ac" -> "liuxubo717/LASS-demopage"
"liuxubo717/cl4ac" -> "liuxubo717/sound_generation"
"liuxubo717/cl4ac" -> "liuxubo717/LASS"
"soundata/soundata" -> "justinsalamon/scaper" ["e"=1]
"cfoster0/CLAP" -> "microsoft/WavText5K"
"nussl/nussl" -> "justinsalamon/scaper" ["e"=1]
"liuxubo717/sound_generation" -> "liuxubo717/cl4ac"
"liuxubo717/sound_generation" -> "liuxubo717/V-ACT"
"liuxubo717/sound_generation" -> "liuxubo717/SimPFs"
"liuxubo717/sound_generation" -> "liuxubo717/LASS-demopage"
"liuxubo717/sound_generation" -> "liuxubo717/LASS"
"facebookresearch/EasyComDataset" -> "DavidDiazGuerra/Cross3D"
"facebookresearch/EasyComDataset" -> "facebookresearch/learning-audio-visual-dereverberation"
"c4dm/dcase-few-shot-bioacoustic" -> "yangdongchao/DCASE2021Task5"
"c4dm/dcase-few-shot-bioacoustic" -> "ilyassmoummad/RCL_FS_BSED"
"c4dm/dcase-few-shot-bioacoustic" -> "haoheliu/DCASE_2022_Task_5"
"musikalkemist/generating-sound-with-neural-networks" -> "musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment"
"musikalkemist/generating-sound-with-neural-networks" -> "musikalkemist/generating-melodies-with-rnn-lstm"
"musikalkemist/generating-sound-with-neural-networks" -> "musikalkemist/praudio"
"musikalkemist/generating-sound-with-neural-networks" -> "moiseshorta/MelSpecVAE" ["e"=1]
"nttcslab/byol-a" -> "nttcslab/eval-audio-repr"
"nttcslab/byol-a" -> "edufonseca/uclser20"
"nttcslab/byol-a" -> "Audio-WestlakeU/audiossl"
"baosenguo/Kaggle-MoA-2nd-Place-Solution" -> "guitarmind/kaggle_moa_winner_hungry_for_gold"
"baosenguo/Kaggle-MoA-2nd-Place-Solution" -> "jfpuget/STFT_Transformer"
"baosenguo/Kaggle-MoA-2nd-Place-Solution" -> "senkin13/kaggle" ["e"=1]
"facebookresearch/BinauralSpeechSynthesis" -> "facebookresearch/2.5D-Visual-Sound"
"facebookresearch/BinauralSpeechSynthesis" -> "SheldonTsui/PseudoBinaural_CVPR2021"
"tattaka/birdclef-2021" -> "koukyo1994/kaggle-birdcall-6th-place"
"sharathadavanne/seld-dcase2021" -> "yinkalario/EIN-SELD"
"sharathadavanne/seld-dcase2021" -> "thomeou/SALSA"
"sharathadavanne/seld-dcase2021" -> "danielkrause/DCASE2022-data-generator"
"mariostrbac/environmental-sound-classification" -> "kamalesh0406/Audio-Classification"
"FloretCat/CMRAN" -> "jasongief/PSP_CVPR_2021"
"oncescuandreea/audio-retrieval" -> "akoepke/audio-retrieval-benchmark"
"shkim816/acnn_speaker_recog" -> "shkim816/temporal_dynamic_cnn"
"karolpiczak/paper-2015-esc-convnet" -> "karolpiczak/paper-2015-esc-dataset"
"karolpiczak/paper-2015-esc-convnet" -> "karolpiczak/echonet"
"karolpiczak/paper-2015-esc-convnet" -> "sunits/EnvironmentalSoundClassification"
"SarthakYadav/fsd50k-pytorch" -> "edufonseca/FSD50K_baseline"
"XinhaoMei/DCASE2021_task6_v2" -> "audio-captioning/audio-captioning-resources"
"XinhaoMei/DCASE2021_task6_v2" -> "XinhaoMei/audio-text_retrieval"
"XinhaoMei/DCASE2021_task6_v2" -> "audio-captioning/audio-captioning-papers"
"frednam93/FilterAugSED" -> "frednam93/FDY-SED"
"frednam93/FilterAugSED" -> "fgnt/pb_sed"
"frednam93/FilterAugSED" -> "DCASE-REPO/DESED_task"
"frednam93/FilterAugSED" -> "shkim816/temporal_dynamic_cnn"
"guitarmind/kaggle_moa_winner_hungry_for_gold" -> "baosenguo/Kaggle-MoA-2nd-Place-Solution"
"YapengTian/CCOL-CVPR21" -> "YYX666660/LAVSS"
"audio-captioning/audio-captioning-resources" -> "audio-captioning/audio-captioning-papers"
"audio-captioning/audio-captioning-resources" -> "XinhaoMei/DCASE2021_task6_v2"
"yangdongchao/DCASE2021Task5" -> "haoheliu/DCASE_2022_Task_5"
"XinhaoMei/ACT" -> "XinhaoMei/audio-text_retrieval"
"LAION-AI/CLAP" -> "LAION-AI/audio-dataset" ["e"=1]
"LAION-AI/CLAP" -> "microsoft/CLAP" ["e"=1]
"LAION-AI/CLAP" -> "facebookresearch/AudioMAE" ["e"=1]
"LAION-AI/CLAP" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"RetroCirce/HTS-Audio-Transformer" -> "kkoutini/PaSST"
"RetroCirce/HTS-Audio-Transformer" -> "YuanGongND/ssast"
"RetroCirce/HTS-Audio-Transformer" -> "soham97/awesome-sound_event_detection"
"RetroCirce/HTS-Audio-Transformer" -> "YuanGongND/ast"
"RetroCirce/HTS-Audio-Transformer" -> "microsoft/CLAP"
"RetroCirce/HTS-Audio-Transformer" -> "qiuqiangkong/audioset_tagging_cnn"
"RetroCirce/HTS-Audio-Transformer" -> "Audio-WestlakeU/ATST-SED"
"RetroCirce/HTS-Audio-Transformer" -> "frednam93/FDY-SED"
"RetroCirce/HTS-Audio-Transformer" -> "fschmid56/EfficientAT"
"RetroCirce/HTS-Audio-Transformer" -> "LAION-AI/CLAP" ["e"=1]
"RetroCirce/HTS-Audio-Transformer" -> "turpaultn/DESED"
"RetroCirce/HTS-Audio-Transformer" -> "RetroCirce/Zero_Shot_Audio_Source_Separation" ["e"=1]
"RetroCirce/HTS-Audio-Transformer" -> "facebookresearch/AudioMAE"
"RetroCirce/HTS-Audio-Transformer" -> "XinhaoMei/WavCaps"
"RetroCirce/HTS-Audio-Transformer" -> "YuanGongND/cav-mae"
"lucidrains/x-clip" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"mfrashad/text2art" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"shkim816/temporal_dynamic_cnn" -> "shkim816/acnn_speaker_recog"
"frednam93/FDY-SED" -> "DCASE-REPO/DESED_task"
"frednam93/FDY-SED" -> "frednam93/FilterAugSED"
"frednam93/FDY-SED" -> "turpaultn/DESED"
"frednam93/FDY-SED" -> "frednam93/MDFD-SED"
"frednam93/FDY-SED" -> "fgnt/pb_sed"
"frednam93/FDY-SED" -> "fgnt/sed_scores_eval"
"frednam93/FDY-SED" -> "Audio-WestlakeU/ATST-SED"
"frednam93/FDY-SED" -> "Anaesthesiaye/sound_event_detection_transformer"
"frednam93/FDY-SED" -> "TUT-ARG/sed_vis"
"v-iashin/SpecVQGAN" -> "haoheliu/audioldm_eval" ["e"=1]
"v-iashin/SpecVQGAN" -> "hche11/VGGSound" ["e"=1]
"kkoutini/PaSST" -> "fschmid56/EfficientAT"
"kkoutini/PaSST" -> "RetroCirce/HTS-Audio-Transformer"
"kkoutini/PaSST" -> "YuanGongND/ssast"
"kkoutini/PaSST" -> "YuanGongND/psla"
"kkoutini/PaSST" -> "kkoutini/passt_hear21"
"kkoutini/PaSST" -> "qiuqiangkong/audioset_tagging_cnn"
"kkoutini/PaSST" -> "microsoft/CLAP"
"kkoutini/PaSST" -> "YuanGongND/ast"
"kkoutini/PaSST" -> "facebookresearch/AudioMAE"
"kkoutini/PaSST" -> "DCASE-REPO/DESED_task"
"kkoutini/PaSST" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"kkoutini/PaSST" -> "soham97/awesome-sound_event_detection"
"kkoutini/PaSST" -> "fgnt/pb_sed"
"kkoutini/PaSST" -> "RicherMans/CED"
"kkoutini/PaSST" -> "LAION-AI/audio-dataset"
"fgnt/sed_scores_eval" -> "marmoi/dcase2023_task4b_baseline"
"YuanGongND/psla" -> "kkoutini/PaSST"
"YuanGongND/psla" -> "YuanGongND/ssast"
"YuanGongND/psla" -> "turpaultn/DESED"
"YuanGongND/psla" -> "haoheliu/DCASE_2022_Task_5"
"YuanGongND/psla" -> "fschmid56/EfficientAT"
"RetroCirce/Zero_Shot_Audio_Source_Separation" -> "liuxubo717/LASS" ["e"=1]
"liuxubo717/LASS" -> "liuxubo717/cl4ac"
"liuxubo717/LASS" -> "liuxubo717/sound_generation"
"liuxubo717/LASS" -> "liuxubo717/V-ACT"
"liuxubo717/LASS" -> "liuxubo717/SimPFs"
"liuxubo717/LASS" -> "liuxubo717/LASS-demopage"
"Audio-WestlakeU/audiossl" -> "Audio-WestlakeU/ATST-SED"
"Audio-WestlakeU/audiossl" -> "RicherMans/CED"
"Audio-WestlakeU/audiossl" -> "Audio-WestlakeU/SAR-SSL" ["e"=1]
"AlanBaade/MAE-AST-Public" -> "nttcslab/msm-mae"
"AlanBaade/MAE-AST-Public" -> "WangHelin1997/MaskSpec"
"facebookresearch/av_hubert" -> "krantiparida/awesome-audio-visual" ["e"=1]
"facebookresearch/av_hubert" -> "GeWu-Lab/awesome-audiovisual-learning" ["e"=1]
"facebookresearch/av_hubert" -> "facebookresearch/AudioMAE" ["e"=1]
"descriptinc/lyrebird-wav2clip" -> "AndreyGuzhov/AudioCLIP"
"descriptinc/lyrebird-wav2clip" -> "hche11/VGGSound"
"descriptinc/lyrebird-wav2clip" -> "microsoft/CLAP"
"GeWu-Lab/MUSIC-AVQA" -> "GeWu-Lab/TSPM"
"GeWu-Lab/MUSIC-AVQA" -> "GeWu-Lab/PSTP-Net"
"GeWu-Lab/MUSIC-AVQA" -> "schowdhury671/meerkat"
"GeWu-Lab/MUSIC-AVQA" -> "GeWu-Lab/MWAFM"
"GeWu-Lab/MUSIC-AVQA" -> "ttgeng233/UnAV"
"GeWu-Lab/MUSIC-AVQA" -> "GeWu-Lab/awesome-audiovisual-learning"
"GeWu-Lab/MUSIC-AVQA" -> "HS-YN/PanoAVQA"
"GeWu-Lab/MUSIC-AVQA" -> "GenjiB/LAVISH"
"GeWu-Lab/OGM-GE_CVPR2022" -> "fanyunfeng-bit/Modal-Imbalance-PMR"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/awesome-audiovisual-learning"
"GeWu-Lab/OGM-GE_CVPR2022" -> "QingyangZhang/QMF" ["e"=1]
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/MMPareto_ICML2024"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation" ["e"=1]
"GeWu-Lab/OGM-GE_CVPR2022" -> "Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation"
"GeWu-Lab/OGM-GE_CVPR2022" -> "hche11/VGGSound"
"GeWu-Lab/OGM-GE_CVPR2022" -> "pliang279/MultiBench" ["e"=1]
"GeWu-Lab/OGM-GE_CVPR2022" -> "TencentAILabHealthcare/mmdynamics" ["e"=1]
"GeWu-Lab/OGM-GE_CVPR2022" -> "lihong2303/AGM"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/awesome-balanced-multimodal-learning"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GenjiB/LAVISH"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/MMCosine_ICASSP23"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/BML_TPAMI2024"
"GeWu-Lab/OGM-GE_CVPR2022" -> "GeWu-Lab/MUSIC-AVQA"
"LAION-AI/audio-dataset" -> "LAION-AI/CLAP" ["e"=1]
"LAION-AI/audio-dataset" -> "microsoft/CLAP"
"LAION-AI/audio-dataset" -> "facebookresearch/AudioMAE"
"LAION-AI/audio-dataset" -> "haoheliu/audioldm_eval"
"LAION-AI/audio-dataset" -> "descriptinc/descript-audio-codec" ["e"=1]
"LAION-AI/audio-dataset" -> "archinetai/audio-diffusion-pytorch" ["e"=1]
"LAION-AI/audio-dataset" -> "teticio/audio-diffusion" ["e"=1]
"LAION-AI/audio-dataset" -> "XinhaoMei/WavCaps"
"LAION-AI/audio-dataset" -> "microsoft/Pengi" ["e"=1]
"LAION-AI/audio-dataset" -> "gudgud96/frechet-audio-distance" ["e"=1]
"LAION-AI/audio-dataset" -> "declare-lab/tango" ["e"=1]
"LAION-AI/audio-dataset" -> "yangdongchao/UniAudio" ["e"=1]
"LAION-AI/audio-dataset" -> "AndreyGuzhov/AudioCLIP"
"LAION-AI/audio-dataset" -> "facebookresearch/AudioDec" ["e"=1]
"LAION-AI/audio-dataset" -> "lucidrains/audiolm-pytorch" ["e"=1]
"akoepke/audio-retrieval-benchmark" -> "oncescuandreea/audio-retrieval"
"akoepke/audio-retrieval-benchmark" -> "XinhaoMei/audio-text_retrieval"
"akoepke/audio-retrieval-benchmark" -> "microsoft/WavText5K"
"amsehili/auditok" -> "justinsalamon/scaper" ["e"=1]
"liuxubo717/LASS-demopage" -> "liuxubo717/V-ACT"
"liuxubo717/LASS-demopage" -> "liuxubo717/cl4ac"
"liuxubo717/LASS-demopage" -> "liuxubo717/SimPFs"
"liuxubo717/LASS-demopage" -> "liuxubo717/sound_generation"
"YuanGongND/ssast" -> "YuanGongND/ast"
"YuanGongND/ssast" -> "RetroCirce/HTS-Audio-Transformer"
"YuanGongND/ssast" -> "kkoutini/PaSST"
"YuanGongND/ssast" -> "YuanGongND/psla"
"YuanGongND/ssast" -> "facebookresearch/AudioMAE"
"YuanGongND/ssast" -> "YuanGongND/cav-mae"
"YuanGongND/ssast" -> "Audio-WestlakeU/audiossl"
"YuanGongND/ssast" -> "nttcslab/msm-mae"
"YuanGongND/ssast" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"YuanGongND/ssast" -> "AlanBaade/MAE-AST-Public"
"YuanGongND/ssast" -> "microsoft/Pengi" ["e"=1]
"YuanGongND/ssast" -> "hche11/VGGSound"
"YuanGongND/ssast" -> "nttcslab/m2d"
"YuanGongND/ssast" -> "microsoft/CLAP"
"YuanGongND/ssast" -> "soham97/awesome-sound_event_detection"
"marmot-xy/CMBS" -> "jasongief/PSP_CVPR_2021"
"marmot-xy/CMBS" -> "YapengTian/AVVP-ECCV20"
"marmot-xy/CMBS" -> "FloretCat/CMRAN"
"Anaesthesiaye/sound_event_detection_transformer" -> "965694547/Hybrid-system-of-frame-wise-model-and-SEDT"
"XinhaoMei/audio-text_retrieval" -> "akoepke/audio-retrieval-benchmark"
"XinhaoMei/audio-text_retrieval" -> "microsoft/WavText5K"
"XinhaoMei/audio-text_retrieval" -> "XinhaoMei/DCASE2021_task6_v2"
"danielkrause/DCASE2022-data-generator" -> "sony/audio-visual-seld-dcase2023"
"danielkrause/DCASE2022-data-generator" -> "Jinbo-Hu/L3DAS22-TASK2"
"danielkrause/DCASE2022-data-generator" -> "sharathadavanne/seld-dcase2022"
"danielkrause/DCASE2022-data-generator" -> "marl/SpatialScaper"
"stoneMo/EZ-VSL" -> "stoneMo/SLAVC"
"stoneMo/EZ-VSL" -> "stoneMo/AVGN"
"stoneMo/EZ-VSL" -> "OpenNLPLab/FNAC_AVL"
"hxixixh/mix-and-localize" -> "stoneMo/SLAVC"
"DavidDiazGuerra/icoCNN" -> "DavidDiazGuerra/icoDOA"
"DavidDiazGuerra/icoDOA" -> "DavidDiazGuerra/icoCNN"
"nttcslab/msm-mae" -> "AlanBaade/MAE-AST-Public"
"nttcslab/msm-mae" -> "WangHelin1997/MaskSpec"
"thomeou/SALSA" -> "sharathadavanne/seld-dcase2021"
"thomeou/SALSA" -> "yinkalario/EIN-SELD"
"thomeou/SALSA" -> "danielkrause/DCASE2022-data-generator"
"thomeou/SALSA" -> "sharathadavanne/seld-dcase2023"
"thomeou/SALSA" -> "sharathadavanne/seld-dcase2022"
"thomeou/SALSA" -> "sony/audio-visual-seld-dcase2023"
"thomeou/SALSA" -> "Jinbo-Hu/DCASE2022-TASK3"
"thomeou/SALSA" -> "thomeou/SALSA-Lite"
"sharathadavanne/seld-dcase2022" -> "danielkrause/DCASE2022-data-generator"
"sharathadavanne/seld-dcase2022" -> "Jinbo-Hu/DCASE2022-TASK3"
"sharathadavanne/seld-dcase2022" -> "yinkalario/EIN-SELD"
"sharathadavanne/seld-dcase2022" -> "thomeou/SALSA"
"sharathadavanne/seld-dcase2022" -> "sony/audio-visual-seld-dcase2023"
"sharathadavanne/seld-dcase2022" -> "marl/SpatialScaper"
"sharathadavanne/seld-dcase2022" -> "sharathadavanne/seld-dcase2021"
"Labbeti/aac-datasets" -> "microsoft/WavText5K"
"Labbeti/aac-datasets" -> "haoheliu/diffres-python"
"Labbeti/aac-datasets" -> "FishMaster93/AFFIA3K"
"Labbeti/aac-datasets" -> "wsntxxn/TextToAudioGrounding"
"Labbeti/aac-datasets" -> "XinhaoMei/audio-text_retrieval"
"Labbeti/aac-datasets" -> "XinhaoMei/WavCaps"
"OpenNLPLab/cosFormer" -> "davidsvy/cosformer-pytorch"
"OpenNLPLab/cosFormer" -> "OpenNLPLab/Tnn"
"OpenNLPLab/cosFormer" -> "OpenNLPLab/Transnormer"
"martinsbruveris/tensorflow-image-models" -> "ryanwongsa/kaggle-birdsong-recognition" ["e"=1]
"etzinis/heterogeneous_separation" -> "FishMaster93/AFFIA3K"
"nttcslab/eval-audio-repr" -> "nttcslab/m2d"
"archinetai/audio-diffusion-pytorch" -> "LAION-AI/audio-dataset" ["e"=1]
"fschmid56/EfficientAT" -> "kkoutini/PaSST"
"fschmid56/EfficientAT" -> "RicherMans/CED"
"fschmid56/EfficientAT" -> "fschmid56/EfficientAT_HEAR"
"fschmid56/EfficientAT" -> "RetroCirce/HTS-Audio-Transformer"
"fschmid56/EfficientAT" -> "YuanGongND/psla"
"fschmid56/EfficientAT" -> "Alibaba-MIIL/AudioClassfication"
"fschmid56/EfficientAT" -> "fschmid56/cpjku_dcase23"
"fschmid56/EfficientAT" -> "soham97/awesome-sound_event_detection"
"fschmid56/EfficientAT" -> "Audio-WestlakeU/audiossl"
"fschmid56/EfficientAT" -> "YuanGongND/cav-mae"
"fschmid56/EfficientAT" -> "Audio-WestlakeU/ATST-SED"
"fschmid56/EfficientAT" -> "qiuqiangkong/audioset_tagging_cnn"
"haoheliu/audioldm_eval" -> "haoheliu/AudioLDM-training-finetuning" ["e"=1]
"haoheliu/audioldm_eval" -> "microsoft/CLAP"
"haoheliu/audioldm_eval" -> "gudgud96/frechet-audio-distance" ["e"=1]
"haoheliu/audioldm_eval" -> "XinhaoMei/WavCaps"
"haoheliu/audioldm_eval" -> "LAION-AI/audio-dataset"
"haoheliu/audioldm_eval" -> "luosiallen/Diff-Foley" ["e"=1]
"haoheliu/audioldm_eval" -> "Stability-AI/stable-audio-metrics" ["e"=1]
"haoheliu/audioldm_eval" -> "LAION-AI/CLAP" ["e"=1]
"haoheliu/audioldm_eval" -> "haoheliu/AudioLDM" ["e"=1]
"haoheliu/audioldm_eval" -> "v-iashin/SpecVQGAN" ["e"=1]
"haoheliu/audioldm_eval" -> "happylittlecat2333/Auffusion" ["e"=1]
"haoheliu/audioldm_eval" -> "Labbeti/aac-datasets"
"haoheliu/audioldm_eval" -> "facebookresearch/AudioMAE"
"haoheliu/audioldm_eval" -> "bytedance/Make-An-Audio-2" ["e"=1]
"haoheliu/audioldm_eval" -> "yangdongchao/UniAudio" ["e"=1]
"Yuan-ManX/ai-audio-datasets" -> "LAION-AI/audio-dataset" ["e"=1]
"nttcslab/m2d" -> "nttcslab/eval-audio-repr"
"nttcslab/m2d" -> "Audio-WestlakeU/audiossl"
"lucidrains/musiclm-pytorch" -> "LAION-AI/audio-dataset" ["e"=1]
"haoheliu/AudioLDM" -> "haoheliu/audioldm_eval" ["e"=1]
"thuml/Flowformer" -> "OpenNLPLab/cosFormer" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Renovamen/Speech-Emotion-Recognition" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "yingdajun/SpeechEmotionAndPeopleAnalyse"
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Vincent-ZHQ/CA-MSER" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "yeyupiaoling/SpeechEmotionRecognition-PaddlePaddle"
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Jiaxin-Ye/TIM-Net_SER" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "yeyupiaoling/AudioClassification-Pytorch"
"TaoRuijie/Loss-Gated-Learning" -> "shkim816/temporal_dynamic_cnn" ["e"=1]
"liuxubo717/SimPFs" -> "liuxubo717/cl4ac"
"liuxubo717/SimPFs" -> "liuxubo717/V-ACT"
"liuxubo717/SimPFs" -> "liuxubo717/LASS-demopage"
"liuxubo717/SimPFs" -> "liuxubo717/sound_generation"
"liuxubo717/SimPFs" -> "liuxubo717/LASS"
"TUT-ARG/sed_eval" -> "TUT-ARG/sed_vis"
"TUT-ARG/sed_eval" -> "TUT-ARG/DCASE2017-baseline-system"
"TUT-ARG/sed_eval" -> "ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars"
"TUT-ARG/sed_eval" -> "MaigoAkisame/cmu-thesis"
"TUT-ARG/sed_eval" -> "sharathadavanne/sed-crnn"
"TUT-ARG/sed_eval" -> "DCASE-REPO/DESED_task"
"TUT-ARG/sed_eval" -> "DCASE-REPO/dcase2018_baseline"
"TUT-ARG/sed_eval" -> "Kikyo-16/Sound_event_detection"
"TUT-ARG/sed_eval" -> "DCASE-REPO/dcase_util"
"TUT-ARG/sed_eval" -> "fgnt/sed_scores_eval"
"GeWu-Lab/awesome-audiovisual-learning" -> "GenjiB/LAVISH"
"GeWu-Lab/awesome-audiovisual-learning" -> "GeWu-Lab/MUSIC-AVQA"
"GeWu-Lab/awesome-audiovisual-learning" -> "krantiparida/awesome-audio-visual"
"GeWu-Lab/awesome-audiovisual-learning" -> "GeWu-Lab/OGM-GE_CVPR2022"
"GeWu-Lab/awesome-audiovisual-learning" -> "joannahong/AV-RelScore" ["e"=1]
"GeWu-Lab/awesome-audiovisual-learning" -> "marmot-xy/CMBS"
"GeWu-Lab/awesome-audiovisual-learning" -> "GeWu-Lab/CSOL_TPAMI2021"
"GeWu-Lab/awesome-audiovisual-learning" -> "YapengTian/AVVP-ECCV20"
"GeWu-Lab/awesome-audiovisual-learning" -> "YuanGongND/cav-mae"
"GeWu-Lab/awesome-audiovisual-learning" -> "hche11/VGGSound"
"GeWu-Lab/awesome-audiovisual-learning" -> "GeWu-Lab/Ref-AVS" ["e"=1]
"GeWu-Lab/awesome-audiovisual-learning" -> "ttgeng233/UnAV"
"GeWu-Lab/awesome-audiovisual-learning" -> "burchim/AVEC" ["e"=1]
"GeWu-Lab/awesome-audiovisual-learning" -> "OpenNLPLab/AVSBench" ["e"=1]
"GeWu-Lab/awesome-audiovisual-learning" -> "facebookresearch/av_hubert" ["e"=1]
"jxzly/Kaggle-American-Express-Default-Prediction-1st-solution" -> "baosenguo/Kaggle-MoA-2nd-Place-Solution" ["e"=1]
"GenjiB/LAVISH" -> "GeWu-Lab/awesome-audiovisual-learning"
"GenjiB/LAVISH" -> "GeWu-Lab/MUSIC-AVQA"
"GenjiB/LAVISH" -> "haoyi-duan/DG-SCT"
"GenjiB/LAVISH" -> "cyh-0/CAVP"
"GenjiB/LAVISH" -> "YuanGongND/cav-mae"
"microsoft/CLAP" -> "LAION-AI/CLAP" ["e"=1]
"microsoft/CLAP" -> "LAION-AI/audio-dataset"
"microsoft/CLAP" -> "YuanGongND/ltu" ["e"=1]
"microsoft/CLAP" -> "haoheliu/audioldm_eval"
"microsoft/CLAP" -> "microsoft/Pengi" ["e"=1]
"microsoft/CLAP" -> "facebookresearch/audiobox-aesthetics" ["e"=1]
"microsoft/CLAP" -> "RetroCirce/HTS-Audio-Transformer"
"microsoft/CLAP" -> "facebookresearch/AudioMAE"
"microsoft/CLAP" -> "kkoutini/PaSST"
"microsoft/CLAP" -> "descriptinc/descript-audio-codec" ["e"=1]
"microsoft/CLAP" -> "XinhaoMei/WavCaps"
"microsoft/CLAP" -> "hche11/VGGSound"
"microsoft/CLAP" -> "AndreyGuzhov/AudioCLIP"
"microsoft/CLAP" -> "cdjkim/audiocaps"
"microsoft/CLAP" -> "facebookresearch/AudioDec" ["e"=1]
"TXH-mercury/VALOR" -> "LAION-AI/audio-dataset" ["e"=1]
"TXH-mercury/VALOR" -> "GeWu-Lab/MUSIC-AVQA" ["e"=1]
"TXH-mercury/VALOR" -> "GenjiB/LAVISH" ["e"=1]
"gudgud96/frechet-audio-distance" -> "haoheliu/audioldm_eval" ["e"=1]
"liuxubo717/V-ACT" -> "liuxubo717/LASS-demopage"
"liuxubo717/V-ACT" -> "liuxubo717/cl4ac"
"liuxubo717/V-ACT" -> "liuxubo717/SimPFs"
"liuxubo717/V-ACT" -> "liuxubo717/sound_generation"
"liuxubo717/V-ACT" -> "liuxubo717/LASS"
"researchmm/MM-Diffusion" -> "cdjkim/audiocaps" ["e"=1]
"researchmm/MM-Diffusion" -> "AndreyGuzhov/AudioCLIP" ["e"=1]
"kylemcdonald/AudioNotebooks" -> "aqibsaeed/Urban-Sound-Classification" ["e"=1]
"OpenNLPLab/FAVDBench" -> "OpenNLPLab/Tnn"
"OpenNLPLab/FAVDBench" -> "OpenNLPLab/Transnormer"
"teticio/audio-diffusion" -> "LAION-AI/audio-dataset" ["e"=1]
"lihanghang/Deep-learning-And-Paper" -> "yingdajun/SpeechEmotionAndPeopleAnalyse"
"facebookresearch/AudioMAE" -> "LAION-AI/audio-dataset"
"facebookresearch/AudioMAE" -> "YuanGongND/ssast"
"facebookresearch/AudioMAE" -> "LAION-AI/CLAP" ["e"=1]
"facebookresearch/AudioMAE" -> "YuanGongND/cav-mae"
"facebookresearch/AudioMAE" -> "microsoft/CLAP"
"facebookresearch/AudioMAE" -> "microsoft/Pengi" ["e"=1]
"facebookresearch/AudioMAE" -> "YuanGongND/ast"
"facebookresearch/AudioMAE" -> "YuanGongND/ltu" ["e"=1]
"facebookresearch/AudioMAE" -> "kkoutini/PaSST"
"facebookresearch/AudioMAE" -> "nttcslab/msm-mae"
"facebookresearch/AudioMAE" -> "XinhaoMei/WavCaps"
"facebookresearch/AudioMAE" -> "facebookresearch/AudioDec" ["e"=1]
"facebookresearch/AudioMAE" -> "asteroid-team/torch-audiomentations" ["e"=1]
"facebookresearch/AudioMAE" -> "haoheliu/audioldm_eval"
"facebookresearch/AudioMAE" -> "descriptinc/descript-audio-codec" ["e"=1]
"lucidrains/zorro-pytorch" -> "YuanGongND/uavm"
"TUT-ARG/sed_vis" -> "TUT-ARG/sed_eval"
"TUT-ARG/sed_vis" -> "fgnt/pb_sed"
"TUT-ARG/sed_vis" -> "frednam93/FDY-SED"
"TUT-ARG/sed_vis" -> "DCASE-REPO/DESED_task"
"TUT-ARG/sed_vis" -> "turpaultn/DESED"
"TUT-ARG/sed_vis" -> "sharathadavanne/sed-crnn"
"stoneMo/SLAVC" -> "hxixixh/mix-and-localize"
"stoneMo/SLAVC" -> "stoneMo/EZ-VSL"
"stoneMo/SLAVC" -> "OpenNLPLab/FNAC_AVL"
"justinsalamon/scaper" -> "turpaultn/DESED"
"justinsalamon/scaper" -> "DCASE-REPO/DESED_task"
"justinsalamon/scaper" -> "sharathadavanne/sed-crnn"
"justinsalamon/scaper" -> "nussl/nussl" ["e"=1]
"justinsalamon/scaper" -> "frednam93/FDY-SED"
"justinsalamon/scaper" -> "Spijkervet/CLMR" ["e"=1]
"justinsalamon/scaper" -> "soundata/soundata" ["e"=1]
"justinsalamon/scaper" -> "marl/openl3"
"justinsalamon/scaper" -> "mir-dataset-loaders/mirdata" ["e"=1]
"justinsalamon/scaper" -> "Kikyo-16/Sound_event_detection"
"justinsalamon/scaper" -> "audioset/ontology"
"justinsalamon/scaper" -> "csteinmetz1/pyloudnorm" ["e"=1]
"justinsalamon/scaper" -> "csteinmetz1/auraloss" ["e"=1]
"justinsalamon/scaper" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"justinsalamon/scaper" -> "KinWaiCheuk/nnAudio" ["e"=1]
"Jinbo-Hu/DCASE2022-TASK3" -> "axeber01/ngcc-seld"
"microsoft/WavText5K" -> "FishMaster93/AFFIA3K"
"microsoft/WavText5K" -> "etzinis/heterogeneous_separation"
"microsoft/WavText5K" -> "haoheliu/diffres-python"
"microsoft/WavText5K" -> "XinhaoMei/audio-text_retrieval"
"hqsiswiliam/persona-adaptive-attention" -> "FishMaster93/AFFIA3K"
"OpenNLPLab/Transnormer" -> "OpenNLPLab/Tnn"
"OpenNLPLab/Transnormer" -> "OpenNLPLab/FNAC_AVL"
"OpenNLPLab/Transnormer" -> "OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion"
"OpenNLPLab/Transnormer" -> "OpenNLPLab/Vicinity-Vision-Transformer"
"facebookresearch/visual-acoustic-matching" -> "facebookresearch/learning-audio-visual-dereverberation"
"facebookresearch/visual-acoustic-matching" -> "facebookresearch/novel-view-acoustic-synthesis"
"YYX666660/LAVSS" -> "YapengTian/CCOL-CVPR21"
"TUT-ARG/DCASE2016-baseline-system-python" -> "gorinars/dcase16-cnn"
"TUT-ARG/DCASE2016-baseline-system-python" -> "TUT-ARG/DCASE2017-baseline-system"
"TUT-ARG/DCASE2016-baseline-system-python" -> "TUT-ARG/DCASE2016-baseline-system-matlab"
"haoheliu/diffres-python" -> "FishMaster93/AFFIA3K"
"haoheliu/diffres-python" -> "microsoft/WavText5K"
"OpenNLPLab/Tnn" -> "OpenNLPLab/Transnormer"
"OpenNLPLab/Tnn" -> "Doraemonzzz/tnn-pytorch"
"OpenNLPLab/Tnn" -> "OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion"
"OpenNLPLab/Tnn" -> "OpenNLPLab/FNAC_AVL"
"OpenNLPLab/Tnn" -> "OpenNLPLab/FAVDBench"
"facebookresearch/learning-audio-visual-dereverberation" -> "facebookresearch/visual-acoustic-matching"
"haoheliu/DCASE_2022_Task_5" -> "yangdongchao/DCASE2021Task5"
"haoheliu/AudioLDM-training-finetuning" -> "haoheliu/audioldm_eval" ["e"=1]
"haoheliu/AudioLDM-training-finetuning" -> "XinhaoMei/WavCaps" ["e"=1]
"haoheliu/AudioLDM-training-finetuning" -> "cwx-worst-one/EAT" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "facebookresearch/AudioMAE" ["e"=1]
"OFA-Sys/ONE-PEACE" -> "LAION-AI/audio-dataset" ["e"=1]
"seungheondoh/lp-music-caps" -> "XinhaoMei/WavCaps" ["e"=1]
"Audio-AGI/WavJourney" -> "LAION-AI/audio-dataset" ["e"=1]
"Audio-AGI/WavJourney" -> "microsoft/CLAP" ["e"=1]
"fschmid56/cpjku_dcase23" -> "fschmid56/EfficientAT_HEAR"
"facebookresearch/SONAR" -> "LAION-AI/audio-dataset" ["e"=1]
"declare-lab/tango" -> "LAION-AI/audio-dataset" ["e"=1]
"declare-lab/tango" -> "haoheliu/audioldm_eval" ["e"=1]
"declare-lab/tango" -> "facebookresearch/AudioMAE" ["e"=1]
"RicherMans/CED" -> "RicherMans/Dasheng"
"RicherMans/CED" -> "XiaoMi/dasheng"
"RicherMans/CED" -> "JishengBai/ICME2024ASC"
"RicherMans/CED" -> "cwx-worst-one/EAT"
"RicherMans/CED" -> "Audio-WestlakeU/audiossl"
"RicherMans/CED" -> "RicherMans/SAT"
"Audio-WestlakeU/ATST-SED" -> "Audio-WestlakeU/audiossl"
"Audio-WestlakeU/ATST-SED" -> "fschmid56/PretrainedSED"
"Audio-WestlakeU/ATST-SED" -> "cai525/Transformer4SED"
"Audio-WestlakeU/ATST-SED" -> "frednam93/MDFD-SED"
"Audio-WestlakeU/ATST-SED" -> "turpaultn/DESED"
"Audio-WestlakeU/ATST-SED" -> "CPJKU/cpjku_dcase24"
"Audio-WestlakeU/ATST-SED" -> "frednam93/FDY-SED"
"Audio-WestlakeU/ATST-SED" -> "DCASE-REPO/DESED_task"
"Audio-WestlakeU/ATST-SED" -> "soham97/awesome-sound_event_detection"
"Audio-WestlakeU/ATST-SED" -> "RicherMans/CED"
"Audio-WestlakeU/ATST-SED" -> "fgnt/sed_scores_eval"
"audioset/ontology" -> "qiuqiangkong/audioset_classification"
"audioset/ontology" -> "unixpickle/audioset"
"audioset/ontology" -> "justinsalamon/scaper"
"audioset/ontology" -> "karolpiczak/ESC-50"
"audioset/ontology" -> "turpaultn/DESED"
"audioset/ontology" -> "marl/audiosetdl"
"audioset/ontology" -> "jordipons/musicnn" ["e"=1]
"audioset/ontology" -> "MaigoAkisame/cmu-thesis"
"audioset/ontology" -> "DCASE-REPO/DESED_task"
"audioset/ontology" -> "RetroCirce/HTS-Audio-Transformer"
"audioset/ontology" -> "marl/openl3"
"audioset/ontology" -> "TUT-ARG/sed_eval"
"audioset/ontology" -> "qiuqiangkong/audioset_tagging_cnn"
"audioset/ontology" -> "yongxuUSTC/dcase2017_task4_cvssp"
"audioset/ontology" -> "yinkalario/General-Purpose-Sound-Recognition-Demo"
"Jakobovski/free-spoken-digit-dataset" -> "karolpiczak/ESC-50" ["e"=1]
"aqibsaeed/Urban-Sound-Classification" -> "karolpiczak/paper-2015-esc-convnet"
"aqibsaeed/Urban-Sound-Classification" -> "ksanjeevan/crnn-audio-classification"
"aqibsaeed/Urban-Sound-Classification" -> "karolpiczak/ESC-50"
"aqibsaeed/Urban-Sound-Classification" -> "imfing/audio-classification"
"aqibsaeed/Urban-Sound-Classification" -> "drscotthawley/panotti"
"aqibsaeed/Urban-Sound-Classification" -> "jaron/deep-listening"
"aqibsaeed/Urban-Sound-Classification" -> "karolpiczak/paper-2015-esc-dataset"
"aqibsaeed/Urban-Sound-Classification" -> "yongxuUSTC/dcase2017_task4_cvssp"
"aqibsaeed/Urban-Sound-Classification" -> "sarthak268/Audio_Classification_using_LSTM"
"aqibsaeed/Urban-Sound-Classification" -> "sharathadavanne/sed-crnn"
"aqibsaeed/Urban-Sound-Classification" -> "rednafi/urban-sound-classification"
"aqibsaeed/Urban-Sound-Classification" -> "seth814/Audio-Classification"
"aqibsaeed/Urban-Sound-Classification" -> "micah5/pyAudioClassification"
"aqibsaeed/Urban-Sound-Classification" -> "awjuliani/sound-cnn"
"aqibsaeed/Urban-Sound-Classification" -> "BenjaminDoran/Urban-Sound-Classification"
"ttgeng233/UnAV" -> "ttgeng233/UniAV"
"ttgeng233/UnAV" -> "ttgeng233/LongVALE"
"ttgeng233/UnAV" -> "Franklin905/VALOR"
"ttgeng233/UnAV" -> "MengyuanChen21/CVPR2023-CMPAE" ["e"=1]
"ttgeng233/UnAV" -> "marmot-xy/CMBS"
"ttgeng233/UnAV" -> "schowdhury671/meerkat"
"YiLunLee/missing_aware_prompts" -> "Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" ["e"=1]
"XinhaoMei/WavCaps" -> "cdjkim/audiocaps"
"XinhaoMei/WavCaps" -> "JishengBai/AudioSetCaps"
"XinhaoMei/WavCaps" -> "XinhaoMei/ACT"
"XinhaoMei/WavCaps" -> "Labbeti/aac-datasets"
"XinhaoMei/WavCaps" -> "haoheliu/AudioLDM-training-finetuning" ["e"=1]
"XinhaoMei/WavCaps" -> "haoheliu/audioldm_eval"
"XinhaoMei/WavCaps" -> "YuanGongND/ltu" ["e"=1]
"XinhaoMei/WavCaps" -> "XinhaoMei/DCASE2021_task6_v2"
"XinhaoMei/WavCaps" -> "XinhaoMei/audio-text_retrieval"
"XinhaoMei/WavCaps" -> "audio-captioning/audio-captioning-papers"
"TXH-mercury/VAST" -> "XinhaoMei/WavCaps" ["e"=1]
"TXH-mercury/VAST" -> "YuanGongND/cav-mae" ["e"=1]
"Audio-AGI/AudioSep" -> "microsoft/CLAP" ["e"=1]
"sony/audio-visual-seld-dcase2023" -> "danielkrause/DCASE2022-data-generator"
"sony/audio-visual-seld-dcase2023" -> "partha2409/DCASE2024_seld_baseline"
"sony/audio-visual-seld-dcase2023" -> "sharathadavanne/seld-dcase2023"
"sony/audio-visual-seld-dcase2023" -> "marl/SpatialScaper"
"sony/audio-visual-seld-dcase2023" -> "Jinbo-Hu/DCASE2022-TASK3"
"marl/SpatialScaper" -> "danielkrause/DCASE2022-data-generator"
"marl/SpatialScaper" -> "sony/audio-visual-seld-dcase2023"
"marl/SpatialScaper" -> "partha2409/DCASE2024_seld_baseline"
"marl/SpatialScaper" -> "axeber01/ngcc-seld"
"marl/SpatialScaper" -> "sharathadavanne/seld-dcase2023"
"marl/SpatialScaper" -> "sakshamsingh1/sound_distance_estimation"
"marl/SpatialScaper" -> "sharathadavanne/seld-dcase2022"
"YuanGongND/whisper-at" -> "YuanGongND/cav-mae" ["e"=1]
"YuanGongND/whisper-at" -> "YuanGongND/ssast" ["e"=1]
"YuanGongND/whisper-at" -> "microsoft/CLAP" ["e"=1]
"keunwoochoi/music-auto_tagging-keras" -> "drscotthawley/audio-classifier-keras-cnn" ["e"=1]
"OpenNLPLab/TransnormerLLM" -> "OpenNLPLab/Transnormer"
"OpenNLPLab/TransnormerLLM" -> "OpenNLPLab/lightning-attention"
"OpenNLPLab/TransnormerLLM" -> "OpenNLPLab/Tnn"
"OpenNLPLab/TransnormerLLM" -> "OpenNLPLab/HGRN2"
"OpenNLPLab/TransnormerLLM" -> "OpenNLPLab/LASP"
"gorinars/dcase16-cnn" -> "TUT-ARG/DCASE2016-baseline-system-python"
"microsoft/Pengi" -> "microsoft/CLAP" ["e"=1]
"microsoft/Pengi" -> "facebookresearch/AudioMAE" ["e"=1]
"microsoft/Pengi" -> "XinhaoMei/WavCaps" ["e"=1]
"YuanGongND/ltu" -> "microsoft/CLAP" ["e"=1]
"YuanGongND/ltu" -> "XinhaoMei/WavCaps" ["e"=1]
"YuanGongND/ltu" -> "facebookresearch/AudioMAE" ["e"=1]
"YuanGongND/cav-mae" -> "YuanGongND/uavm"
"YuanGongND/cav-mae" -> "GenjiB/LAVISH"
"YuanGongND/cav-mae" -> "facebookresearch/AudioMAE"
"YuanGongND/cav-mae" -> "YuanGongND/ssast"
"YuanGongND/cav-mae" -> "GeWu-Lab/awesome-audiovisual-learning"
"YuanGongND/cav-mae" -> "hche11/VGGSound"
"YuanGongND/cav-mae" -> "luosiallen/Diff-Foley" ["e"=1]
"YuanGongND/cav-mae" -> "stoneMo/DeepAVFusion"
"YuanGongND/cav-mae" -> "LAION-AI/audio-dataset"
"YuanGongND/cav-mae" -> "RetroCirce/HTS-Audio-Transformer"
"YuanGongND/cav-mae" -> "YuanGongND/ast"
"facebookresearch/replay_dataset" -> "facebookresearch/novel-view-acoustic-synthesis"
"luosiallen/Diff-Foley" -> "haoheliu/audioldm_eval" ["e"=1]
"OpenNLPLab/FNAC_AVL" -> "stoneMo/SLAVC"
"stoneMo/AVGN" -> "stoneMo/SLAVC"
"stoneMo/AVGN" -> "stoneMo/EZ-VSL"
"stoneMo/AVGN" -> "OpenNLPLab/FNAC_AVL"
"RicherMans/SAT" -> "RicherMans/PSL"
"GeWu-Lab/MWAFM" -> "GeWu-Lab/PSTP-Net"
"sharathadavanne/seld-dcase2023" -> "sony/audio-visual-seld-dcase2023"
"sharathadavanne/seld-dcase2023" -> "partha2409/DCASE2024_seld_baseline"
"sharathadavanne/seld-dcase2023" -> "danielkrause/DCASE2022-data-generator"
"sharathadavanne/seld-dcase2023" -> "thomeou/SALSA"
"sharathadavanne/seld-dcase2023" -> "marl/SpatialScaper"
"facebookresearch/novel-view-acoustic-synthesis" -> "facebookresearch/replay_dataset"
"GeWu-Lab/PSTP-Net" -> "GeWu-Lab/TSPM"
"GeWu-Lab/PSTP-Net" -> "GeWu-Lab/MWAFM"
"FishMaster93/U-FFIA" -> "FishMaster93/AFFIA3K"
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" -> "GeWu-Lab/awesome-balanced-multimodal-learning"
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" -> "Haoyu-ha/LNLN" ["e"=1]
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" -> "Cecile-hi/Radian-Weight-Modification" ["e"=1]
"despoisj/DeepAudioClassification" -> "seth814/Audio-Classification" ["e"=1]
"despoisj/DeepAudioClassification" -> "ksanjeevan/crnn-audio-classification" ["e"=1]
"despoisj/DeepAudioClassification" -> "imfing/audio-classification" ["e"=1]
"OpenNLPLab/lightning-attention" -> "OpenNLPLab/TransnormerLLM"
"OpenNLPLab/lightning-attention" -> "OpenNLPLab/LASP"
"XuezheMax/megalodon" -> "OpenNLPLab/lightning-attention" ["e"=1]
"cwx-worst-one/EAT" -> "RicherMans/CED"
"cwx-worst-one/EAT" -> "tencent-ailab/MuQ" ["e"=1]
"cvondrick/soundnet" -> "eborboihuc/SoundNet-tensorflow"
"cvondrick/soundnet" -> "ardasnck/learning_to_localize_sound_source"
"cvondrick/soundnet" -> "marl/audiosetdl"
"cvondrick/soundnet" -> "afourast/avobjects"
"cvondrick/soundnet" -> "keunhong/pytorch-soundnet"
"cvondrick/soundnet" -> "hangzhaomit/Sound-of-Pixels"
"cvondrick/soundnet" -> "xiaolonw/ss-gan" ["e"=1]
"cvondrick/soundnet" -> "qiuqiangkong/audioset_classification"
"cvondrick/soundnet" -> "andrewowens/multisensory"
"cvondrick/soundnet" -> "Guim3/IcGAN" ["e"=1]
"cvondrick/soundnet" -> "audioset/ontology"
"cvondrick/soundnet" -> "cvondrick/videogan" ["e"=1]
"cvondrick/soundnet" -> "kimiyoung/review_net" ["e"=1]
"cvondrick/soundnet" -> "facebookarchive/eyescream" ["e"=1]
"cvondrick/soundnet" -> "reedscot/nips2016" ["e"=1]
"rikeilong/Bay-CAT" -> "schowdhury671/meerkat"
"musikalkemist/generativemusicaicourse" -> "musikalkemist/generating-melodies-with-rnn-lstm"
"keunwoochoi/kapre" -> "seth814/Audio-Classification" ["e"=1]
"keunwoochoi/kapre" -> "marl/openl3" ["e"=1]
"Beomi/InfiniTransformer" -> "OpenNLPLab/lightning-attention" ["e"=1]
"CrowdCurio/audio-annotator" -> "justinsalamon/scaper" ["e"=1]
"partha2409/DCASE2024_seld_baseline" -> "sony/audio-visual-seld-dcase2023"
"partha2409/DCASE2024_seld_baseline" -> "sharathadavanne/seld-dcase2023"
"partha2409/DCASE2024_seld_baseline" -> "Jinbo-Hu/DCASE2022-TASK3"
"partha2409/DCASE2024_seld_baseline" -> "danielkrause/DCASE2022-data-generator"
"jaron/deep-listening" -> "imfing/audio-classification"
"jaron/deep-listening" -> "karolpiczak/paper-2015-esc-convnet"
"stoneMo/DeepAVFusion" -> "stoneMo/OneAVM"
"ttgeng233/UniAV" -> "ttgeng233/UnAV"
"ttgeng233/UniAV" -> "Franklin905/VALOR"
"Ming-er/LGC-SED" -> "Ming-er/MGA-CLAP"
"OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion" -> "Doraemonzzz/tnn-pytorch"
"RicherMans/Dasheng" -> "RicherMans/CED"
"RicherMans/Dasheng" -> "jimbozhang/xares"
"cai525/Transformer4SED" -> "frednam93/MDFD-SED"
"cai525/Transformer4SED" -> "Audio-WestlakeU/ATST-SED"
"JishengBai/AudioSetCaps" -> "XinhaoMei/WavCaps"
"schowdhury671/meerkat" -> "GeWu-Lab/TSPM"
"schowdhury671/meerkat" -> "GeWu-Lab/Crab"
"NVIDIA/audio-flamingo" -> "XinhaoMei/WavCaps" ["e"=1]
"XiaoMi/dasheng" -> "RicherMans/CED"
"XiaoMi/dasheng" -> "xiaomi-research/r1-aqa" ["e"=1]
"CPJKU/cpjku_dcase24" -> "fschmid56/PretrainedSED"
"drscotthawley/audio-classifier-keras-cnn" -> "drscotthawley/panotti"
"drscotthawley/panotti" -> "micah5/pyAudioClassification"
"drscotthawley/panotti" -> "drscotthawley/audio-classifier-keras-cnn"
"drscotthawley/panotti" -> "imfing/audio-classification"
"drscotthawley/panotti" -> "aqibsaeed/Urban-Sound-Classification"
"drscotthawley/panotti" -> "jhartquist/fastai_audio" ["e"=1]
"drscotthawley/panotti" -> "jaron/deep-listening"
"drscotthawley/panotti" -> "sainathadapa/kaggle-freesound-audio-tagging"
"drscotthawley/panotti" -> "CVxTz/audio_classification"
"drscotthawley/panotti" -> "jordipons/sklearn-audio-transfer-learning" ["e"=1]
"drscotthawley/panotti" -> "ksanjeevan/crnn-audio-classification"
"drscotthawley/panotti" -> "luuil/Tensorflow-Audio-Classification"
"drscotthawley/panotti" -> "keunwoochoi/dl4mir" ["e"=1]
"drscotthawley/panotti" -> "channelCS/Audio-Vision"
"fschmid56/PretrainedSED" -> "CPJKU/cpjku_dcase24"
"unixpickle/audioset" -> "marl/audiosetdl"
"unixpickle/audioset" -> "jim-schwoebel/download_audioset"
"eborboihuc/SoundNet-tensorflow" -> "cvondrick/soundnet"
"eborboihuc/SoundNet-tensorflow" -> "pseeth/soundnet_keras"
"eborboihuc/SoundNet-tensorflow" -> "Yuliang-Zou/tf_videogan"
"TUT-ARG/DCASE2017-baseline-system" -> "TUT-ARG/sed_eval"
"TUT-ARG/DCASE2017-baseline-system" -> "TUT-ARG/DCASE2016-baseline-system-python"
"TUT-ARG/DCASE2017-baseline-system" -> "ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars"
"frednam93/MDFD-SED" -> "Ming-er/LGC-SED"
"GeWu-Lab/awesome-balanced-multimodal-learning" -> "GeWu-Lab/Diagnosing_Relearning_ECCV2024"
"GeWu-Lab/awesome-balanced-multimodal-learning" -> "Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation"
"GeWu-Lab/TSPM" -> "GeWu-Lab/PSTP-Net"
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" -> "krantiparida/awesome-audio-visual" ["e"=1]
"xiaomi-research/r1-aqa" -> "RicherMans/Dasheng" ["e"=1]
"xiaomi-research/r1-aqa" -> "XiaoMi/dasheng" ["e"=1]
"xiaomi-research/r1-aqa" -> "RicherMans/CED" ["e"=1]
"facebookresearch/audiobox-aesthetics" -> "microsoft/CLAP" ["e"=1]
"facebookresearch/audiobox-aesthetics" -> "JishengBai/AudioSetCaps" ["e"=1]
"OpenMOSS/SpeechGPT-2.0-preview" -> "JishengBai/AudioSetCaps" ["e"=1]
"tensorgi/T6" -> "OpenNLPLab/lightning-attention" ["e"=1]
"bestfitting/kaggle" -> "qrfaction/2nd-Freesound-Audio-Tagging-2019" ["e"=1]
"qiuqiangkong/audioset_tagging_cnn" ["l"="39.671,5.414"]
"YuanGongND/ast" ["l"="39.639,5.452"]
"qiuqiangkong/torchlibrosa" ["l"="38.542,4.01", "c"=201]
"qiuqiangkong/panns_inference" ["l"="39.668,5.438"]
"kkoutini/PaSST" ["l"="39.67,5.487"]
"RetroCirce/HTS-Audio-Transformer" ["l"="39.665,5.466"]
"LAION-AI/CLAP" ["l"="38.633,1.997", "c"=54]
"qiuqiangkong/audioset_classification" ["l"="39.736,5.387"]
"karolpiczak/ESC-50" ["l"="39.675,5.378"]
"iver56/audiomentations" ["l"="38.484,3.982", "c"=201]
"qiuqiangkong/panns_transfer_to_gtzan" ["l"="39.699,5.422"]
"yinkalario/General-Purpose-Sound-Recognition-Demo" ["l"="39.69,5.452"]
"s3prl/s3prl" ["l"="37.227,2.374", "c"=117]
"asteroid-team/torch-audiomentations" ["l"="38.52,4.013", "c"=201]
"fschmid56/EfficientAT" ["l"="39.688,5.493"]
"facebookresearch/AudioMAE" ["l"="39.624,5.481"]
"NVIDIA/nvvl" ["l"="47.725,33.947", "c"=168]
"cvondrick/soundnet" ["l"="39.701,5.56"]
"YapengTian/AVE-ECCV18" ["l"="39.6,5.607"]
"YapengTian/AVVP-ECCV20" ["l"="39.589,5.627"]
"jasongief/PSP_CVPR_2021" ["l"="39.576,5.645"]
"FloretCat/CMRAN" ["l"="39.592,5.645"]
"ardasnck/learning_to_localize_sound_source" ["l"="39.629,5.642"]
"krantiparida/awesome-audio-visual" ["l"="39.614,5.621"]
"DTaoo/Discriminative-Sounding-Objects-Localization" ["l"="39.634,5.629"]
"marmot-xy/CMBS" ["l"="39.569,5.632"]
"hche11/VGGSound" ["l"="39.6,5.565"]
"Yu-Wu/Modaily-Aware-Audio-Visual-Video-Parsing" ["l"="39.575,5.625"]
"hche11/Localizing-Visual-Sounds-the-Hard-Way" ["l"="39.613,5.642"]
"GenjiB/LAVISH" ["l"="39.559,5.586"]
"ttgeng233/UnAV" ["l"="39.551,5.648"]
"hangzhaomit/Sound-of-Pixels" ["l"="39.646,5.646"]
"GeWu-Lab/awesome-audiovisual-learning" ["l"="39.569,5.601"]
"GeWu-Lab/MUSIC-AVQA" ["l"="39.538,5.625"]
"danmic/av-se" ["l"="40.398,5.038", "c"=1285]
"facebookresearch/av_hubert" ["l"="40.463,5.07", "c"=1285]
"afourast/avobjects" ["l"="39.657,5.634"]
"smeetrs/deep_avsr" ["l"="40.45,5.041", "c"=1285]
"rhgao/co-separation" ["l"="39.639,5.662"]
"YuanGongND/cav-mae" ["l"="39.61,5.532"]
"pedro-morgado/spatialaudiogen" ["l"="39.614,5.689"]
"joonson/syncnet_python" ["l"="31.998,30.417", "c"=297]
"facebookresearch/2.5D-Visual-Sound" ["l"="39.64,5.69"]
"facebookresearch/EasyComDataset" ["l"="39.709,5.675"]
"jim-schwoebel/voicebook" ["l"="39.887,5.25"]
"jim-schwoebel/voice_gender_detection" ["l"="39.929,5.243"]
"jim-schwoebel/voice_datasets" ["l"="37.238,2.339", "c"=117]
"jim-schwoebel/allie" ["l"="39.921,5.212"]
"jim-schwoebel/download_audioset" ["l"="39.826,5.312"]
"edufonseca/icassp19" ["l"="39.826,5.232"]
"jim-schwoebel/audioset_models" ["l"="39.865,5.284"]
"Renovamen/Speech-Emotion-Recognition" ["l"="56.834,27.996", "c"=940]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" ["l"="39.546,5.349"]
"yingdajun/SpeechEmotionAndPeopleAnalyse" ["l"="39.467,5.312"]
"unixpickle/audioset" ["l"="39.793,5.359"]
"IBM/MAX-Audio-Classifier" ["l"="39.76,5.359"]
"IBM/audioset-classification" ["l"="39.742,5.359"]
"seth814/Audio-Classification" ["l"="39.668,5.325"]
"keunwoochoi/kapre" ["l"="38.417,4.078", "c"=201]
"ksanjeevan/crnn-audio-classification" ["l"="39.694,5.349"]
"imfing/audio-classification" ["l"="39.701,5.322"]
"marcogdepinto/emotion-classification-from-audio-files" ["l"="56.817,27.943", "c"=940]
"aqibsaeed/Urban-Sound-Classification" ["l"="39.722,5.326"]
"musikalkemist/DeepLearningForAudioWithPython" ["l"="39.6,5.25"]
"jonnor/machinehearing" ["l"="39.63,5.21"]
"jaron/deep-listening" ["l"="39.698,5.301"]
"luuil/Tensorflow-Audio-Classification" ["l"="39.714,5.36"]
"despoisj/DeepAudioClassification" ["l"="38.321,4.137", "c"=201]
"marl/openl3" ["l"="39.719,5.442"]
"musikalkemist/AudioSignalProcessingForML" ["l"="39.609,5.298"]
"shvdiwnkozbw/Multi-Source-Sound-Localization" ["l"="39.681,5.622"]
"zjsong/SSPL" ["l"="39.668,5.683"]
"stoneMo/EZ-VSL" ["l"="39.582,5.713"]
"liyidi/soundnet_localize_sound_source" ["l"="39.634,5.611"]
"stoneMo/SLAVC" ["l"="39.578,5.734"]
"jonnor/ESC-CNN-microcontroller" ["l"="39.62,5.164"]
"araobp/acoustic-features" ["l"="39.606,5.114"]
"yuanxiaosc/Multimodal-short-video-dataset-and-baseline-classification-model" ["l"="39.813,5.536"]
"PALMJJ/Multimodal-short-video-classification" ["l"="39.84,5.563"]
"yt1120948918/short-video-classification" ["l"="39.837,5.549"]
"Luka0612/ChineseVLBert" ["l"="39.867,5.577"]
"kadoufall/Urban-Sound-Classification-VS" ["l"="39.633,5.346"]
"yeyupiaoling/AudioClassification-Tensorflow" ["l"="39.606,5.354"]
"nitinvwaran/UrbanSound8K-audio-classification-with-ResNet" ["l"="39.654,5.343"]
"micah5/pyAudioClassification" ["l"="39.734,5.285"]
"drscotthawley/panotti" ["l"="39.715,5.287"]
"vishalshar/Audio-Classification-using-CNN-MLP" ["l"="39.692,5.261"]
"CVxTz/audio_classification" ["l"="39.711,5.264"]
"daisukelab/ml-sound-classifier" ["l"="39.661,5.265"]
"lRomul/argus-freesound" ["l"="39.763,5.247"]
"qrfaction/2nd-Freesound-Audio-Tagging-2019" ["l"="39.775,5.217"]
"ebouteillon/freesound-audio-tagging-2019" ["l"="39.802,5.222"]
"ex4sperans/freesound-classification" ["l"="39.768,5.195"]
"lRomul/argus" ["l"="50.815,30.796", "c"=83]
"ryanwongsa/kaggle-birdsong-recognition" ["l"="39.79,5.151"]
"sainathadapa/kaggle-freesound-audio-tagging" ["l"="39.741,5.25"]
"mnpinto/audiotagging2019" ["l"="49.59,28.527", "c"=1136]
"Cocoxili/DCASE2018Task2" ["l"="39.751,5.22"]
"MyLtYkRiTiK/ComputerVision_Tutorials_in_Russian" ["l"="50.872,30.744", "c"=83]
"zcaceres/spec_augment" ["l"="35.689,2.265", "c"=308]
"bastibe/python-soundfile" ["l"="38.379,4.051", "c"=201]
"justinsalamon/scaper" ["l"="39.763,5.44"]
"facebookresearch/FAIR-Play" ["l"="39.629,5.679"]
"SheldonTsui/SepStereo_ECCV2020" ["l"="39.627,5.699"]
"SheldonTsui/PseudoBinaural_CVPR2021" ["l"="39.636,5.717"]
"facebookresearch/learning-audio-visual-dereverberation" ["l"="39.667,5.731"]
"soerenab/AudioMNIST" ["l"="35.512,2.431", "c"=308]
"microsoft/CLAP" ["l"="39.623,5.5"]
"csteinmetz1/pyloudnorm" ["l"="36.843,4.319", "c"=128]
"harritaylor/torchvggish" ["l"="39.691,5.436"]
"tcvrick/audioset-vggish-tensorflow-to-pytorch" ["l"="39.709,5.462"]
"DTaoo/VGGish" ["l"="39.712,5.392"]
"linrongc/youtube-8m" ["l"="47.738,33.855", "c"=168]
"balavenkatesh3322/audio-pretrained-model" ["l"="48.392,26.263", "c"=323]
"v-iashin/video_features" ["l"="47.966,32.886", "c"=373]
"lyakaap/NetVLAD-pytorch" ["l"="59.353,9.439", "c"=274]
"jordipons/musicnn" ["l"="38.477,4.139", "c"=201]
"audioset/ontology" ["l"="39.736,5.422"]
"osai-ai/tensor-stream" ["l"="50.836,30.728", "c"=83]
"mir-dataset-loaders/mirdata" ["l"="38.573,4.128", "c"=201]
"rohitrango/objects-that-sound" ["l"="39.667,5.572"]
"Kajiyu/LLLNet" ["l"="39.653,5.587"]
"kyuyeonpooh/objects-that-sound" ["l"="39.637,5.529"]
"marl/l3embedding" ["l"="39.701,5.517"]
"auroracramer/flickr-soundnet-dl" ["l"="39.674,5.591"]
"sharathadavanne/seld-net" ["l"="39.834,5.511"]
"sharathadavanne/sed-crnn" ["l"="39.809,5.44"]
"yinkalario/Two-Stage-Polyphonic-Sound-Event-Detection-and-Localization" ["l"="39.843,5.473"]
"yinkalario/EIN-SELD" ["l"="39.877,5.498"]
"Audio-WestlakeU/FN-SSL" ["l"="36.661,4.234", "c"=128]
"sharathadavanne/seld-dcase2019" ["l"="39.828,5.471"]
"sharathadavanne/seld-dcase2022" ["l"="39.901,5.515"]
"sharathadavanne/seld-dcase2020" ["l"="39.858,5.495"]
"thomeou/SALSA" ["l"="39.895,5.497"]
"MaigoAkisame/cmu-thesis" ["l"="39.789,5.435"]
"DavidDiazGuerra/gpuRIR" ["l"="36.758,4.378", "c"=128]
"Soumitro-Chakrabarty/Single-speaker-localization" ["l"="37.107,4.637", "c"=128]
"DavidDiazGuerra/Cross3D" ["l"="39.816,5.628"]
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" ["l"="36.879,4.514", "c"=128]
"giusenso/seld-tcn" ["l"="39.871,5.543"]
"cdjkim/audiocaps" ["l"="39.532,5.495"]
"XinhaoMei/WavCaps" ["l"="39.559,5.49"]
"JishengBai/AudioSetCaps" ["l"="39.544,5.522"]
"XinhaoMei/ACT" ["l"="39.528,5.474"]
"wsntxxn/AudioCaption" ["l"="39.487,5.487"]
"audio-captioning/clotho-dataset" ["l"="39.477,5.507"]
"audio-captioning/audio-captioning-resources" ["l"="39.502,5.471"]
"fastaudio/fastaudio" ["l"="49.529,28.535", "c"=1136]
"andrewowens/multisensory" ["l"="39.65,5.618"]
"avivga/audio-visual-speech-enhancement" ["l"="40.429,4.908", "c"=1285]
"bill9800/speech_separation" ["l"="40.327,5.029", "c"=1285]
"ajinkyaT/Lip_Reading_in_the_Wild_AVSR" ["l"="40.449,4.956", "c"=1285]
"mayurnewase/looking-to-listen-at-cocktail-party" ["l"="40.3,5.014", "c"=1285]
"jhartquist/fastai_audio" ["l"="49.552,28.521", "c"=1136]
"KinWaiCheuk/nnAudio" ["l"="38.518,4.05", "c"=201]
"jordipons/sklearn-audio-transfer-learning" ["l"="38.406,4.135", "c"=201]
"MTG/freesound-datasets" ["l"="38.457,3.699", "c"=201]
"bmcfee/muda" ["l"="38.407,4.057", "c"=201]
"Spijkervet/CLMR" ["l"="38.555,4.162", "c"=201]
"mir-evaluation/mir_eval" ["l"="38.502,4.102", "c"=201]
"keunwoochoi/torchaudio-contrib" ["l"="38.27,4.019", "c"=201]
"soundata/soundata" ["l"="38.535,4.055", "c"=201]
"TUT-ARG/sed_eval" ["l"="39.797,5.425"]
"DCASE-REPO/DESED_task" ["l"="39.752,5.459"]
"DCASE-REPO/dcase2018_baseline" ["l"="39.806,5.404"]
"Kikyo-16/Sound_event_detection" ["l"="39.794,5.45"]
"qiuqiangkong/sed_time_freq_segmentation" ["l"="39.84,5.449"]
"ankitshah009/Task-4-Large-scale-weakly-supervised-sound-event-detection-for-smart-cars" ["l"="39.82,5.418"]
"dr-costas/dnd-sed" ["l"="39.843,5.433"]
"qiuqiangkong/sound_event_detection_dcase2017_task4" ["l"="39.78,5.405"]
"turpaultn/DESED" ["l"="39.759,5.469"]
"TUT-ARG/DCASE2017-baseline-system" ["l"="39.823,5.402"]
"marl/audiosetdl" ["l"="39.766,5.409"]
"speedyseal/audiosetdl" ["l"="39.575,5.572"]
"YuanGongND/ssast" ["l"="39.65,5.507"]
"LAION-AI/audio-dataset" ["l"="39.597,5.515"]
"roudimit/MUSIC_dataset" ["l"="39.671,5.661"]
"rhgao/Deep-MIML-Network" ["l"="39.654,5.675"]
"YapengTian/CCOL-CVPR21" ["l"="39.656,5.69"]
"yongxuUSTC/dcase2017_task4_cvssp" ["l"="39.792,5.394"]
"TUT-ARG/sed_vis" ["l"="39.779,5.457"]
"DCASE-REPO/dcase_util" ["l"="39.84,5.411"]
"TUT-ARG/DCASE2016-baseline-system-python" ["l"="39.846,5.391"]
"turpaultn/DCASE2019_task4" ["l"="39.819,5.432"]
"turpaultn/dcase20_task4" ["l"="39.802,5.464"]
"qiuqiangkong/dcase2019_task4" ["l"="39.86,5.423"]
"lihanghang/CASR-DEMO" ["l"="39.378,5.267"]
"lihanghang/Deep-learning-And-Paper" ["l"="39.415,5.285"]
"kamalesh0406/Audio-Classification" ["l"="39.623,5.325"]
"sarthak268/Audio_Classification_using_LSTM" ["l"="39.663,5.305"]
"yeyupiaoling/AudioClassification-Pytorch" ["l"="39.631,5.38"]
"toni-heittola/icassp2019-tutorial" ["l"="39.811,5.383"]
"MihawkHu/DCASE2020_task1" ["l"="39.957,5.384"]
"CPJKU/dcase_task2" ["l"="39.843,5.366"]
"pedro-morgado/AVSpatialAlignment" ["l"="39.602,5.727"]
"h2oai/pystacknet" ["l"="57.422,23.977", "c"=864]
"aoifemcdonagh/audioset-processing" ["l"="39.855,5.26"]
"MorenoLaQuatra/audioset-download" ["l"="39.871,5.223"]
"qiuqiangkong/dcase2019_task3" ["l"="39.871,5.47"]
"danielkrause/DCASE2022-data-generator" ["l"="39.911,5.504"]
"yinkalario/DCASE2019-TASK3" ["l"="39.887,5.464"]
"Jinbo-Hu/DCASE2022-TASK3" ["l"="39.909,5.493"]
"kkoutini/cpjku_dcase19" ["l"="39.983,5.374"]
"kkoutini/cpjku_dcase20" ["l"="39.984,5.391"]
"McDonnell-Lab/DCASE2019-Task1" ["l"="39.98,5.357"]
"toni-heittola/dcase2020_task1_baseline" ["l"="40,5.377"]
"pudae/kaggle-humpback" ["l"="50.55,30.478", "c"=83]
"qiuqiangkong/ICASSP2018_audioset" ["l"="39.776,5.381"]
"ChangsongYu/Eusipco2018_Google_AudioSet" ["l"="39.77,5.343"]
"RicherMans/AudioCaption" ["l"="39.508,5.446"]
"audio-captioning/audio-captioning-papers" ["l"="39.488,5.462"]
"microsoft/WavText5K" ["l"="39.582,5.453"]
"daisukelab/freesound-audio-tagging-2019" ["l"="39.82,5.193"]
"fgnt/pb_sed" ["l"="39.742,5.47"]
"edufonseca/FSD50K_baseline" ["l"="39.877,5.439"]
"araobp/image-features" ["l"="39.592,5.099"]
"araobp/stm32-mcu" ["l"="39.607,5.086"]
"kingfengji/DeepMIML" ["l"="41.73,27.125", "c"=369]
"sony/CLIPSep" ["l"="36.541,4.047", "c"=128]
"tqbl/dcase2018_task2" ["l"="39.867,5.344"]
"finejuly/dcase2018_task2_cochlearai" ["l"="39.875,5.356"]
"qiuqiangkong/dcase2018_task4" ["l"="39.819,5.363"]
"MihawkHu/Acoustic_Lottery" ["l"="39.965,5.361"]
"tqbl/gccaps" ["l"="39.892,5.33"]
"koukyo1994/kaggle-birdcall-resnet-baseline-training" ["l"="39.854,5.068"]
"fkubota/spectrogram-tree" ["l"="39.87,5.047"]
"koukyo1994/kaggle-birdcall-6th-place" ["l"="39.827,5.106"]
"yeyupiaoling/VoiceprintRecognition-Tensorflow" ["l"="36.816,3.291", "c"=526]
"frednam93/FDY-SED" ["l"="39.749,5.484"]
"Audio-WestlakeU/ATST-SED" ["l"="39.739,5.503"]
"cai525/Transformer4SED" ["l"="39.76,5.5"]
"fgnt/sed_scores_eval" ["l"="39.775,5.474"]
"tyiannak/pyAudioAnalysis" ["l"="38.365,4.176", "c"=201]
"vlomme/Birdcall-Identification-competition" ["l"="39.796,5.127"]
"TheoViel/kaggle_birdcall_identification" ["l"="39.777,5.127"]
"tattaka/birdclef-2021" ["l"="39.819,5.124"]
"jfpuget/STFT_Transformer" ["l"="39.79,5.082"]
"musikalkemist/pytorchforaudio" ["l"="39.579,5.28"]
"musikalkemist/Deep-Learning-Audio-Application-From-Design-to-Deployment" ["l"="39.573,5.254"]
"musikalkemist/generating-sound-with-neural-networks" ["l"="39.569,5.237"]
"iranroman/musicinformationretrieval.com" ["l"="38.472,4.118", "c"=201]
"csteinmetz1/ai-audio-startups" ["l"="38.752,2.011", "c"=54]
"wenet-e2e/speech-synthesis-paper" ["l"="37.286,2.43", "c"=117]
"pytorch/audio" ["l"="38.443,4.022", "c"=201]
"musikalkemist/audioDataAugmentationTutorial" ["l"="39.593,5.268"]
"magenta/ddsp" ["l"="38.563,4.061", "c"=201]
"lucidrains/linear-attention-transformer" ["l"="48.797,33.949", "c"=556]
"OpenNLPLab/cosFormer" ["l"="39.481,5.858"]
"liuxubo717/LASS" ["l"="39.69,5.72"]
"musikalkemist/generating-melodies-with-rnn-lstm" ["l"="39.578,5.217"]
"musikalkemist/generativemusicaicourse" ["l"="39.575,5.192"]
"frednam93/FilterAugSED" ["l"="39.768,5.486"]
"965694547/Hybrid-system-of-frame-wise-model-and-SEDT" ["l"="39.783,5.491"]
"vbelz/Speech-enhancement" ["l"="36.727,4.398", "c"=128]
"musikalkemist/spotifyplaylistgenerator" ["l"="39.553,5.219"]
"musikalkemist/praudio" ["l"="39.544,5.24"]
"AI-Guru/music-generation-research" ["l"="38.726,4.135", "c"=201]
"aiXander/Realtime_PyAudio_FFT" ["l"="38.355,4.009", "c"=201]
"facebookresearch/sound-spaces" ["l"="38.097,3.597", "c"=201]
"facebookresearch/visual-acoustic-matching" ["l"="39.668,5.776"]
"spotify/klio" ["l"="38.525,4.16", "c"=201]
"ubc-vision/TriBERT" ["l"="39.605,5.676"]
"facebookresearch/Listen-to-Look" ["l"="47.515,33.015", "c"=373]
"mariostrbac/environmental-sound-classification" ["l"="39.592,5.329"]
"geekysethi/audio_classification" ["l"="39.588,5.313"]
"AndreyGuzhov/ESResNet" ["l"="39.573,5.318"]
"facebookresearch/VisualVoice" ["l"="40.398,5.068", "c"=1285]
"joonson/syncnet_trainer" ["l"="31.958,30.361", "c"=297]
"MCG-NJU/JoMoLD" ["l"="46.276,30.787", "c"=367]
"yinkalario/Sound-Event-Detection-AudioSet" ["l"="39.695,5.471"]
"etzinis/heterogeneous_separation" ["l"="39.62,5.436"]
"haoheliu/diffres-python" ["l"="39.605,5.443"]
"akoepke/audio-retrieval-benchmark" ["l"="39.583,5.433"]
"FishMaster93/AFFIA3K" ["l"="39.612,5.455"]
"idiap/nnsslm" ["l"="39.701,5.651"]
"GAMMA-UMD/doa-release" ["l"="37.079,4.604", "c"=128]
"DavidDiazGuerra/icoDOA" ["l"="39.86,5.651"]
"dr-costas/SEDLM" ["l"="39.882,5.416"]
"cevers/sap_locata_io" ["l"="39.84,5.659"]
"emilywg/DCASE2020-Task1" ["l"="39.97,5.401"]
"sharathadavanne/seld-dcase2021" ["l"="39.885,5.514"]
"SarthakYadav/fsd50k-pytorch" ["l"="39.905,5.433"]
"cevers/sap_locata_eval" ["l"="39.854,5.676"]
"AgaMiko/bird-recognition-review" ["l"="-52.444,10.649", "c"=19]
"audioanalytic/psds_eval" ["l"="39.785,5.528"]
"audio-captioning/dcase-2020-baseline" ["l"="39.46,5.462"]
"XinhaoMei/DCASE2021_task6_v2" ["l"="39.518,5.463"]
"lukewys/dcase_2020_T6" ["l"="39.454,5.443"]
"qiuqiangkong/autoth" ["l"="39.797,5.376"]
"wavewangyue/mae" ["l"="39.899,5.6"]
"fkubota/anima" ["l"="39.884,5.024"]
"fkubota/kagglelike-leaderboard" ["l"="39.895,5.007"]
"haltakov/natural-language-image-search" ["l"="49.146,30.374", "c"=191]
"AndreyGuzhov/AudioCLIP" ["l"="39.6,5.488"]
"yeyupiaoling/VoiceprintRecognition-Pytorch" ["l"="36.907,3.28", "c"=526]
"facebookresearch/dora" ["l"="39.814,5.718"]
"facebookresearch/flashy" ["l"="39.84,5.754"]
"nttcslab/eval-audio-repr" ["l"="39.768,5.645"]
"microsoft/DNS-Challenge" ["l"="36.768,4.346", "c"=128]
"WenzheLiu-Speech/awesome-speech-enhancement" ["l"="36.75,4.357", "c"=128]
"karolpiczak/paper-2015-esc-dataset" ["l"="39.682,5.306"]
"LCAV/pyroomacoustics" ["l"="36.815,4.416", "c"=128]
"YuanGongND/psla" ["l"="39.68,5.511"]
"YuanGongND/ltu" ["l"="38.435,2.153", "c"=54]
"TaoRuijie/TalkNet-ASD" ["l"="47.49,34.035", "c"=168]
"google-research/leaf-audio" ["l"="38.502,3.964", "c"=201]
"JustinYuu/MM_Pyramid" ["l"="39.565,5.675"]
"xiaobai1217/Awesome-Video-Datasets" ["l"="47.974,33.748", "c"=168]
"csukuangfj/kaldifeat" ["l"="35.708,2.39", "c"=308]
"RicherMans/Dasheng" ["l"="39.779,5.591"]
"descriptinc/lyrebird-wav2clip" ["l"="39.576,5.531"]
"researchmm/MM-Diffusion" ["l"="33.697,31.367", "c"=109]
"v-iashin/SpecVQGAN" ["l"="38.609,2.266", "c"=54]
"microsoft/Pengi" ["l"="38.378,2.204", "c"=54]
"ArrowLuo/CLIP4Clip" ["l"="47.909,32.98", "c"=373]
"sooftware/conformer" ["l"="35.754,2.242", "c"=308]
"vince9515/SER" ["l"="39.444,5.304"]
"yeyupiaoling/AudioClassification-PaddlePaddle" ["l"="35.562,1.902", "c"=308]
"TaoRuijie/ECAPA-TDNN" ["l"="36.982,3.29", "c"=526]
"KingH12138/Pytorch-AudioClassification-master" ["l"="39.586,5.373"]
"Alibaba-MIIL/AudioClassfication" ["l"="39.636,5.419"]
"karolpiczak/paper-2015-esc-convnet" ["l"="39.684,5.277"]
"pliang279/MultiBench" ["l"="56.58,28.053", "c"=940]
"GeWu-Lab/OGM-GE_CVPR2022" ["l"="39.505,5.611"]
"soham97/awesome-sound_event_detection" ["l"="39.711,5.488"]
"robertanto/Real-Time-Sound-Event-Detection" ["l"="39.725,5.522"]
"liuxubo717/cl4ac" ["l"="39.691,5.748"]
"liuxubo717/V-ACT" ["l"="39.701,5.74"]
"liuxubo717/SimPFs" ["l"="39.714,5.741"]
"liuxubo717/LASS-demopage" ["l"="39.699,5.758"]
"liuxubo717/sound_generation" ["l"="39.711,5.755"]
"cfoster0/CLAP" ["l"="39.534,5.414"]
"nussl/nussl" ["l"="36.642,4.428", "c"=128]
"c4dm/dcase-few-shot-bioacoustic" ["l"="39.712,5.629"]
"yangdongchao/DCASE2021Task5" ["l"="39.704,5.608"]
"ilyassmoummad/RCL_FS_BSED" ["l"="39.725,5.652"]
"haoheliu/DCASE_2022_Task_5" ["l"="39.697,5.587"]
"moiseshorta/MelSpecVAE" ["l"="38.859,3.754", "c"=201]
"nttcslab/byol-a" ["l"="39.785,5.631"]
"edufonseca/uclser20" ["l"="39.809,5.669"]
"Audio-WestlakeU/audiossl" ["l"="39.729,5.548"]
"baosenguo/Kaggle-MoA-2nd-Place-Solution" ["l"="39.793,5.031"]
"guitarmind/kaggle_moa_winner_hungry_for_gold" ["l"="39.794,5.003"]
"senkin13/kaggle" ["l"="6.032,-41.081", "c"=259]
"facebookresearch/BinauralSpeechSynthesis" ["l"="39.631,5.748"]
"oncescuandreea/audio-retrieval" ["l"="39.562,5.415"]
"shkim816/acnn_speaker_recog" ["l"="39.817,5.519"]
"shkim816/temporal_dynamic_cnn" ["l"="39.803,5.507"]
"karolpiczak/echonet" ["l"="39.665,5.24"]
"sunits/EnvironmentalSoundClassification" ["l"="39.68,5.239"]
"XinhaoMei/audio-text_retrieval" ["l"="39.548,5.455"]
"YYX666660/LAVSS" ["l"="39.663,5.71"]
"RetroCirce/Zero_Shot_Audio_Source_Separation" ["l"="36.543,4.11", "c"=128]
"lucidrains/x-clip" ["l"="48.971,30.385", "c"=191]
"mfrashad/text2art" ["l"="44.642,31.461", "c"=1003]
"frednam93/MDFD-SED" ["l"="39.766,5.518"]
"Anaesthesiaye/sound_event_detection_transformer" ["l"="39.783,5.508"]
"haoheliu/audioldm_eval" ["l"="39.578,5.497"]
"kkoutini/passt_hear21" ["l"="39.661,5.531"]
"RicherMans/CED" ["l"="39.752,5.555"]
"marmoi/dcase2023_task4b_baseline" ["l"="39.803,5.488"]
"Audio-WestlakeU/SAR-SSL" ["l"="36.9,3.042", "c"=526]
"AlanBaade/MAE-AST-Public" ["l"="39.583,5.469"]
"nttcslab/msm-mae" ["l"="39.599,5.462"]
"WangHelin1997/MaskSpec" ["l"="39.563,5.44"]
"GeWu-Lab/TSPM" ["l"="39.521,5.656"]
"GeWu-Lab/PSTP-Net" ["l"="39.518,5.642"]
"schowdhury671/meerkat" ["l"="39.511,5.67"]
"GeWu-Lab/MWAFM" ["l"="39.505,5.649"]
"HS-YN/PanoAVQA" ["l"="39.51,5.634"]
"fanyunfeng-bit/Modal-Imbalance-PMR" ["l"="39.461,5.597"]
"QingyangZhang/QMF" ["l"="52.909,30.048", "c"=547]
"GeWu-Lab/MMPareto_ICML2024" ["l"="39.47,5.642"]
"GeWu-Lab/Valuate-and-Enhance-Multimodal-Cooperation" ["l"="52.866,30.032", "c"=547]
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" ["l"="39.45,5.62"]
"TencentAILabHealthcare/mmdynamics" ["l"="52.927,30.042", "c"=547]
"lihong2303/AGM" ["l"="39.476,5.605"]
"GeWu-Lab/awesome-balanced-multimodal-learning" ["l"="39.443,5.638"]
"GeWu-Lab/MMCosine_ICASSP23" ["l"="39.485,5.634"]
"GeWu-Lab/BML_TPAMI2024" ["l"="39.477,5.621"]
"descriptinc/descript-audio-codec" ["l"="38.554,2.011", "c"=54]
"archinetai/audio-diffusion-pytorch" ["l"="38.697,1.983", "c"=54]
"teticio/audio-diffusion" ["l"="38.716,2.034", "c"=54]
"gudgud96/frechet-audio-distance" ["l"="38.747,4.037", "c"=201]
"declare-lab/tango" ["l"="38.625,2.069", "c"=54]
"yangdongchao/UniAudio" ["l"="38.492,2.071", "c"=54]
"facebookresearch/AudioDec" ["l"="38.484,2.093", "c"=54]
"lucidrains/audiolm-pytorch" ["l"="38.625,1.96", "c"=54]
"amsehili/auditok" ["l"="36.753,4.532", "c"=128]
"nttcslab/m2d" ["l"="39.732,5.591"]
"sony/audio-visual-seld-dcase2023" ["l"="39.919,5.518"]
"Jinbo-Hu/L3DAS22-TASK2" ["l"="39.945,5.486"]
"marl/SpatialScaper" ["l"="39.936,5.514"]
"stoneMo/AVGN" ["l"="39.563,5.742"]
"OpenNLPLab/FNAC_AVL" ["l"="39.553,5.778"]
"hxixixh/mix-and-localize" ["l"="39.573,5.758"]
"DavidDiazGuerra/icoCNN" ["l"="39.878,5.663"]
"sharathadavanne/seld-dcase2023" ["l"="39.928,5.503"]
"thomeou/SALSA-Lite" ["l"="39.922,5.479"]
"Labbeti/aac-datasets" ["l"="39.562,5.462"]
"wsntxxn/TextToAudioGrounding" ["l"="39.527,5.436"]
"davidsvy/cosformer-pytorch" ["l"="39.453,5.868"]
"OpenNLPLab/Tnn" ["l"="39.524,5.854"]
"OpenNLPLab/Transnormer" ["l"="39.511,5.847"]
"martinsbruveris/tensorflow-image-models" ["l"="45.803,25.521", "c"=68]
"fschmid56/EfficientAT_HEAR" ["l"="39.697,5.531"]
"fschmid56/cpjku_dcase23" ["l"="39.681,5.534"]
"haoheliu/AudioLDM-training-finetuning" ["l"="38.604,4.176", "c"=201]
"luosiallen/Diff-Foley" ["l"="38.66,2.318", "c"=54]
"Stability-AI/stable-audio-metrics" ["l"="38.647,4.108", "c"=201]
"haoheliu/AudioLDM" ["l"="38.666,1.981", "c"=54]
"happylittlecat2333/Auffusion" ["l"="38.64,2.284", "c"=54]
"bytedance/Make-An-Audio-2" ["l"="38.585,2.235", "c"=54]
"Yuan-ManX/ai-audio-datasets" ["l"="38.528,2.065", "c"=54]
"lucidrains/musiclm-pytorch" ["l"="38.69,1.93", "c"=54]
"thuml/Flowformer" ["l"="44.829,24.416", "c"=166]
"Vincent-ZHQ/CA-MSER" ["l"="56.919,27.965", "c"=940]
"yeyupiaoling/SpeechEmotionRecognition-PaddlePaddle" ["l"="39.512,5.336"]
"Jiaxin-Ye/TIM-Net_SER" ["l"="56.923,27.949", "c"=940]
"TaoRuijie/Loss-Gated-Learning" ["l"="36.965,3.322", "c"=526]
"joannahong/AV-RelScore" ["l"="40.466,5.134", "c"=1285]
"GeWu-Lab/CSOL_TPAMI2021" ["l"="39.536,5.605"]
"GeWu-Lab/Ref-AVS" ["l"="49.273,31.952", "c"=300]
"burchim/AVEC" ["l"="40.469,5.089", "c"=1285]
"OpenNLPLab/AVSBench" ["l"="49.99,3.283", "c"=941]
"jxzly/Kaggle-American-Express-Default-Prediction-1st-solution" ["l"="57.373,22.975", "c"=876]
"haoyi-duan/DG-SCT" ["l"="39.524,5.584"]
"cyh-0/CAVP" ["l"="39.5,5.579"]
"facebookresearch/audiobox-aesthetics" ["l"="38.494,2.137", "c"=54]
"TXH-mercury/VALOR" ["l"="47.778,32.932", "c"=373]
"kylemcdonald/AudioNotebooks" ["l"="38.545,3.808", "c"=201]
"OpenNLPLab/FAVDBench" ["l"="39.524,5.875"]
"lucidrains/zorro-pytorch" ["l"="39.466,5.545"]
"YuanGongND/uavm" ["l"="39.521,5.541"]
"csteinmetz1/auraloss" ["l"="38.618,4.005", "c"=201]
"pranaymanocha/PerceptualAudio" ["l"="38.535,3.947", "c"=201]
"axeber01/ngcc-seld" ["l"="39.95,5.5"]
"hqsiswiliam/persona-adaptive-attention" ["l"="39.585,5.415"]
"OpenNLPLab/ETSC-Exact-Toeplitz-to-SSM-Conversion" ["l"="39.538,5.845"]
"OpenNLPLab/Vicinity-Vision-Transformer" ["l"="39.501,5.868"]
"facebookresearch/novel-view-acoustic-synthesis" ["l"="39.675,5.82"]
"gorinars/dcase16-cnn" ["l"="39.868,5.378"]
"TUT-ARG/DCASE2016-baseline-system-matlab" ["l"="39.882,5.384"]
"Doraemonzzz/tnn-pytorch" ["l"="39.546,5.862"]
"cwx-worst-one/EAT" ["l"="39.787,5.57"]
"OFA-Sys/ONE-PEACE" ["l"="48.896,30.217", "c"=191]
"seungheondoh/lp-music-caps" ["l"="38.621,4.18", "c"=201]
"Audio-AGI/WavJourney" ["l"="38.63,4.122", "c"=201]
"facebookresearch/SONAR" ["l"="38.54,2.134", "c"=54]
"XiaoMi/dasheng" ["l"="39.759,5.584"]
"JishengBai/ICME2024ASC" ["l"="39.769,5.569"]
"RicherMans/SAT" ["l"="39.809,5.591"]
"fschmid56/PretrainedSED" ["l"="39.762,5.535"]
"CPJKU/cpjku_dcase24" ["l"="39.748,5.528"]
"Jakobovski/free-spoken-digit-dataset" ["l"="35.581,2.401", "c"=308]
"rednafi/urban-sound-classification" ["l"="39.765,5.312"]
"awjuliani/sound-cnn" ["l"="39.782,5.287"]
"BenjaminDoran/Urban-Sound-Classification" ["l"="39.755,5.295"]
"ttgeng233/UniAV" ["l"="39.538,5.668"]
"ttgeng233/LongVALE" ["l"="39.545,5.68"]
"Franklin905/VALOR" ["l"="39.529,5.682"]
"MengyuanChen21/CVPR2023-CMPAE" ["l"="48.048,34.112", "c"=168]
"YiLunLee/missing_aware_prompts" ["l"="56.454,27.984", "c"=940]
"TXH-mercury/VAST" ["l"="47.793,32.925", "c"=373]
"Audio-AGI/AudioSep" ["l"="38.679,2.044", "c"=54]
"partha2409/DCASE2024_seld_baseline" ["l"="39.932,5.525"]
"sakshamsingh1/sound_distance_estimation" ["l"="39.965,5.525"]
"YuanGongND/whisper-at" ["l"="38.363,2.241", "c"=54]
"keunwoochoi/music-auto_tagging-keras" ["l"="38.38,4.132", "c"=201]
"drscotthawley/audio-classifier-keras-cnn" ["l"="39.718,5.236"]
"OpenNLPLab/TransnormerLLM" ["l"="39.5,5.906"]
"OpenNLPLab/lightning-attention" ["l"="39.488,5.94"]
"OpenNLPLab/HGRN2" ["l"="39.467,5.917"]
"OpenNLPLab/LASP" ["l"="39.514,5.94"]
"stoneMo/DeepAVFusion" ["l"="39.561,5.552"]
"facebookresearch/replay_dataset" ["l"="39.678,5.842"]
"RicherMans/PSL" ["l"="39.84,5.611"]
"FishMaster93/U-FFIA" ["l"="39.597,5.425"]
"Haoyu-ha/LNLN" ["l"="56.488,28.015", "c"=940]
"Cecile-hi/Radian-Weight-Modification" ["l"="38.099,2.692", "c"=54]
"XuezheMax/megalodon" ["l"="49.086,33.89", "c"=556]
"tencent-ailab/MuQ" ["l"="38.502,2.165", "c"=54]
"eborboihuc/SoundNet-tensorflow" ["l"="39.734,5.617"]
"keunhong/pytorch-soundnet" ["l"="39.714,5.587"]
"xiaolonw/ss-gan" ["l"="45.951,29.231", "c"=170]
"Guim3/IcGAN" ["l"="45.958,29.137", "c"=170]
"cvondrick/videogan" ["l"="45.873,29.296", "c"=170]
"kimiyoung/review_net" ["l"="48.436,31.985", "c"=300]
"facebookarchive/eyescream" ["l"="45.858,29.323", "c"=170]
"reedscot/nips2016" ["l"="45.889,29.247", "c"=170]
"rikeilong/Bay-CAT" ["l"="39.477,5.697"]
"Beomi/InfiniTransformer" ["l"="37.884,-1.429", "c"=1218]
"CrowdCurio/audio-annotator" ["l"="38.434,3.883", "c"=201]
"stoneMo/OneAVM" ["l"="39.534,5.559"]
"Ming-er/LGC-SED" ["l"="39.797,5.55"]
"Ming-er/MGA-CLAP" ["l"="39.821,5.57"]
"jimbozhang/xares" ["l"="39.802,5.611"]
"GeWu-Lab/Crab" ["l"="39.498,5.694"]
"NVIDIA/audio-flamingo" ["l"="38.414,2.173", "c"=54]
"xiaomi-research/r1-aqa" ["l"="38.382,2.15", "c"=54]
"keunwoochoi/dl4mir" ["l"="38.426,4.139", "c"=201]
"channelCS/Audio-Vision" ["l"="39.699,5.233"]
"pseeth/soundnet_keras" ["l"="39.743,5.645"]
"Yuliang-Zou/tf_videogan" ["l"="39.753,5.662"]
"GeWu-Lab/Diagnosing_Relearning_ECCV2024" ["l"="39.415,5.651"]
"HuaizhengZhang/Awsome-Deep-Learning-for-Video-Analysis" ["l"="47.913,33.872", "c"=168]
"OpenMOSS/SpeechGPT-2.0-preview" ["l"="38.391,2.112", "c"=54]
"tensorgi/T6" ["l"="37.568,-0.815", "c"=126]
"bestfitting/kaggle" ["l"="6.042,-41.09", "c"=259]
}