digraph G {
"maxchehab/CSS-Keylogging" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"zalandoresearch/fashion-mnist" -> "lengstrom/fast-style-transfer" ["e"=1]
"zalandoresearch/fashion-mnist" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"tensorflow/lucid" -> "soumith/ganhacks" ["e"=1]
"microsoft/tensorwatch" -> "timsainb/tensorflow2-generative-models" ["e"=1]
"NVIDIA/FastPhotoStyle" -> "luanfujun/deep-photo-styletransfer"
"NVIDIA/FastPhotoStyle" -> "lengstrom/fast-style-transfer"
"NVIDIA/FastPhotoStyle" -> "NVIDIA/vid2vid"
"NVIDIA/FastPhotoStyle" -> "luanfujun/deep-painterly-harmonization"
"NVIDIA/FastPhotoStyle" -> "NVIDIA/pix2pixHD"
"NVIDIA/FastPhotoStyle" -> "esimov/caire" ["e"=1]
"NVIDIA/FastPhotoStyle" -> "yunjey/stargan"
"NVIDIA/FastPhotoStyle" -> "facebookresearch/Detectron" ["e"=1]
"NVIDIA/FastPhotoStyle" -> "junyanz/CycleGAN"
"NVIDIA/FastPhotoStyle" -> "tkarras/progressive_growing_of_gans"
"NVIDIA/FastPhotoStyle" -> "jcjohnson/fast-neural-style"
"NVIDIA/FastPhotoStyle" -> "NVlabs/SPADE"
"NVIDIA/FastPhotoStyle" -> "NVlabs/stylegan"
"NVIDIA/FastPhotoStyle" -> "jcjohnson/neural-style"
"NVIDIA/FastPhotoStyle" -> "DmitryUlyanov/deep-image-prior"
"deeppomf/DeepCreamPy" -> "lllyasviel/style2paints" ["e"=1]
"HarisIqbal88/PlotNeuralNet" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"HarisIqbal88/PlotNeuralNet" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"esimov/caire" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"esimov/caire" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"NVlabs/stylegan" -> "NVlabs/stylegan2" ["e"=1]
"NVlabs/stylegan" -> "NVlabs/ffhq-dataset" ["e"=1]
"NVlabs/stylegan" -> "tkarras/progressive_growing_of_gans"
"NVlabs/stylegan" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"NVlabs/stylegan" -> "NVlabs/SPADE"
"NVlabs/stylegan" -> "NVlabs/stylegan2-ada-pytorch" ["e"=1]
"NVlabs/stylegan" -> "NVIDIA/pix2pixHD"
"NVlabs/stylegan" -> "hindupuravinash/the-gan-zoo"
"NVlabs/stylegan" -> "NVlabs/stylegan3" ["e"=1]
"NVlabs/stylegan" -> "junyanz/CycleGAN"
"NVlabs/stylegan" -> "soumith/ganhacks"
"NVlabs/stylegan" -> "yunjey/stargan"
"NVlabs/stylegan" -> "NVIDIA/vid2vid"
"NVlabs/stylegan" -> "eriklindernoren/Keras-GAN"
"NVlabs/stylegan" -> "eriklindernoren/PyTorch-GAN"
"run-youngjoo/SC-FEGAN" -> "JiahuiYu/generative_inpainting" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "switchablenorms/CelebAMask-HQ" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "knazeri/edge-connect" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "NVlabs/SPADE"
"run-youngjoo/SC-FEGAN" -> "NVlabs/stylegan"
"run-youngjoo/SC-FEGAN" -> "clovaai/stargan-v2" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "shaoanlu/faceswap-GAN" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "NVIDIA/partialconv" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "NVlabs/FUNIT"
"run-youngjoo/SC-FEGAN" -> "zllrunning/face-parsing.PyTorch" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "SummitKwan/transparent_latent_gan"
"run-youngjoo/SC-FEGAN" -> "genforce/interfacegan" ["e"=1]
"run-youngjoo/SC-FEGAN" -> "yunjey/stargan"
"run-youngjoo/SC-FEGAN" -> "NVIDIA/vid2vid"
"run-youngjoo/SC-FEGAN" -> "Puzer/stylegan-encoder" ["e"=1]
"emilwallner/Screenshot-to-code" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"utkuozbulak/pytorch-cnn-visualizations" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"Gsllchb/Handright" -> "kaonashi-tyc/zi2zi" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"eriklindernoren/PyTorch-GAN" -> "hindupuravinash/the-gan-zoo"
"eriklindernoren/PyTorch-GAN" -> "soumith/ganhacks"
"eriklindernoren/PyTorch-GAN" -> "eriklindernoren/Keras-GAN"
"eriklindernoren/PyTorch-GAN" -> "pytorch/examples" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "huggingface/pytorch-image-models" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "lucidrains/vit-pytorch" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "AntixK/PyTorch-VAE" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "yunjey/pytorch-tutorial" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "wiseodd/generative-models"
"eriklindernoren/PyTorch-GAN" -> "open-mmlab/mmdetection" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "pytorch/vision" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "Cadene/pretrained-models.pytorch" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "lucidrains/denoising-diffusion-pytorch" ["e"=1]
"eriklindernoren/PyTorch-GAN" -> "jindongwang/transferlearning" ["e"=1]
"facebookresearch/DensePose" -> "NVIDIA/vid2vid" ["e"=1]
"nashory/gans-awesome-applications" -> "soumith/ganhacks"
"nashory/gans-awesome-applications" -> "nightrome/really-awesome-gan"
"nashory/gans-awesome-applications" -> "hindupuravinash/the-gan-zoo"
"nashory/gans-awesome-applications" -> "wiseodd/generative-models"
"nashory/gans-awesome-applications" -> "eriklindernoren/Keras-GAN"
"nashory/gans-awesome-applications" -> "zhangqianhui/AdversarialNetsPapers"
"nashory/gans-awesome-applications" -> "eriklindernoren/PyTorch-GAN"
"nashory/gans-awesome-applications" -> "tkarras/progressive_growing_of_gans"
"nashory/gans-awesome-applications" -> "NVIDIA/pix2pixHD"
"nashory/gans-awesome-applications" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"nashory/gans-awesome-applications" -> "pytorch/examples" ["e"=1]
"nashory/gans-awesome-applications" -> "yunjey/stargan"
"nashory/gans-awesome-applications" -> "kjw0612/awesome-deep-vision" ["e"=1]
"nashory/gans-awesome-applications" -> "NVlabs/stylegan"
"nashory/gans-awesome-applications" -> "znxlwm/pytorch-generative-model-collections"
"lucabergamini/VAEGAN-PYTORCH" -> "ry85/VAE-GAN"
"lucabergamini/VAEGAN-PYTORCH" -> "andersbll/autoencoding_beyond_pixels"
"lucabergamini/VAEGAN-PYTORCH" -> "zhangqianhui/vae-gan-tensorflow"
"lucabergamini/VAEGAN-PYTORCH" -> "anitan0925/vaegan"
"lucabergamini/VAEGAN-PYTORCH" -> "crmaximo/VAEGAN"
"lucabergamini/VAEGAN-PYTORCH" -> "rohithreddy024/VAE-GAN-Pytorch"
"lucabergamini/VAEGAN-PYTORCH" -> "seangal/dcgan_vae_pytorch"
"lucabergamini/VAEGAN-PYTORCH" -> "rishabhd786/VAE-GAN-PYTORCH"
"lucabergamini/VAEGAN-PYTORCH" -> "escuccim/vaegan-pytorch"
"lucabergamini/VAEGAN-PYTORCH" -> "JeremyCCHsu/tf-vaegan"
"lucabergamini/VAEGAN-PYTORCH" -> "tkazusa/CVAE-GAN"
"JiahuiYu/generative_inpainting" -> "run-youngjoo/SC-FEGAN" ["e"=1]
"JiahuiYu/generative_inpainting" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"MrNothing/AI-Blocks" -> "AKSHAYUBHAT/DeepVideoAnalytics" ["e"=1]
"MrNothing/AI-Blocks" -> "andabi/deep-voice-conversion" ["e"=1]
"MrNothing/AI-Blocks" -> "buriburisuri/speech-to-text-wavenet" ["e"=1]
"MrNothing/AI-Blocks" -> "junyanz/iGAN"
"MrNothing/AI-Blocks" -> "OpenNMT/OpenNMT" ["e"=1]
"MrNothing/AI-Blocks" -> "PAIR-code/facets" ["e"=1]
"MrNothing/AI-Blocks" -> "oarriaga/face_classification" ["e"=1]
"MrNothing/AI-Blocks" -> "facebookresearch/fairseq-lua" ["e"=1]
"MrNothing/AI-Blocks" -> "yunjey/stargan"
"MrNothing/AI-Blocks" -> "google-deepmind/sonnet" ["e"=1]
"MrNothing/AI-Blocks" -> "DmitryUlyanov/deep-image-prior"
"MrNothing/AI-Blocks" -> "tensorflow/tfjs-core" ["e"=1]
"MrNothing/AI-Blocks" -> "pyro-ppl/pyro" ["e"=1]
"MrNothing/AI-Blocks" -> "NVIDIA/pix2pixHD"
"MrNothing/AI-Blocks" -> "lengstrom/fast-style-transfer"
"google/tangent" -> "bioinf-jku/SNNs" ["e"=1]
"google/compare_gan" -> "ajbrock/BigGAN-PyTorch"
"google/compare_gan" -> "pfnet-research/sngan_projection"
"google/compare_gan" -> "bioinf-jku/TTUR"
"google/compare_gan" -> "heykeetae/Self-Attention-GAN"
"google/compare_gan" -> "igul222/improved_wgan_training"
"google/compare_gan" -> "facebookresearch/pytorch_GAN_zoo"
"google/compare_gan" -> "LMescheder/GAN_stability"
"google/compare_gan" -> "openai/improved-gan"
"google/compare_gan" -> "CSAILVision/gandissect"
"google/compare_gan" -> "openai/glow"
"google/compare_gan" -> "tkarras/progressive_growing_of_gans"
"google/compare_gan" -> "hwalsuklee/tensorflow-generative-model-collections"
"google/compare_gan" -> "brain-research/self-attention-gan"
"google/compare_gan" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"google/compare_gan" -> "wiseodd/generative-models"
"NVlabs/MUNIT" -> "mingyuliutw/UNIT"
"NVlabs/MUNIT" -> "HsinYingLee/DRIT"
"NVlabs/MUNIT" -> "NVlabs/FUNIT"
"NVlabs/MUNIT" -> "junyanz/BicycleGAN"
"NVlabs/MUNIT" -> "taki0112/MUNIT-Tensorflow"
"NVlabs/MUNIT" -> "lzhbrian/image-to-image-papers"
"NVlabs/MUNIT" -> "yunjey/stargan"
"NVlabs/MUNIT" -> "NVIDIA/pix2pixHD"
"NVlabs/MUNIT" -> "xunhuang1995/AdaIN-style" ["e"=1]
"NVlabs/MUNIT" -> "tkarras/progressive_growing_of_gans"
"NVlabs/MUNIT" -> "NVlabs/imaginaire" ["e"=1]
"NVlabs/MUNIT" -> "pfnet-research/sngan_projection"
"NVlabs/MUNIT" -> "clovaai/stargan-v2" ["e"=1]
"NVlabs/MUNIT" -> "heykeetae/Self-Attention-GAN"
"NVlabs/MUNIT" -> "taesungp/contrastive-unpaired-translation" ["e"=1]
"google/gin-config" -> "google/compare_gan" ["e"=1]
"rosinality/vq-vae-2-pytorch" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"rosinality/vq-vae-2-pytorch" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"IBM/MAX-Image-Resolution-Enhancer" -> "alexjc/neural-enhance" ["e"=1]
"xinario/awesome-gan-for-medical-imaging" -> "nightrome/really-awesome-gan" ["e"=1]
"luuuyi/CBAM.PyTorch" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"sjvasquez/handwriting-synthesis" -> "kaonashi-tyc/zi2zi" ["e"=1]
"sjvasquez/handwriting-synthesis" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"poloclub/ganlab" -> "CSAILVision/gandissect" ["e"=1]
"poloclub/ganlab" -> "google/compare_gan" ["e"=1]
"davidADSP/GDL_code" -> "GANs-in-Action/gans-in-action" ["e"=1]
"davidADSP/GDL_code" -> "eriklindernoren/Keras-GAN" ["e"=1]
"davidADSP/GDL_code" -> "timsainb/tensorflow2-generative-models" ["e"=1]
"podgorskiy/ALAE" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"podgorskiy/ALAE" -> "NVlabs/stylegan" ["e"=1]
"podgorskiy/ALAE" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"chaitanya100100/VAE-for-Image-Generation" -> "SashaMalysheva/Pytorch-VAE"
"chaitanya100100/VAE-for-Image-Generation" -> "EmilienDupont/vae-concrete"
"chaitanya100100/VAE-for-Image-Generation" -> "ksharsha/CifarVAE"
"cgarciae/pypeln" -> "cybertronai/imagenet18_old" ["e"=1]
"cgarciae/pypeln" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["e"=1]
"RedditSota/state-of-the-art-result-for-machine-learning-problems" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"notAI-tech/NudeNet" -> "ryanjay0/miles-deep" ["e"=1]
"goodfeli/dlbook_notation" -> "goodfeli/adversarial" ["e"=1]
"goodfeli/dlbook_notation" -> "wiseodd/generative-models" ["e"=1]
"milesial/Pytorch-UNet" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"milesial/Pytorch-UNet" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"Externalizable/bongo.cat" -> "httpcats/http.cat" ["e"=1]
"NVIDIA/pix2pixHD" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"NVIDIA/pix2pixHD" -> "yunjey/stargan"
"NVIDIA/pix2pixHD" -> "phillipi/pix2pix"
"NVIDIA/pix2pixHD" -> "tkarras/progressive_growing_of_gans"
"NVIDIA/pix2pixHD" -> "NVIDIA/vid2vid"
"NVIDIA/pix2pixHD" -> "NVlabs/SPADE"
"NVIDIA/pix2pixHD" -> "affinelayer/pix2pix-tensorflow"
"NVIDIA/pix2pixHD" -> "junyanz/CycleGAN"
"NVIDIA/pix2pixHD" -> "junyanz/iGAN"
"NVIDIA/pix2pixHD" -> "NVlabs/MUNIT"
"NVIDIA/pix2pixHD" -> "soumith/ganhacks"
"NVIDIA/pix2pixHD" -> "NVlabs/stylegan"
"NVIDIA/pix2pixHD" -> "junyanz/BicycleGAN"
"NVIDIA/pix2pixHD" -> "hindupuravinash/the-gan-zoo"
"NVIDIA/pix2pixHD" -> "DmitryUlyanov/deep-image-prior"
"taki0112/UGATIT" -> "NVlabs/stylegan" ["e"=1]
"taki0112/UGATIT" -> "lllyasviel/style2paints" ["e"=1]
"taki0112/UGATIT" -> "NVlabs/SPADE" ["e"=1]
"taki0112/UGATIT" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"taki0112/UGATIT" -> "run-youngjoo/SC-FEGAN" ["e"=1]
"znxlwm/UGATIT-pytorch" -> "NVlabs/FUNIT" ["e"=1]
"znxlwm/UGATIT-pytorch" -> "HsinYingLee/DRIT" ["e"=1]
"znxlwm/UGATIT-pytorch" -> "NVlabs/MUNIT" ["e"=1]
"znxlwm/UGATIT-pytorch" -> "mingyuliutw/UNIT" ["e"=1]
"znxlwm/UGATIT-pytorch" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"jantic/DeOldify" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"jantic/DeOldify" -> "NVlabs/stylegan" ["e"=1]
"jantic/DeOldify" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"jantic/DeOldify" -> "lllyasviel/style2paints" ["e"=1]
"jantic/DeOldify" -> "alexjc/neural-enhance" ["e"=1]
"jantic/DeOldify" -> "NVIDIA/vid2vid" ["e"=1]
"rohitrango/automatic-watermark-detection" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"NVlabs/noise2noise" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"kennyledet/Algorithm-Implementations" -> "kaishengtai/neuralart" ["e"=1]
"google-research/disentanglement_lib" -> "google/compare_gan" ["e"=1]
"pytorch/hub" -> "facebookresearch/pytorch_GAN_zoo" ["e"=1]
"diego-vicente/som-tsp" -> "NVIDIA/vid2vid" ["e"=1]
"elvisyjlin/SpatialAttentionGAN" -> "wdyin/GeoGAN"
"elvisyjlin/SpatialAttentionGAN" -> "elvisyjlin/AttGAN-PyTorch"
"elvisyjlin/SpatialAttentionGAN" -> "bluestyle97/STGAN-pytorch"
"wb14123/seq2seq-couplet" -> "lllyasviel/style2paints" ["e"=1]
"tensorspace-team/tensorspace" -> "NVIDIA/vid2vid" ["e"=1]
"benedekrozemberczki/awesome-decision-tree-papers" -> "timsainb/tensorflow2-generative-models" ["e"=1]
"NVIDIA/vid2vid" -> "NVIDIA/pix2pixHD"
"NVIDIA/vid2vid" -> "facebookresearch/DensePose" ["e"=1]
"NVIDIA/vid2vid" -> "tkarras/progressive_growing_of_gans"
"NVIDIA/vid2vid" -> "yunjey/stargan"
"NVIDIA/vid2vid" -> "NVlabs/SPADE"
"NVIDIA/vid2vid" -> "NVlabs/few-shot-vid2vid" ["e"=1]
"NVIDIA/vid2vid" -> "NVlabs/stylegan"
"NVIDIA/vid2vid" -> "NVIDIA/FastPhotoStyle"
"NVIDIA/vid2vid" -> "albertpumarola/GANimation"
"NVIDIA/vid2vid" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"NVIDIA/vid2vid" -> "NVlabs/imaginaire" ["e"=1]
"NVIDIA/vid2vid" -> "luanfujun/deep-painterly-harmonization"
"NVIDIA/vid2vid" -> "facebookresearch/Detectron" ["e"=1]
"NVIDIA/vid2vid" -> "openai/glow"
"NVIDIA/vid2vid" -> "phillipi/pix2pix"
"hzwer/ICCV2019-LearningToPaint" -> "NVlabs/FUNIT" ["e"=1]
"hzwer/ICCV2019-LearningToPaint" -> "NVlabs/SPADE" ["e"=1]
"hzwer/ICCV2019-LearningToPaint" -> "lzhbrian/image-to-image-papers" ["e"=1]
"hzwer/ICCV2019-LearningToPaint" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"NVlabs/SPADE" -> "NVIDIA/pix2pixHD"
"NVlabs/SPADE" -> "NVlabs/stylegan"
"NVlabs/SPADE" -> "NVlabs/imaginaire" ["e"=1]
"NVlabs/SPADE" -> "NVIDIA/vid2vid"
"NVlabs/SPADE" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"NVlabs/SPADE" -> "ajbrock/BigGAN-PyTorch"
"NVlabs/SPADE" -> "NVlabs/MUNIT"
"NVlabs/SPADE" -> "NVlabs/stylegan2" ["e"=1]
"NVlabs/SPADE" -> "tkarras/progressive_growing_of_gans"
"NVlabs/SPADE" -> "rosinality/stylegan2-pytorch" ["e"=1]
"NVlabs/SPADE" -> "run-youngjoo/SC-FEGAN"
"NVlabs/SPADE" -> "yunjey/stargan"
"NVlabs/SPADE" -> "tamarott/SinGAN" ["e"=1]
"NVlabs/SPADE" -> "clovaai/stargan-v2" ["e"=1]
"NVlabs/SPADE" -> "NVlabs/FUNIT"
"zllrunning/video-object-removal" -> "run-youngjoo/SC-FEGAN" ["e"=1]
"cybertronai/gradient-checkpointing" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"mseitzer/pytorch-fid" -> "sbarratt/inception-score-pytorch" ["e"=1]
"mseitzer/pytorch-fid" -> "bioinf-jku/TTUR" ["e"=1]
"mseitzer/pytorch-fid" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"tengshaofeng/ResidualAttentionNetwork-pytorch" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "huggingface/pytorch-pretrained-BigGAN"
"ajbrock/BigGAN-PyTorch" -> "google/compare_gan"
"ajbrock/BigGAN-PyTorch" -> "heykeetae/Self-Attention-GAN"
"ajbrock/BigGAN-PyTorch" -> "rosinality/stylegan2-pytorch" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "pfnet-research/sngan_projection"
"ajbrock/BigGAN-PyTorch" -> "facebookresearch/pytorch_GAN_zoo"
"ajbrock/BigGAN-PyTorch" -> "tkarras/progressive_growing_of_gans"
"ajbrock/BigGAN-PyTorch" -> "rosinality/style-based-gan-pytorch"
"ajbrock/BigGAN-PyTorch" -> "tamarott/SinGAN" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "sxhxliang/BigGAN-pytorch"
"ajbrock/BigGAN-PyTorch" -> "NVlabs/stylegan2-ada-pytorch" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "mit-han-lab/data-efficient-gans" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "clovaai/stargan-v2" ["e"=1]
"ajbrock/BigGAN-PyTorch" -> "yunjey/stargan"
"ajbrock/BigGAN-PyTorch" -> "mseitzer/pytorch-fid" ["e"=1]
"epfml/attention-cnn" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"hwalsuklee/tensorflow-generative-model-collections" -> "znxlwm/pytorch-generative-model-collections"
"hwalsuklee/tensorflow-generative-model-collections" -> "wiseodd/generative-models"
"hwalsuklee/tensorflow-generative-model-collections" -> "carpedm20/DCGAN-tensorflow"
"hwalsuklee/tensorflow-generative-model-collections" -> "soumith/ganhacks"
"hwalsuklee/tensorflow-generative-model-collections" -> "zhangqianhui/AdversarialNetsPapers"
"hwalsuklee/tensorflow-generative-model-collections" -> "igul222/improved_wgan_training"
"hwalsuklee/tensorflow-generative-model-collections" -> "tkarras/progressive_growing_of_gans"
"hwalsuklee/tensorflow-generative-model-collections" -> "google/compare_gan"
"hwalsuklee/tensorflow-generative-model-collections" -> "hindupuravinash/the-gan-zoo"
"hwalsuklee/tensorflow-generative-model-collections" -> "openai/improved-gan"
"hwalsuklee/tensorflow-generative-model-collections" -> "martinarjovsky/WassersteinGAN"
"hwalsuklee/tensorflow-generative-model-collections" -> "nightrome/really-awesome-gan"
"hwalsuklee/tensorflow-generative-model-collections" -> "eriklindernoren/Keras-GAN"
"hwalsuklee/tensorflow-generative-model-collections" -> "yunjey/stargan"
"hwalsuklee/tensorflow-generative-model-collections" -> "vahidk/EffectiveTensorflow" ["e"=1]
"anopara/texture-synthesis-nonparametric-sampling" -> "anopara/patch-based-texture-synthesis"
"anopara/texture-synthesis-nonparametric-sampling" -> "anopara/multi-resolution-texture-synthesis"
"yuanxiaosc/DeepImage-an-Image-to-Image-technology" -> "NVIDIA/pix2pixHD" ["e"=1]
"yuanxiaosc/DeepImage-an-Image-to-Image-technology" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"porn-vault/porn-vault" -> "ryanjay0/miles-deep" ["e"=1]
"hanzhanggit/StackGAN-Pytorch" -> "hanzhanggit/StackGAN-v2"
"hanzhanggit/StackGAN-Pytorch" -> "taoxugit/AttnGAN"
"hanzhanggit/StackGAN-Pytorch" -> "hanzhanggit/StackGAN"
"hanzhanggit/StackGAN-Pytorch" -> "aelnouby/Text-to-Image-Synthesis"
"hanzhanggit/StackGAN-Pytorch" -> "reedscot/icml2016"
"hanzhanggit/StackGAN-Pytorch" -> "lzhbrian/arbitrary-text-to-image-papers"
"hanzhanggit/StackGAN-Pytorch" -> "hanzhanggit/StackGAN-inception-model"
"hanzhanggit/StackGAN-Pytorch" -> "mrlibw/ControlGAN"
"hanzhanggit/StackGAN-Pytorch" -> "sbarratt/inception-score-pytorch"
"hanzhanggit/StackGAN-Pytorch" -> "ypxie/HDGan"
"hanzhanggit/StackGAN-Pytorch" -> "MinfengZhu/DM-GAN"
"hanzhanggit/StackGAN-Pytorch" -> "google/sg2im" ["e"=1]
"hanzhanggit/StackGAN-Pytorch" -> "qiaott/MirrorGAN"
"hanzhanggit/StackGAN-Pytorch" -> "tohinz/multiple-objects-gan"
"hanzhanggit/StackGAN-Pytorch" -> "davidstap/AttnGAN"
"yunjey/stargan" -> "clovaai/stargan-v2" ["e"=1]
"yunjey/stargan" -> "NVIDIA/pix2pixHD"
"yunjey/stargan" -> "tkarras/progressive_growing_of_gans"
"yunjey/stargan" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"yunjey/stargan" -> "junyanz/iGAN"
"yunjey/stargan" -> "NVlabs/MUNIT"
"yunjey/stargan" -> "wiseodd/generative-models"
"yunjey/stargan" -> "junyanz/CycleGAN"
"yunjey/stargan" -> "DmitryUlyanov/deep-image-prior"
"yunjey/stargan" -> "soumith/ganhacks"
"yunjey/stargan" -> "zhangqianhui/AdversarialNetsPapers"
"yunjey/stargan" -> "hindupuravinash/the-gan-zoo"
"yunjey/stargan" -> "albertpumarola/GANimation"
"yunjey/stargan" -> "NVIDIA/vid2vid"
"yunjey/stargan" -> "phillipi/pix2pix"
"shaoanlu/faceswap-GAN" -> "albertpumarola/GANimation" ["e"=1]
"shaoanlu/faceswap-GAN" -> "yunjey/stargan" ["e"=1]
"kongyanye/cwgan-gp" -> "cameronfabbri/cWGANs"
"naoto0804/pytorch-AdaIN" -> "NVlabs/MUNIT" ["e"=1]
"naoto0804/pytorch-AdaIN" -> "tomguluson92/StyleGAN_PyTorch" ["e"=1]
"naoto0804/pytorch-AdaIN" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"naoto0804/pytorch-AdaIN" -> "HsinYingLee/DRIT" ["e"=1]
"hzy46/Deep-Learning-21-Examples" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"bojone/vae" -> "bojone/attention" ["e"=1]
"bojone/vae" -> "AntixK/PyTorch-VAE" ["e"=1]
"bojone/vae" -> "bojone/gan"
"bojone/vae" -> "slim1017/VaDE" ["e"=1]
"bojone/vae" -> "jaanli/variational-autoencoder"
"bojone/vae" -> "wiseodd/generative-models"
"bojone/vae" -> "y0ast/VAE-TensorFlow"
"bojone/vae" -> "cdoersch/vae_tutorial"
"bojone/vae" -> "tkipf/gae" ["e"=1]
"bojone/vae" -> "timbmg/VAE-CVAE-MNIST"
"bojone/vae" -> "bojone/seq2seq" ["e"=1]
"bojone/vae" -> "timbmg/Sentence-VAE" ["e"=1]
"bojone/vae" -> "hwalsuklee/tensorflow-mnist-VAE"
"bojone/vae" -> "bojone/flow" ["e"=1]
"bojone/vae" -> "ethanluoyc/pytorch-vae"
"openai/glow" -> "chaiyujin/glow-pytorch" ["e"=1]
"openai/glow" -> "rosinality/glow-pytorch" ["e"=1]
"openai/glow" -> "LMescheder/GAN_stability"
"openai/glow" -> "tkarras/progressive_growing_of_gans"
"openai/glow" -> "google/compare_gan"
"openai/glow" -> "NVlabs/MUNIT"
"openai/glow" -> "pfnet-research/sngan_projection"
"openai/glow" -> "martinarjovsky/WassersteinGAN"
"openai/glow" -> "albertpumarola/GANimation"
"openai/glow" -> "yunjey/stargan"
"openai/glow" -> "wiseodd/generative-models"
"openai/glow" -> "NVIDIA/vid2vid"
"openai/glow" -> "soumith/ganhacks"
"openai/glow" -> "caogang/wgan-gp"
"openai/glow" -> "openai/improved-gan"
"swapagarwal/swag-for-dev" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"cchen156/Learning-to-See-in-the-Dark" -> "yunjey/stargan" ["e"=1]
"torch/torch7" -> "jcjohnson/neural-style" ["e"=1]
"NVlabs/ffhq-dataset" -> "NVlabs/stylegan" ["e"=1]
"NVlabs/ffhq-dataset" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"jorge-pessoa/pytorch-msssim" -> "nashory/pggan-pytorch" ["e"=1]
"MrGemy95/Tensorflow-Project-Template" -> "hwalsuklee/tensorflow-generative-model-collections" ["e"=1]
"reiinakano/arbitrary-image-stylization-tfjs" -> "reiinakano/fast-style-transfer-deeplearnjs" ["e"=1]
"reiinakano/arbitrary-image-stylization-tfjs" -> "lengstrom/fast-style-transfer" ["e"=1]
"reiinakano/arbitrary-image-stylization-tfjs" -> "jcjohnson/fast-neural-style" ["e"=1]
"lexfridman/deeptraffic" -> "lengstrom/fast-style-transfer" ["e"=1]
"keras-team/keras-applications" -> "eriklindernoren/Keras-GAN" ["e"=1]
"TwistedW/tensorflow-GANs" -> "TwistedW/pytorch-GANs"
"TwistedW/tensorflow-GANs" -> "taki0112/RelativisticGAN-Tensorflow"
"diegoalejogm/gans" -> "nashory/gans-awesome-applications"
"diegoalejogm/gans" -> "devnag/pytorch-generative-adversarial-networks"
"diegoalejogm/gans" -> "higgsfield/Capsule-Network-Tutorial" ["e"=1]
"diegoalejogm/gans" -> "jaanli/variational-autoencoder"
"diegoalejogm/gans" -> "openai/improved-gan"
"diegoalejogm/gans" -> "luisguiserrano/gans"
"diegoalejogm/gans" -> "diegoalejogm/deep-q-learning" ["e"=1]
"diegoalejogm/gans" -> "soumith/ganhacks"
"diegoalejogm/gans" -> "savan77/The-GAN-World"
"diegoalejogm/gans" -> "astorfi/TensorFlow-World-Resources" ["e"=1]
"diegoalejogm/gans" -> "yunjey/mnist-svhn-transfer"
"diegoalejogm/gans" -> "shayneobrien/generative-models"
"diegoalejogm/gans" -> "adeshpande3/Generative-Adversarial-Networks"
"diegoalejogm/gans" -> "wiseodd/generative-models"
"diegoalejogm/gans" -> "kvfrans/variational-autoencoder"
"heykeetae/Self-Attention-GAN" -> "brain-research/self-attention-gan"
"heykeetae/Self-Attention-GAN" -> "taki0112/Self-Attention-GAN-Tensorflow"
"heykeetae/Self-Attention-GAN" -> "ajbrock/BigGAN-PyTorch"
"heykeetae/Self-Attention-GAN" -> "caogang/wgan-gp"
"heykeetae/Self-Attention-GAN" -> "pfnet-research/sngan_projection"
"heykeetae/Self-Attention-GAN" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"heykeetae/Self-Attention-GAN" -> "google/compare_gan"
"heykeetae/Self-Attention-GAN" -> "junfu1115/DANet" ["e"=1]
"heykeetae/Self-Attention-GAN" -> "znxlwm/pytorch-generative-model-collections"
"heykeetae/Self-Attention-GAN" -> "igul222/improved_wgan_training"
"heykeetae/Self-Attention-GAN" -> "martinarjovsky/WassersteinGAN"
"heykeetae/Self-Attention-GAN" -> "mseitzer/pytorch-fid" ["e"=1]
"heykeetae/Self-Attention-GAN" -> "NVlabs/MUNIT"
"heykeetae/Self-Attention-GAN" -> "yunjey/stargan"
"heykeetae/Self-Attention-GAN" -> "tamarott/SinGAN" ["e"=1]
"albertpumarola/GANimation" -> "bendangnuksung/Image-OutPainting"
"albertpumarola/GANimation" -> "donydchen/ganimation_replicate" ["e"=1]
"albertpumarola/GANimation" -> "yunjey/stargan"
"albertpumarola/GANimation" -> "CSAILVision/gandissect"
"albertpumarola/GANimation" -> "switchablenorms/CelebAMask-HQ" ["e"=1]
"albertpumarola/GANimation" -> "NVlabs/MUNIT"
"albertpumarola/GANimation" -> "openai/glow"
"albertpumarola/GANimation" -> "NVIDIA/vid2vid"
"albertpumarola/GANimation" -> "apchenstu/Facial_Details_Synthesis" ["e"=1]
"albertpumarola/GANimation" -> "nyoki-mtl/pytorch-EverybodyDanceNow" ["e"=1]
"albertpumarola/GANimation" -> "grey-eye/talking-heads" ["e"=1]
"albertpumarola/GANimation" -> "tranluan/Nonlinear_Face_3DMM" ["e"=1]
"albertpumarola/GANimation" -> "yfeng95/face3d" ["e"=1]
"albertpumarola/GANimation" -> "cleardusk/3DDFA" ["e"=1]
"albertpumarola/GANimation" -> "shaoanlu/faceswap-GAN" ["e"=1]
"facebookresearch/pytorch_GAN_zoo" -> "ajbrock/BigGAN-PyTorch"
"facebookresearch/pytorch_GAN_zoo" -> "rosinality/style-based-gan-pytorch"
"facebookresearch/pytorch_GAN_zoo" -> "google/compare_gan"
"facebookresearch/pytorch_GAN_zoo" -> "rosinality/stylegan2-pytorch" ["e"=1]
"facebookresearch/pytorch_GAN_zoo" -> "nashory/pggan-pytorch"
"facebookresearch/pytorch_GAN_zoo" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"facebookresearch/pytorch_GAN_zoo" -> "pfnet-research/sngan_projection"
"facebookresearch/pytorch_GAN_zoo" -> "tkarras/progressive_growing_of_gans"
"facebookresearch/pytorch_GAN_zoo" -> "akanimax/pro_gan_pytorch"
"facebookresearch/pytorch_GAN_zoo" -> "torchgan/torchgan"
"facebookresearch/pytorch_GAN_zoo" -> "POSTECH-CVLab/PyTorch-StudioGAN" ["e"=1]
"facebookresearch/pytorch_GAN_zoo" -> "caogang/wgan-gp"
"facebookresearch/pytorch_GAN_zoo" -> "tomguluson92/StyleGAN_PyTorch"
"facebookresearch/pytorch_GAN_zoo" -> "LMescheder/GAN_stability"
"facebookresearch/pytorch_GAN_zoo" -> "tamarott/SinGAN" ["e"=1]
"tkarras/progressive_growing_of_gans" -> "NVIDIA/pix2pixHD"
"tkarras/progressive_growing_of_gans" -> "yunjey/stargan"
"tkarras/progressive_growing_of_gans" -> "NVlabs/stylegan"
"tkarras/progressive_growing_of_gans" -> "soumith/ganhacks"
"tkarras/progressive_growing_of_gans" -> "carpedm20/DCGAN-tensorflow"
"tkarras/progressive_growing_of_gans" -> "igul222/improved_wgan_training"
"tkarras/progressive_growing_of_gans" -> "wiseodd/generative-models"
"tkarras/progressive_growing_of_gans" -> "martinarjovsky/WassersteinGAN"
"tkarras/progressive_growing_of_gans" -> "junyanz/CycleGAN"
"tkarras/progressive_growing_of_gans" -> "ajbrock/BigGAN-PyTorch"
"tkarras/progressive_growing_of_gans" -> "openai/improved-gan"
"tkarras/progressive_growing_of_gans" -> "zhangqianhui/AdversarialNetsPapers"
"tkarras/progressive_growing_of_gans" -> "NVIDIA/vid2vid"
"tkarras/progressive_growing_of_gans" -> "NVlabs/MUNIT"
"tkarras/progressive_growing_of_gans" -> "hindupuravinash/the-gan-zoo"
"avinashpaliwal/Super-SloMo" -> "NVIDIA/vid2vid" ["e"=1]
"cosme12/SimpleCoin" -> "NVIDIA/vid2vid" ["e"=1]
"joshua-wu/deepfakes_faceswap" -> "yunjey/stargan" ["e"=1]
"joshua-wu/deepfakes_faceswap" -> "tjwei/GANotebooks" ["e"=1]
"tipsy/bubbly-bg" -> "reiinakano/fast-style-transfer-deeplearnjs" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "yunjey/stargan"
"DmitryUlyanov/deep-image-prior" -> "NVIDIA/pix2pixHD"
"DmitryUlyanov/deep-image-prior" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"DmitryUlyanov/deep-image-prior" -> "luanfujun/deep-photo-styletransfer"
"DmitryUlyanov/deep-image-prior" -> "junyanz/iGAN"
"DmitryUlyanov/deep-image-prior" -> "lengstrom/fast-style-transfer"
"DmitryUlyanov/deep-image-prior" -> "tkarras/progressive_growing_of_gans"
"DmitryUlyanov/deep-image-prior" -> "JiahuiYu/generative_inpainting" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "alexjc/neural-enhance"
"DmitryUlyanov/deep-image-prior" -> "tensorlayer/SRGAN" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "oarriaga/face_classification" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "KupynOrest/DeblurGAN" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "NVlabs/noise2noise" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "XPixelGroup/BasicSR" ["e"=1]
"DmitryUlyanov/deep-image-prior" -> "cszn/KAIR" ["e"=1]
"rosinality/glow-pytorch" -> "openai/glow" ["e"=1]
"naturomics/CapsNet-Tensorflow" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"naturomics/CapsNet-Tensorflow" -> "wiseodd/generative-models" ["e"=1]
"luanfujun/deep-painterly-harmonization" -> "luanfujun/deep-photo-styletransfer"
"luanfujun/deep-painterly-harmonization" -> "NVIDIA/vid2vid"
"luanfujun/deep-painterly-harmonization" -> "NVIDIA/FastPhotoStyle"
"luanfujun/deep-painterly-harmonization" -> "tkarras/progressive_growing_of_gans"
"luanfujun/deep-painterly-harmonization" -> "NVlabs/MUNIT"
"luanfujun/deep-painterly-harmonization" -> "CSAILVision/gandissect"
"luanfujun/deep-painterly-harmonization" -> "yunjey/stargan"
"luanfujun/deep-painterly-harmonization" -> "jcjohnson/fast-neural-style"
"luanfujun/deep-painterly-harmonization" -> "NVIDIA/pix2pixHD"
"luanfujun/deep-painterly-harmonization" -> "facebookresearch/DensePose" ["e"=1]
"luanfujun/deep-painterly-harmonization" -> "albertpumarola/GANimation"
"luanfujun/deep-painterly-harmonization" -> "lengstrom/fast-style-transfer"
"luanfujun/deep-painterly-harmonization" -> "bendangnuksung/Image-OutPainting"
"luanfujun/deep-painterly-harmonization" -> "run-youngjoo/SC-FEGAN"
"luanfujun/deep-painterly-harmonization" -> "junyanz/CycleGAN"
"Ha0Tang/AttentionGAN" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" ["e"=1]
"Ha0Tang/AttentionGAN" -> "HsinYingLee/DRIT" ["e"=1]
"Ha0Tang/AttentionGAN" -> "alokwhitewolf/Pytorch-Attention-Guided-CycleGAN" ["e"=1]
"Ha0Tang/AttentionGAN" -> "lzhbrian/image-to-image-papers" ["e"=1]
"Ha0Tang/AttentionGAN" -> "sangwoomo/instagan" ["e"=1]
"Luolc/AdaBound" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"SharpAI/DeepCamera" -> "huggingface/pytorch-pretrained-BigGAN" ["e"=1]
"karpathy/pytorch-made" -> "ptrblck/prog_gans_pytorch_inference" ["e"=1]
"stacklikemind/deepnude_official" -> "NVIDIA/pix2pixHD" ["e"=1]
"SummitKwan/transparent_latent_gan" -> "Puzer/stylegan-encoder" ["e"=1]
"SummitKwan/transparent_latent_gan" -> "CSAILVision/gandissect"
"SummitKwan/transparent_latent_gan" -> "LynnHo/AttGAN-Tensorflow"
"SummitKwan/transparent_latent_gan" -> "tkarras/progressive_growing_of_gans"
"SummitKwan/transparent_latent_gan" -> "run-youngjoo/SC-FEGAN"
"SummitKwan/transparent_latent_gan" -> "openai/glow"
"SummitKwan/transparent_latent_gan" -> "genforce/interfacegan" ["e"=1]
"SummitKwan/transparent_latent_gan" -> "albertpumarola/GANimation"
"SummitKwan/transparent_latent_gan" -> "NVlabs/MUNIT"
"SummitKwan/transparent_latent_gan" -> "yunjey/stargan"
"SummitKwan/transparent_latent_gan" -> "NVlabs/FUNIT"
"SummitKwan/transparent_latent_gan" -> "pbaylies/stylegan-encoder" ["e"=1]
"SummitKwan/transparent_latent_gan" -> "csmliu/STGAN"
"SummitKwan/transparent_latent_gan" -> "NVlabs/stylegan"
"SummitKwan/transparent_latent_gan" -> "switchablenorms/CelebAMask-HQ" ["e"=1]
"davidcpage/cifar10-fast" -> "fastai/imagenet-fast"
"davidcpage/cifar10-fast" -> "f-dangel/cockpit" ["e"=1]
"davidcpage/cifar10-fast" -> "cybertronai/imagenet18_old"
"davidcpage/cifar10-fast" -> "rwightman/gen-efficientnet-pytorch" ["e"=1]
"davidcpage/cifar10-fast" -> "anokland/local-loss" ["e"=1]
"codyogden/killedbygoogle" -> "httpcats/http.cat" ["e"=1]
"grey-eye/talking-heads" -> "NVlabs/FUNIT" ["e"=1]
"grey-eye/talking-heads" -> "albertpumarola/GANimation" ["e"=1]
"bernhard2202/improved-video-gan" -> "cvondrick/videogan" ["e"=1]
"taoxugit/AttnGAN" -> "hanzhanggit/StackGAN-v2"
"taoxugit/AttnGAN" -> "hanzhanggit/StackGAN"
"taoxugit/AttnGAN" -> "hanzhanggit/StackGAN-Pytorch"
"taoxugit/AttnGAN" -> "reedscot/icml2016"
"taoxugit/AttnGAN" -> "MinfengZhu/DM-GAN"
"taoxugit/AttnGAN" -> "aelnouby/Text-to-Image-Synthesis"
"taoxugit/AttnGAN" -> "mrlibw/ControlGAN"
"taoxugit/AttnGAN" -> "jamesli1618/Obj-GAN"
"taoxugit/AttnGAN" -> "tobran/DF-GAN"
"taoxugit/AttnGAN" -> "google/sg2im" ["e"=1]
"taoxugit/AttnGAN" -> "lzhbrian/arbitrary-text-to-image-papers"
"taoxugit/AttnGAN" -> "zsdonghao/text-to-image"
"taoxugit/AttnGAN" -> "qiaott/MirrorGAN"
"taoxugit/AttnGAN" -> "davidstap/AttnGAN"
"taoxugit/AttnGAN" -> "heykeetae/Self-Attention-GAN"
"harveyslash/Deep-Image-Analogy-PyTorch" -> "Ben-Louis/Deep-Image-Analogy-PyTorch"
"google-research/tensor2robot" -> "timsainb/tensorflow2-generative-models" ["e"=1]
"danmacnish/cartoonify" -> "googlecreativelab/quickdraw-dataset" ["e"=1]
"elgris/microservice-app-example" -> "MrNothing/AI-Blocks" ["e"=1]
"andabi/deep-voice-conversion" -> "MrNothing/AI-Blocks" ["e"=1]
"andabi/deep-voice-conversion" -> "yunjey/stargan" ["e"=1]
"andabi/deep-voice-conversion" -> "junyanz/iGAN" ["e"=1]
"salu133445/musegan" -> "magenta/magenta" ["e"=1]
"akanimax/pro_gan_pytorch" -> "nashory/pggan-pytorch"
"akanimax/pro_gan_pytorch" -> "akanimax/BMSG-GAN"
"akanimax/pro_gan_pytorch" -> "akanimax/pro_gan_pytorch-examples"
"akanimax/pro_gan_pytorch" -> "akanimax/msg-gan-v1"
"akanimax/pro_gan_pytorch" -> "tomguluson92/StyleGAN_PyTorch"
"akanimax/pro_gan_pytorch" -> "rosinality/style-based-gan-pytorch"
"akanimax/pro_gan_pytorch" -> "ptrblck/prog_gans_pytorch_inference"
"akanimax/pro_gan_pytorch" -> "lernapparat/lernapparat" ["e"=1]
"akanimax/pro_gan_pytorch" -> "facebookresearch/pytorch_GAN_zoo"
"akanimax/pro_gan_pytorch" -> "pbaylies/stylegan-encoder" ["e"=1]
"akanimax/pro_gan_pytorch" -> "akanimax/T2F"
"akanimax/pro_gan_pytorch" -> "akanimax/msg-stylegan-tf"
"akanimax/pro_gan_pytorch" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"akanimax/pro_gan_pytorch" -> "huangzh13/StyleGAN.pytorch" ["e"=1]
"akanimax/pro_gan_pytorch" -> "tomguluson92/StyleGAN2_PyTorch"
"youyuge34/PI-REC" -> "lzhbrian/image-to-image-papers" ["e"=1]
"youyuge34/PI-REC" -> "lllyasviel/style2paints" ["e"=1]
"youyuge34/PI-REC" -> "luanfujun/deep-painterly-harmonization" ["e"=1]
"youyuge34/PI-REC" -> "run-youngjoo/SC-FEGAN" ["e"=1]
"youyuge34/PI-REC" -> "NVlabs/SPADE" ["e"=1]
"idealo/image-super-resolution" -> "alexjc/neural-enhance" ["e"=1]
"PacktPublishing/Generative-Adversarial-Networks-Projects" -> "PacktPublishing/Generative-Adversarial-Networks-Cookbook"
"PacktPublishing/Generative-Adversarial-Networks-Projects" -> "PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras"
"PacktPublishing/Generative-Adversarial-Networks-Projects" -> "PacktPublishing/Learning-Generative-Adversarial-Networks"
"tensorflow/adanet" -> "bendangnuksung/Image-OutPainting" ["e"=1]
"ybayle/awesome-deep-learning-music" -> "magenta/magenta" ["e"=1]
"erikaduan/r_tips" -> "googlecreativelab/quickdraw-dataset" ["e"=1]
"Jongchan/attention-module" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" -> "roatienza/Deep-Learning-Experiments" ["e"=1]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" -> "eriklindernoren/Keras-GAN" ["e"=1]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" -> "GANs-in-Action/gans-in-action" ["e"=1]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" -> "PacktPublishing/Generative-Adversarial-Networks-Projects" ["e"=1]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" -> "bstriner/keras-adversarial" ["e"=1]
"remicnrd/ml_cheatsheet" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["e"=1]
"taki0112/GAN_Metrics-Tensorflow" -> "lzhbrian/metrics"
"taki0112/GAN_Metrics-Tensorflow" -> "xuqiantong/GAN-Metrics"
"taki0112/GAN_Metrics-Tensorflow" -> "tsc2017/Frechet-Inception-Distance"
"taki0112/GAN_Metrics-Tensorflow" -> "tsc2017/Inception-Score"
"taki0112/GAN_Metrics-Tensorflow" -> "nnUyi/Inception-Score"
"taki0112/GAN_Metrics-Tensorflow" -> "bioinf-jku/TTUR"
"taki0112/GAN_Metrics-Tensorflow" -> "taki0112/BigGAN-Tensorflow"
"taki0112/GAN_Metrics-Tensorflow" -> "sbarratt/inception-score-pytorch"
"taki0112/GAN_Metrics-Tensorflow" -> "taki0112/SphereGAN-Tensorflow"
"taki0112/GAN_Metrics-Tensorflow" -> "abdulfatir/gan-metrics-pytorch"
"taki0112/GAN_Metrics-Tensorflow" -> "taki0112/RelativisticGAN-Tensorflow"
"ericjang/normalizing-flows-tutorial" -> "openai/iaf" ["e"=1]
"janesjanes/Pytorch-TextureGAN" -> "Cuiyirui/TextureGAN"
"AlexiaJM/RelativisticGAN" -> "pfnet-research/sngan_projection"
"AlexiaJM/RelativisticGAN" -> "LMescheder/GAN_stability"
"AlexiaJM/RelativisticGAN" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"AlexiaJM/RelativisticGAN" -> "AlexiaJM/relativistic-f-divergences"
"AlexiaJM/RelativisticGAN" -> "HsinYingLee/DRIT"
"AlexiaJM/RelativisticGAN" -> "bioinf-jku/TTUR"
"AlexiaJM/RelativisticGAN" -> "google/compare_gan"
"AlexiaJM/RelativisticGAN" -> "roimehrez/contextualLoss" ["e"=1]
"AlexiaJM/RelativisticGAN" -> "akanimax/BMSG-GAN"
"AlexiaJM/RelativisticGAN" -> "NVlabs/MUNIT"
"AlexiaJM/RelativisticGAN" -> "nashory/pggan-pytorch"
"AlexiaJM/RelativisticGAN" -> "godisboy/SN-GAN"
"AlexiaJM/RelativisticGAN" -> "brain-research/self-attention-gan"
"AlexiaJM/RelativisticGAN" -> "AlexiaJM/Deep-learning-with-cats"
"AlexiaJM/RelativisticGAN" -> "caogang/wgan-gp"
"chaiyujin/glow-pytorch" -> "openai/glow" ["e"=1]
"lzhbrian/image-to-image-papers" -> "HsinYingLee/DRIT"
"lzhbrian/image-to-image-papers" -> "NVlabs/MUNIT"
"lzhbrian/image-to-image-papers" -> "weihaox/awesome-image-translation" ["e"=1]
"lzhbrian/image-to-image-papers" -> "sangwoomo/instagan"
"lzhbrian/image-to-image-papers" -> "NVlabs/FUNIT"
"lzhbrian/image-to-image-papers" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"lzhbrian/image-to-image-papers" -> "Ha0Tang/AttentionGAN" ["e"=1]
"lzhbrian/image-to-image-papers" -> "HelenMao/MSGAN"
"lzhbrian/image-to-image-papers" -> "Ha0Tang/SelectionGAN" ["e"=1]
"lzhbrian/image-to-image-papers" -> "Prinsphield/ELEGANT"
"lzhbrian/image-to-image-papers" -> "csmliu/STGAN"
"lzhbrian/image-to-image-papers" -> "mingyuliutw/UNIT"
"lzhbrian/image-to-image-papers" -> "junyanz/BicycleGAN"
"lzhbrian/image-to-image-papers" -> "albertpumarola/GANimation"
"lzhbrian/image-to-image-papers" -> "tamarott/SinGAN" ["e"=1]
"bojone/gan-qp" -> "bojone/o-gan"
"bojone/gan-qp" -> "bojone/T-GANs"
"bojone/gan-qp" -> "RahulBhalley/gan-qp.pytorch"
"CSAILVision/gandissect" -> "albertpumarola/GANimation"
"CSAILVision/gandissect" -> "google/compare_gan"
"CSAILVision/gandissect" -> "nyoki-mtl/pytorch-EverybodyDanceNow" ["e"=1]
"CSAILVision/gandissect" -> "bendangnuksung/Image-OutPainting"
"CSAILVision/gandissect" -> "ajbrock/BigGAN-PyTorch"
"CSAILVision/gandissect" -> "cybertronai/imagenet18_old"
"CSAILVision/gandissect" -> "NVlabs/MUNIT"
"CSAILVision/gandissect" -> "LMescheder/GAN_stability"
"CSAILVision/gandissect" -> "google/sg2im" ["e"=1]
"CSAILVision/gandissect" -> "NVIDIA/vid2vid"
"CSAILVision/gandissect" -> "poloclub/ganlab" ["e"=1]
"CSAILVision/gandissect" -> "heykeetae/Self-Attention-GAN"
"CSAILVision/gandissect" -> "junyanz/BicycleGAN"
"CSAILVision/gandissect" -> "SummitKwan/transparent_latent_gan"
"CSAILVision/gandissect" -> "tkarras/progressive_growing_of_gans"
"akanimax/BMSG-GAN" -> "akanimax/msg-stylegan-tf"
"akanimax/BMSG-GAN" -> "akanimax/msg-gan-v1"
"akanimax/BMSG-GAN" -> "akanimax/big-discriminator-batch-spoofing-gan"
"akanimax/BMSG-GAN" -> "akanimax/pro_gan_pytorch"
"akanimax/BMSG-GAN" -> "kam1107/RealnessGAN" ["e"=1]
"akanimax/BMSG-GAN" -> "akanimax/T2F"
"akanimax/BMSG-GAN" -> "rosinality/style-based-gan-pytorch"
"akanimax/BMSG-GAN" -> "AlexiaJM/RelativisticGAN"
"akanimax/BMSG-GAN" -> "LMescheder/GAN_stability"
"akanimax/BMSG-GAN" -> "ajbrock/BigGAN-PyTorch"
"akanimax/BMSG-GAN" -> "pfnet-research/sngan_projection"
"akanimax/BMSG-GAN" -> "facebookresearch/pytorch_GAN_zoo"
"akanimax/BMSG-GAN" -> "mit-han-lab/data-efficient-gans" ["e"=1]
"akanimax/BMSG-GAN" -> "rosinality/stylegan2-pytorch" ["e"=1]
"akanimax/BMSG-GAN" -> "nashory/pggan-pytorch"
"weilinie/RelGAN" -> "elvisyjlin/RelGAN-PyTorch" ["e"=1]
"huggingface/pytorch-pretrained-BigGAN" -> "ajbrock/BigGAN-PyTorch"
"huggingface/pytorch-pretrained-BigGAN" -> "sxhxliang/BigGAN-pytorch"
"huggingface/pytorch-pretrained-BigGAN" -> "LMescheder/GAN_stability"
"huggingface/pytorch-pretrained-BigGAN" -> "pfnet-research/sngan_projection"
"huggingface/pytorch-pretrained-BigGAN" -> "rosinality/style-based-gan-pytorch"
"huggingface/pytorch-pretrained-BigGAN" -> "facebookresearch/pytorch_GAN_zoo"
"huggingface/pytorch-pretrained-BigGAN" -> "taki0112/BigGAN-Tensorflow"
"huggingface/pytorch-pretrained-BigGAN" -> "akanimax/BMSG-GAN"
"huggingface/pytorch-pretrained-BigGAN" -> "google/compare_gan"
"huggingface/pytorch-pretrained-BigGAN" -> "taoxugit/AttnGAN"
"huggingface/pytorch-pretrained-BigGAN" -> "akanimax/pro_gan_pytorch"
"huggingface/pytorch-pretrained-BigGAN" -> "mit-han-lab/data-efficient-gans" ["e"=1]
"huggingface/pytorch-pretrained-BigGAN" -> "CSAILVision/gandissect"
"huggingface/pytorch-pretrained-BigGAN" -> "mkocabas/EpipolarPose" ["e"=1]
"huggingface/pytorch-pretrained-BigGAN" -> "torchgan/torchgan"
"NVlabs/FUNIT" -> "NVlabs/MUNIT"
"NVlabs/FUNIT" -> "HsinYingLee/DRIT"
"NVlabs/FUNIT" -> "mingyuliutw/UNIT"
"NVlabs/FUNIT" -> "lzhbrian/image-to-image-papers"
"NVlabs/FUNIT" -> "shaoanlu/fewshot-face-translation-GAN" ["e"=1]
"NVlabs/FUNIT" -> "sangwoomo/instagan"
"NVlabs/FUNIT" -> "rosinality/style-based-gan-pytorch"
"NVlabs/FUNIT" -> "grey-eye/talking-heads" ["e"=1]
"NVlabs/FUNIT" -> "genforce/interfacegan" ["e"=1]
"NVlabs/FUNIT" -> "tamarott/SinGAN" ["e"=1]
"NVlabs/FUNIT" -> "clovaai/stargan-v2" ["e"=1]
"NVlabs/FUNIT" -> "HelenMao/MSGAN"
"NVlabs/FUNIT" -> "znxlwm/UGATIT-pytorch" ["e"=1]
"NVlabs/FUNIT" -> "ajbrock/BigGAN-PyTorch"
"NVlabs/FUNIT" -> "junyanz/BicycleGAN"
"LMescheder/GAN_stability" -> "pfnet-research/sngan_projection"
"LMescheder/GAN_stability" -> "AlexiaJM/RelativisticGAN"
"LMescheder/GAN_stability" -> "google/compare_gan"
"LMescheder/GAN_stability" -> "bioinf-jku/TTUR"
"LMescheder/GAN_stability" -> "openai/glow"
"LMescheder/GAN_stability" -> "rosinality/style-based-gan-pytorch"
"LMescheder/GAN_stability" -> "ajbrock/BigGAN-PyTorch"
"LMescheder/GAN_stability" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"LMescheder/GAN_stability" -> "sbarratt/inception-score-pytorch"
"LMescheder/GAN_stability" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"LMescheder/GAN_stability" -> "NVlabs/MUNIT"
"LMescheder/GAN_stability" -> "CSAILVision/gandissect"
"LMescheder/GAN_stability" -> "HsinYingLee/DRIT"
"LMescheder/GAN_stability" -> "autonomousvision/graf" ["e"=1]
"LMescheder/GAN_stability" -> "huggingface/pytorch-pretrained-BigGAN"
"kewellcjj/pytorch-multiple-style-transfer" -> "MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer"
"joel-simon/ganbreeder" -> "robbiebarrat/art-DCGAN" ["e"=1]
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification"
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "MingtaoGuo/Calligraphic-Images-Denoising-by-GAN"
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "yunchenlo/Font2Font"
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "iamsohard/ChineseCalligraphyGenerator"
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "zhuojg/chinese-calligraphy-dataset"
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"jiqizhixin/ML-Tutorial-Experiment" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"jiqizhixin/ML-Tutorial-Experiment" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"jiqizhixin/ML-Tutorial-Experiment" -> "hindupuravinash/the-gan-zoo" ["e"=1]
"jiqizhixin/ML-Tutorial-Experiment" -> "wiseodd/generative-models" ["e"=1]
"nathanhubens/Autoencoders" -> "Nana0606/autoencoder"
"nathanhubens/Autoencoders" -> "wblgers/tensorflow_stacked_denoising_autoencoder"
"HelenMao/MSGAN" -> "HsinYingLee/DRIT"
"HelenMao/MSGAN" -> "Ha0Tang/SelectionGAN" ["e"=1]
"HelenMao/MSGAN" -> "sangwoomo/instagan"
"HelenMao/MSGAN" -> "Xiaoming-Yu/DMIT"
"HelenMao/MSGAN" -> "NVlabs/FUNIT"
"HelenMao/MSGAN" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"HelenMao/MSGAN" -> "lzhbrian/image-to-image-papers"
"HelenMao/MSGAN" -> "sbarratt/inception-score-pytorch"
"HelenMao/MSGAN" -> "bioinf-jku/TTUR"
"HelenMao/MSGAN" -> "junyanz/BicycleGAN"
"HelenMao/MSGAN" -> "WonwoongCho/GDWCT" ["e"=1]
"HelenMao/MSGAN" -> "HsinYingLee/MDMM"
"HelenMao/MSGAN" -> "egorzakharov/PerceptualGAN"
"HelenMao/MSGAN" -> "maga33/DSGAN"
"HelenMao/MSGAN" -> "kkanshul/finegan" ["e"=1]
"koz4k/dni-pytorch" -> "andrewliao11/dni.pytorch"
"koz4k/dni-pytorch" -> "slowbull/DDG"
"koz4k/dni-pytorch" -> "ptrblck/prog_gans_pytorch_inference"
"taehoonlee/tensornets" -> "yunjey/domain-transfer-network" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "taesungp/contrastive-unpaired-translation" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"aitorzip/PyTorch-CycleGAN" -> "arnab39/cycleGAN-PyTorch"
"aitorzip/PyTorch-CycleGAN" -> "mrzhu-cool/pix2pix-pytorch"
"aitorzip/PyTorch-CycleGAN" -> "Lornatang/CycleGAN-PyTorch"
"aitorzip/PyTorch-CycleGAN" -> "Ha0Tang/AttentionGAN" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "NVlabs/MUNIT"
"aitorzip/PyTorch-CycleGAN" -> "togheppi/CycleGAN"
"aitorzip/PyTorch-CycleGAN" -> "Po-Hsun-Su/pytorch-ssim" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "mseitzer/pytorch-fid" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "yunjey/mnist-svhn-transfer"
"aitorzip/PyTorch-CycleGAN" -> "heykeetae/Self-Attention-GAN"
"aitorzip/PyTorch-CycleGAN" -> "caogang/wgan-gp"
"aitorzip/PyTorch-CycleGAN" -> "znxlwm/UGATIT-pytorch" ["e"=1]
"aitorzip/PyTorch-CycleGAN" -> "rosinality/stylegan2-pytorch" ["e"=1]
"znxlwm/pytorch-generative-model-collections" -> "hwalsuklee/tensorflow-generative-model-collections"
"znxlwm/pytorch-generative-model-collections" -> "wiseodd/generative-models"
"znxlwm/pytorch-generative-model-collections" -> "martinarjovsky/WassersteinGAN"
"znxlwm/pytorch-generative-model-collections" -> "heykeetae/Self-Attention-GAN"
"znxlwm/pytorch-generative-model-collections" -> "igul222/improved_wgan_training"
"znxlwm/pytorch-generative-model-collections" -> "caogang/wgan-gp"
"znxlwm/pytorch-generative-model-collections" -> "soumith/ganhacks"
"znxlwm/pytorch-generative-model-collections" -> "zhangqianhui/AdversarialNetsPapers"
"znxlwm/pytorch-generative-model-collections" -> "nightrome/really-awesome-gan"
"znxlwm/pytorch-generative-model-collections" -> "google/compare_gan"
"znxlwm/pytorch-generative-model-collections" -> "eriklindernoren/PyTorch-GAN"
"znxlwm/pytorch-generative-model-collections" -> "openai/improved-gan"
"znxlwm/pytorch-generative-model-collections" -> "hindupuravinash/the-gan-zoo"
"znxlwm/pytorch-generative-model-collections" -> "yunjey/stargan"
"znxlwm/pytorch-generative-model-collections" -> "tkarras/progressive_growing_of_gans"
"yu4u/noise2noise" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"1Konny/FactorVAE" -> "bhpfelix/Variational-Autoencoder-PyTorch" ["e"=1]
"1Konny/Beta-VAE" -> "ethanluoyc/pytorch-vae" ["e"=1]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "alokwhitewolf/Pytorch-Attention-Guided-CycleGAN"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "Ha0Tang/AttentionGAN" ["e"=1]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "HsinYingLee/DRIT"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "yhlleo/uaggan"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "sangwoomo/instagan"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "Xiaoming-Yu/SingleGAN"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "Ha0Tang/SelectionGAN" ["e"=1]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "Prinsphield/ELEGANT"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "HsinYingLee/MDMM"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "lzhbrian/image-to-image-papers"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "HelenMao/MSGAN"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "brownvc/ganimorph"
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "hyperplane-lab/ACL-GAN" ["e"=1]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "alpc91/NICE-GAN-pytorch" ["e"=1]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" -> "NVlabs/MUNIT"
"magenta/magenta-js" -> "magenta/magenta" ["e"=1]
"CortexFoundation/StyleTransferTrilogy" -> "hzy46/fast-neural-style-tensorflow" ["e"=1]
"jsn5/dancenet" -> "albertpumarola/GANimation" ["e"=1]
"jsn5/dancenet" -> "bendangnuksung/Image-OutPainting" ["e"=1]
"jsn5/dancenet" -> "openai/glow" ["e"=1]
"googlecreativelab/open-nsynth-super" -> "magenta/magenta" ["e"=1]
"minimaxir/person-blocker" -> "luanfujun/deep-painterly-harmonization" ["e"=1]
"minimaxir/person-blocker" -> "NVlabs/MUNIT" ["e"=1]
"minimaxir/person-blocker" -> "kaishengtai/neuralart" ["e"=1]
"minimaxir/person-blocker" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"minimaxir/person-blocker" -> "cybertronai/imagenet18_old" ["e"=1]
"minimaxir/person-blocker" -> "CSAILVision/gandissect" ["e"=1]
"hzy46/TensorFlow-Time-Series-Examples" -> "hzy46/fast-neural-style-tensorflow" ["e"=1]
"brain-research/self-attention-gan" -> "heykeetae/Self-Attention-GAN"
"brain-research/self-attention-gan" -> "pfnet-research/sngan_projection"
"brain-research/self-attention-gan" -> "taki0112/Self-Attention-GAN-Tensorflow"
"brain-research/self-attention-gan" -> "bioinf-jku/TTUR"
"brain-research/self-attention-gan" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"brain-research/self-attention-gan" -> "ajbrock/BigGAN-PyTorch"
"brain-research/self-attention-gan" -> "google/compare_gan"
"brain-research/self-attention-gan" -> "LMescheder/GAN_stability"
"brain-research/self-attention-gan" -> "voletiv/self-attention-GAN-pytorch"
"brain-research/self-attention-gan" -> "AlexiaJM/RelativisticGAN"
"brain-research/self-attention-gan" -> "igul222/improved_wgan_training"
"brain-research/self-attention-gan" -> "sxhxliang/BigGAN-pytorch"
"brain-research/self-attention-gan" -> "openai/improved-gan"
"brain-research/self-attention-gan" -> "CSAILVision/gandissect"
"brain-research/self-attention-gan" -> "HsinYingLee/DRIT"
"adobe/antialiased-cnns" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"willylulu/celeba-hq-modified" -> "willylulu/RelGAN"
"willylulu/celeba-hq-modified" -> "nperraud/download-celebA-HQ"
"elvisyjlin/AttGAN-PyTorch" -> "LynnHo/AttGAN-Tensorflow"
"elvisyjlin/AttGAN-PyTorch" -> "bluestyle97/STGAN-pytorch"
"elvisyjlin/AttGAN-PyTorch" -> "csmliu/STGAN"
"elvisyjlin/AttGAN-PyTorch" -> "elvisyjlin/SpatialAttentionGAN"
"elvisyjlin/AttGAN-PyTorch" -> "LynnHo/HD-CelebA-Cropper"
"elvisyjlin/AttGAN-PyTorch" -> "elvisyjlin/RelGAN-PyTorch"
"elvisyjlin/AttGAN-PyTorch" -> "imlixinyang/HiSD" ["e"=1]
"elvisyjlin/AttGAN-PyTorch" -> "genforce/interfacegan" ["e"=1]
"elvisyjlin/AttGAN-PyTorch" -> "willylulu/celeba-hq-modified"
"elvisyjlin/AttGAN-PyTorch" -> "younesbelkada/interfacegan"
"khanrc/tf.gans-comparison" -> "hmi88/BEGAN-tensorflow"
"khanrc/tf.gans-comparison" -> "GKalliatakis/Delving-deep-into-GANs"
"khanrc/tf.gans-comparison" -> "carpedm20/BEGAN-tensorflow"
"khanrc/tf.gans-comparison" -> "minhnhat93/tf-SNDCGAN"
"khanrc/tf.gans-comparison" -> "kodalinaveen3/DRAGAN" ["e"=1]
"khanrc/tf.gans-comparison" -> "clvrai/SSGAN-Tensorflow"
"khanrc/tf.gans-comparison" -> "shekkizh/WassersteinGAN.tensorflow"
"khanrc/tf.gans-comparison" -> "pfnet-research/sngan_projection"
"khanrc/tf.gans-comparison" -> "pfnet-research/chainer-gan-lib" ["e"=1]
"khanrc/tf.gans-comparison" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"khanrc/tf.gans-comparison" -> "carpedm20/simulated-unsupervised-tensorflow"
"khanrc/tf.gans-comparison" -> "sanghoon/tf-exercise-gan"
"khanrc/tf.gans-comparison" -> "hwalsuklee/tensorflow-generative-model-collections"
"khanrc/tf.gans-comparison" -> "mjdietzx/SimGAN"
"khanrc/tf.gans-comparison" -> "fairytale0011/Conditional-WassersteinGAN"
"artix41/awesome-transfer-learning" -> "nightrome/really-awesome-gan" ["e"=1]
"davidstap/AttnGAN" -> "Kyfafyd/MirrorGAN"
"rosinality/style-based-gan-pytorch" -> "rosinality/stylegan2-pytorch" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "huangzh13/StyleGAN.pytorch" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "tomguluson92/StyleGAN_PyTorch"
"rosinality/style-based-gan-pytorch" -> "lernapparat/lernapparat" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "genforce/interfacegan" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "Puzer/stylegan-encoder" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "ajbrock/BigGAN-PyTorch"
"rosinality/style-based-gan-pytorch" -> "facebookresearch/pytorch_GAN_zoo"
"rosinality/style-based-gan-pytorch" -> "nashory/pggan-pytorch"
"rosinality/style-based-gan-pytorch" -> "NVlabs/FUNIT"
"rosinality/style-based-gan-pytorch" -> "LMescheder/GAN_stability"
"rosinality/style-based-gan-pytorch" -> "lucidrains/stylegan2-pytorch" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "NVlabs/stylegan2-ada-pytorch" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "eladrich/pixel2style2pixel" ["e"=1]
"rosinality/style-based-gan-pytorch" -> "akanimax/pro_gan_pytorch"
"timbmg/VAE-CVAE-MNIST" -> "YixinChen-AI/CVAE-GAN-zoos-PyTorch-Beginner" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "hujinsen/pytorch_VAE_CVAE"
"timbmg/VAE-CVAE-MNIST" -> "jaanli/variational-autoencoder"
"timbmg/VAE-CVAE-MNIST" -> "ethanluoyc/pytorch-vae"
"timbmg/VAE-CVAE-MNIST" -> "sksq96/pytorch-vae"
"timbmg/VAE-CVAE-MNIST" -> "unnir/cVAE"
"timbmg/VAE-CVAE-MNIST" -> "AntixK/PyTorch-VAE" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "hwalsuklee/tensorflow-mnist-CVAE"
"timbmg/VAE-CVAE-MNIST" -> "1Konny/Beta-VAE" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "bojone/vae"
"timbmg/VAE-CVAE-MNIST" -> "emited/VariationalRecurrentNeuralNetwork" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "timbmg/Sentence-VAE" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "ucals/cvae"
"timbmg/VAE-CVAE-MNIST" -> "YannDubs/disentangling-vae" ["e"=1]
"timbmg/VAE-CVAE-MNIST" -> "kvfrans/variational-autoencoder"
"Ha0Tang/SelectionGAN" -> "HelenMao/MSGAN" ["e"=1]
"Ha0Tang/SelectionGAN" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" ["e"=1]
"marcbelmont/cnn-watermark-removal" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"google-research/exoplanet-ml" -> "cybertronai/imagenet18_old" ["e"=1]
"google-research/exoplanet-ml" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "reiinakano/arbitrary-image-stylization-tfjs" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "tipsy/bubbly-bg" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "reiinakano/gan-playground" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "tensorflow/tfjs-core" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "yusuketomoto/chainer-fast-neuralstyle"
"reiinakano/fast-style-transfer-deeplearnjs" -> "jcjohnson/fast-neural-style"
"reiinakano/fast-style-transfer-deeplearnjs" -> "pauli-space/foundations_for_deep_learning" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "lengstrom/fast-style-transfer"
"reiinakano/fast-style-transfer-deeplearnjs" -> "awentzonline/image-analogies"
"reiinakano/fast-style-transfer-deeplearnjs" -> "ajbrock/Neural-Photo-Editor"
"reiinakano/fast-style-transfer-deeplearnjs" -> "tomepel/Technical_Book_DL" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "msracver/Deep-Image-Analogy"
"reiinakano/fast-style-transfer-deeplearnjs" -> "kaonashi-tyc/Rewrite" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "eridgd/WCT-TF" ["e"=1]
"reiinakano/fast-style-transfer-deeplearnjs" -> "sunshineatnoon/PytorchWCT" ["e"=1]
"ProGamerGov/neural-style-pt" -> "titu1994/Neural-Style-Transfer" ["e"=1]
"ProGamerGov/neural-style-pt" -> "cysmith/neural-style-tf" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "cybertronai/imagenet18_old"
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "bendangnuksung/Image-OutPainting"
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "nyoki-mtl/pytorch-EverybodyDanceNow" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "salesforce/decaNLP" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "google-research/exoplanet-ml" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "CSAILVision/gandissect"
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "tensorflow/adanet" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "facebookresearch/DensePose" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "higgsfield-ai/higgsfield" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "albertpumarola/GANimation"
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "NVIDIA/waveglow" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "higgsfield/Capsule-Network-Tutorial" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "cgarciae/pypeln" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "AppliedDataSciencePartners/DeepReinforcementLearning" ["e"=1]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" -> "IntelLabs/nlp-architect" ["e"=1]
"google/sg2im" -> "taoxugit/AttnGAN" ["e"=1]
"google/sg2im" -> "hanzhanggit/StackGAN" ["e"=1]
"google/sg2im" -> "CSAILVision/gandissect" ["e"=1]
"google/sg2im" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"pytorchbearer/torchbearer" -> "cgnorthcutt/benchmarking-keras-pytorch" ["e"=1]
"github-pengge/PyTorch-progressive_growing_of_gans" -> "nashory/pggan-pytorch"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "ptrblck/prog_gans_pytorch_inference"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "zhangqianhui/progressive_growing_of_gans_tensorflow"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "tkarras/progressive_growing_of_gans"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "pfnet-research/sngan_projection"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "LMescheder/GAN_stability"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "godisboy/SN-GAN"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "caogang/wgan-gp"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "facebookresearch/pytorch_GAN_zoo"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "rosinality/style-based-gan-pytorch"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "heykeetae/Self-Attention-GAN"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "HsinYingLee/DRIT"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "bioinf-jku/TTUR"
"github-pengge/PyTorch-progressive_growing_of_gans" -> "sbarratt/inception-score-pytorch"
"bendangnuksung/Image-OutPainting" -> "albertpumarola/GANimation"
"bendangnuksung/Image-OutPainting" -> "cybertronai/imagenet18_old"
"bendangnuksung/Image-OutPainting" -> "CSAILVision/gandissect"
"bendangnuksung/Image-OutPainting" -> "nyoki-mtl/pytorch-EverybodyDanceNow" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "dongjun-Lee/text-classification-models-tf" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks"
"bendangnuksung/Image-OutPainting" -> "ShinyCode/image-outpainting"
"bendangnuksung/Image-OutPainting" -> "tensorflow/adanet" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "LMescheder/GAN_stability"
"bendangnuksung/Image-OutPainting" -> "NVIDIA/waveglow" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "luanfujun/deep-painterly-harmonization"
"bendangnuksung/Image-OutPainting" -> "google-research/exoplanet-ml" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "jsn5/dancenet" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "facebookresearch/DensePose" ["e"=1]
"bendangnuksung/Image-OutPainting" -> "NVIDIA/vid2vid"
"nadavbh12/VQ-VAE" -> "hsinyilin19/ResNetVAE" ["e"=1]
"nadavbh12/VQ-VAE" -> "ethanluoyc/pytorch-vae" ["e"=1]
"dongjun-Lee/text-classification-models-tf" -> "bendangnuksung/Image-OutPainting" ["e"=1]
"dongjun-Lee/text-classification-models-tf" -> "LMescheder/GAN_stability" ["e"=1]
"dongjun-Lee/text-classification-models-tf" -> "albertpumarola/GANimation" ["e"=1]
"julianstastny/VAE-ResNet18-PyTorch" -> "hsinyilin19/ResNetVAE"
"julianstastny/VAE-ResNet18-PyTorch" -> "jan-xu/autoencoders"
"GANs-in-Action/gans-in-action" -> "davidADSP/GDL_code" ["e"=1]
"GANs-in-Action/gans-in-action" -> "eriklindernoren/Keras-GAN"
"GANs-in-Action/gans-in-action" -> "kozistr/Awesome-GANs"
"GANs-in-Action/gans-in-action" -> "google/compare_gan"
"GANs-in-Action/gans-in-action" -> "PacktPublishing/Generative-Adversarial-Networks-Projects"
"GANs-in-Action/gans-in-action" -> "PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras"
"GANs-in-Action/gans-in-action" -> "nashory/gans-awesome-applications"
"GANs-in-Action/gans-in-action" -> "timsainb/tensorflow2-generative-models"
"GANs-in-Action/gans-in-action" -> "nightrome/really-awesome-gan"
"GANs-in-Action/gans-in-action" -> "PacktPublishing/Generative-Adversarial-Networks-Cookbook"
"GANs-in-Action/gans-in-action" -> "tjwei/GANotebooks"
"GANs-in-Action/gans-in-action" -> "soumith/ganhacks"
"GANs-in-Action/gans-in-action" -> "openai/improved-gan"
"GANs-in-Action/gans-in-action" -> "totalgood/nlpia" ["e"=1]
"GANs-in-Action/gans-in-action" -> "facebookresearch/pytorch_GAN_zoo"
"torchgan/torchgan" -> "kwotsin/mimicry" ["e"=1]
"torchgan/torchgan" -> "google/compare_gan"
"torchgan/torchgan" -> "facebookresearch/pytorch_GAN_zoo"
"torchgan/torchgan" -> "ajbrock/BigGAN-PyTorch"
"torchgan/torchgan" -> "pfnet-research/sngan_projection"
"torchgan/torchgan" -> "sxhxliang/BigGAN-pytorch"
"torchgan/torchgan" -> "heykeetae/Self-Attention-GAN"
"torchgan/torchgan" -> "caogang/wgan-gp"
"torchgan/torchgan" -> "CSAILVision/gandissect"
"torchgan/torchgan" -> "LMescheder/GAN_stability"
"torchgan/torchgan" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"torchgan/torchgan" -> "znxlwm/pytorch-generative-model-collections"
"torchgan/torchgan" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"torchgan/torchgan" -> "martinarjovsky/WassersteinGAN"
"torchgan/torchgan" -> "StacyYang/gluoncv-torch" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "lernapparat/lernapparat" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "rosinality/style-based-gan-pytorch"
"tomguluson92/StyleGAN_PyTorch" -> "huangzh13/StyleGAN.pytorch" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "rosinality/stylegan2-pytorch" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "SiskonEmilia/StyleGAN-PyTorch" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "genforce/interfacegan" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "akanimax/pro_gan_pytorch"
"tomguluson92/StyleGAN_PyTorch" -> "nashory/pggan-pytorch"
"tomguluson92/StyleGAN_PyTorch" -> "lucidrains/stylegan2-pytorch" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "HsinYingLee/DRIT"
"tomguluson92/StyleGAN_PyTorch" -> "naoto0804/pytorch-AdaIN" ["e"=1]
"tomguluson92/StyleGAN_PyTorch" -> "tomguluson92/StyleGAN2_PyTorch"
"tomguluson92/StyleGAN_PyTorch" -> "NVlabs/MUNIT"
"tomguluson92/StyleGAN_PyTorch" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"tomguluson92/StyleGAN_PyTorch" -> "facebookresearch/pytorch_GAN_zoo"
"jalola/improved-wgan-pytorch" -> "caogang/wgan-gp"
"jalola/improved-wgan-pytorch" -> "Zeleni9/pytorch-wgan"
"jalola/improved-wgan-pytorch" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch"
"jalola/improved-wgan-pytorch" -> "igul222/improved_wgan_training"
"jalola/improved-wgan-pytorch" -> "EmilienDupont/wgan-gp"
"jalola/improved-wgan-pytorch" -> "clvrai/ACGAN-PyTorch"
"jalola/improved-wgan-pytorch" -> "pfnet-research/sngan_projection"
"jalola/improved-wgan-pytorch" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"jalola/improved-wgan-pytorch" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"jalola/improved-wgan-pytorch" -> "LMescheder/GAN_stability"
"jalola/improved-wgan-pytorch" -> "znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN"
"jalola/improved-wgan-pytorch" -> "eveningglow/multitask-CycleGAN"
"jalola/improved-wgan-pytorch" -> "taey16/pix2pixBEGAN.pytorch"
"jalola/improved-wgan-pytorch" -> "godisboy/SN-GAN"
"jalola/improved-wgan-pytorch" -> "carpedm20/BEGAN-pytorch"
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "cybertronai/imagenet18_old" ["e"=1]
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "CSAILVision/gandissect" ["e"=1]
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "bendangnuksung/Image-OutPainting" ["e"=1]
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "albertpumarola/GANimation" ["e"=1]
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["e"=1]
"nyoki-mtl/pytorch-EverybodyDanceNow" -> "NVIDIA/vid2vid" ["e"=1]
"aysunrhn/Adaptive-Soft-Sensor-Design" -> "hkaneko1985/adaptive_soft_sensors"
"aysunrhn/Adaptive-Soft-Sensor-Design" -> "JustusvLiebig/Inferential_Sensor_Experiment"
"Yijunmaverick/UniversalStyleTransfer" -> "msracver/Deep-Image-Analogy" ["e"=1]
"junyanz/BicycleGAN" -> "NVlabs/MUNIT"
"junyanz/BicycleGAN" -> "HsinYingLee/DRIT"
"junyanz/BicycleGAN" -> "mingyuliutw/UNIT"
"junyanz/BicycleGAN" -> "NVIDIA/pix2pixHD"
"junyanz/BicycleGAN" -> "yunjey/stargan"
"junyanz/BicycleGAN" -> "NVlabs/FUNIT"
"junyanz/BicycleGAN" -> "pfnet-research/sngan_projection"
"junyanz/BicycleGAN" -> "HelenMao/MSGAN"
"junyanz/BicycleGAN" -> "heykeetae/Self-Attention-GAN"
"junyanz/BicycleGAN" -> "tkarras/progressive_growing_of_gans"
"junyanz/BicycleGAN" -> "martinarjovsky/WassersteinGAN"
"junyanz/BicycleGAN" -> "lzhbrian/image-to-image-papers"
"junyanz/BicycleGAN" -> "CSAILVision/gandissect"
"junyanz/BicycleGAN" -> "taesungp/contrastive-unpaired-translation" ["e"=1]
"junyanz/BicycleGAN" -> "openai/improved-gan"
"jerryli27/TwinGAN" -> "NVlabs/MUNIT" ["e"=1]
"jerryli27/TwinGAN" -> "taki0112/MUNIT-Tensorflow" ["e"=1]
"jerryli27/TwinGAN" -> "HsinYingLee/DRIT" ["e"=1]
"jerryli27/TwinGAN" -> "khanrc/tf.gans-comparison" ["e"=1]
"jhoffman/cycada_release" -> "HsinYingLee/DRIT" ["e"=1]
"Natsu6767/InfoGAN-PyTorch" -> "openai/InfoGAN" ["e"=1]
"sangwoomo/instagan" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"sangwoomo/instagan" -> "HsinYingLee/DRIT"
"sangwoomo/instagan" -> "lzhbrian/image-to-image-papers"
"sangwoomo/instagan" -> "NVlabs/FUNIT"
"sangwoomo/instagan" -> "HelenMao/MSGAN"
"sangwoomo/instagan" -> "NVlabs/MUNIT"
"sangwoomo/instagan" -> "tengteng95/Pose-Transfer" ["e"=1]
"sangwoomo/instagan" -> "Ha0Tang/AttentionGAN" ["e"=1]
"sangwoomo/instagan" -> "mingyuliutw/UNIT"
"sangwoomo/instagan" -> "Ha0Tang/SelectionGAN" ["e"=1]
"sangwoomo/instagan" -> "brownvc/ganimorph"
"sangwoomo/instagan" -> "ZPdesu/SEAN" ["e"=1]
"sangwoomo/instagan" -> "CSAILVision/gandissect"
"sangwoomo/instagan" -> "pfnet-research/sngan_projection"
"sangwoomo/instagan" -> "junyanz/BicycleGAN"
"shaoanlu/fewshot-face-translation-GAN" -> "NVlabs/FUNIT" ["e"=1]
"taki0112/StarGAN-Tensorflow" -> "taki0112/Self-Attention-GAN-Tensorflow"
"taki0112/StarGAN-Tensorflow" -> "taki0112/MUNIT-Tensorflow"
"taki0112/StarGAN-Tensorflow" -> "yunjey/stargan"
"taki0112/StarGAN-Tensorflow" -> "vanhuyz/CycleGAN-TensorFlow"
"taki0112/StarGAN-Tensorflow" -> "taki0112/DRIT-Tensorflow"
"taki0112/StarGAN-Tensorflow" -> "albertpumarola/GANimation"
"taki0112/StarGAN-Tensorflow" -> "taki0112/StarGAN_v2-Tensorflow" ["e"=1]
"taki0112/StarGAN-Tensorflow" -> "brain-research/self-attention-gan"
"taki0112/StarGAN-Tensorflow" -> "openai/glow"
"taki0112/StarGAN-Tensorflow" -> "pfnet-research/sngan_projection"
"taki0112/StarGAN-Tensorflow" -> "google/compare_gan"
"taki0112/StarGAN-Tensorflow" -> "taki0112/SphereGAN-Tensorflow"
"taki0112/StarGAN-Tensorflow" -> "csmliu/STGAN"
"taki0112/StarGAN-Tensorflow" -> "xiaowei-hu/CycleGAN-tensorflow"
"taki0112/StarGAN-Tensorflow" -> "leehomyc/cyclegan-1"
"pclucas14/pixel-cnn-pp" -> "openai/pixel-cnn" ["e"=1]
"pclucas14/pixel-cnn-pp" -> "PrajitR/fast-pixel-cnn" ["e"=1]
"woozzu/tagan" -> "woozzu/dong_iccv_2017"
"woozzu/tagan" -> "mrlibw/ControlGAN"
"woozzu/tagan" -> "vtddggg/BilinearGAN_for_LBIE"
"woozzu/tagan" -> "hanzhanggit/StackGAN-inception-model"
"woozzu/tagan" -> "qiaott/MirrorGAN"
"woozzu/tagan" -> "qiaott/LeicaGAN"
"woozzu/tagan" -> "mrlibw/ManiGAN"
"kmkolasinski/deep-learning-notes" -> "openai/glow" ["e"=1]
"kmkolasinski/deep-learning-notes" -> "google/compare_gan" ["e"=1]
"Zeleni9/pytorch-wgan" -> "caogang/wgan-gp"
"Zeleni9/pytorch-wgan" -> "jalola/improved-wgan-pytorch"
"Zeleni9/pytorch-wgan" -> "EmilienDupont/wgan-gp"
"Zeleni9/pytorch-wgan" -> "igul222/improved_wgan_training"
"Zeleni9/pytorch-wgan" -> "martinarjovsky/WassersteinGAN"
"Zeleni9/pytorch-wgan" -> "znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN"
"Zeleni9/pytorch-wgan" -> "heykeetae/Self-Attention-GAN"
"Zeleni9/pytorch-wgan" -> "w86763777/pytorch-gan-collections" ["e"=1]
"Zeleni9/pytorch-wgan" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch"
"Zeleni9/pytorch-wgan" -> "sbarratt/inception-score-pytorch"
"Zeleni9/pytorch-wgan" -> "YixinChen-AI/CVAE-GAN-zoos-PyTorch-Beginner" ["e"=1]
"Zeleni9/pytorch-wgan" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"Zeleni9/pytorch-wgan" -> "pfnet-research/sngan_projection"
"Zeleni9/pytorch-wgan" -> "yfeng95/GAN"
"Zeleni9/pytorch-wgan" -> "mseitzer/pytorch-fid" ["e"=1]
"znxlwm/pytorch-CartoonGAN" -> "znxlwm/pytorch-Conditional-image-to-image-translation" ["e"=1]
"znxlwm/pytorch-CartoonGAN" -> "HsinYingLee/DRIT" ["e"=1]
"zhuofupan/Pytorch-Deep-Neural-Networks" -> "JustusvLiebig/Soft_Sensor_Experiments" ["e"=1]
"lllyasviel/MangaCraft" -> "lllyasviel/style2paints" ["e"=1]
"aaronpenne/generative_art" -> "robbiebarrat/art-DCGAN" ["e"=1]
"quolc/neural-collage" -> "LMescheder/GAN_stability" ["e"=1]
"quolc/neural-collage" -> "NVlabs/FUNIT" ["e"=1]
"quolc/neural-collage" -> "csmliu/STGAN" ["e"=1]
"bojone/flow" -> "bojone/gan-qp" ["e"=1]
"sbarratt/inception-score-pytorch" -> "mseitzer/pytorch-fid" ["e"=1]
"sbarratt/inception-score-pytorch" -> "bioinf-jku/TTUR"
"sbarratt/inception-score-pytorch" -> "pfnet-research/sngan_projection"
"sbarratt/inception-score-pytorch" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"sbarratt/inception-score-pytorch" -> "openai/improved-gan"
"sbarratt/inception-score-pytorch" -> "hanzhanggit/StackGAN-Pytorch"
"sbarratt/inception-score-pytorch" -> "xuqiantong/GAN-Metrics"
"sbarratt/inception-score-pytorch" -> "taki0112/GAN_Metrics-Tensorflow"
"sbarratt/inception-score-pytorch" -> "HelenMao/MSGAN"
"sbarratt/inception-score-pytorch" -> "caogang/wgan-gp"
"sbarratt/inception-score-pytorch" -> "LMescheder/GAN_stability"
"sbarratt/inception-score-pytorch" -> "lzhbrian/metrics"
"sbarratt/inception-score-pytorch" -> "ajbrock/BigGAN-PyTorch"
"sbarratt/inception-score-pytorch" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"sbarratt/inception-score-pytorch" -> "HsinYingLee/DRIT"
"LynnHo/AttGAN-Tensorflow" -> "csmliu/STGAN"
"LynnHo/AttGAN-Tensorflow" -> "elvisyjlin/AttGAN-PyTorch"
"LynnHo/AttGAN-Tensorflow" -> "LynnHo/HD-CelebA-Cropper"
"LynnHo/AttGAN-Tensorflow" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"LynnHo/AttGAN-Tensorflow" -> "Prinsphield/ELEGANT"
"LynnHo/AttGAN-Tensorflow" -> "facebookresearch/FaderNetworks"
"LynnHo/AttGAN-Tensorflow" -> "Guim3/IcGAN"
"LynnHo/AttGAN-Tensorflow" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch"
"LynnHo/AttGAN-Tensorflow" -> "genforce/interfacegan" ["e"=1]
"LynnHo/AttGAN-Tensorflow" -> "bluestyle97/STGAN-pytorch"
"LynnHo/AttGAN-Tensorflow" -> "switchablenorms/CelebAMask-HQ" ["e"=1]
"LynnHo/AttGAN-Tensorflow" -> "zhangqianhui/Sparsely-Grouped-GAN"
"LynnHo/AttGAN-Tensorflow" -> "LynnHo/CycleGAN-Tensorflow-2"
"LynnHo/AttGAN-Tensorflow" -> "elvisyjlin/SpatialAttentionGAN"
"LynnHo/AttGAN-Tensorflow" -> "SummitKwan/transparent_latent_gan"
"Puzer/stylegan-encoder" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"Puzer/stylegan-encoder" -> "SummitKwan/transparent_latent_gan" ["e"=1]
"Puzer/stylegan-encoder" -> "NVlabs/FUNIT" ["e"=1]
"vlukiyanov/pt-dec" -> "vlukiyanov/pt-sdae" ["e"=1]
"crmaximo/VAEGAN" -> "baudm/vaegan-celebs-keras"
"crmaximo/VAEGAN" -> "anitan0925/vaegan"
"texturedesign/texturize" -> "afruehstueck/tileGAN" ["e"=1]
"yitong91/StoryGAN" -> "jamesli1618/Obj-GAN"
"yitong91/StoryGAN" -> "CrickWu/Clevr-for-StoryGAN" ["e"=1]
"yitong91/StoryGAN" -> "uvavision/Text2Scene"
"yitong91/StoryGAN" -> "lzhbrian/arbitrary-text-to-image-papers"
"yitong91/StoryGAN" -> "qiaott/MirrorGAN"
"yitong91/StoryGAN" -> "adymaharana/VLCStoryGan" ["e"=1]
"yitong91/StoryGAN" -> "tohinz/multiple-objects-gan"
"yitong91/StoryGAN" -> "ypxie/HDGan"
"HRLTY/TP-GAN" -> "Prinsphield/ELEGANT" ["e"=1]
"afruehstueck/tileGAN" -> "jessemelpolio/non-stationary_texture_syn"
"afruehstueck/tileGAN" -> "anopara/patch-based-texture-synthesis"
"MingtaoGuo/PatchMatch" -> "MingtaoGuo/Deep-image-analogy-TensorFlow" ["e"=1]
"MingtaoGuo/PatchMatch" -> "Ben-Louis/Deep-Image-Analogy-PyTorch" ["e"=1]
"MingtaoGuo/PatchMatch" -> "MingtaoGuo/sngan_projection_TensorFlow" ["e"=1]
"rohitrango/Image-Quilting-for-Texture-Synthesis" -> "afrozalm/Patch-Based-Texture-Synthesis"
"hkaneko1985/adaptive_soft_sensors" -> "aysunrhn/Adaptive-Soft-Sensor-Design"
"hkaneko1985/adaptive_soft_sensors" -> "vigorfif/Soft-Sensor-Modelling"
"vigorfif/Soft-Sensor-Modelling" -> "hkaneko1985/adaptive_soft_sensors"
"vigorfif/Soft-Sensor-Modelling" -> "tonyzyl/Semisupervised-VAE-for-Regression-Application-on-Soft-Sensor"
"vigorfif/Soft-Sensor-Modelling" -> "MingweiJia/GCN-based_soft_sensor"
"vigorfif/Soft-Sensor-Modelling" -> "iamownt/LSTM-DeepFM"
"zalandoresearch/famos" -> "zalandoresearch/psgan"
"dvlab-research/Facelet_Bank" -> "paulu/deepfeatinterp"
"dvlab-research/Facelet_Bank" -> "Prinsphield/ELEGANT"
"dvlab-research/Facelet_Bank" -> "Zhongdao/FaceAttributeManipulation"
"Yijunmaverick/CartoonGAN-Test-Pytorch-Torch" -> "HelenMao/MSGAN" ["e"=1]
"taki0112/MUNIT-Tensorflow" -> "taki0112/DRIT-Tensorflow"
"taki0112/MUNIT-Tensorflow" -> "NVlabs/MUNIT"
"taki0112/MUNIT-Tensorflow" -> "taki0112/UNIT-Tensorflow"
"taki0112/MUNIT-Tensorflow" -> "shaoanlu/MUNIT-keras"
"taki0112/MUNIT-Tensorflow" -> "taki0112/StarGAN-Tensorflow"
"taki0112/MUNIT-Tensorflow" -> "taki0112/Self-Attention-GAN-Tensorflow"
"taki0112/MUNIT-Tensorflow" -> "clvrai/BicycleGAN-Tensorflow"
"taki0112/MUNIT-Tensorflow" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"taki0112/MUNIT-Tensorflow" -> "HsinYingLee/DRIT"
"taki0112/MUNIT-Tensorflow" -> "taki0112/Spectral_Normalization-Tensorflow"
"Ben-Louis/Deep-Image-Analogy-PyTorch" -> "harveyslash/Deep-Image-Analogy-PyTorch"
"Ben-Louis/Deep-Image-Analogy-PyTorch" -> "harveyslash/PatchMatch" ["e"=1]
"Ben-Louis/Deep-Image-Analogy-PyTorch" -> "msracver/Deep-Image-Analogy"
"lernapparat/lernapparat" -> "tomguluson92/StyleGAN_PyTorch" ["e"=1]
"lernapparat/lernapparat" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"lernapparat/lernapparat" -> "akanimax/pro_gan_pytorch" ["e"=1]
"nashory/pggan-pytorch" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"nashory/pggan-pytorch" -> "akanimax/pro_gan_pytorch"
"nashory/pggan-pytorch" -> "rosinality/style-based-gan-pytorch"
"nashory/pggan-pytorch" -> "tkarras/progressive_growing_of_gans"
"nashory/pggan-pytorch" -> "ptrblck/prog_gans_pytorch_inference"
"nashory/pggan-pytorch" -> "facebookresearch/pytorch_GAN_zoo"
"nashory/pggan-pytorch" -> "tomguluson92/StyleGAN_PyTorch"
"nashory/pggan-pytorch" -> "pfnet-research/sngan_projection"
"nashory/pggan-pytorch" -> "sxhxliang/BigGAN-pytorch"
"nashory/pggan-pytorch" -> "AlexiaJM/RelativisticGAN"
"nashory/pggan-pytorch" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"nashory/pggan-pytorch" -> "rosinality/stylegan2-pytorch" ["e"=1]
"nashory/pggan-pytorch" -> "heykeetae/Self-Attention-GAN"
"nashory/pggan-pytorch" -> "NVlabs/MUNIT"
"nashory/pggan-pytorch" -> "bioinf-jku/TTUR"
"y0ast/VAE-Torch" -> "y0ast/Variational-Autoencoder" ["e"=1]
"y0ast/VAE-Torch" -> "RuiShu/cvae" ["e"=1]
"y0ast/VAE-Torch" -> "y0ast/VAE-TensorFlow" ["e"=1]
"zhangqianhui/progressive_growing_of_gans_tensorflow" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"zhangqianhui/progressive_growing_of_gans_tensorflow" -> "preritj/progressive_growing_of_GANs"
"zhangqianhui/progressive_growing_of_gans_tensorflow" -> "nnUyi/PGGAN"
"taki0112/Self-Attention-GAN-Tensorflow" -> "taki0112/BigGAN-Tensorflow"
"taki0112/Self-Attention-GAN-Tensorflow" -> "heykeetae/Self-Attention-GAN"
"taki0112/Self-Attention-GAN-Tensorflow" -> "brain-research/self-attention-gan"
"taki0112/Self-Attention-GAN-Tensorflow" -> "pfnet-research/sngan_projection"
"taki0112/Self-Attention-GAN-Tensorflow" -> "taki0112/StarGAN-Tensorflow"
"taki0112/Self-Attention-GAN-Tensorflow" -> "taki0112/Spectral_Normalization-Tensorflow"
"taki0112/Self-Attention-GAN-Tensorflow" -> "taki0112/MUNIT-Tensorflow"
"taki0112/Self-Attention-GAN-Tensorflow" -> "taki0112/GAN_Metrics-Tensorflow"
"taki0112/Self-Attention-GAN-Tensorflow" -> "minhnhat93/tf-SNDCGAN"
"taki0112/Self-Attention-GAN-Tensorflow" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"taki0112/Self-Attention-GAN-Tensorflow" -> "akanimax/fagan"
"taki0112/Self-Attention-GAN-Tensorflow" -> "AlexiaJM/RelativisticGAN"
"taki0112/Self-Attention-GAN-Tensorflow" -> "bioinf-jku/TTUR"
"taki0112/Self-Attention-GAN-Tensorflow" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"taki0112/Self-Attention-GAN-Tensorflow" -> "google/compare_gan"
"taki0112/BigGAN-Tensorflow" -> "taki0112/Self-Attention-GAN-Tensorflow"
"taki0112/BigGAN-Tensorflow" -> "ANIME305/Anime-GAN-tensorflow" ["e"=1]
"taki0112/BigGAN-Tensorflow" -> "sxhxliang/BigGAN-pytorch"
"taki0112/BigGAN-Tensorflow" -> "taki0112/GAN_Metrics-Tensorflow"
"taki0112/BigGAN-Tensorflow" -> "taki0112/RelativisticGAN-Tensorflow"
"hanzhanggit/StackGAN-v2" -> "hanzhanggit/StackGAN-Pytorch"
"hanzhanggit/StackGAN-v2" -> "taoxugit/AttnGAN"
"hanzhanggit/StackGAN-v2" -> "hanzhanggit/StackGAN"
"hanzhanggit/StackGAN-v2" -> "reedscot/icml2016"
"hanzhanggit/StackGAN-v2" -> "zsdonghao/text-to-image"
"hanzhanggit/StackGAN-v2" -> "aelnouby/Text-to-Image-Synthesis"
"hanzhanggit/StackGAN-v2" -> "ypxie/HDGan"
"hanzhanggit/StackGAN-v2" -> "mansimov/text2image"
"hanzhanggit/StackGAN-v2" -> "reedscot/cvpr2016"
"hanzhanggit/StackGAN-v2" -> "lzhbrian/arbitrary-text-to-image-papers"
"hanzhanggit/StackGAN-v2" -> "mrlibw/ControlGAN"
"hanzhanggit/StackGAN-v2" -> "qiaott/MirrorGAN"
"hanzhanggit/StackGAN-v2" -> "hanzhanggit/StackGAN-inception-model"
"hanzhanggit/StackGAN-v2" -> "bioinf-jku/TTUR"
"hanzhanggit/StackGAN-v2" -> "MinfengZhu/DM-GAN"
"sksq96/pytorch-vae" -> "LukeDitria/CNN-VAE"
"sksq96/pytorch-vae" -> "bhpfelix/Variational-Autoencoder-PyTorch"
"sksq96/pytorch-vae" -> "ethanluoyc/pytorch-vae"
"sksq96/pytorch-vae" -> "lyeoni/pytorch-mnist-VAE"
"sksq96/pytorch-vae" -> "foamliu/Autoencoder"
"sksq96/pytorch-vae" -> "seangal/dcgan_vae_pytorch"
"sksq96/pytorch-vae" -> "hsinyilin19/ResNetVAE"
"sksq96/pytorch-vae" -> "timbmg/VAE-CVAE-MNIST"
"sksq96/pytorch-vae" -> "coolvision/vae_conv"
"sksq96/pytorch-vae" -> "o-tawab/Variational-Autoencoder-pytorch"
"sksq96/pytorch-vae" -> "lucabergamini/VAEGAN-PYTORCH"
"sksq96/pytorch-vae" -> "chaitanya100100/VAE-for-Image-Generation"
"cybertronai/imagenet18_old" -> "nyoki-mtl/pytorch-EverybodyDanceNow" ["e"=1]
"cybertronai/imagenet18_old" -> "fastai/imagenet-fast"
"cybertronai/imagenet18_old" -> "cgarciae/pypeln" ["e"=1]
"cybertronai/imagenet18_old" -> "bendangnuksung/Image-OutPainting"
"cybertronai/imagenet18_old" -> "CSAILVision/gandissect"
"cybertronai/imagenet18_old" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks"
"cybertronai/imagenet18_old" -> "albertpumarola/GANimation"
"cybertronai/imagenet18_old" -> "google-research/exoplanet-ml" ["e"=1]
"cybertronai/imagenet18_old" -> "NVIDIA/waveglow" ["e"=1]
"cybertronai/imagenet18_old" -> "tensorflow/adanet" ["e"=1]
"cybertronai/imagenet18_old" -> "chenxi116/PNASNet.pytorch" ["e"=1]
"cybertronai/imagenet18_old" -> "shrubb/box-convolutions" ["e"=1]
"cybertronai/imagenet18_old" -> "cgnorthcutt/benchmarking-keras-pytorch"
"cybertronai/imagenet18_old" -> "fastai/fastai_old" ["e"=1]
"cybertronai/imagenet18_old" -> "davidcpage/cifar10-fast"
"20100507/emotional_analysis" -> "csmliu/STGAN" ["e"=1]
"anopara/patch-based-texture-synthesis" -> "anopara/texture-synthesis-nonparametric-sampling"
"anopara/patch-based-texture-synthesis" -> "anopara/multi-resolution-texture-synthesis"
"cleardusk/MeGlass" -> "LynnHo/HD-CelebA-Cropper" ["e"=1]
"tducret/amazon-scraper-python" -> "Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["e"=1]
"schelotto/Wasserstein-AutoEncoders" -> "neale/Adversarial-Autoencoder" ["e"=1]
"schelotto/Wasserstein-AutoEncoders" -> "bhpfelix/Variational-Autoencoder-PyTorch" ["e"=1]
"schelotto/Wasserstein-AutoEncoders" -> "maitek/waae-pytorch" ["e"=1]
"lyeoni/pytorch-mnist-VAE" -> "dragen1860/pytorch-mnist-vae"
"lyeoni/pytorch-mnist-VAE" -> "lyeoni/pytorch-mnist-CVAE"
"ShayanPersonal/stacked-autoencoder-pytorch" -> "vlukiyanov/pt-sdae"
"ShayanPersonal/stacked-autoencoder-pytorch" -> "zhangxu0307/stack-autoencoder"
"ShayanPersonal/stacked-autoencoder-pytorch" -> "pranjaldatta/Denoising-Autoencoder-in-Pytorch"
"vlukiyanov/pt-sdae" -> "vlukiyanov/pt-dec" ["e"=1]
"vlukiyanov/pt-sdae" -> "MadhumitaSushil/SDAE"
"vlukiyanov/pt-sdae" -> "ShayanPersonal/stacked-autoencoder-pytorch"
"vlukiyanov/pt-sdae" -> "haohlin/SDAE_pytorch"
"crcrpar/pytorch.sngan_projection" -> "pfnet-research/sngan_projection"
"MingtaoGuo/Deep-Feature-Interporlation-Face-Attribute-manipulation-Glasses-Remove-Youth2Senior-etc.-TensorFlow" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Deep-Feature-Interporlation-Face-Attribute-manipulation-Glasses-Remove-Youth2Senior-etc.-TensorFlow" -> "MingtaoGuo/ContextEncoder_Cat-s_head_Inpainting_TensorFlow"
"lecomte/glasses-removal-gan" -> "MingtaoGuo/Deep-Feature-Interporlation-Face-Attribute-manipulation-Glasses-Remove-Youth2Senior-etc.-TensorFlow"
"lecomte/glasses-removal-gan" -> "JubilantJerry/CNN-Glasses-Remover"
"lecomte/glasses-removal-gan" -> "ash11sh/remove-glass"
"shayneobrien/generative-models" -> "ctallec/pyvarinf" ["e"=1]
"shayneobrien/generative-models" -> "LMescheder/GAN_stability"
"shayneobrien/generative-models" -> "znxlwm/pytorch-generative-model-collections"
"minhnhat93/tf-SNDCGAN" -> "pfnet-research/chainer-gan-lib" ["e"=1]
"minhnhat93/tf-SNDCGAN" -> "taki0112/Spectral_Normalization-Tensorflow"
"minhnhat93/tf-SNDCGAN" -> "pfnet-research/sngan_projection"
"minhnhat93/tf-SNDCGAN" -> "godisboy/SN-GAN"
"minhnhat93/tf-SNDCGAN" -> "kodalinaveen3/DRAGAN" ["e"=1]
"lzhbrian/arbitrary-text-to-image-papers" -> "qiaott/MirrorGAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "jamesli1618/Obj-GAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "ypxie/HDGan"
"lzhbrian/arbitrary-text-to-image-papers" -> "tohinz/multiple-objects-gan"
"lzhbrian/arbitrary-text-to-image-papers" -> "MinfengZhu/DM-GAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "aelnouby/Text-to-Image-Synthesis"
"lzhbrian/arbitrary-text-to-image-papers" -> "yitong91/StoryGAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"lzhbrian/arbitrary-text-to-image-papers" -> "woozzu/tagan"
"lzhbrian/arbitrary-text-to-image-papers" -> "mrlibw/ControlGAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "davidstap/AttnGAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "taoxugit/AttnGAN"
"lzhbrian/arbitrary-text-to-image-papers" -> "hanzhanggit/StackGAN-Pytorch"
"lzhbrian/arbitrary-text-to-image-papers" -> "hanzhanggit/StackGAN-v2"
"lzhbrian/arbitrary-text-to-image-papers" -> "hanzhanggit/StackGAN-inception-model"
"robbiebarrat/plant-art" -> "robbiebarrat/Bach_AI"
"robbiebarrat/plant-art" -> "robbiebarrat/Sculpture-GAN"
"chenhsuanlin/spatial-transformer-GAN" -> "chenhsuanlin/inverse-compositional-STN" ["e"=1]
"chenhsuanlin/spatial-transformer-GAN" -> "azadis/CompositionalGAN"
"chenhsuanlin/spatial-transformer-GAN" -> "jwyang/lr-gan.pytorch"
"chenhsuanlin/spatial-transformer-GAN" -> "wdyin/GeoGAN"
"chenhsuanlin/spatial-transformer-GAN" -> "csmliu/STGAN"
"chenhsuanlin/spatial-transformer-GAN" -> "Prinsphield/ELEGANT"
"chenhsuanlin/spatial-transformer-GAN" -> "xiaolonw/ss-gan"
"chenhsuanlin/spatial-transformer-GAN" -> "Prinsphield/GeneGAN"
"clvrai/ACGAN-PyTorch" -> "kimhc6028/acgan-pytorch"
"clvrai/ACGAN-PyTorch" -> "Hydrino/ACGAN_cifar10"
"clvrai/ACGAN-PyTorch" -> "LynnHo/Conditional-GANs-Pytorch"
"clvrai/ACGAN-PyTorch" -> "jalola/improved-wgan-pytorch"
"clvrai/ACGAN-PyTorch" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "pfnet-research/sngan_projection"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "godisboy/SN-GAN"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "heykeetae/Self-Attention-GAN"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "AlexiaJM/RelativisticGAN"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "caogang/wgan-gp"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "brain-research/self-attention-gan"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "bioinf-jku/TTUR"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "sbarratt/inception-score-pytorch"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "google/compare_gan"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "LMescheder/GAN_stability"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "rosinality/style-based-gan-pytorch"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "mseitzer/pytorch-fid" ["e"=1]
"christiancosgrove/pytorch-spectral-normalization-gan" -> "nashory/pggan-pytorch"
"christiancosgrove/pytorch-spectral-normalization-gan" -> "martinarjovsky/WassersteinGAN"
"hsinyilin19/ResNetVAE" -> "julianstastny/VAE-ResNet18-PyTorch"
"hsinyilin19/ResNetVAE" -> "sksq96/pytorch-vae"
"HsinYingLee/DRIT" -> "NVlabs/MUNIT"
"HsinYingLee/DRIT" -> "HelenMao/MSGAN"
"HsinYingLee/DRIT" -> "mingyuliutw/UNIT"
"HsinYingLee/DRIT" -> "HsinYingLee/MDMM"
"HsinYingLee/DRIT" -> "junyanz/BicycleGAN"
"HsinYingLee/DRIT" -> "taki0112/DRIT-Tensorflow"
"HsinYingLee/DRIT" -> "lzhbrian/image-to-image-papers"
"HsinYingLee/DRIT" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"HsinYingLee/DRIT" -> "NVlabs/FUNIT"
"HsinYingLee/DRIT" -> "sangwoomo/instagan"
"HsinYingLee/DRIT" -> "jhoffman/cycada_release" ["e"=1]
"HsinYingLee/DRIT" -> "Ha0Tang/AttentionGAN" ["e"=1]
"HsinYingLee/DRIT" -> "taesungp/contrastive-unpaired-translation" ["e"=1]
"HsinYingLee/DRIT" -> "pfnet-research/sngan_projection"
"HsinYingLee/DRIT" -> "ustclby/Unsupervised-Domain-Specific-Deblurring" ["e"=1]
"taki0112/Switchable_Normalization-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/Switchable_Normalization-Tensorflow" -> "taki0112/Group_Normalization-Tensorflow"
"chen0040/keras-text-to-image" -> "hellochick/text-to-image"
"vibertthio/awesome-machine-learning-art" -> "robbiebarrat/art-DCGAN" ["e"=1]
"akanimax/msg-gan-v1" -> "akanimax/msg-stylegan-tf"
"akanimax/msg-gan-v1" -> "akanimax/BMSG-GAN"
"akanimax/msg-gan-v1" -> "akanimax/big-discriminator-batch-spoofing-gan"
"cgnorthcutt/benchmarking-keras-pytorch" -> "toodef/neural-pipeline" ["e"=1]
"cgnorthcutt/benchmarking-keras-pytorch" -> "cybertronai/imagenet18_old"
"conan7882/adversarial-autoencoders" -> "Naresh1318/Adversarial_Autoencoder"
"conan7882/adversarial-autoencoders" -> "hwalsuklee/tensorflow-mnist-AAE"
"conan7882/adversarial-autoencoders" -> "bfarzin/pytorch_aae"
"conan7882/adversarial-autoencoders" -> "neale/Adversarial-Autoencoder"
"conan7882/adversarial-autoencoders" -> "mingukkang/Adversarial-AutoEncoder"
"conan7882/adversarial-autoencoders" -> "musyoku/adversarial-autoencoder"
"llSourcell/Pokemon_GAN" -> "uclaacmai/Generative-Adversarial-Network-Tutorial" ["e"=1]
"gsurma/image_generator" -> "gsurma/face_generator"
"tensorflow/gan" -> "google/compare_gan"
"tensorflow/gan" -> "yfeng95/GAN"
"tensorflow/gan" -> "eriklindernoren/Keras-GAN"
"tensorflow/gan" -> "bioinf-jku/TTUR"
"tensorflow/gan" -> "facebookresearch/pytorch_GAN_zoo"
"tensorflow/gan" -> "pfnet-research/sngan_projection"
"tensorflow/gan" -> "taki0112/GAN_Metrics-Tensorflow"
"tensorflow/gan" -> "timsainb/tensorflow2-generative-models"
"tensorflow/gan" -> "kwotsin/mimicry" ["e"=1]
"tensorflow/gan" -> "brain-research/self-attention-gan"
"tensorflow/gan" -> "torchgan/torchgan"
"tensorflow/gan" -> "mit-han-lab/data-efficient-gans" ["e"=1]
"tensorflow/gan" -> "justinpinkney/awesome-pretrained-stylegan2" ["e"=1]
"tensorflow/gan" -> "taki0112/BigGAN-Tensorflow"
"tensorflow/gan" -> "ajbrock/BigGAN-PyTorch"
"xuqiantong/GAN-Metrics" -> "taki0112/GAN_Metrics-Tensorflow"
"xuqiantong/GAN-Metrics" -> "sbarratt/inception-score-pytorch"
"xuqiantong/GAN-Metrics" -> "lzhbrian/metrics"
"xuqiantong/GAN-Metrics" -> "bioinf-jku/TTUR"
"xuqiantong/GAN-Metrics" -> "LMescheder/GAN_stability"
"xuqiantong/GAN-Metrics" -> "pfnet-research/sngan_projection"
"xuqiantong/GAN-Metrics" -> "dongb5/GAN-Timeline"
"xuqiantong/GAN-Metrics" -> "yhlleo/GAN-Metrics"
"xuqiantong/GAN-Metrics" -> "HsinYingLee/DRIT"
"xuqiantong/GAN-Metrics" -> "tsc2017/Inception-Score"
"xuqiantong/GAN-Metrics" -> "AlexiaJM/RelativisticGAN"
"xuqiantong/GAN-Metrics" -> "heykeetae/Self-Attention-GAN"
"xuqiantong/GAN-Metrics" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"hujinsen/pytorch_VAE_CVAE" -> "unnir/cVAE"
"wxs/subjective-functions" -> "jessemelpolio/non-stationary_texture_syn"
"wxs/subjective-functions" -> "Yijunmaverick/MultiTextureSynthesis"
"manuelruder/fast-artistic-videos" -> "manuelruder/artistic-videos" ["e"=1]
"manuelruder/fast-artistic-videos" -> "zeruniverse/fast-artistic-videos" ["e"=1]
"jessemelpolio/non-stationary_texture_syn" -> "wxs/subjective-functions"
"jessemelpolio/non-stationary_texture_syn" -> "afruehstueck/tileGAN"
"jessemelpolio/non-stationary_texture_syn" -> "leongatys/DeepTextures"
"jessemelpolio/non-stationary_texture_syn" -> "anopara/patch-based-texture-synthesis"
"jessemelpolio/non-stationary_texture_syn" -> "zalandoresearch/psgan"
"jessemelpolio/non-stationary_texture_syn" -> "janesjanes/Pytorch-TextureGAN"
"jessemelpolio/non-stationary_texture_syn" -> "anopara/texture-synthesis-nonparametric-sampling"
"jessemelpolio/non-stationary_texture_syn" -> "afrozalm/Patch-Based-Texture-Synthesis"
"jessemelpolio/non-stationary_texture_syn" -> "zalandoresearch/famos"
"akanimax/T2F" -> "akanimax/BMSG-GAN"
"akanimax/T2F" -> "lzhbrian/arbitrary-text-to-image-papers"
"akanimax/T2F" -> "akanimax/pro_gan_pytorch"
"akanimax/T2F" -> "taoxugit/AttnGAN"
"akanimax/T2F" -> "hanzhanggit/StackGAN-v2"
"akanimax/T2F" -> "akanimax/msg-stylegan-tf"
"akanimax/T2F" -> "zsdonghao/text-to-image"
"akanimax/T2F" -> "reedscot/icml2016"
"akanimax/T2F" -> "reedscot/cvpr2016"
"akanimax/T2F" -> "woozzu/tagan"
"akanimax/T2F" -> "qiaott/MirrorGAN"
"akanimax/T2F" -> "chen0040/keras-text-to-image"
"akanimax/T2F" -> "jamesli1618/Obj-GAN"
"akanimax/T2F" -> "dashayushman/TAC-GAN"
"akanimax/T2F" -> "ypxie/HDGan"
"gazijarin/AdamAI" -> "gazijarin/OdinBot"
"y0ast/Variational-Autoencoder" -> "y0ast/VAE-Torch" ["e"=1]
"y0ast/Variational-Autoencoder" -> "y0ast/VAE-TensorFlow"
"y0ast/Variational-Autoencoder" -> "dpkingma/nips14-ssl" ["e"=1]
"y0ast/Variational-Autoencoder" -> "casperkaae/parmesan" ["e"=1]
"y0ast/Variational-Autoencoder" -> "jych/nips2015_vrnn" ["e"=1]
"y0ast/Variational-Autoencoder" -> "caglar/autoencoders"
"y0ast/Variational-Autoencoder" -> "mikesj-public/convolutional_autoencoder"
"y0ast/Variational-Autoencoder" -> "y0ast/Variational-Recurrent-Autoencoder" ["e"=1]
"y0ast/Variational-Autoencoder" -> "cdoersch/vae_tutorial"
"y0ast/Variational-Autoencoder" -> "jbornschein/draw" ["e"=1]
"y0ast/Variational-Autoencoder" -> "jych/cle" ["e"=1]
"y0ast/Variational-Autoencoder" -> "kvfrans/variational-autoencoder"
"y0ast/Variational-Autoencoder" -> "yburda/iwae" ["e"=1]
"y0ast/Variational-Autoencoder" -> "skaae/lasagne-draw" ["e"=1]
"y0ast/Variational-Autoencoder" -> "mila-iqia/blocks" ["e"=1]
"LynnHo/HD-CelebA-Cropper" -> "csmliu/STGAN"
"LynnHo/HD-CelebA-Cropper" -> "Prinsphield/ELEGANT"
"LynnHo/HD-CelebA-Cropper" -> "elvisyjlin/AttGAN-PyTorch"
"LynnHo/HD-CelebA-Cropper" -> "LynnHo/AttGAN-Tensorflow"
"LynnHo/HD-CelebA-Cropper" -> "wdyin/GeoGAN"
"LynnHo/HD-CelebA-Cropper" -> "willylulu/celeba-hq-modified"
"csmliu/STGAN" -> "LynnHo/AttGAN-Tensorflow"
"csmliu/STGAN" -> "bluestyle97/STGAN-pytorch"
"csmliu/STGAN" -> "elvisyjlin/AttGAN-PyTorch"
"csmliu/STGAN" -> "Prinsphield/ELEGANT"
"csmliu/STGAN" -> "LynnHo/HD-CelebA-Cropper"
"csmliu/STGAN" -> "cientgu/Mask_Guided_Portrait_Editing"
"csmliu/STGAN" -> "chenhsuanlin/spatial-transformer-GAN"
"csmliu/STGAN" -> "wdyin/GeoGAN"
"csmliu/STGAN" -> "genforce/interfacegan" ["e"=1]
"csmliu/STGAN" -> "ZPdesu/SEAN" ["e"=1]
"csmliu/STGAN" -> "facebookresearch/FaderNetworks"
"csmliu/STGAN" -> "elvisyjlin/SpatialAttentionGAN"
"csmliu/STGAN" -> "willylulu/celeba-hq-modified"
"csmliu/STGAN" -> "lzhbrian/image-to-image-papers"
"csmliu/STGAN" -> "apchenstu/Facial_Details_Synthesis" ["e"=1]
"baoqianyue/GANCalligraphy" -> "zhuojg/chinese-calligraphy-dataset"
"baoqianyue/GANCalligraphy" -> "iamsohard/ChineseCalligraphyGenerator"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/sngan_projection_TensorFlow"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "he-zh/vibration_gan" ["e"=1]
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "taki0112/Spectral_Normalization-Tensorflow"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "bojone/gan"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Deep-image-analogy-TensorFlow"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/Semantic-Image-Inpainting-face-inpainting-TensorFlow"
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"Nana0606/autoencoder" -> "nathanhubens/Autoencoders"
"Nana0606/autoencoder" -> "wblgers/tensorflow_stacked_denoising_autoencoder"
"Nana0606/autoencoder" -> "LitoNeo/pytorch-AutoEncoders"
"Nana0606/autoencoder" -> "CLaraRR/autoencoder_practice"
"Nana0606/autoencoder" -> "jaanli/variational-autoencoder"
"Nana0606/autoencoder" -> "Kaixhin/Autoencoders" ["e"=1]
"Nana0606/autoencoder" -> "ShayanPersonal/stacked-autoencoder-pytorch"
"Nana0606/autoencoder" -> "zhangxiaoling/Bearing-fault-detection" ["e"=1]
"Nana0606/autoencoder" -> "caglar/autoencoders"
"Nana0606/autoencoder" -> "erickrf/autoencoder" ["e"=1]
"Nana0606/autoencoder" -> "foamliu/Autoencoder"
"taki0112/SPADE-Tensorflow" -> "taki0112/GAN_Metrics-Tensorflow" ["e"=1]
"taki0112/SPADE-Tensorflow" -> "csmliu/STGAN" ["e"=1]
"azadis/MC-GAN" -> "kaonashi-tyc/zi2zi" ["e"=1]
"pfnet-research/sngan_projection" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"pfnet-research/sngan_projection" -> "godisboy/SN-GAN"
"pfnet-research/sngan_projection" -> "igul222/improved_wgan_training"
"pfnet-research/sngan_projection" -> "brain-research/self-attention-gan"
"pfnet-research/sngan_projection" -> "crcrpar/pytorch.sngan_projection"
"pfnet-research/sngan_projection" -> "AlexiaJM/RelativisticGAN"
"pfnet-research/sngan_projection" -> "google/compare_gan"
"pfnet-research/sngan_projection" -> "heykeetae/Self-Attention-GAN"
"pfnet-research/sngan_projection" -> "bioinf-jku/TTUR"
"pfnet-research/sngan_projection" -> "LMescheder/GAN_stability"
"pfnet-research/sngan_projection" -> "pfnet-research/chainer-gan-lib" ["e"=1]
"pfnet-research/sngan_projection" -> "caogang/wgan-gp"
"pfnet-research/sngan_projection" -> "ajbrock/BigGAN-PyTorch"
"pfnet-research/sngan_projection" -> "martinarjovsky/WassersteinGAN"
"pfnet-research/sngan_projection" -> "minhnhat93/tf-SNDCGAN"
"Prinsphield/ELEGANT" -> "Prinsphield/GeneGAN"
"Prinsphield/ELEGANT" -> "wdyin/GeoGAN"
"Prinsphield/ELEGANT" -> "csmliu/STGAN"
"Prinsphield/ELEGANT" -> "Prinsphield/DNA-GAN"
"Prinsphield/ELEGANT" -> "LynnHo/HD-CelebA-Cropper"
"Prinsphield/ELEGANT" -> "zhangqianhui/GazeAnimationV2" ["e"=1]
"Prinsphield/ELEGANT" -> "LynnHo/AttGAN-Tensorflow"
"Prinsphield/ELEGANT" -> "dvlab-research/Facelet_Bank"
"Prinsphield/ELEGANT" -> "facebookresearch/FaderNetworks"
"Prinsphield/ELEGANT" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"sxhxliang/BigGAN-pytorch" -> "taki0112/BigGAN-Tensorflow"
"sxhxliang/BigGAN-pytorch" -> "ajbrock/BigGAN-PyTorch"
"sxhxliang/BigGAN-pytorch" -> "huggingface/pytorch-pretrained-BigGAN"
"sxhxliang/BigGAN-pytorch" -> "heykeetae/Self-Attention-GAN"
"sxhxliang/BigGAN-pytorch" -> "google/compare_gan"
"sxhxliang/BigGAN-pytorch" -> "nashory/pggan-pytorch"
"sxhxliang/BigGAN-pytorch" -> "rosinality/style-based-gan-pytorch"
"sxhxliang/BigGAN-pytorch" -> "brain-research/self-attention-gan"
"sxhxliang/BigGAN-pytorch" -> "pfnet-research/sngan_projection"
"sxhxliang/BigGAN-pytorch" -> "torchgan/torchgan"
"sxhxliang/BigGAN-pytorch" -> "NVlabs/FUNIT"
"sxhxliang/BigGAN-pytorch" -> "rosinality/sagan-pytorch"
"sxhxliang/BigGAN-pytorch" -> "akanimax/BMSG-GAN"
"sxhxliang/BigGAN-pytorch" -> "HelenMao/MSGAN"
"sxhxliang/BigGAN-pytorch" -> "taki0112/Self-Attention-GAN-Tensorflow"
"LDOUBLEV/style_transfer-perceptual_loss" -> "ShafeenTejani/fast-style-transfer" ["e"=1]
"LDOUBLEV/style_transfer-perceptual_loss" -> "hzy46/fast-neural-style-tensorflow"
"ptrblck/prog_gans_pytorch_inference" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"ptrblck/prog_gans_pytorch_inference" -> "stormraiser/GAN-weight-norm"
"ptrblck/prog_gans_pytorch_inference" -> "nashory/pggan-pytorch"
"ptrblck/prog_gans_pytorch_inference" -> "koz4k/dni-pytorch"
"ptrblck/prog_gans_pytorch_inference" -> "carpedm20/BEGAN-pytorch"
"fastai/imagenet-fast" -> "cybertronai/imagenet18_old"
"fastai/imagenet-fast" -> "diux-dev/cluster"
"tolstikhin/wae" -> "musyoku/adversarial-autoencoder" ["e"=1]
"cameronfabbri/cWGANs" -> "kongyanye/cwgan-gp"
"xjqicuhk/SIMS" -> "xcyan/neurips18_hierchical_image_manipulation"
"PaperWeeklyCode/GAN-discussions" -> "dongb5/GAN-Timeline"
"PaperWeeklyCode/GAN-discussions" -> "guojunq/lsgan"
"PaperWeeklyCode/GAN-discussions" -> "godisboy/SN-GAN"
"PaperWeeklyCode/GAN-discussions" -> "kimiyoung/ssl_bad_gan" ["e"=1]
"mafda/generative_adversarial_networks_101" -> "znxlwm/tensorflow-MNIST-cGAN-cDCGAN"
"simontomaskarlsson/CycleGAN-Keras" -> "LynnHo/CycleGAN-Tensorflow-2" ["e"=1]
"malzantot/Pytorch-conditional-GANs" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"sgugger/Deep-Learning" -> "davidcpage/cifar10-fast" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "google-research/tensor2robot" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "benedekrozemberczki/awesome-decision-tree-papers" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "ranahanocka/MeshCNN" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "microsoft/tensorwatch" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"timsainb/tensorflow2-generative-models" -> "TDAmeritrade/stumpy" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"timsainb/tensorflow2-generative-models" -> "LynnHo/CycleGAN-Tensorflow-2"
"timsainb/tensorflow2-generative-models" -> "interpretml/interpret" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "crmaximo/VAEGAN"
"timsainb/tensorflow2-generative-models" -> "CSAILVision/gandissect"
"timsainb/tensorflow2-generative-models" -> "google/compare_gan"
"timsainb/tensorflow2-generative-models" -> "mesolitica/NLP-Models-Tensorflow" ["e"=1]
"timsainb/tensorflow2-generative-models" -> "timsainb/GAIA"
"timsainb/tensorflow2-generative-models" -> "tensorflow/gan"
"gsurma/face_generator" -> "gsurma/image_generator"
"togheppi/CycleGAN" -> "znxlwm/pytorch-CycleGAN"
"SashaMalysheva/Pytorch-VAE" -> "chaitanya100100/VAE-for-Image-Generation"
"Yangyangii/GAN-Tutorial" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"Yangyangii/GAN-Tutorial" -> "Yangyangii/pytorch-practice"
"Yangyangii/GAN-Tutorial" -> "WICWIU/WICWIU" ["e"=1]
"Yangyangii/GAN-Tutorial" -> "csinva/gan-vae-pretrained-pytorch"
"Yangyangii/GAN-Tutorial" -> "znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN"
"dragen1860/pytorch-mnist-vae" -> "lyeoni/pytorch-mnist-VAE"
"zhangxu0307/stack-autoencoder" -> "hkaneko1985/adaptive_soft_sensors"
"JPlin/Relabeled-HELEN-Dataset" -> "Eskender-B/roi-tanh"
"JPlin/Relabeled-HELEN-Dataset" -> "Eskender-B/icnn"
"JPlin/Relabeled-HELEN-Dataset" -> "aod321/Face-parsing-via-tanh-warping"
"enomotokenji/pytorch-Neural-Style-Transfer" -> "MingtaoGuo/Style-transfer-with-neural-algorithm"
"bluestyle97/STGAN-pytorch" -> "elvisyjlin/AttGAN-PyTorch"
"bluestyle97/STGAN-pytorch" -> "csmliu/STGAN"
"bluestyle97/STGAN-pytorch" -> "elvisyjlin/SpatialAttentionGAN"
"jamesli1618/Obj-GAN" -> "yitong91/StoryGAN"
"jamesli1618/Obj-GAN" -> "MinfengZhu/DM-GAN"
"jamesli1618/Obj-GAN" -> "tohinz/multiple-objects-gan"
"jamesli1618/Obj-GAN" -> "lzhbrian/arbitrary-text-to-image-papers"
"jamesli1618/Obj-GAN" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"jamesli1618/Obj-GAN" -> "qiaott/MirrorGAN"
"jamesli1618/Obj-GAN" -> "mrlibw/ControlGAN"
"jamesli1618/Obj-GAN" -> "uvavision/Text2Scene"
"jamesli1618/Obj-GAN" -> "taoxugit/AttnGAN"
"jamesli1618/Obj-GAN" -> "dongdongdong666/CPGAN"
"jamesli1618/Obj-GAN" -> "woozzu/tagan"
"jamesli1618/Obj-GAN" -> "hanzhanggit/StackGAN-inception-model"
"jamesli1618/Obj-GAN" -> "ypxie/HDGan"
"jamesli1618/Obj-GAN" -> "tobran/DF-GAN"
"jamesli1618/Obj-GAN" -> "google/sg2im" ["e"=1]
"Sleepychord/ImprovedGAN-pytorch" -> "zhenxuan00/triple-gan" ["e"=1]
"Sleepychord/ImprovedGAN-pytorch" -> "openai/improved-gan" ["e"=1]
"eveningglow/multitask-CycleGAN" -> "eveningglow/BicycleGAN-pytorch"
"tsc2017/Frechet-Inception-Distance" -> "tsc2017/Inception-Score"
"tsc2017/Frechet-Inception-Distance" -> "taki0112/GAN_Metrics-Tensorflow"
"CQFIO/FastImageProcessing" -> "CQFIO/PhotographicImageSynthesis" ["e"=1]
"PacktPublishing/Generative-Adversarial-Networks-Cookbook" -> "PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras"
"PacktPublishing/Generative-Adversarial-Networks-Cookbook" -> "PacktPublishing/Generative-Adversarial-Networks-Projects"
"PacktPublishing/Generative-Adversarial-Networks-Cookbook" -> "PacktPublishing/Learning-Generative-Adversarial-Networks"
"o-tawab/Variational-Autoencoder-pytorch" -> "coolvision/vae_conv"
"aelnouby/Text-to-Image-Synthesis" -> "reedscot/icml2016"
"aelnouby/Text-to-Image-Synthesis" -> "zsdonghao/text-to-image"
"aelnouby/Text-to-Image-Synthesis" -> "hanzhanggit/StackGAN-Pytorch"
"aelnouby/Text-to-Image-Synthesis" -> "lzhbrian/arbitrary-text-to-image-papers"
"aelnouby/Text-to-Image-Synthesis" -> "hanzhanggit/StackGAN-v2"
"aelnouby/Text-to-Image-Synthesis" -> "taoxugit/AttnGAN"
"aelnouby/Text-to-Image-Synthesis" -> "ypxie/HDGan"
"aelnouby/Text-to-Image-Synthesis" -> "reedscot/cvpr2016"
"aelnouby/Text-to-Image-Synthesis" -> "crisbodnar/text-to-image"
"aelnouby/Text-to-Image-Synthesis" -> "paarthneekhara/text-to-image"
"aelnouby/Text-to-Image-Synthesis" -> "reedscot/nips2016"
"aelnouby/Text-to-Image-Synthesis" -> "Rakshith-Manandi/text-to-image-using-GAN"
"aelnouby/Text-to-Image-Synthesis" -> "qiaott/MirrorGAN"
"aelnouby/Text-to-Image-Synthesis" -> "tohinz/multiple-objects-gan"
"aelnouby/Text-to-Image-Synthesis" -> "hanzhanggit/StackGAN"
"MingtaoGuo/sngan_projection_TensorFlow" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/sngan_projection_TensorFlow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/sngan_projection_TensorFlow" -> "MingtaoGuo/Deep-image-analogy-TensorFlow"
"MingtaoGuo/sngan_projection_TensorFlow" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"MingtaoGuo/sngan_projection_TensorFlow" -> "MingtaoGuo/CycleGAN"
"tkazusa/CVAE-GAN" -> "tatsy/keras-generative"
"tkazusa/CVAE-GAN" -> "One-sixth/CVAE-GAN_tensorlayer"
"tkazusa/CVAE-GAN" -> "yanzhicong/VAE-GAN"
"tkazusa/CVAE-GAN" -> "chloeguoqing/Towards-Open-Set-Identity-Preserving-Face-Synthesis"
"tkazusa/CVAE-GAN" -> "ToniCreswell/attribute-cVAEGAN"
"EmilienDupont/wgan-gp" -> "Zeleni9/pytorch-wgan"
"EmilienDupont/wgan-gp" -> "caogang/wgan-gp"
"EmilienDupont/wgan-gp" -> "arturml/pytorch-wgan-gp"
"EmilienDupont/wgan-gp" -> "jalola/improved-wgan-pytorch"
"EmilienDupont/wgan-gp" -> "cameronfabbri/cWGANs"
"PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras" -> "PacktPublishing/Learning-Generative-Adversarial-Networks"
"PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras" -> "PacktPublishing/Generative-Adversarial-Networks-Cookbook"
"PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras" -> "PacktPublishing/Generative-Adversarial-Networks-Projects"
"cientgu/Mask_Guided_Portrait_Editing" -> "Eskender-B/roi-tanh"
"cientgu/Mask_Guided_Portrait_Editing" -> "JPlin/Relabeled-HELEN-Dataset"
"hollobit/All-About-the-GAN" -> "dongb5/GAN-Timeline"
"hollobit/All-About-the-GAN" -> "shawnyuen/gans_paper_collection"
"hollobit/All-About-the-GAN" -> "GKalliatakis/Delving-deep-into-GANs"
"hollobit/All-About-the-GAN" -> "nightrome/really-awesome-gan"
"hollobit/All-About-the-GAN" -> "xinario/SAGAN" ["e"=1]
"hollobit/All-About-the-GAN" -> "lzhbrian/image-to-image-papers"
"hollobit/All-About-the-GAN" -> "znxlwm/pytorch-generative-model-collections"
"hollobit/All-About-the-GAN" -> "sjchoi86/bayes-nn" ["e"=1]
"hollobit/All-About-the-GAN" -> "albarqouni/Deep-Learning-for-Medical-Applications" ["e"=1]
"togheppi/cDCGAN" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"anopara/multi-resolution-texture-synthesis" -> "anopara/patch-based-texture-synthesis"
"anopara/multi-resolution-texture-synthesis" -> "anopara/texture-synthesis-nonparametric-sampling"
"dansuh17/alexnet-pytorch" -> "Lornatang/AlexNet-PyTorch"
"bfarzin/pytorch_aae" -> "fducau/AAE_pytorch"
"bfarzin/pytorch_aae" -> "yoonsanghyu/AAE-PyTorch"
"shaohua0116/VAE-Tensorflow" -> "hwalsuklee/tensorflow-mnist-VAE"
"shaohua0116/VAE-Tensorflow" -> "y0ast/VAE-TensorFlow"
"shaohua0116/VAE-Tensorflow" -> "Chung-I/Variational-Recurrent-Autoencoder-Tensorflow" ["e"=1]
"gaborvecsei/CDCGAN-Keras" -> "sarahwolf32/conditional-DCGAN-for-MNIST"
"zhangqianhui/GazeAnimationV2" -> "wdyin/GeoGAN" ["e"=1]
"zhangqianhui/GazeAnimationV2" -> "Prinsphield/ELEGANT" ["e"=1]
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/Group_Normalization-Tensorflow"
"taki0112/Spectral_Normalization-Tensorflow" -> "MingtaoGuo/sngan_projection_TensorFlow"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/Tensorflow-DatasetAPI"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/Switchable_Normalization-Tensorflow"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/TripleGAN-Tensorflow"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/DiscoGAN-Tensorflow"
"taki0112/Spectral_Normalization-Tensorflow" -> "minhnhat93/tf-SNDCGAN"
"taki0112/Spectral_Normalization-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"lzhbrian/metrics" -> "taki0112/GAN_Metrics-Tensorflow"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "MadhumitaSushil/SDAE"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "ramarlina/DenoisingAutoEncoder"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "vlukiyanov/pt-sdae"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "ShayanPersonal/stacked-autoencoder-pytorch"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "rajarsheem/libsdae-autoencoder-tensorflow"
"wblgers/tensorflow_stacked_denoising_autoencoder" -> "Nana0606/autoencoder"
"9310gaurav/ali-pytorch" -> "jeffdonahue/bigan"
"9310gaurav/ali-pytorch" -> "fmu2/Wasserstein-BiGAN"
"9310gaurav/ali-pytorch" -> "WilliBee/bigan_SRL"
"9310gaurav/ali-pytorch" -> "mperezcarrasco/PyTorch-BiGAN"
"MingtaoGuo/Style-transfer-with-neural-algorithm" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/Style-transfer-with-neural-algorithm" -> "MingtaoGuo/Real-Time-Arbitrary-Style-Transfer-AdaIN-TensorFlow"
"MingtaoGuo/Style-transfer-with-neural-algorithm" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Style-transfer-with-neural-algorithm" -> "MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation"
"MingtaoGuo/Style-transfer-with-neural-algorithm" -> "MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification"
"kimiyoung/ssl_bad_gan" -> "zhenxuan00/triple-gan" ["e"=1]
"donydchen/ganimation_replicate" -> "albertpumarola/GANimation" ["e"=1]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch" -> "jalola/improved-wgan-pytorch"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch" -> "LynnHo/AttGAN-Tensorflow"
"tsc2017/Inception-Score" -> "tsc2017/Frechet-Inception-Distance"
"tsc2017/Inception-Score" -> "taki0112/GAN_Metrics-Tensorflow"
"coolvision/vae_conv" -> "o-tawab/Variational-Autoencoder-pytorch"
"changebo/HCCG-CycleGAN" -> "MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" ["e"=1]
"neale/Adversarial-Autoencoder" -> "maitek/waae-pytorch"
"woozzu/dong_iccv_2017" -> "woozzu/tagan"
"taki0112/DRIT-Tensorflow" -> "taki0112/MUNIT-Tensorflow"
"taki0112/DRIT-Tensorflow" -> "HsinYingLee/DRIT"
"WilliBee/bigan_SRL" -> "Hyeokreal/ali_bigan_mnist_pytorch"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/Deep-Feature-Interporlation-Face-Attribute-manipulation-Glasses-Remove-Youth2Senior-etc.-TensorFlow"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/Deep-image-analogy-TensorFlow"
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"codyznash/GANs_for_Credit_Card_Data" -> "mjdietzx/GAN-Sandbox"
"codyznash/GANs_for_Credit_Card_Data" -> "krantirk/Credit-GANS"
"taki0112/FusionGAN-Tensorflow" -> "taki0112/SphereGAN-Tensorflow"
"uvavision/Text2Scene" -> "yitong91/StoryGAN"
"uvavision/Text2Scene" -> "tohinz/multiple-objects-gan"
"uvavision/Text2Scene" -> "jamesli1618/Obj-GAN"
"MingtaoGuo/CartoonGAN-tensorflow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"yzwxx/vae-celebA" -> "houxianxu/DFC-VAE"
"yzwxx/vae-celebA" -> "bhpfelix/Variational-Autoencoder-PyTorch"
"yzwxx/vae-celebA" -> "JeremyCCHsu/tf-vaegan"
"csinva/gan-vae-pretrained-pytorch" -> "SashaMalysheva/Pytorch-VAE"
"architrathore/CycleGAN" -> "leehomyc/cyclegan-1"
"architrathore/CycleGAN" -> "LynnHo/CycleGAN-Tensorflow-2"
"architrathore/CycleGAN" -> "xiaowei-hu/CycleGAN-tensorflow"
"architrathore/CycleGAN" -> "hardikbansal/CycleGAN"
"architrathore/CycleGAN" -> "vanhuyz/CycleGAN-TensorFlow"
"architrathore/CycleGAN" -> "goldkim92/StarGAN-tensorflow"
"PacktPublishing/Learning-Generative-Adversarial-Networks" -> "PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras"
"LingDong-/edges2calligraphy" -> "iamsohard/ChineseCalligraphyGenerator"
"LingDong-/edges2calligraphy" -> "herrkaefer/chinese-calligraphy-vectorization"
"LingDong-/edges2calligraphy" -> "MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification"
"LingDong-/edges2calligraphy" -> "MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing"
"MingtaoGuo/Semantic-Image-Inpainting-face-inpainting-TensorFlow" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Semantic-Image-Inpainting-face-inpainting-TensorFlow" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"nperraud/download-celebA-HQ" -> "willylulu/celeba-hq-modified"
"qiaott/MirrorGAN" -> "MinfengZhu/DM-GAN"
"qiaott/MirrorGAN" -> "komiya-m/MirrorGAN"
"qiaott/MirrorGAN" -> "mrlibw/ControlGAN"
"qiaott/MirrorGAN" -> "lzhbrian/arbitrary-text-to-image-papers"
"qiaott/MirrorGAN" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"qiaott/MirrorGAN" -> "qiaott/LeicaGAN"
"qiaott/MirrorGAN" -> "jamesli1618/Obj-GAN"
"qiaott/MirrorGAN" -> "ypxie/HDGan"
"qiaott/MirrorGAN" -> "tohinz/multiple-objects-gan"
"qiaott/MirrorGAN" -> "woozzu/tagan"
"qiaott/MirrorGAN" -> "dongdongdong666/CPGAN"
"ANIME305/Anime-GAN-tensorflow" -> "taki0112/BigGAN-Tensorflow" ["e"=1]
"MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification" -> "MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing"
"MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification" -> "MingtaoGuo/Calligraphic-Images-Denoising-by-GAN"
"LDOUBLEV/semi-supervised-GAN" -> "clvrai/SSGAN-Tensorflow" ["e"=1]
"HsinYingLee/MDMM" -> "Xiaoming-Yu/DMIT"
"HsinYingLee/MDMM" -> "HsinYingLee/DRIT"
"taki0112/RelativisticGAN-Tensorflow" -> "taki0112/SphereGAN-Tensorflow"
"taki0112/Tensorflow-DatasetAPI" -> "taki0112/DCGAN-Tensorflow"
"taki0112/Tensorflow-DatasetAPI" -> "taki0112/CycleGAN-Tensorflow"
"taki0112/Tensorflow-DatasetAPI" -> "taki0112/pix2pix-Tensorflow"
"taki0112/Tensorflow-DatasetAPI" -> "taki0112/UNIT-Tensorflow"
"taki0112/Tensorflow-DatasetAPI" -> "taki0112/Group_Normalization-Tensorflow"
"hwalsuklee/tensorflow-mnist-AAE" -> "hwalsuklee/tensorflow-mnist-CVAE"
"hwalsuklee/tensorflow-mnist-AAE" -> "mingukkang/Adversarial-AutoEncoder"
"hwalsuklee/tensorflow-mnist-AAE" -> "conan7882/adversarial-autoencoders"
"hwalsuklee/tensorflow-mnist-AAE" -> "musyoku/adversarial-autoencoder"
"hwalsuklee/tensorflow-mnist-AAE" -> "hwalsuklee/tensorflow-mnist-VAE"
"alokwhitewolf/Pytorch-Attention-Guided-CycleGAN" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"alokwhitewolf/Pytorch-Attention-Guided-CycleGAN" -> "yhlleo/uaggan"
"MingtaoGuo/Calligraphic-Images-Denoising-by-GAN" -> "MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification"
"MingtaoGuo/Calligraphic-Images-Denoising-by-GAN" -> "MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing"
"MingtaoGuo/Calligraphic-Images-Denoising-by-GAN" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"taki0112/SphereGAN-Tensorflow" -> "taki0112/RelativisticGAN-Tensorflow"
"taki0112/SphereGAN-Tensorflow" -> "LynnHo/f-GAN-Tensorflow" ["e"=1]
"rohithreddy024/VAE-GAN-Pytorch" -> "seangal/dcgan_vae_pytorch"
"rohithreddy024/VAE-GAN-Pytorch" -> "ry85/VAE-GAN"
"kvmanohar22/img2imgGAN" -> "clvrai/BicycleGAN-Tensorflow"
"bhpfelix/Variational-Autoencoder-PyTorch" -> "podgorskiy/VAE"
"bhpfelix/Variational-Autoencoder-PyTorch" -> "1Konny/FactorVAE" ["e"=1]
"bhpfelix/Variational-Autoencoder-PyTorch" -> "sksq96/pytorch-vae"
"bhpfelix/Variational-Autoencoder-PyTorch" -> "ethanluoyc/pytorch-vae"
"bhpfelix/Variational-Autoencoder-PyTorch" -> "schelotto/Wasserstein-AutoEncoders" ["e"=1]
"Prinsphield/DNA-GAN" -> "zhangqianhui/Residual_Image_Learning_GAN"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/Deep-image-analogy-TensorFlow"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"Rakshith-Manandi/text-to-image-using-GAN" -> "utsav-195/text-to-image-generator-gan"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"shaohua0116/DCGAN-Tensorflow" -> "4thgen/DCGAN-CIFAR10"
"Eskender-B/icnn" -> "Eskender-B/roi-tanh"
"godisboy/SN-GAN" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"godisboy/SN-GAN" -> "pfnet-research/sngan_projection"
"godisboy/SN-GAN" -> "dannysdeng/selu"
"godisboy/SN-GAN" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"godisboy/SN-GAN" -> "minhnhat93/tf-SNDCGAN"
"godisboy/SN-GAN" -> "christiancosgrove/pytorch-sagan"
"godisboy/SN-GAN" -> "AlexiaJM/RelativisticGAN"
"godisboy/SN-GAN" -> "crcrpar/pytorch.sngan_projection"
"taki0112/UNIT-Tensorflow" -> "taki0112/Tensorflow-DatasetAPI"
"preritj/progressive_growing_of_GANs" -> "nnUyi/PGGAN"
"davrempe/domain-transfer-net" -> "taey16/DomainTransferNetwork.pytorch"
"akanimax/fagan" -> "akanimax/attn_gan_pytorch"
"ypxie/HDGan" -> "hanzhanggit/StackGAN-inception-model"
"ypxie/HDGan" -> "lzhbrian/arbitrary-text-to-image-papers"
"ypxie/HDGan" -> "MinfengZhu/DM-GAN"
"ypxie/HDGan" -> "qiaott/MirrorGAN"
"ypxie/HDGan" -> "tohinz/multiple-objects-gan"
"yhlleo/uaggan" -> "alokwhitewolf/Pytorch-Attention-Guided-CycleGAN"
"Xiaoming-Yu/SingleGAN" -> "HelenMao/SAVI2I"
"taki0112/TripleGAN-Tensorflow" -> "zhenxuan00/triple-gan"
"taki0112/TripleGAN-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"taki0112/TripleGAN-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/TripleGAN-Tensorflow" -> "LiqunChen0606/Triangle-GAN"
"baudm/vaegan-celebs-keras" -> "crmaximo/VAEGAN"
"maitek/waae-pytorch" -> "neale/Adversarial-Autoencoder"
"bojone/o-gan" -> "bojone/gan-qp"
"hanzhanggit/StackGAN-inception-model" -> "mrlibw/ControlGAN"
"hanzhanggit/StackGAN-inception-model" -> "ypxie/HDGan"
"tohinz/multiple-objects-gan" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"tohinz/multiple-objects-gan" -> "jamesli1618/Obj-GAN"
"tohinz/multiple-objects-gan" -> "lzhbrian/arbitrary-text-to-image-papers"
"tohinz/multiple-objects-gan" -> "qiaott/MirrorGAN"
"togheppi/pix2pix" -> "znxlwm/pytorch-pix2pix"
"togheppi/pix2pix" -> "TeeyoHuang/pix2pix-pytorch"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/CycleGAN"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution"
"MingtaoGuo/Deep-image-analogy-TensorFlow" -> "MingtaoGuo/ContextEncoder_Cat-s_head_Inpainting_TensorFlow"
"taki0112/Batch_Instance_Normalization-Tensorflow" -> "taki0112/Switchable_Normalization-Tensorflow"
"MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/CycleGAN" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution" -> "MingtaoGuo/Summary-of-deep-learning-papers"
"MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution" -> "MingtaoGuo/Deep-image-analogy-TensorFlow"
"MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution" -> "MingtaoGuo/CapsuleNet_Tensorflow"
"taki0112/CycleGAN-Tensorflow" -> "taki0112/DCGAN-Tensorflow"
"taki0112/CycleGAN-Tensorflow" -> "taki0112/DiscoGAN-Tensorflow"
"taki0112/CycleGAN-Tensorflow" -> "taki0112/StableGAN-Tensorflow"
"taki0112/CycleGAN-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/StableGAN-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"taki0112/StableGAN-Tensorflow" -> "taki0112/DCGAN-Tensorflow"
"taki0112/StableGAN-Tensorflow" -> "taki0112/DiscoGAN-Tensorflow"
"taki0112/Group_Normalization-Tensorflow" -> "taki0112/DiscoGAN-Tensorflow"
"taki0112/Group_Normalization-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/Group_Normalization-Tensorflow" -> "taki0112/DCGAN-Tensorflow"
"taki0112/Group_Normalization-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"taki0112/Group_Normalization-Tensorflow" -> "taki0112/StableGAN-Tensorflow"
"RahulBhalley/gan-qp.pytorch" -> "rahulbhalley/turing-gan"
"taki0112/pix2pix-Tensorflow" -> "taki0112/DiscoGAN-Tensorflow"
"taki0112/pix2pix-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"deezer/spleeter" -> "magenta/magenta" ["e"=1]
"AliaksandrSiarohin/first-order-model" -> "NVlabs/stylegan" ["e"=1]
"AliaksandrSiarohin/first-order-model" -> "NVIDIA/vid2vid" ["e"=1]
"alex-damian/pulse" -> "NVlabs/stylegan" ["e"=1]
"NVlabs/stylegan2" -> "NVlabs/stylegan" ["e"=1]
"NVlabs/stylegan2" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"NVlabs/stylegan2" -> "NVlabs/SPADE" ["e"=1]
"NVlabs/stylegan2" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"NVlabs/stylegan2" -> "NVIDIA/pix2pixHD" ["e"=1]
"openai/jukebox" -> "magenta/magenta" ["e"=1]
"karpathy/neuraltalk" -> "Newmu/dcgan_code" ["e"=1]
"NVlabs/imaginaire" -> "NVlabs/SPADE" ["e"=1]
"NVlabs/imaginaire" -> "NVlabs/MUNIT" ["e"=1]
"NVlabs/imaginaire" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"NVlabs/imaginaire" -> "NVIDIA/vid2vid" ["e"=1]
"cs231n/cs231n.github.io" -> "soumith/ganhacks" ["e"=1]
"AntixK/PyTorch-VAE" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"AntixK/PyTorch-VAE" -> "wiseodd/generative-models" ["e"=1]
"keras-team/keras-io" -> "eriklindernoren/Keras-GAN" ["e"=1]
"YixinChen-AI/CVAE-GAN-zoos-PyTorch-Beginner" -> "timbmg/VAE-CVAE-MNIST" ["e"=1]
"POSTECH-CVLab/PyTorch-StudioGAN" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"Ha0Tang/BiGraphGAN" -> "tobran/DF-GAN" ["e"=1]
"lucidrains/stylegan2-pytorch" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"lucidrains/stylegan2-pytorch" -> "tomguluson92/StyleGAN_PyTorch" ["e"=1]
"TachibanaYoshino/AnimeGANv2" -> "lllyasviel/style2paints" ["e"=1]
"nagadomi/lbpcascade_animeface" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"nagadomi/lbpcascade_animeface" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"websockets/wscat" -> "vi/websocat" ["e"=1]
"websockets/wscat" -> "AlexiaJM/Deep-learning-with-cats"
"websockets/wscat" -> "typelevel/cats-effect" ["e"=1]
"websockets/wscat" -> "Endava/cats" ["e"=1]
"websockets/wscat" -> "nyaadevs/nyaa" ["e"=1]
"websockets/wscat" -> "httpcats/http.cat"
"websockets/wscat" -> "owenthereal/ccat" ["e"=1]
"websockets/wscat" -> "websockets/ws" ["e"=1]
"websockets/wscat" -> "typelevel/cats" ["e"=1]
"websockets/wscat" -> "Luohuayu/CatServer" ["e"=1]
"websockets/wscat" -> "absolute-quantum/cats-blender-plugin" ["e"=1]
"websockets/wscat" -> "harthur/kittydar" ["e"=1]
"websockets/wscat" -> "websocket-client/websocket-client" ["e"=1]
"websockets/wscat" -> "aws-samples/simple-websockets-chat-app" ["e"=1]
"websockets/wscat" -> "junyanz/CatPapers"
"aladdinpersson/Machine-Learning-Collection" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"NervanaSystems/neon" -> "Newmu/dcgan_code" ["e"=1]
"andersbll/deeppy" -> "andersbll/neural_artistic_style" ["e"=1]
"bloc97/Anime4K" -> "lllyasviel/style2paints" ["e"=1]
"tamarott/SinGAN" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"tamarott/SinGAN" -> "NVlabs/MUNIT" ["e"=1]
"tamarott/SinGAN" -> "NVlabs/FUNIT" ["e"=1]
"tamarott/SinGAN" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"tamarott/SinGAN" -> "NVIDIA/pix2pixHD" ["e"=1]
"tamarott/SinGAN" -> "NVlabs/SPADE" ["e"=1]
"tamarott/SinGAN" -> "google/compare_gan" ["e"=1]
"junhyukoh/caffe-lstm" -> "Russell91/apollocaffe" ["e"=1]
"kwotsin/mimicry" -> "torchgan/torchgan" ["e"=1]
"kwotsin/mimicry" -> "pfnet-research/sngan_projection" ["e"=1]
"kwotsin/mimicry" -> "LMescheder/GAN_stability" ["e"=1]
"toshas/torch-fidelity" -> "bioinf-jku/TTUR" ["e"=1]
"zhangqianhui/GazeAnimation" -> "tobran/DF-GAN" ["e"=1]
"rosinality/stylegan2-pytorch" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"amperser/proselint" -> "awentzonline/image-analogies" ["e"=1]
"goodfeli/adversarial" -> "carpedm20/DCGAN-tensorflow"
"goodfeli/adversarial" -> "zhangqianhui/AdversarialNetsPapers"
"goodfeli/adversarial" -> "martinarjovsky/WassersteinGAN"
"goodfeli/adversarial" -> "Newmu/dcgan_code"
"goodfeli/adversarial" -> "openai/improved-gan"
"goodfeli/adversarial" -> "wiseodd/generative-models"
"goodfeli/adversarial" -> "soumith/ganhacks"
"goodfeli/adversarial" -> "igul222/improved_wgan_training"
"goodfeli/adversarial" -> "hindupuravinash/the-gan-zoo"
"goodfeli/adversarial" -> "yfeng95/GAN"
"goodfeli/adversarial" -> "nightrome/really-awesome-gan"
"goodfeli/adversarial" -> "soumith/dcgan.torch"
"goodfeli/adversarial" -> "phillipi/pix2pix"
"goodfeli/adversarial" -> "KaimingHe/deep-residual-networks" ["e"=1]
"goodfeli/adversarial" -> "junyanz/CycleGAN"
"karpathy/recurrentjs" -> "facebookarchive/eyescream" ["e"=1]
"Lasagne/Lasagne" -> "Newmu/dcgan_code" ["e"=1]
"LingDong-/cope" -> "LingDong-/edges2calligraphy" ["e"=1]
"Endava/cats" -> "AlexiaJM/Deep-learning-with-cats" ["e"=1]
"Endava/cats" -> "websockets/wscat" ["e"=1]
"dpkingma/nips14-ssl" -> "y0ast/Variational-Autoencoder" ["e"=1]
"dpkingma/nips14-ssl" -> "openai/iaf" ["e"=1]
"VITA-Group/AutoGAN" -> "HelenMao/MSGAN" ["e"=1]
"oreillymedia/t-SNE-tutorial" -> "bioinf-jku/SNNs" ["e"=1]
"WisconsinAIVision/MixNMatch" -> "NVlabs/MUNIT" ["e"=1]
"WisconsinAIVision/MixNMatch" -> "NVlabs/FUNIT" ["e"=1]
"mit-han-lab/data-efficient-gans" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"clovaai/tunit" -> "HsinYingLee/DRIT" ["e"=1]
"EuphoriaYan/zi2zi-pytorch" -> "yunchenlo/Font2Font" ["e"=1]
"EuphoriaYan/zi2zi-pytorch" -> "kaonashi-tyc/zi2zi" ["e"=1]
"Xtra-Computing/thundersvm" -> "bioinf-jku/SNNs" ["e"=1]
"jsvine/markovify" -> "robbiebarrat/rapping-neural-network" ["e"=1]
"clovaai/stargan-v2" -> "yunjey/stargan" ["e"=1]
"clovaai/stargan-v2" -> "NVlabs/MUNIT" ["e"=1]
"clovaai/stargan-v2" -> "ajbrock/BigGAN-PyTorch" ["e"=1]
"clovaai/stargan-v2" -> "NVlabs/FUNIT" ["e"=1]
"advimman/HiDT" -> "lzhbrian/image-to-image-papers" ["e"=1]
"advimman/HiDT" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" ["e"=1]
"huangzh13/StyleGAN.pytorch" -> "rosinality/style-based-gan-pytorch" ["e"=1]
"huangzh13/StyleGAN.pytorch" -> "tomguluson92/StyleGAN_PyTorch" ["e"=1]
"huangzh13/StyleGAN.pytorch" -> "akanimax/pro_gan_pytorch" ["e"=1]
"huangzh13/StyleGAN.pytorch" -> "akanimax/msg-stylegan-tf" ["e"=1]
"huangzh13/StyleGAN.pytorch" -> "nashory/pggan-pytorch" ["e"=1]
"manicman1999/StyleGAN2-Tensorflow-2.0" -> "LynnHo/CycleGAN-Tensorflow-2" ["e"=1]
"weihaox/awesome-image-translation" -> "lzhbrian/image-to-image-papers" ["e"=1]
"weihaox/awesome-image-translation" -> "HsinYingLee/DRIT" ["e"=1]
"taesungp/contrastive-unpaired-translation" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"taesungp/contrastive-unpaired-translation" -> "NVlabs/MUNIT" ["e"=1]
"taesungp/contrastive-unpaired-translation" -> "HsinYingLee/DRIT" ["e"=1]
"LingDong-/skeleton-tracing" -> "navis-org/skeletor" ["e"=1]
"LingDong-/skeleton-tracing" -> "mmkamani7/SkeletonMatching"
"LingDong-/skeleton-tracing" -> "FlorisSteenkamp/MAT"
"LingDong-/skeleton-tracing" -> "LingDong-/edges2calligraphy"
"LingDong-/skeleton-tracing" -> "LingDong-/chinese-hershey-font"
"LingDong-/skeleton-tracing" -> "LingDong-/linedraw" ["e"=1]
"LingDong-/skeleton-tracing" -> "SHI-Labs/SGL-Retinal-Vessel-Segmentation" ["e"=1]
"crockpotveggies/tinderbox" -> "ryanjay0/miles-deep" ["e"=1]
"NVlabs/few-shot-vid2vid" -> "NVIDIA/vid2vid" ["e"=1]
"NVlabs/few-shot-vid2vid" -> "NVlabs/FUNIT" ["e"=1]
"unnir/cVAE" -> "hujinsen/pytorch_VAE_CVAE"
"Lornatang/AlexNet-PyTorch" -> "Lornatang/pytorch-alexnet-cifar100"
"gazijarin/TDSBHomeworkManagement" -> "gazijarin/OdinBot"
"akanimax/msg-stylegan-tf" -> "akanimax/msg-gan-v1"
"akanimax/msg-stylegan-tf" -> "akanimax/BMSG-GAN"
"akanimax/msg-stylegan-tf" -> "google-research/lag"
"kam1107/RealnessGAN" -> "akanimax/msg-gan-v1" ["e"=1]
"kam1107/RealnessGAN" -> "akanimax/BMSG-GAN" ["e"=1]
"kam1107/RealnessGAN" -> "Xiaoming-Yu/DMIT" ["e"=1]
"nccuviplab/CursiveChineseCalligraphyDataset" -> "zhuojg/chinese-calligraphy-dataset"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "ethanluoyc/pytorch-vae"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "Jackson-Kang/Pytorch-Diffusion-Model-Tutorial"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "lyeoni/pytorch-mnist-VAE"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "HGU-DLLAB/Korean-FastSpeech2-Pytorch" ["e"=1]
"Jackson-Kang/Pytorch-VAE-tutorial" -> "williamFalcon/pytorch-lightning-vae"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "SashaMalysheva/Pytorch-VAE"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "zalandoresearch/pytorch-vq-vae" ["e"=1]
"Jackson-Kang/Pytorch-VAE-tutorial" -> "LukeDitria/CNN-VAE"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "sksq96/pytorch-vae"
"Jackson-Kang/Pytorch-VAE-tutorial" -> "WICWIU/WICWIU" ["e"=1]
"peterldowns/clickbait-classifier" -> "saurabhmathur96/clickbait-detector"
"siefkenj/2020-MAT-335-webpage" -> "slakh96/no-mans-land"
"jd-opensource/lapa-dataset" -> "JPlin/Relabeled-HELEN-Dataset" ["e"=1]
"Lornatang/CycleGAN-PyTorch" -> "Lornatang/pytorch-alexnet-cifar100"
"mit-han-lab/gan-compression" -> "NVlabs/FUNIT" ["e"=1]
"alpc91/NICE-GAN-pytorch" -> "alokwhitewolf/Pytorch-Attention-Guided-CycleGAN" ["e"=1]
"alpc91/NICE-GAN-pytorch" -> "HsinYingLee/DRIT" ["e"=1]
"rishabhd786/VAE-GAN-PYTORCH" -> "ry85/VAE-GAN"
"LukeDitria/CNN-VAE" -> "sksq96/pytorch-vae"
"boschresearch/unetgan" -> "akanimax/msg-gan-v1" ["e"=1]
"boschresearch/unetgan" -> "akanimax/BMSG-GAN" ["e"=1]
"Ha0Tang/XingGAN" -> "tobran/DF-GAN" ["e"=1]
"iamsohard/ChineseCalligraphyGenerator" -> "herrkaefer/chinese-calligraphy-vectorization"
"mrlibw/ControlGAN" -> "mrlibw/ManiGAN"
"mrlibw/ControlGAN" -> "MinfengZhu/DM-GAN"
"mrlibw/ControlGAN" -> "woozzu/tagan"
"mrlibw/ControlGAN" -> "qiaott/MirrorGAN"
"mrlibw/ControlGAN" -> "qiaott/LeicaGAN"
"mrlibw/ControlGAN" -> "hanzhanggit/StackGAN-inception-model"
"mrlibw/ControlGAN" -> "tobran/DF-GAN"
"mrlibw/ControlGAN" -> "dongdongdong666/CPGAN"
"mrlibw/ControlGAN" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"mrlibw/ControlGAN" -> "jamesli1618/Obj-GAN"
"mrlibw/ControlGAN" -> "IIGROUP/TediGAN" ["e"=1]
"mrlibw/ControlGAN" -> "maincarry/R-Precision"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "tohinz/multiple-objects-gan"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "MinfengZhu/DM-GAN"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "qiaott/MirrorGAN"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "jamesli1618/Obj-GAN"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "dongdongdong666/CPGAN"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "mrlibw/ControlGAN"
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" -> "google-research/trecs_image_generation"
"ry85/VAE-GAN" -> "lisadunlap/VAE-GAN"
"ry85/VAE-GAN" -> "rishabhd786/VAE-GAN-PYTORCH"
"tobran/DF-GAN" -> "Ha0Tang/BiGraphGAN" ["e"=1]
"tobran/DF-GAN" -> "MinfengZhu/DM-GAN"
"tobran/DF-GAN" -> "Ha0Tang/XingGAN" ["e"=1]
"tobran/DF-GAN" -> "zhangqianhui/GazeAnimation" ["e"=1]
"tobran/DF-GAN" -> "mrlibw/ControlGAN"
"tobran/DF-GAN" -> "tobran/GALIP"
"tobran/DF-GAN" -> "wtliao/text2image"
"tobran/DF-GAN" -> "senmaoy/RAT-GAN"
"tobran/DF-GAN" -> "dongdongdong666/CPGAN"
"tobran/DF-GAN" -> "google-research/xmcgan_image_generation"
"tobran/DF-GAN" -> "taoxugit/AttnGAN"
"tobran/DF-GAN" -> "davidstap/AttnGAN"
"tobran/DF-GAN" -> "IIGROUP/TediGAN" ["e"=1]
"tobran/DF-GAN" -> "Ha0Tang/GestureGAN" ["e"=1]
"tobran/DF-GAN" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"Xiaoming-Yu/DMIT" -> "HsinYingLee/MDMM"
"Xiaoming-Yu/DMIT" -> "Xiaoming-Yu/SingleGAN"
"mrlibw/ManiGAN" -> "mrlibw/ControlGAN"
"mrlibw/ManiGAN" -> "woozzu/tagan"
"mrlibw/ManiGAN" -> "mrlibw/Lightweight-Manipulation"
"mrlibw/ManiGAN" -> "MinfengZhu/DM-GAN"
"zhuojg/chinese-calligraphy-dataset" -> "nccuviplab/CursiveChineseCalligraphyDataset"
"MinfengZhu/DM-GAN" -> "qiaott/MirrorGAN"
"MinfengZhu/DM-GAN" -> "mrlibw/ControlGAN"
"MinfengZhu/DM-GAN" -> "dongdongdong666/CPGAN"
"MinfengZhu/DM-GAN" -> "tobran/DF-GAN"
"MinfengZhu/DM-GAN" -> "jamesli1618/Obj-GAN"
"MinfengZhu/DM-GAN" -> "tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis"
"MinfengZhu/DM-GAN" -> "ypxie/HDGan"
"MinfengZhu/DM-GAN" -> "lzhbrian/arbitrary-text-to-image-papers"
"MinfengZhu/DM-GAN" -> "taoxugit/AttnGAN"
"MinfengZhu/DM-GAN" -> "tohinz/multiple-objects-gan"
"MinfengZhu/DM-GAN" -> "huiyegit/T2I_CL"
"MinfengZhu/DM-GAN" -> "google-research/xmcgan_image_generation"
"MinfengZhu/DM-GAN" -> "mrlibw/ManiGAN"
"herrkaefer/chinese-calligraphy-vectorization" -> "iamsohard/ChineseCalligraphyGenerator"
"Eskender-B/roi-tanh" -> "JPlin/Relabeled-HELEN-Dataset"
"Eskender-B/roi-tanh" -> "Eskender-B/icnn"
"elvisyjlin/RelGAN-PyTorch" -> "willylulu/RelGAN"
"dongdongdong666/CPGAN" -> "MinfengZhu/DM-GAN"
"willylulu/RelGAN" -> "elvisyjlin/RelGAN-PyTorch"
"willylulu/RelGAN" -> "BCV-Uniandes/SMIT"
"junrushao1994/ACM-ICPC-Standard-Code-Library" -> "junrushao/Final-Fanatic-Facility"
"karpathy/char-rnn" -> "jcjohnson/neural-style" ["e"=1]
"karpathy/char-rnn" -> "magenta/magenta" ["e"=1]
"nagadomi/waifu2x" -> "lllyasviel/style2paints" ["e"=1]
"lucidrains/vit-pytorch" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"google/deepdream" -> "jcjohnson/neural-style" ["e"=1]
"google/deepdream" -> "graphific/DeepDreamVideo" ["e"=1]
"google/deepdream" -> "alexjc/neural-doodle" ["e"=1]
"google/deepdream" -> "magenta/magenta" ["e"=1]
"NVlabs/stylegan2-ada-pytorch" -> "NVlabs/stylegan" ["e"=1]
"gazijarin/Gazi" -> "gazijarin/AdamAI"
"gazijarin/Gazi" -> "gazijarin/OdinBot"
"gazijarin/Gazi" -> "gazijarin/TDSBHomeworkManagement"
"gazijarin/Gazi" -> "slakh96/no-mans-land"
"gazijarin/Gazi" -> "gazijarin/Truth"
"hardikvasa/google-images-download" -> "soumith/ganhacks" ["e"=1]
"VITA-Group/TransGAN" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"kjw0612/awesome-deep-vision" -> "soumith/ganhacks" ["e"=1]
"kjw0612/awesome-deep-vision" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"kjw0612/awesome-deep-vision" -> "nightrome/really-awesome-gan" ["e"=1]
"tonybaloney/vscode-pets" -> "httpcats/http.cat" ["e"=1]
"soumith/cvpr2015" -> "soumith/dcgan.torch" ["e"=1]
"soumith/cvpr2015" -> "facebookarchive/eyescream" ["e"=1]
"jcjohnson/cnn-vis" -> "jrosebr1/bat-country"
"jcjohnson/cnn-vis" -> "facebookarchive/eyescream"
"jcjohnson/cnn-vis" -> "317070/Twitch-plays-LSD-neural-net"
"jcjohnson/cnn-vis" -> "samim23/DeepDreamAnim"
"jcjohnson/cnn-vis" -> "Russell91/apollocaffe"
"jcjohnson/cnn-vis" -> "skaae/lasagne-draw" ["e"=1]
"jcjohnson/cnn-vis" -> "wojciechz/learning_to_execute" ["e"=1]
"jcjohnson/cnn-vis" -> "Russell91/apollo"
"jcjohnson/cnn-vis" -> "ajtulloch/dnngraph" ["e"=1]
"jcjohnson/cnn-vis" -> "auduno/deepdraw" ["e"=1]
"jcjohnson/cnn-vis" -> "VISIONAI/clouddream"
"jcjohnson/cnn-vis" -> "facebookarchive/fb-caffe-exts" ["e"=1]
"jcjohnson/cnn-vis" -> "aravindhm/deep-goggle"
"jcjohnson/cnn-vis" -> "stitchfix/fauxtograph" ["e"=1]
"jcjohnson/cnn-vis" -> "skaae/recurrent-spatial-transformer-code" ["e"=1]
"f-dangel/cockpit" -> "davidcpage/cifar10-fast" ["e"=1]
"fyu/lsun" -> "bioinf-jku/TTUR"
"fyu/lsun" -> "soumith/dcgan.torch"
"fyu/lsun" -> "sbarratt/inception-score-pytorch"
"fyu/lsun" -> "mseitzer/pytorch-fid" ["e"=1]
"fyu/lsun" -> "leVirve/lsun-room" ["e"=1]
"fyu/lsun" -> "GaParmar/clean-fid" ["e"=1]
"fyu/lsun" -> "rosinality/style-based-gan-pytorch"
"fyu/lsun" -> "martinarjovsky/WassersteinGAN"
"fyu/lsun" -> "pfnet-research/sngan_projection"
"fyu/lsun" -> "phizaz/diffae" ["e"=1]
"yosinski/deep-visualization-toolbox" -> "Newmu/dcgan_code" ["e"=1]
"kelvinxu/arctic-captions" -> "mansimov/text2image" ["e"=1]
"ryankiros/skip-thoughts" -> "paarthneekhara/text-to-image" ["e"=1]
"wtliao/text2image" -> "tobran/DF-GAN"
"wtliao/text2image" -> "senmaoy/RAT-GAN"
"Lasagne/Recipes" -> "Newmu/dcgan_code" ["e"=1]
"facebookarchive/eyescream" -> "skaae/torch-gan" ["e"=1]
"facebookarchive/eyescream" -> "xiaolonw/ss-gan"
"facebookarchive/eyescream" -> "twitter-archive/torch-autograd" ["e"=1]
"facebookarchive/eyescream" -> "y0ast/VAE-Torch" ["e"=1]
"facebookarchive/eyescream" -> "reedscot/icml2016"
"facebookarchive/eyescream" -> "siemanko/tf-adversarial" ["e"=1]
"facebookarchive/eyescream" -> "soumith/dcgan.torch"
"facebookarchive/eyescream" -> "vivanov879/draw" ["e"=1]
"facebookarchive/eyescream" -> "reedscot/nips2016"
"facebookarchive/eyescream" -> "DmitryUlyanov/texture_nets"
"facebookarchive/eyescream" -> "Newmu/dcgan_code"
"facebookarchive/eyescream" -> "jcjohnson/cnn-vis"
"facebookarchive/eyescream" -> "reedscot/cvpr2016"
"facebookarchive/eyescream" -> "Evolving-AI-Lab/synthesizing"
"facebookarchive/eyescream" -> "cvondrick/videogan"
"graphific/DeepDreamVideo" -> "samim23/DeepDreamAnim"
"graphific/DeepDreamVideo" -> "google/deepdream" ["e"=1]
"graphific/DeepDreamVideo" -> "VISIONAI/clouddream"
"graphific/DeepDreamVideo" -> "manuelruder/artistic-videos"
"graphific/DeepDreamVideo" -> "kesara/deepdreamer"
"graphific/DeepDreamVideo" -> "ryankennedyio/deep-dream-generator"
"graphific/DeepDreamVideo" -> "jcjohnson/cnn-vis"
"graphific/DeepDreamVideo" -> "jrosebr1/bat-country"
"graphific/DeepDreamVideo" -> "JohnMount/CaffeECSExample"
"graphific/DeepDreamVideo" -> "alexjc/neural-doodle"
"graphific/DeepDreamVideo" -> "chjj/ttystudio" ["e"=1]
"graphific/DeepDreamVideo" -> "Newmu/dcgan_code"
"graphific/DeepDreamVideo" -> "awentzonline/image-analogies"
"graphific/DeepDreamVideo" -> "jcjohnson/neural-style"
"graphific/DeepDreamVideo" -> "kaishengtai/neuralart"
"tmadl/semisup-learn" -> "clvrai/SSGAN-Tensorflow" ["e"=1]
"ajtulloch/dnngraph" -> "jcjohnson/cnn-vis" ["e"=1]
"JustusvLiebig/Soft_Sensor_Experiments" -> "JustusvLiebig/Inferential_Sensor_Experiment"
"JustusvLiebig/Soft_Sensor_Experiments" -> "iamownt/LSTM-DeepFM"
"JustusvLiebig/Soft_Sensor_Experiments" -> "vigorfif/Soft-Sensor-Modelling"
"JustusvLiebig/Soft_Sensor_Experiments" -> "hkaneko1985/adaptive_soft_sensors"
"JustusvLiebig/Soft_Sensor_Experiments" -> "tonyzyl/Semisupervised-VAE-for-Regression-Application-on-Soft-Sensor"
"JustusvLiebig/Soft_Sensor_Experiments" -> "aysunrhn/Adaptive-Soft-Sensor-Design"
"JustusvLiebig/Soft_Sensor_Experiments" -> "MingweiJia/GCN-based_soft_sensor"
"JustusvLiebig/Soft_Sensor_Experiments" -> "kxytim/DLVM_for_process_monitoring"
"teradeep/demo-apps" -> "facebookarchive/eyescream" ["e"=1]
"teradeep/demo-apps" -> "Russell91/apollo" ["e"=1]
"CuriousAI/ladder" -> "facebookarchive/eyescream" ["e"=1]
"samim23/DeepDreamAnim" -> "graphific/DeepDreamVideo"
"samim23/DeepDreamAnim" -> "kesara/deepdreamer"
"samim23/DeepDreamAnim" -> "VISIONAI/clouddream"
"samim23/DeepDreamAnim" -> "jcjohnson/cnn-vis"
"samim23/DeepDreamAnim" -> "317070/Twitch-plays-LSD-neural-net"
"samim23/DeepDreamAnim" -> "ryankennedyio/deep-dream-generator"
"samim23/DeepDreamAnim" -> "jrosebr1/bat-country"
"samim23/DeepDreamAnim" -> "Dhar/image-dreamer"
"samim23/DeepDreamAnim" -> "mtyka/neural_artistic_style"
"samim23/DeepDreamAnim" -> "samim23/NeuralTalkAnimator"
"samim23/DeepDreamAnim" -> "auduno/deepdraw" ["e"=1]
"samim23/DeepDreamAnim" -> "samim23/GitXiv"
"samim23/DeepDreamAnim" -> "jbornschein/draw" ["e"=1]
"kesara/deepdreamer" -> "samim23/DeepDreamAnim"
"IIGROUP/TediGAN" -> "mrlibw/ControlGAN" ["e"=1]
"IIGROUP/TediGAN" -> "tobran/DF-GAN" ["e"=1]
"jbornschein/draw" -> "ericjang/draw" ["e"=1]
"jbornschein/draw" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"bearpaw/clothing-co-parsing" -> "sangwoomo/instagan" ["e"=1]
"VISIONAI/clouddream" -> "mjibson/ddd"
"VISIONAI/clouddream" -> "samim23/DeepDreamAnim"
"VISIONAI/clouddream" -> "jrosebr1/bat-country"
"VISIONAI/clouddream" -> "graphific/DeepDreamVideo"
"VISIONAI/clouddream" -> "kesara/deepdreamer"
"VISIONAI/clouddream" -> "ryankennedyio/deep-dream-generator"
"VISIONAI/clouddream" -> "graphific/dl-machine"
"VISIONAI/clouddream" -> "JohnMount/CaffeECSExample"
"VISIONAI/clouddream" -> "jcjohnson/cnn-vis"
"VISIONAI/clouddream" -> "herval/deepdream-docker"
"VISIONAI/clouddream" -> "317070/Twitch-plays-LSD-neural-net"
"imlixinyang/HiSD" -> "elvisyjlin/AttGAN-PyTorch" ["e"=1]
"imlixinyang/HiSD" -> "bluestyle97/STGAN-pytorch" ["e"=1]
"ryankennedyio/deep-dream-generator" -> "VISIONAI/clouddream"
"ryankennedyio/deep-dream-generator" -> "kesara/deepdreamer"
"jrosebr1/bat-country" -> "jcjohnson/cnn-vis"
"jrosebr1/bat-country" -> "VISIONAI/clouddream"
"jrosebr1/bat-country" -> "317070/Twitch-plays-LSD-neural-net"
"jrosebr1/bat-country" -> "OverStruck/deep-dream-maker"
"EderSantana/seya" -> "phreeza/keras-GAN" ["e"=1]
"Jackson-Kang/Pytorch-Diffusion-Model-Tutorial" -> "Jackson-Kang/VQVC-Pytorch"
"Russell91/nlpcaffe" -> "Russell91/apollocaffe" ["e"=1]
"aravindhm/deep-goggle" -> "jbmpark/image_invert"
"aravindhm/deep-goggle" -> "donglaiw/mNeuron"
"aravindhm/deep-goggle" -> "bharath272/sds_eccv2014"
"aravindhm/deep-goggle" -> "Russell91/apollocaffe"
"aravindhm/deep-goggle" -> "aravindhm/nnpreimage"
"Russell91/apollocaffe" -> "Russell91/apollo"
"Russell91/apollocaffe" -> "Russell91/ReInspect" ["e"=1]
"317070/Twitch-plays-LSD-neural-net" -> "an-kumar/caffe-theano-conversion" ["e"=1]
"JustusvLiebig/Inferential_Sensor_Experiment" -> "yaole0720/VTR-based-Soft-Sensor"
"Russell91/apollo" -> "Russell91/apollocaffe"
"herval/deepdream-docker" -> "saturnism/deepdream-docker"
"mikesj-public/convolutional_autoencoder" -> "y0ast/Variational-Autoencoder"
"mikesj-public/convolutional_autoencoder" -> "nanopony/keras-convautoencoder"
"mikesj-public/convolutional_autoencoder" -> "mikesj-public/dcgan-autoencoder"
"mikesj-public/convolutional_autoencoder" -> "ramarlina/DenoisingAutoEncoder"
"junrushao/Final-Fanatic-Facility" -> "junrushao1994/ACM-ICPC-Standard-Code-Library"
"johnbuluba/Yatcobot" -> "AuxProc/twitter-contest"
"carpedm20/DCGAN-tensorflow" -> "Newmu/dcgan_code"
"carpedm20/DCGAN-tensorflow" -> "zhangqianhui/AdversarialNetsPapers"
"carpedm20/DCGAN-tensorflow" -> "wiseodd/generative-models"
"carpedm20/DCGAN-tensorflow" -> "soumith/ganhacks"
"carpedm20/DCGAN-tensorflow" -> "openai/improved-gan"
"carpedm20/DCGAN-tensorflow" -> "igul222/improved_wgan_training"
"carpedm20/DCGAN-tensorflow" -> "martinarjovsky/WassersteinGAN"
"carpedm20/DCGAN-tensorflow" -> "affinelayer/pix2pix-tensorflow"
"carpedm20/DCGAN-tensorflow" -> "goodfeli/adversarial"
"carpedm20/DCGAN-tensorflow" -> "hindupuravinash/the-gan-zoo"
"carpedm20/DCGAN-tensorflow" -> "tkarras/progressive_growing_of_gans"
"carpedm20/DCGAN-tensorflow" -> "phillipi/pix2pix"
"carpedm20/DCGAN-tensorflow" -> "hwalsuklee/tensorflow-generative-model-collections"
"carpedm20/DCGAN-tensorflow" -> "junyanz/CycleGAN"
"carpedm20/DCGAN-tensorflow" -> "bamos/dcgan-completion.tensorflow"
"httpcats/http.cat" -> "nyaadevs/nyaa" ["e"=1]
"httpcats/http.cat" -> "AlexiaJM/Deep-learning-with-cats"
"httpcats/http.cat" -> "typelevel/cats" ["e"=1]
"httpcats/http.cat" -> "typelevel/cats-effect" ["e"=1]
"httpcats/http.cat" -> "websockets/wscat"
"httpcats/http.cat" -> "Endava/cats" ["e"=1]
"httpcats/http.cat" -> "MrGlockenspiel/activate-linux" ["e"=1]
"httpcats/http.cat" -> "Discord-Datamining/Discord-Datamining" ["e"=1]
"httpcats/http.cat" -> "codyogden/killedbygoogle" ["e"=1]
"httpcats/http.cat" -> "absolute-quantum/cats-blender-plugin" ["e"=1]
"httpcats/http.cat" -> "Externalizable/bongo.cat" ["e"=1]
"httpcats/http.cat" -> "owenthereal/ccat" ["e"=1]
"httpcats/http.cat" -> "PrismLauncher/PrismLauncher" ["e"=1]
"httpcats/http.cat" -> "Luohuayu/CatServer" ["e"=1]
"httpcats/http.cat" -> "mkrl/misbrands" ["e"=1]
"NVlabs/stylegan3" -> "NVlabs/stylegan" ["e"=1]
"karpathy/neuraltalk2" -> "Newmu/dcgan_code" ["e"=1]
"karpathy/neuraltalk2" -> "jcjohnson/neural-style" ["e"=1]
"karpathy/neuraltalk2" -> "jcjohnson/fast-neural-style" ["e"=1]
"schollz/find" -> "pavelgonchar/colornet" ["e"=1]
"jazzsaxmafia/show_attend_and_tell.tensorflow" -> "mansimov/text2image" ["e"=1]
"Newmu/dcgan_code" -> "carpedm20/DCGAN-tensorflow"
"Newmu/dcgan_code" -> "soumith/dcgan.torch"
"Newmu/dcgan_code" -> "openai/improved-gan"
"Newmu/dcgan_code" -> "martinarjovsky/WassersteinGAN"
"Newmu/dcgan_code" -> "junyanz/iGAN"
"Newmu/dcgan_code" -> "goodfeli/adversarial"
"Newmu/dcgan_code" -> "jacobgil/keras-dcgan"
"Newmu/dcgan_code" -> "igul222/improved_wgan_training"
"Newmu/dcgan_code" -> "Lasagne/Lasagne" ["e"=1]
"Newmu/dcgan_code" -> "zhangqianhui/AdversarialNetsPapers"
"Newmu/dcgan_code" -> "soumith/ganhacks"
"Newmu/dcgan_code" -> "openai/InfoGAN"
"Newmu/dcgan_code" -> "bamos/dcgan-completion.tensorflow"
"Newmu/dcgan_code" -> "wiseodd/generative-models"
"Newmu/dcgan_code" -> "facebookarchive/eyescream"
"soumith/dcgan.torch" -> "Newmu/dcgan_code"
"soumith/dcgan.torch" -> "reedscot/icml2016"
"soumith/dcgan.torch" -> "carpedm20/DCGAN-tensorflow"
"soumith/dcgan.torch" -> "robbiebarrat/art-DCGAN"
"soumith/dcgan.torch" -> "openai/improved-gan"
"soumith/dcgan.torch" -> "martinarjovsky/WassersteinGAN"
"soumith/dcgan.torch" -> "mattya/chainer-DCGAN" ["e"=1]
"soumith/dcgan.torch" -> "facebookarchive/eyescream"
"soumith/dcgan.torch" -> "carpedm20/awesome-torch" ["e"=1]
"soumith/dcgan.torch" -> "torch/nn" ["e"=1]
"soumith/dcgan.torch" -> "Element-Research/rnn" ["e"=1]
"soumith/dcgan.torch" -> "facebookarchive/fb.resnet.torch" ["e"=1]
"soumith/dcgan.torch" -> "y0ast/VAE-Torch" ["e"=1]
"soumith/dcgan.torch" -> "skaae/torch-gan" ["e"=1]
"soumith/dcgan.torch" -> "soumith/imagenet-multiGPU.torch" ["e"=1]
"ckmarkoh/neuralart_tensorflow" -> "log0/neural-style-painting"
"ckmarkoh/neuralart_tensorflow" -> "woodrush/neural-art-tf"
"ckmarkoh/neuralart_tensorflow" -> "ckmarkoh/AcrosticPoem" ["e"=1]
"ckmarkoh/neuralart_tensorflow" -> "abalone0204/Clairvoyance" ["e"=1]
"mansimov/text2image" -> "reedscot/icml2016"
"mansimov/text2image" -> "reedscot/nips2016"
"mansimov/text2image" -> "kelvinxu/arctic-captions" ["e"=1]
"mansimov/text2image" -> "paarthneekhara/text-to-image"
"mansimov/text2image" -> "hanzhanggit/StackGAN-v2"
"mansimov/text2image" -> "ryankiros/skip-thoughts" ["e"=1]
"mansimov/text2image" -> "ryankiros/visual-semantic-embedding" ["e"=1]
"mansimov/text2image" -> "jiasenlu/AdaptiveAttention" ["e"=1]
"mansimov/text2image" -> "cvondrick/videogan"
"mansimov/text2image" -> "jazzsaxmafia/show_attend_and_tell.tensorflow" ["e"=1]
"mansimov/text2image" -> "jcjohnson/densecap" ["e"=1]
"mansimov/text2image" -> "ericjang/draw"
"mansimov/text2image" -> "hanzhanggit/StackGAN"
"mansimov/text2image" -> "DeepRNN/image_captioning" ["e"=1]
"mansimov/text2image" -> "jbornschein/draw" ["e"=1]
"jcjohnson/neural-style" -> "alexjc/neural-doodle"
"jcjohnson/neural-style" -> "google/deepdream" ["e"=1]
"jcjohnson/neural-style" -> "jcjohnson/fast-neural-style"
"jcjohnson/neural-style" -> "luanfujun/deep-photo-styletransfer"
"jcjohnson/neural-style" -> "anishathalye/neural-style"
"jcjohnson/neural-style" -> "karpathy/char-rnn" ["e"=1]
"jcjohnson/neural-style" -> "lengstrom/fast-style-transfer"
"jcjohnson/neural-style" -> "torch/torch7" ["e"=1]
"jcjohnson/neural-style" -> "kaishengtai/neuralart"
"jcjohnson/neural-style" -> "BVLC/caffe" ["e"=1]
"jcjohnson/neural-style" -> "magenta/magenta"
"jcjohnson/neural-style" -> "alexjc/neural-enhance"
"jcjohnson/neural-style" -> "junyanz/CycleGAN"
"jcjohnson/neural-style" -> "karpathy/neuraltalk2" ["e"=1]
"jcjohnson/neural-style" -> "apache/mxnet" ["e"=1]
"brendenlake/BPL" -> "Newmu/dcgan_code" ["e"=1]
"szcom/rnnlib" -> "ericjang/draw" ["e"=1]
"szcom/rnnlib" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"szcom/rnnlib" -> "carpedm20/pixel-rnn-tensorflow" ["e"=1]
"google/inception" -> "facebookarchive/eyescream" ["e"=1]
"anishathalye/neural-style" -> "lengstrom/fast-style-transfer"
"anishathalye/neural-style" -> "andersbll/neural_artistic_style"
"anishathalye/neural-style" -> "fzliu/style-transfer"
"anishathalye/neural-style" -> "cysmith/neural-style-tf"
"anishathalye/neural-style" -> "jcjohnson/neural-style"
"anishathalye/neural-style" -> "jcjohnson/fast-neural-style"
"anishathalye/neural-style" -> "titu1994/Neural-Style-Transfer"
"anishathalye/neural-style" -> "carpedm20/DCGAN-tensorflow"
"anishathalye/neural-style" -> "alexjc/neural-doodle"
"anishathalye/neural-style" -> "hzy46/fast-neural-style-tensorflow"
"anishathalye/neural-style" -> "luanfujun/deep-photo-styletransfer"
"anishathalye/neural-style" -> "magenta/magenta"
"anishathalye/neural-style" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"anishathalye/neural-style" -> "ethereon/caffe-tensorflow" ["e"=1]
"anishathalye/neural-style" -> "affinelayer/pix2pix-tensorflow"
"robertsdionne/neural-network-papers" -> "Newmu/dcgan_code" ["e"=1]
"woodrush/neural-art-tf" -> "jazzsaxmafia/show_and_tell.tensorflow" ["e"=1]
"woodrush/neural-art-tf" -> "Ivaylo-Popov/Theano-Lights" ["e"=1]
"woodrush/neural-art-tf" -> "siemanko/tensorflow-deepq" ["e"=1]
"woodrush/neural-art-tf" -> "ckmarkoh/neuralart_tensorflow"
"woodrush/neural-art-tf" -> "jazzsaxmafia/show_attend_and_tell.tensorflow" ["e"=1]
"woodrush/neural-art-tf" -> "DmitryUlyanov/texture_nets"
"woodrush/neural-art-tf" -> "chuanli11/MGANs"
"woodrush/neural-art-tf" -> "google/prettytensor" ["e"=1]
"woodrush/neural-art-tf" -> "ericjang/draw"
"woodrush/neural-art-tf" -> "anishathalye/neural-style"
"woodrush/neural-art-tf" -> "coreylynch/async-rl" ["e"=1]
"woodrush/neural-art-tf" -> "fzliu/style-transfer"
"woodrush/neural-art-tf" -> "kaishengtai/neuralart"
"woodrush/neural-art-tf" -> "andersbll/neural_artistic_style"
"woodrush/neural-art-tf" -> "NickShahML/tensorflow_with_latest_papers" ["e"=1]
"aleju/face-generator" -> "aleju/cat-generator"
"aleju/face-generator" -> "gsurma/face_generator"
"achael/eht-imaging" -> "NVlabs/SPADE" ["e"=1]
"andersbll/neural_artistic_style" -> "fzliu/style-transfer"
"andersbll/neural_artistic_style" -> "anishathalye/neural-style"
"andersbll/neural_artistic_style" -> "kaishengtai/neuralart"
"andersbll/neural_artistic_style" -> "andersbll/deeppy" ["e"=1]
"andersbll/neural_artistic_style" -> "jcjohnson/neural-style"
"andersbll/neural_artistic_style" -> "andersbll/cudarray" ["e"=1]
"andersbll/neural_artistic_style" -> "yusuketomoto/chainer-fast-neuralstyle"
"andersbll/neural_artistic_style" -> "DmitryUlyanov/texture_nets"
"andersbll/neural_artistic_style" -> "manuelruder/artistic-videos"
"andersbll/neural_artistic_style" -> "jcjohnson/fast-neural-style"
"andersbll/neural_artistic_style" -> "alexjc/neural-doodle"
"andersbll/neural_artistic_style" -> "ryankiros/neural-storyteller" ["e"=1]
"andersbll/neural_artistic_style" -> "mbartoli/neural-animation"
"andersbll/neural_artistic_style" -> "woodrush/neural-art-tf"
"andersbll/neural_artistic_style" -> "awentzonline/image-analogies"
"fzliu/style-transfer" -> "andersbll/neural_artistic_style"
"fzliu/style-transfer" -> "anishathalye/neural-style"
"fzliu/style-transfer" -> "titu1994/Neural-Style-Transfer"
"fzliu/style-transfer" -> "jcjohnson/fast-neural-style"
"fzliu/style-transfer" -> "chuanli11/CNNMRF"
"fzliu/style-transfer" -> "lengstrom/fast-style-transfer"
"fzliu/style-transfer" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"fzliu/style-transfer" -> "yusuketomoto/chainer-fast-neuralstyle"
"fzliu/style-transfer" -> "manuelruder/artistic-videos"
"fzliu/style-transfer" -> "woodrush/neural-art-tf"
"fzliu/style-transfer" -> "hzy46/fast-neural-style-tensorflow"
"fzliu/style-transfer" -> "jcjohnson/neural-style"
"fzliu/style-transfer" -> "DmitryUlyanov/texture_nets"
"fzliu/style-transfer" -> "kaishengtai/neuralart"
"fzliu/style-transfer" -> "cysmith/neural-style-tf"
"ryankiros/neural-storyteller" -> "Newmu/dcgan_code" ["e"=1]
"ryankiros/neural-storyteller" -> "alexjc/neural-doodle" ["e"=1]
"ryankiros/neural-storyteller" -> "paarthneekhara/text-to-image" ["e"=1]
"ryankiros/neural-storyteller" -> "awentzonline/image-analogies" ["e"=1]
"SergeyMorugin/ostagram" -> "jcjohnson/neural-style"
"SergeyMorugin/ostagram" -> "manuelruder/artistic-videos"
"SergeyMorugin/ostagram" -> "chuanli11/CNNMRF"
"SergeyMorugin/ostagram" -> "kaishengtai/neuralart"
"SergeyMorugin/ostagram" -> "awentzonline/image-analogies"
"SergeyMorugin/ostagram" -> "yusuketomoto/chainer-fast-neuralstyle"
"SergeyMorugin/ostagram" -> "alexjc/neural-doodle"
"SergeyMorugin/ostagram" -> "andersbll/neural_artistic_style"
"SergeyMorugin/ostagram" -> "fzliu/style-transfer"
"SergeyMorugin/ostagram" -> "DmitryUlyanov/fast-neural-doodle"
"SergeyMorugin/ostagram" -> "DmitryUlyanov/texture_nets"
"SergeyMorugin/ostagram" -> "soumith/cvpr2015" ["e"=1]
"SergeyMorugin/ostagram" -> "titu1994/Neural-Style-Transfer"
"SergeyMorugin/ostagram" -> "jcjohnson/fast-neural-style"
"SergeyMorugin/ostagram" -> "anishathalye/neural-style"
"gabrieleangeletti/Deep-Learning-TensorFlow" -> "cmgreen210/TensorFlowDeepAutoencoder" ["e"=1]
"gabrieleangeletti/Deep-Learning-TensorFlow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"gabrieleangeletti/Deep-Learning-TensorFlow" -> "rajarsheem/libsdae-autoencoder-tensorflow" ["e"=1]
"tensorpack/tensorpack" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"dschep/ntfy" -> "david-gpu/srez" ["e"=1]
"davidADSP/Generative_Deep_Learning_2nd_Edition" -> "GANs-in-Action/gans-in-action" ["e"=1]
"s9xie/hed" -> "affinelayer/pix2pix-tensorflow" ["e"=1]
"zer0n/deepframeworks" -> "Newmu/dcgan_code" ["e"=1]
"facebookarchive/fb-caffe-exts" -> "facebookarchive/eyescream" ["e"=1]
"autumnai/leaf" -> "alexjc/neural-doodle" ["e"=1]
"kaishengtai/neuralart" -> "andersbll/neural_artistic_style"
"kaishengtai/neuralart" -> "jcjohnson/neural-style"
"kaishengtai/neuralart" -> "chuanli11/CNNMRF"
"kaishengtai/neuralart" -> "awentzonline/image-analogies"
"kaishengtai/neuralart" -> "manuelruder/artistic-videos"
"kaishengtai/neuralart" -> "DmitryUlyanov/texture_nets"
"kaishengtai/neuralart" -> "ryankiros/neural-storyteller" ["e"=1]
"kaishengtai/neuralart" -> "Element-Research/rnn" ["e"=1]
"kaishengtai/neuralart" -> "mbartoli/neural-animation"
"kaishengtai/neuralart" -> "Newmu/dcgan_code"
"kaishengtai/neuralart" -> "robertsdionne/neural-network-papers" ["e"=1]
"kaishengtai/neuralart" -> "torch/torch7" ["e"=1]
"kaishengtai/neuralart" -> "NervanaSystems/neon" ["e"=1]
"kaishengtai/neuralart" -> "alexjc/neural-doodle"
"kaishengtai/neuralart" -> "jcjohnson/fast-neural-style"
"karpathy/arxiv-sanity-preserver" -> "soumith/ganhacks" ["e"=1]
"oneThousand1000/HairMapper" -> "StoryMY/take-off-eyeglasses" ["e"=1]
"ryankiros/visual-semantic-embedding" -> "mansimov/text2image" ["e"=1]
"jazzsaxmafia/show_and_tell.tensorflow" -> "woodrush/neural-art-tf" ["e"=1]
"mansimov/unsupervised-videos" -> "cvondrick/videogan" ["e"=1]
"andersbll/autoencoding_beyond_pixels" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"andersbll/autoencoding_beyond_pixels" -> "IshmaelBelghazi/ALI"
"andersbll/autoencoding_beyond_pixels" -> "lucabergamini/VAEGAN-PYTORCH"
"andersbll/autoencoding_beyond_pixels" -> "zhangqianhui/vae-gan-tensorflow"
"andersbll/autoencoding_beyond_pixels" -> "anitan0925/vaegan"
"andersbll/autoencoding_beyond_pixels" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"andersbll/autoencoding_beyond_pixels" -> "y0ast/VAE-Torch" ["e"=1]
"andersbll/autoencoding_beyond_pixels" -> "musyoku/adversarial-autoencoder"
"andersbll/autoencoding_beyond_pixels" -> "stitchfix/fauxtograph" ["e"=1]
"andersbll/autoencoding_beyond_pixels" -> "JeremyCCHsu/tf-vaegan"
"andersbll/autoencoding_beyond_pixels" -> "openai/InfoGAN"
"andersbll/autoencoding_beyond_pixels" -> "openai/iaf"
"andersbll/autoencoding_beyond_pixels" -> "facebookarchive/eyescream"
"andersbll/autoencoding_beyond_pixels" -> "openai/improved-gan"
"andersbll/autoencoding_beyond_pixels" -> "dpkingma/nips14-ssl" ["e"=1]
"fogleman/ln" -> "awentzonline/image-analogies" ["e"=1]
"danieldjohnson/biaxial-rnn-music-composition" -> "magenta/magenta" ["e"=1]
"danieldjohnson/biaxial-rnn-music-composition" -> "awentzonline/image-analogies" ["e"=1]
"danieldjohnson/biaxial-rnn-music-composition" -> "Newmu/dcgan_code" ["e"=1]
"ericjang/genadv_tutorial" -> "AYLIEN/gan-intro"
"ry/tensorflow-vgg16" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"lucidrains/nuwa-pytorch" -> "drboog/Lafite" ["e"=1]
"jcjohnson/densecap" -> "mansimov/text2image" ["e"=1]
"jcjohnson/densecap" -> "DmitryUlyanov/texture_nets" ["e"=1]
"yburda/iwae" -> "tonywu95/eval_gen" ["e"=1]
"yburda/iwae" -> "openai/iaf" ["e"=1]
"mattya/chainer-DCGAN" -> "soumith/dcgan.torch" ["e"=1]
"mattya/chainer-DCGAN" -> "Newmu/dcgan_code" ["e"=1]
"mattya/chainer-DCGAN" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"mattya/chainer-DCGAN" -> "aleju/cat-generator" ["e"=1]
"chuanli11/CNNMRF" -> "DmitryUlyanov/texture_nets"
"chuanli11/CNNMRF" -> "chuanli11/MGANs"
"chuanli11/CNNMRF" -> "awentzonline/image-analogies"
"chuanli11/CNNMRF" -> "rtqichen/style-swap" ["e"=1]
"chuanli11/CNNMRF" -> "msracver/Deep-Image-Analogy"
"chuanli11/CNNMRF" -> "yusuketomoto/chainer-fast-neuralstyle"
"chuanli11/CNNMRF" -> "skaae/torch-gan" ["e"=1]
"chuanli11/CNNMRF" -> "manuelruder/artistic-videos"
"chuanli11/CNNMRF" -> "facebookarchive/eyescream"
"chuanli11/CNNMRF" -> "leongatys/NeuralImageSynthesis" ["e"=1]
"chuanli11/CNNMRF" -> "jcjohnson/fast-neural-style"
"chuanli11/CNNMRF" -> "qassemoquab/stnbhwd" ["e"=1]
"chuanli11/CNNMRF" -> "soumith/dcgan.torch"
"chuanli11/CNNMRF" -> "kaishengtai/neuralart"
"chuanli11/CNNMRF" -> "leehomyc/Faster-High-Res-Neural-Inpainting" ["e"=1]
"HFAiLab/clip-gen" -> "drboog/Lafite"
"cmgreen210/TensorFlowDeepAutoencoder" -> "rajarsheem/libsdae-autoencoder-tensorflow"
"hardmaru/sketch-rnn" -> "hardmaru/cppn-gan-vae-tensorflow" ["e"=1]
"hardmaru/sketch-rnn" -> "Newmu/dcgan_code" ["e"=1]
"hardmaru/sketch-rnn" -> "chuanli11/CNNMRF" ["e"=1]
"kurozael/twitter-contest-bot" -> "robbiebarrat/twitter-contest-enterer"
"kurozael/twitter-contest-bot" -> "raulrene/twitter-contest-js-bot"
"kurozael/twitter-contest-bot" -> "AuxProc/twitter-contest"
"kurozael/twitter-contest-bot" -> "johnbuluba/Yatcobot"
"robbiebarrat/twitter-contest-enterer" -> "kurozael/twitter-contest-bot"
"robbiebarrat/twitter-contest-enterer" -> "robbiebarrat/Stock_advisor"
"erikbern/deep-fonts" -> "DmitryUlyanov/online-neural-doodle" ["e"=1]
"erikbern/deep-fonts" -> "Evolving-AI-Lab/ppgn" ["e"=1]
"drboog/Lafite" -> "drboog/Shifted_Diffusion"
"drboog/Lafite" -> "HFAiLab/clip-gen"
"drboog/Lafite" -> "senmaoy/RAT-GAN"
"drboog/Lafite" -> "zhihengli-UR/StyleT2I"
"pystruct/pystruct" -> "y0ast/Variational-Autoencoder" ["e"=1]
"google/prettytensor" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"jych/nips2015_vrnn" -> "y0ast/Variational-Autoencoder" ["e"=1]
"jych/nips2015_vrnn" -> "tonywu95/eval_gen" ["e"=1]
"skaae/torch-gan" -> "xiaolonw/ss-gan" ["e"=1]
"skaae/torch-gan" -> "facebookarchive/eyescream" ["e"=1]
"cientgu/VQ-Diffusion" -> "HFAiLab/clip-gen" ["e"=1]
"StoryMY/take-off-eyeglasses" -> "ash11sh/remove-glass"
"StoryMY/take-off-eyeglasses" -> "mantasu/glasses-detector"
"StoryMY/take-off-eyeglasses" -> "Bingwen-Hu/ERGAN-Pytorch"
"aleju/cat-generator" -> "skaae/torch-gan" ["e"=1]
"aleju/cat-generator" -> "Evolving-AI-Lab/synthesizing"
"aleju/cat-generator" -> "aleju/face-generator"
"aleju/cat-generator" -> "jhayes14/GAN"
"aleju/cat-generator" -> "facebookarchive/eyescream"
"leongatys/DeepTextures" -> "mkeid/Texture-Synthesis"
"leongatys/DeepTextures" -> "DmitryUlyanov/texture_nets"
"leongatys/DeepTextures" -> "jessemelpolio/non-stationary_texture_syn"
"leongatys/DeepTextures" -> "rtqichen/style-swap" ["e"=1]
"leongatys/DeepTextures" -> "skaae/torch-gan" ["e"=1]
"leongatys/DeepTextures" -> "leongatys/NeuralImageSynthesis" ["e"=1]
"leongatys/DeepTextures" -> "LabForComputationalVision/textureSynth"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "ericjang/draw"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "carpedm20/pixel-rnn-tensorflow"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "andersbll/autoencoding_beyond_pixels"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "jbornschein/draw" ["e"=1]
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "hardmaru/cppn-gan-vae-tensorflow"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "openai/improved-gan"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "y0ast/VAE-TensorFlow"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "buriburisuri/ebgan"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "IshmaelBelghazi/ALI"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "openai/pixel-cnn"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "shekkizh/WassersteinGAN.tensorflow"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "google/prettytensor" ["e"=1]
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "carpedm20/BEGAN-tensorflow"
"ikostrikov/TensorFlow-VAE-GAN-DRAW" -> "openai/InfoGAN"
"CasualGANPapers/Make-A-Scene" -> "drboog/Lafite" ["e"=1]
"mikesj-public/dcgan-autoencoder" -> "avealle/dcgan-denosing-autoencoder"
"casperkaae/parmesan" -> "kundan2510/pixelCNN" ["e"=1]
"casperkaae/parmesan" -> "y0ast/Variational-Autoencoder" ["e"=1]
"pfnet-research/chainer-gogh" -> "yusuketomoto/chainer-fast-neuralstyle" ["e"=1]
"phreeza/keras-GAN" -> "osh/KerasGAN"
"phreeza/keras-GAN" -> "AgnezIO/agnez" ["e"=1]
"hardmaru/write-rnn-tensorflow" -> "ericjang/draw" ["e"=1]
"hardmaru/write-rnn-tensorflow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"hardmaru/write-rnn-tensorflow" -> "carpedm20/pixel-rnn-tensorflow" ["e"=1]
"slakh96/no-mans-land" -> "siefkenj/2020-MAT-335-webpage"
"mbartoli/neural-animation" -> "bamos/dream-art"
"mbartoli/neural-animation" -> "slakh96/no-mans-land"
"Russell91/ReInspect" -> "Russell91/apollocaffe" ["e"=1]
"LabForComputationalVision/matlabPyrTools" -> "LabForComputationalVision/textureSynth" ["e"=1]
"mtyka/neural_artistic_style" -> "mtyka/neural-style"
"iamownt/LSTM-DeepFM" -> "vigorfif/Soft-Sensor-Modelling"
"iamownt/LSTM-DeepFM" -> "tonyzyl/Semisupervised-VAE-for-Regression-Application-on-Soft-Sensor"
"iamownt/LSTM-DeepFM" -> "hkaneko1985/adaptive_soft_sensors"
"younesbelkada/interfacegan" -> "clementapa/CelebFaces_Attributes_Classification"
"raulrene/twitter-contest-js-bot" -> "analog-nico/twitter-reply-bot"
"raulrene/twitter-contest-js-bot" -> "kurozael/twitter-contest-bot"
"takerum/adversarial_autoencoder" -> "hjweide/adversarial-autoencoder"
"titu1994/Neural-Style-Transfer" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"titu1994/Neural-Style-Transfer" -> "anishathalye/neural-style"
"titu1994/Neural-Style-Transfer" -> "cysmith/neural-style-tf"
"titu1994/Neural-Style-Transfer" -> "jcjohnson/fast-neural-style"
"titu1994/Neural-Style-Transfer" -> "lengstrom/fast-style-transfer"
"titu1994/Neural-Style-Transfer" -> "fzliu/style-transfer"
"titu1994/Neural-Style-Transfer" -> "ProGamerGov/neural-style-pt" ["e"=1]
"titu1994/Neural-Style-Transfer" -> "DmitryUlyanov/texture_nets"
"titu1994/Neural-Style-Transfer" -> "yusuketomoto/chainer-fast-neuralstyle"
"titu1994/Neural-Style-Transfer" -> "manuelruder/artistic-videos"
"titu1994/Neural-Style-Transfer" -> "jcjohnson/neural-style"
"titu1994/Neural-Style-Transfer" -> "xunhuang1995/AdaIN-style" ["e"=1]
"titu1994/Neural-Style-Transfer" -> "LouieYang/deep-photo-styletransfer-tf" ["e"=1]
"titu1994/Neural-Style-Transfer" -> "msracver/Deep-Image-Analogy"
"titu1994/Neural-Style-Transfer" -> "rtqichen/style-swap" ["e"=1]
"vdumoulin/conv_arithmetic" -> "soumith/ganhacks" ["e"=1]
"vdumoulin/conv_arithmetic" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"vdumoulin/conv_arithmetic" -> "hindupuravinash/the-gan-zoo" ["e"=1]
"maxpumperla/hyperas" -> "bstriner/keras-adversarial" ["e"=1]
"magenta/magenta" -> "lengstrom/fast-style-transfer"
"magenta/magenta" -> "google-deepmind/sonnet" ["e"=1]
"magenta/magenta" -> "luanfujun/deep-photo-styletransfer"
"magenta/magenta" -> "ibab/tensorflow-wavenet" ["e"=1]
"magenta/magenta" -> "tensorflow/models" ["e"=1]
"magenta/magenta" -> "facebookresearch/fastText" ["e"=1]
"magenta/magenta" -> "jtoy/awesome-tensorflow" ["e"=1]
"magenta/magenta" -> "jcjohnson/neural-style"
"magenta/magenta" -> "openai/gym" ["e"=1]
"magenta/magenta" -> "keras-team/keras" ["e"=1]
"magenta/magenta" -> "karpathy/char-rnn" ["e"=1]
"magenta/magenta" -> "tensorflow/tensor2tensor" ["e"=1]
"magenta/magenta" -> "librosa/librosa" ["e"=1]
"magenta/magenta" -> "openai/jukebox" ["e"=1]
"magenta/magenta" -> "terryum/awesome-deep-learning-papers" ["e"=1]
"Rochester-NRT/RocAlphaGo" -> "alexjc/neural-doodle" ["e"=1]
"heuritech/convnets-keras" -> "jacobgil/keras-dcgan" ["e"=1]
"heuritech/convnets-keras" -> "osh/KerasGAN" ["e"=1]
"bijection/g9" -> "somewacko/deconvfaces" ["e"=1]
"dxa4481/Pastejacking" -> "pavelgonchar/colornet" ["e"=1]
"PRML/PRMLT" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "pavelgonchar/colornet" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "manuelruder/artistic-videos" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "DmitryUlyanov/texture_nets" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "chuanli11/CNNMRF" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "jcjohnson/fast-neural-style" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "Newmu/dcgan_code" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "david-gpu/srez" ["e"=1]
"satoshiiizuka/siggraph2016_colorization" -> "kaishengtai/neuralart" ["e"=1]
"carpedm20/variational-text-tensorflow" -> "openai/iaf" ["e"=1]
"tflearn/tflearn" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"pavelgonchar/colornet" -> "richzhang/colorization" ["e"=1]
"pavelgonchar/colornet" -> "awentzonline/image-analogies"
"pavelgonchar/colornet" -> "alexjc/neural-doodle"
"pavelgonchar/colornet" -> "schollz/find" ["e"=1]
"pavelgonchar/colornet" -> "ryankiros/neural-storyteller" ["e"=1]
"pavelgonchar/colornet" -> "david-gpu/srez"
"pavelgonchar/colornet" -> "jisungk/deepjazz" ["e"=1]
"pavelgonchar/colornet" -> "satoshiiizuka/siggraph2016_colorization" ["e"=1]
"pavelgonchar/colornet" -> "tflearn/tflearn" ["e"=1]
"pavelgonchar/colornet" -> "alexjc/neural-enhance"
"pavelgonchar/colornet" -> "yenchenlin/DeepLearningFlappyBird" ["e"=1]
"pavelgonchar/colornet" -> "jcjohnson/neural-style"
"pavelgonchar/colornet" -> "karpathy/neuraltalk2" ["e"=1]
"pavelgonchar/colornet" -> "autumnai/leaf" ["e"=1]
"pavelgonchar/colornet" -> "IonicaBizau/scrape-it" ["e"=1]
"tensorflow/playground" -> "magenta/magenta" ["e"=1]
"alexjc/neural-doodle" -> "jcjohnson/neural-style"
"alexjc/neural-doodle" -> "awentzonline/image-analogies"
"alexjc/neural-doodle" -> "alexjc/neural-enhance"
"alexjc/neural-doodle" -> "luanfujun/deep-photo-styletransfer"
"alexjc/neural-doodle" -> "pavelgonchar/colornet"
"alexjc/neural-doodle" -> "google/deepdream" ["e"=1]
"alexjc/neural-doodle" -> "lengstrom/fast-style-transfer"
"alexjc/neural-doodle" -> "anishathalye/neural-style"
"alexjc/neural-doodle" -> "magenta/magenta"
"alexjc/neural-doodle" -> "Rochester-NRT/RocAlphaGo" ["e"=1]
"alexjc/neural-doodle" -> "jcjohnson/fast-neural-style"
"alexjc/neural-doodle" -> "ryankiros/neural-storyteller" ["e"=1]
"alexjc/neural-doodle" -> "tflearn/tflearn" ["e"=1]
"alexjc/neural-doodle" -> "junyanz/CycleGAN"
"alexjc/neural-doodle" -> "phillipi/pix2pix"
"yenchenlin/DeepLearningFlappyBird" -> "lengstrom/fast-style-transfer" ["e"=1]
"yenchenlin/DeepLearningFlappyBird" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"jisungk/deepjazz" -> "magenta/magenta" ["e"=1]
"jisungk/deepjazz" -> "pavelgonchar/colornet" ["e"=1]
"jisungk/deepjazz" -> "alexjc/neural-doodle" ["e"=1]
"jisungk/deepjazz" -> "awentzonline/image-analogies" ["e"=1]
"ml4a/ml4a.github.io" -> "robbiebarrat/art-DCGAN" ["e"=1]
"jcjohnson/torch-rnn" -> "soumith/dcgan.torch" ["e"=1]
"blei-lab/edward" -> "wiseodd/generative-models" ["e"=1]
"ericjang/draw" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"ericjang/draw" -> "jbornschein/draw" ["e"=1]
"ericjang/draw" -> "czm0/draw_pytorch"
"ericjang/draw" -> "carpedm20/pixel-rnn-tensorflow"
"ericjang/draw" -> "kvfrans/draw-color"
"ericjang/draw" -> "vivanov879/draw" ["e"=1]
"ericjang/draw" -> "mansimov/text2image"
"ericjang/draw" -> "openai/InfoGAN"
"ericjang/draw" -> "hardmaru/cppn-gan-vae-tensorflow"
"ericjang/draw" -> "shekkizh/WassersteinGAN.tensorflow"
"ericjang/draw" -> "EderSantana/seya" ["e"=1]
"ericjang/draw" -> "openai/pixel-cnn"
"ericjang/draw" -> "carpedm20/NTM-tensorflow" ["e"=1]
"ericjang/draw" -> "reedscot/icml2016"
"ericjang/draw" -> "facebookarchive/eyescream"
"y0ast/VAE-TensorFlow" -> "y0ast/Variational-Autoencoder"
"y0ast/VAE-TensorFlow" -> "hwalsuklee/tensorflow-mnist-VAE"
"y0ast/VAE-TensorFlow" -> "y0ast/VAE-Torch" ["e"=1]
"y0ast/VAE-TensorFlow" -> "saemundsson/semisupervised_vae" ["e"=1]
"y0ast/VAE-TensorFlow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"y0ast/VAE-TensorFlow" -> "fastforwardlabs/vae-tf"
"y0ast/VAE-TensorFlow" -> "cdoersch/vae_tutorial"
"y0ast/VAE-TensorFlow" -> "shaohua0116/VAE-Tensorflow"
"y0ast/VAE-TensorFlow" -> "Chung-I/Variational-Recurrent-Autoencoder-Tensorflow" ["e"=1]
"awentzonline/image-analogies" -> "alexjc/neural-doodle"
"awentzonline/image-analogies" -> "chuanli11/CNNMRF"
"awentzonline/image-analogies" -> "pavelgonchar/colornet"
"awentzonline/image-analogies" -> "jcjohnson/neural-style"
"awentzonline/image-analogies" -> "msracver/Deep-Image-Analogy"
"awentzonline/image-analogies" -> "ajbrock/Neural-Photo-Editor"
"awentzonline/image-analogies" -> "kaishengtai/neuralart"
"awentzonline/image-analogies" -> "ryankiros/neural-storyteller" ["e"=1]
"awentzonline/image-analogies" -> "david-gpu/srez"
"awentzonline/image-analogies" -> "Newmu/dcgan_code"
"awentzonline/image-analogies" -> "DmitryUlyanov/texture_nets"
"awentzonline/image-analogies" -> "jcjohnson/fast-neural-style"
"awentzonline/image-analogies" -> "junyanz/iGAN"
"awentzonline/image-analogies" -> "autumnai/leaf" ["e"=1]
"awentzonline/image-analogies" -> "manuelruder/artistic-videos"
"antontarasenko/smq" -> "pavelgonchar/colornet" ["e"=1]
"piiswrong/deep3d" -> "chuanli11/CNNMRF" ["e"=1]
"machrisaa/tensorflow-vgg" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"DmitryUlyanov/texture_nets" -> "chuanli11/CNNMRF"
"DmitryUlyanov/texture_nets" -> "yusuketomoto/chainer-fast-neuralstyle"
"DmitryUlyanov/texture_nets" -> "rtqichen/style-swap" ["e"=1]
"DmitryUlyanov/texture_nets" -> "jcjohnson/fast-neural-style"
"DmitryUlyanov/texture_nets" -> "chuanli11/MGANs"
"DmitryUlyanov/texture_nets" -> "manuelruder/artistic-videos"
"DmitryUlyanov/texture_nets" -> "xunhuang1995/AdaIN-style" ["e"=1]
"DmitryUlyanov/texture_nets" -> "DmitryUlyanov/fast-neural-doodle"
"DmitryUlyanov/texture_nets" -> "leongatys/DeepTextures"
"DmitryUlyanov/texture_nets" -> "facebookarchive/eyescream"
"DmitryUlyanov/texture_nets" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"DmitryUlyanov/texture_nets" -> "szagoruyko/loadcaffe" ["e"=1]
"DmitryUlyanov/texture_nets" -> "skaae/torch-gan" ["e"=1]
"DmitryUlyanov/texture_nets" -> "msracver/Deep-Image-Analogy"
"DmitryUlyanov/texture_nets" -> "facebookarchive/torchnet" ["e"=1]
"somewacko/deconvfaces" -> "ajbrock/Neural-Photo-Editor"
"somewacko/deconvfaces" -> "facebookarchive/eyescream"
"somewacko/deconvfaces" -> "yunjey/domain-transfer-network"
"somewacko/deconvfaces" -> "cvondrick/videogan"
"somewacko/deconvfaces" -> "Newmu/dcgan_code"
"somewacko/deconvfaces" -> "Evolving-AI-Lab/synthesizing"
"somewacko/deconvfaces" -> "Guim3/IcGAN"
"somewacko/deconvfaces" -> "keplr-io/quiver" ["e"=1]
"somewacko/deconvfaces" -> "DmitryUlyanov/texture_nets"
"somewacko/deconvfaces" -> "facebookresearch/CommAI-env" ["e"=1]
"somewacko/deconvfaces" -> "saikatbsk/Vincent-AI-Artist"
"somewacko/deconvfaces" -> "junyanz/iGAN"
"somewacko/deconvfaces" -> "atriumlts/subpixel" ["e"=1]
"somewacko/deconvfaces" -> "basveeling/wavenet" ["e"=1]
"somewacko/deconvfaces" -> "tomlepaine/fast-wavenet" ["e"=1]
"aleju/papers" -> "soumith/ganhacks" ["e"=1]
"aleju/papers" -> "nightrome/really-awesome-gan" ["e"=1]
"aleju/papers" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"aleju/papers" -> "wiseodd/generative-models" ["e"=1]
"aleju/papers" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"aleju/papers" -> "tkarras/progressive_growing_of_gans" ["e"=1]
"aleju/papers" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"musyoku/adversarial-autoencoder" -> "Naresh1318/Adversarial_Autoencoder"
"musyoku/adversarial-autoencoder" -> "fducau/AAE_pytorch"
"musyoku/adversarial-autoencoder" -> "hwalsuklee/tensorflow-mnist-AAE"
"musyoku/adversarial-autoencoder" -> "nicklhy/AdversarialAutoEncoder"
"musyoku/adversarial-autoencoder" -> "layerwise/AAE-tensorflow"
"musyoku/adversarial-autoencoder" -> "hjweide/adversarial-autoencoder"
"musyoku/adversarial-autoencoder" -> "takerum/adversarial_autoencoder"
"musyoku/adversarial-autoencoder" -> "andersbll/autoencoding_beyond_pixels"
"musyoku/adversarial-autoencoder" -> "conan7882/adversarial-autoencoders"
"anitan0925/vaegan" -> "JeremyCCHsu/tf-vaegan"
"anitan0925/vaegan" -> "crmaximo/VAEGAN"
"anitan0925/vaegan" -> "dsanno/chainer-vae-gan"
"anitan0925/vaegan" -> "zhangqianhui/vae-gan-tensorflow"
"goodfeli/dlbook_exercises" -> "goodfeli/adversarial" ["e"=1]
"richzhang/colorization" -> "pavelgonchar/colornet" ["e"=1]
"richzhang/colorization" -> "phillipi/pix2pix" ["e"=1]
"richzhang/colorization" -> "jcjohnson/fast-neural-style" ["e"=1]
"richzhang/colorization" -> "alexjc/neural-enhance" ["e"=1]
"rhsimplex/image-match" -> "awentzonline/image-analogies" ["e"=1]
"rhsimplex/image-match" -> "alexjc/neural-doodle" ["e"=1]
"rhsimplex/image-match" -> "pavelgonchar/colornet" ["e"=1]
"ibaaj/dijkstra-cartography" -> "pavelgonchar/colornet" ["e"=1]
"amygdala/tensorflow-workshop" -> "anantzoid/Conditional-PixelCNN-decoder" ["e"=1]
"jacobgil/keras-dcgan" -> "bstriner/keras-adversarial"
"jacobgil/keras-dcgan" -> "osh/KerasGAN"
"jacobgil/keras-dcgan" -> "Newmu/dcgan_code"
"jacobgil/keras-dcgan" -> "tdeboissiere/DeepLearningImplementations"
"jacobgil/keras-dcgan" -> "carpedm20/DCGAN-tensorflow"
"jacobgil/keras-dcgan" -> "bamos/dcgan-completion.tensorflow"
"jacobgil/keras-dcgan" -> "heuritech/convnets-keras" ["e"=1]
"jacobgil/keras-dcgan" -> "soumith/dcgan.torch"
"jacobgil/keras-dcgan" -> "clvrai/SSGAN-Tensorflow"
"jacobgil/keras-dcgan" -> "openai/improved-gan"
"jacobgil/keras-dcgan" -> "martinarjovsky/WassersteinGAN"
"jacobgil/keras-dcgan" -> "raghakot/keras-resnet" ["e"=1]
"jacobgil/keras-dcgan" -> "yhenon/keras-frcnn" ["e"=1]
"jacobgil/keras-dcgan" -> "igul222/improved_wgan_training"
"jacobgil/keras-dcgan" -> "phreeza/keras-GAN"
"tysam-code/hlb-CIFAR10" -> "davidcpage/cifar10-fast" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "gafr/chainer-fast-neuralstyle-models" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "DmitryUlyanov/texture_nets"
"yusuketomoto/chainer-fast-neuralstyle" -> "chuanli11/CNNMRF"
"yusuketomoto/chainer-fast-neuralstyle" -> "OlavHN/fast-neural-style"
"yusuketomoto/chainer-fast-neuralstyle" -> "manuelruder/artistic-videos"
"yusuketomoto/chainer-fast-neuralstyle" -> "genekogan/CubistMirror" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "jcjohnson/fast-neural-style"
"yusuketomoto/chainer-fast-neuralstyle" -> "pfnet-research/chainer-gogh" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "titu1994/Fast-Neural-Style" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "rtqichen/style-swap" ["e"=1]
"yusuketomoto/chainer-fast-neuralstyle" -> "chuanli11/MGANs"
"yusuketomoto/chainer-fast-neuralstyle" -> "pavelgonchar/neural-art-mini"
"yusuketomoto/chainer-fast-neuralstyle" -> "titu1994/Neural-Style-Transfer"
"yusuketomoto/chainer-fast-neuralstyle" -> "junrushao/fast-neural-style.tf"
"yusuketomoto/chainer-fast-neuralstyle" -> "andersbll/neural_artistic_style"
"DmitryUlyanov/fast-neural-doodle" -> "DmitryUlyanov/online-neural-doodle"
"DmitryUlyanov/fast-neural-doodle" -> "chuanli11/MGANs"
"DmitryUlyanov/fast-neural-doodle" -> "DmitryUlyanov/texture_nets"
"pathak22/context-encoder" -> "bamos/dcgan-completion.tensorflow" ["e"=1]
"traverseda/pycraft" -> "pavelgonchar/colornet" ["e"=1]
"manuelruder/artistic-videos" -> "manuelruder/fast-artistic-videos" ["e"=1]
"manuelruder/artistic-videos" -> "DmitryUlyanov/texture_nets"
"manuelruder/artistic-videos" -> "yusuketomoto/chainer-fast-neuralstyle"
"manuelruder/artistic-videos" -> "jcjohnson/fast-neural-style"
"manuelruder/artistic-videos" -> "chuanli11/CNNMRF"
"manuelruder/artistic-videos" -> "cysmith/neural-style-tf"
"manuelruder/artistic-videos" -> "jcjohnson/neural-style"
"manuelruder/artistic-videos" -> "kaishengtai/neuralart"
"manuelruder/artistic-videos" -> "chuanli11/MGANs"
"manuelruder/artistic-videos" -> "andersbll/neural_artistic_style"
"manuelruder/artistic-videos" -> "titu1994/Neural-Style-Transfer"
"manuelruder/artistic-videos" -> "facebookarchive/eyescream"
"manuelruder/artistic-videos" -> "awentzonline/image-analogies"
"manuelruder/artistic-videos" -> "msracver/Deep-Image-Analogy"
"manuelruder/artistic-videos" -> "zeruniverse/fast-artistic-videos"
"Cloud-CV/Fabrik" -> "MrNothing/AI-Blocks" ["e"=1]
"awjuliani/TF-Tutorials" -> "awjuliani/oreilly-rl-tutorial"
"awjuliani/TF-Tutorials" -> "shekkizh/WassersteinGAN.tensorflow"
"awjuliani/TF-Tutorials" -> "Zardinality/WGAN-tensorflow"
"awjuliani/TF-Tutorials" -> "awjuliani/DeepRL-Agents" ["e"=1]
"awjuliani/TF-Tutorials" -> "adeshpande3/Generative-Adversarial-Networks"
"awjuliani/TF-Tutorials" -> "uclaacmai/Generative-Adversarial-Network-Tutorial"
"awjuliani/TF-Tutorials" -> "bamos/dcgan-completion.tensorflow"
"awjuliani/TF-Tutorials" -> "ry/tensorflow-resnet" ["e"=1]
"awjuliani/TF-Tutorials" -> "awjuliani/Pix2Pix-Film"
"awjuliani/TF-Tutorials" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"awjuliani/TF-Tutorials" -> "oduerr/dl_tutorial"
"awjuliani/TF-Tutorials" -> "khanrc/tf.gans-comparison"
"awjuliani/TF-Tutorials" -> "ericjang/genadv_tutorial"
"awjuliani/TF-Tutorials" -> "sjchoi86/advanced-tensorflow" ["e"=1]
"raghakot/keras-resnet" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"raghakot/keras-resnet" -> "jacobgil/keras-dcgan" ["e"=1]
"terryum/TensorFlow_Exercises" -> "zsdonghao/text-to-image" ["e"=1]
"chuanli11/MGANs" -> "chuanli11/CNNMRF"
"chuanli11/MGANs" -> "DmitryUlyanov/texture_nets"
"chuanli11/MGANs" -> "staturecrane/dcgan_vae_torch" ["e"=1]
"chuanli11/MGANs" -> "leongatys/NeuralImageSynthesis" ["e"=1]
"chuanli11/MGANs" -> "DmitryUlyanov/fast-neural-doodle"
"chuanli11/MGANs" -> "rtqichen/style-swap" ["e"=1]
"chuanli11/MGANs" -> "pavelgonchar/neural-art-mini"
"defaultnamehere/zzzzz" -> "awentzonline/image-analogies" ["e"=1]
"defaultnamehere/zzzzz" -> "pavelgonchar/colornet" ["e"=1]
"DmitryUlyanov/online-neural-doodle" -> "DmitryUlyanov/fast-neural-doodle"
"hardmaru/cppn-gan-vae-tensorflow" -> "hardmaru/cppn-tensorflow" ["e"=1]
"hardmaru/cppn-gan-vae-tensorflow" -> "hardmaru/resnet-cppn-gan-tensorflow"
"hardmaru/cppn-gan-vae-tensorflow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"hardmaru/cppn-gan-vae-tensorflow" -> "hardmaru/cppn-gan-vae-cifar-tensorflow"
"hardmaru/cppn-gan-vae-tensorflow" -> "anitan0925/vaegan"
"hardmaru/cppn-gan-vae-tensorflow" -> "andersbll/autoencoding_beyond_pixels"
"hardmaru/cppn-gan-vae-tensorflow" -> "ericjang/draw"
"hardmaru/cppn-gan-vae-tensorflow" -> "hochthom/cppn-keras" ["e"=1]
"hjweide/adversarial-autoencoder" -> "takerum/adversarial_autoencoder"
"IshmaelBelghazi/ALI" -> "jeffdonahue/bigan"
"IshmaelBelghazi/ALI" -> "andersbll/autoencoding_beyond_pixels"
"IshmaelBelghazi/ALI" -> "edgarriba/ali-pytorch"
"IshmaelBelghazi/ALI" -> "skaae/torch-gan" ["e"=1]
"IshmaelBelghazi/ALI" -> "yujiali/gmmn" ["e"=1]
"IshmaelBelghazi/ALI" -> "coupriec/VideoPredictionICLR2016" ["e"=1]
"IshmaelBelghazi/ALI" -> "buriburisuri/ebgan"
"nanopony/keras-convautoencoder" -> "Seratna/TensorFlow-Convolutional-AutoEncoder"
"nanopony/keras-convautoencoder" -> "jcklie/keras-autoencoder"
"nanopony/keras-convautoencoder" -> "mikesj-public/convolutional_autoencoder"
"nanopony/keras-convautoencoder" -> "despoisj/ConvolutionalAutoencoder"
"nanopony/keras-convautoencoder" -> "keunwoochoi/residual_block_keras"
"rajarsheem/libsdae-autoencoder-tensorflow" -> "cmgreen210/TensorFlowDeepAutoencoder"
"rajarsheem/libsdae-autoencoder-tensorflow" -> "ramarlina/DenoisingAutoEncoder"
"tobran/GALIP" -> "tobran/DF-GAN"
"tobran/GALIP" -> "senmaoy/RAT-GAN"
"tobran/GALIP" -> "drboog/Lafite"
"tobran/GALIP" -> "tobran/DE-Net"
"hardmaru/cppn-tensorflow" -> "hardmaru/cppn-gan-vae-tensorflow" ["e"=1]
"mattjj/svae" -> "openai/iaf" ["e"=1]
"sugyan/tf-dcgan" -> "sugyan/face-generator"
"sugyan/tf-dcgan" -> "tensorlayer/DCGAN"
"log0/neural-style-painting" -> "ckmarkoh/neuralart_tensorflow"
"clinicalml/structuredinference" -> "tonywu95/eval_gen" ["e"=1]
"OlavHN/fast-neural-style" -> "junrushao/fast-neural-style.tf"
"OlavHN/fast-neural-style" -> "hzy46/fast-neural-style-tensorflow"
"OlavHN/fast-neural-style" -> "yusuketomoto/chainer-fast-neuralstyle"
"OlavHN/fast-neural-style" -> "burness/neural_style_tensorflow"
"OlavHN/fast-neural-style" -> "DmitryUlyanov/online-neural-doodle"
"OlavHN/fast-neural-style" -> "wisewong/ImageStyleTransform"
"OlavHN/fast-neural-style" -> "awentzonline/keras-rtst"
"avealle/dcgan-denosing-autoencoder" -> "WenchenLi/PhotoRestoration"
"Guim3/IcGAN" -> "facebookresearch/FaderNetworks"
"Guim3/IcGAN" -> "reedscot/nips2016"
"Guim3/IcGAN" -> "guojunq/lsgan"
"Guim3/IcGAN" -> "Evolving-AI-Lab/ppgn"
"Guim3/IcGAN" -> "xcyan/eccv16_attr2img"
"Guim3/IcGAN" -> "buriburisuri/ac-gan"
"Guim3/IcGAN" -> "LynnHo/AttGAN-Tensorflow"
"Guim3/IcGAN" -> "Prinsphield/ELEGANT"
"Guim3/IcGAN" -> "fxia22/PixelDTGAN"
"Guim3/IcGAN" -> "SKTBrain/DiscoGAN"
"Guim3/IcGAN" -> "Zhongdao/FaceAttributeManipulation"
"Guim3/IcGAN" -> "skaae/torch-gan" ["e"=1]
"tonyzyl/Semisupervised-VAE-for-Regression-Application-on-Soft-Sensor" -> "vigorfif/Soft-Sensor-Modelling"
"RuiShu/cvae" -> "jramapuram/CVAE"
"RuiShu/cvae" -> "y0ast/VAE-Torch" ["e"=1]
"RuiShu/cvae" -> "hwalsuklee/tensorflow-mnist-CVAE"
"WenchenLi/PhotoRestoration" -> "avealle/dcgan-denosing-autoencoder"
"afrozalm/Patch-Based-Texture-Synthesis" -> "rohitrango/Image-Quilting-for-Texture-Synthesis"
"sugyan/face-generator" -> "sugyan/tf-dcgan"
"igul222/pixel_rnn" -> "igul222/speech"
"jcjohnson/fast-neural-style" -> "lengstrom/fast-style-transfer"
"jcjohnson/fast-neural-style" -> "DmitryUlyanov/texture_nets"
"jcjohnson/fast-neural-style" -> "jcjohnson/neural-style"
"jcjohnson/fast-neural-style" -> "anishathalye/neural-style"
"jcjohnson/fast-neural-style" -> "cysmith/neural-style-tf"
"jcjohnson/fast-neural-style" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"jcjohnson/fast-neural-style" -> "xunhuang1995/AdaIN-style" ["e"=1]
"jcjohnson/fast-neural-style" -> "manuelruder/artistic-videos"
"jcjohnson/fast-neural-style" -> "junyanz/CycleGAN"
"jcjohnson/fast-neural-style" -> "titu1994/Neural-Style-Transfer"
"jcjohnson/fast-neural-style" -> "yusuketomoto/chainer-fast-neuralstyle"
"jcjohnson/fast-neural-style" -> "phillipi/pix2pix"
"jcjohnson/fast-neural-style" -> "luanfujun/deep-photo-styletransfer"
"jcjohnson/fast-neural-style" -> "chuanli11/CNNMRF"
"jcjohnson/fast-neural-style" -> "Newmu/dcgan_code"
"lengstrom/fast-style-transfer" -> "anishathalye/neural-style"
"lengstrom/fast-style-transfer" -> "luanfujun/deep-photo-styletransfer"
"lengstrom/fast-style-transfer" -> "jcjohnson/fast-neural-style"
"lengstrom/fast-style-transfer" -> "yenchenlin/DeepLearningFlappyBird" ["e"=1]
"lengstrom/fast-style-transfer" -> "junyanz/CycleGAN"
"lengstrom/fast-style-transfer" -> "magenta/magenta"
"lengstrom/fast-style-transfer" -> "cysmith/neural-style-tf"
"lengstrom/fast-style-transfer" -> "jcjohnson/neural-style"
"lengstrom/fast-style-transfer" -> "junyanz/iGAN"
"lengstrom/fast-style-transfer" -> "NVIDIA/FastPhotoStyle"
"lengstrom/fast-style-transfer" -> "alexjc/neural-enhance"
"lengstrom/fast-style-transfer" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"lengstrom/fast-style-transfer" -> "titu1994/Neural-Style-Transfer"
"lengstrom/fast-style-transfer" -> "google-deepmind/sonnet" ["e"=1]
"lengstrom/fast-style-transfer" -> "yunjey/stargan"
"facebookresearch/deepmask" -> "DmitryUlyanov/texture_nets" ["e"=1]
"facebookresearch/deepmask" -> "Newmu/dcgan_code" ["e"=1]
"pytorch/examples" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"pytorch/examples" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"pytorch/examples" -> "soumith/ganhacks" ["e"=1]
"pytorch/tutorials" -> "soumith/ganhacks" ["e"=1]
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "andersbll/autoencoding_beyond_pixels"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "zhangqianhui/vae-gan-tensorflow"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "JeremyCCHsu/tf-vaegan"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "carpedm20/pixel-rnn-tensorflow"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "shekkizh/WassersteinGAN.tensorflow"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "facebookarchive/eyescream"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "anantzoid/Conditional-PixelCNN-decoder"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "IshmaelBelghazi/ALI"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "openai/improved-gan"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "artcg/BEGAN"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "hardmaru/cppn-gan-vae-tensorflow"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "openai/iaf"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "timsainb/tensorflow2-generative-models"
"timsainb/Tensorflow-MultiGPU-VAE-GAN" -> "xiaolonw/ss-gan"
"jeffheaton/t81_558_deep_learning" -> "eriklindernoren/Keras-GAN" ["e"=1]
"mzucker/noteshrink" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"DeepRNN/image_captioning" -> "mansimov/text2image" ["e"=1]
"librosa/librosa" -> "magenta/magenta" ["e"=1]
"tonybeltramelli/Deep-Lyrics" -> "enriqueav/lstm_lyrics"
"tonybeltramelli/Deep-Lyrics" -> "llSourcell/Rap_Lyric_Generator"
"cleverhans-lab/cleverhans" -> "soumith/ganhacks" ["e"=1]
"fogleman/primitive" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"fogleman/primitive" -> "alexjc/neural-doodle" ["e"=1]
"fogleman/primitive" -> "jcjohnson/neural-style" ["e"=1]
"fogleman/primitive" -> "alexjc/neural-enhance" ["e"=1]
"kootenpv/whereami" -> "alexjc/neural-enhance" ["e"=1]
"a1studmuffin/SpaceshipGenerator" -> "alexjc/neural-doodle" ["e"=1]
"carpedm20/pixel-rnn-tensorflow" -> "anantzoid/Conditional-PixelCNN-decoder"
"carpedm20/pixel-rnn-tensorflow" -> "openai/pixel-cnn"
"carpedm20/pixel-rnn-tensorflow" -> "kundan2510/pixelCNN"
"carpedm20/pixel-rnn-tensorflow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"carpedm20/pixel-rnn-tensorflow" -> "igul222/pixel_rnn"
"carpedm20/pixel-rnn-tensorflow" -> "shirgur/PixelRNN"
"carpedm20/pixel-rnn-tensorflow" -> "ericjang/draw"
"carpedm20/pixel-rnn-tensorflow" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"carpedm20/pixel-rnn-tensorflow" -> "yueatsprograms/Stochastic_Depth" ["e"=1]
"carpedm20/pixel-rnn-tensorflow" -> "NickShahML/tensorflow_with_latest_papers" ["e"=1]
"carpedm20/pixel-rnn-tensorflow" -> "facebookarchive/eyescream"
"carpedm20/pixel-rnn-tensorflow" -> "ryankiros/layer-norm" ["e"=1]
"carpedm20/pixel-rnn-tensorflow" -> "mansimov/text2image"
"carpedm20/pixel-rnn-tensorflow" -> "andersbll/autoencoding_beyond_pixels"
"carpedm20/pixel-rnn-tensorflow" -> "fyu/dilation" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "cvondrick/videogan" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "carpedm20/pixel-rnn-tensorflow" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "mansimov/text2image" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "reedscot/icml2016" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "openai/pixel-cnn" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "openai/InfoGAN" ["e"=1]
"dyelax/Adversarial_Video_Generation" -> "openai/improved-gan" ["e"=1]
"paarthneekhara/text-to-image" -> "reedscot/icml2016"
"paarthneekhara/text-to-image" -> "zsdonghao/text-to-image"
"paarthneekhara/text-to-image" -> "hanzhanggit/StackGAN"
"paarthneekhara/text-to-image" -> "ryankiros/skip-thoughts" ["e"=1]
"paarthneekhara/text-to-image" -> "mansimov/text2image"
"paarthneekhara/text-to-image" -> "junyanz/iGAN"
"paarthneekhara/text-to-image" -> "carpedm20/DCGAN-tensorflow"
"paarthneekhara/text-to-image" -> "Newmu/dcgan_code"
"paarthneekhara/text-to-image" -> "openai/improved-gan"
"paarthneekhara/text-to-image" -> "reedscot/nips2016"
"paarthneekhara/text-to-image" -> "taoxugit/AttnGAN"
"paarthneekhara/text-to-image" -> "aelnouby/Text-to-Image-Synthesis"
"paarthneekhara/text-to-image" -> "hanzhanggit/StackGAN-v2"
"paarthneekhara/text-to-image" -> "david-gpu/srez"
"paarthneekhara/text-to-image" -> "soumith/dcgan.torch"
"yahoo/open_nsfw" -> "ryanjay0/miles-deep" ["e"=1]
"yahoo/open_nsfw" -> "david-gpu/srez" ["e"=1]
"yahoo/open_nsfw" -> "alexjc/neural-enhance" ["e"=1]
"ibab/tensorflow-wavenet" -> "magenta/magenta" ["e"=1]
"ibab/tensorflow-wavenet" -> "openai/pixel-cnn" ["e"=1]
"ibab/tensorflow-wavenet" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"junyanz/iGAN" -> "yunjey/stargan"
"junyanz/iGAN" -> "ajbrock/Neural-Photo-Editor"
"junyanz/iGAN" -> "Newmu/dcgan_code"
"junyanz/iGAN" -> "NVIDIA/pix2pixHD"
"junyanz/iGAN" -> "phillipi/pix2pix"
"junyanz/iGAN" -> "junyanz/CycleGAN"
"junyanz/iGAN" -> "carpedm20/DCGAN-tensorflow"
"junyanz/iGAN" -> "lengstrom/fast-style-transfer"
"junyanz/iGAN" -> "openai/improved-gan"
"junyanz/iGAN" -> "buriburisuri/speech-to-text-wavenet" ["e"=1]
"junyanz/iGAN" -> "MrNothing/AI-Blocks"
"junyanz/iGAN" -> "affinelayer/pix2pix-tensorflow"
"junyanz/iGAN" -> "AKSHAYUBHAT/DeepVideoAnalytics" ["e"=1]
"junyanz/iGAN" -> "paarthneekhara/text-to-image"
"junyanz/iGAN" -> "OpenNMT/OpenNMT" ["e"=1]
"alexjc/neural-enhance" -> "david-gpu/srez"
"alexjc/neural-enhance" -> "alexjc/neural-doodle"
"alexjc/neural-enhance" -> "lengstrom/fast-style-transfer"
"alexjc/neural-enhance" -> "idealo/image-super-resolution" ["e"=1]
"alexjc/neural-enhance" -> "jcjohnson/neural-style"
"alexjc/neural-enhance" -> "luanfujun/deep-photo-styletransfer"
"alexjc/neural-enhance" -> "phillipi/pix2pix"
"alexjc/neural-enhance" -> "DmitryUlyanov/deep-image-prior"
"alexjc/neural-enhance" -> "tensorlayer/SRGAN" ["e"=1]
"alexjc/neural-enhance" -> "atriumlts/subpixel" ["e"=1]
"alexjc/neural-enhance" -> "junyanz/CycleGAN"
"alexjc/neural-enhance" -> "kjw0612/awesome-deep-vision" ["e"=1]
"alexjc/neural-enhance" -> "nagadomi/waifu2x" ["e"=1]
"alexjc/neural-enhance" -> "jcjohnson/fast-neural-style"
"alexjc/neural-enhance" -> "cmusatyalab/openface" ["e"=1]
"dailenson/SDT" -> "kaonashi-tyc/zi2zi" ["e"=1]
"kvfrans/variational-autoencoder" -> "jaanli/variational-autoencoder"
"kvfrans/variational-autoencoder" -> "kvfrans/generative-adversial"
"kvfrans/variational-autoencoder" -> "hwalsuklee/tensorflow-mnist-VAE"
"kvfrans/variational-autoencoder" -> "y0ast/Variational-Autoencoder"
"kvfrans/variational-autoencoder" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"kvfrans/variational-autoencoder" -> "y0ast/VAE-TensorFlow"
"kvfrans/variational-autoencoder" -> "andersbll/autoencoding_beyond_pixels"
"kvfrans/variational-autoencoder" -> "hardmaru/cppn-gan-vae-tensorflow"
"kvfrans/variational-autoencoder" -> "ethanluoyc/pytorch-vae"
"kvfrans/variational-autoencoder" -> "shaohua0116/VAE-Tensorflow"
"kvfrans/variational-autoencoder" -> "y0ast/VAE-Torch" ["e"=1]
"kvfrans/variational-autoencoder" -> "cdoersch/vae_tutorial"
"kvfrans/variational-autoencoder" -> "Naresh1318/Adversarial_Autoencoder"
"kvfrans/variational-autoencoder" -> "fastforwardlabs/vae-tf"
"kvfrans/variational-autoencoder" -> "carpedm20/pixel-rnn-tensorflow"
"david-gpu/srez" -> "alexjc/neural-enhance"
"david-gpu/srez" -> "atriumlts/subpixel" ["e"=1]
"david-gpu/srez" -> "junyanz/iGAN"
"david-gpu/srez" -> "tensorlayer/SRGAN" ["e"=1]
"david-gpu/srez" -> "Newmu/dcgan_code"
"david-gpu/srez" -> "paarthneekhara/text-to-image"
"david-gpu/srez" -> "alexjc/neural-doodle"
"david-gpu/srez" -> "carpedm20/DCGAN-tensorflow"
"david-gpu/srez" -> "awentzonline/image-analogies"
"david-gpu/srez" -> "ajbrock/Neural-Photo-Editor"
"david-gpu/srez" -> "pavelgonchar/colornet"
"david-gpu/srez" -> "PHPixie/Project" ["e"=1]
"david-gpu/srez" -> "phillipi/pix2pix"
"david-gpu/srez" -> "facebookresearch/deepmask" ["e"=1]
"david-gpu/srez" -> "YapengTian/Single-Image-Super-Resolution" ["e"=1]
"dropbox/lepton" -> "pavelgonchar/colornet" ["e"=1]
"ajbrock/Neural-Photo-Editor" -> "junyanz/iGAN"
"ajbrock/Neural-Photo-Editor" -> "atriumlts/subpixel" ["e"=1]
"ajbrock/Neural-Photo-Editor" -> "jcjohnson/fast-neural-style"
"ajbrock/Neural-Photo-Editor" -> "Newmu/dcgan_code"
"ajbrock/Neural-Photo-Editor" -> "somewacko/deconvfaces"
"ajbrock/Neural-Photo-Editor" -> "DmitryUlyanov/texture_nets"
"ajbrock/Neural-Photo-Editor" -> "awentzonline/image-analogies"
"ajbrock/Neural-Photo-Editor" -> "facebookarchive/eyescream"
"ajbrock/Neural-Photo-Editor" -> "paarthneekhara/text-to-image"
"ajbrock/Neural-Photo-Editor" -> "reedscot/icml2016"
"ajbrock/Neural-Photo-Editor" -> "yunjey/domain-transfer-network"
"ajbrock/Neural-Photo-Editor" -> "leehomyc/Faster-High-Res-Neural-Inpainting" ["e"=1]
"ajbrock/Neural-Photo-Editor" -> "david-gpu/srez"
"ajbrock/Neural-Photo-Editor" -> "openai/pixel-cnn"
"ajbrock/Neural-Photo-Editor" -> "tomlepaine/fast-wavenet" ["e"=1]
"jaanli/variational-autoencoder" -> "kvfrans/variational-autoencoder"
"jaanli/variational-autoencoder" -> "timbmg/VAE-CVAE-MNIST"
"jaanli/variational-autoencoder" -> "cdoersch/vae_tutorial"
"jaanli/variational-autoencoder" -> "y0ast/Variational-Autoencoder"
"jaanli/variational-autoencoder" -> "ethanluoyc/pytorch-vae"
"jaanli/variational-autoencoder" -> "hwalsuklee/tensorflow-mnist-VAE"
"jaanli/variational-autoencoder" -> "1Konny/Beta-VAE" ["e"=1]
"jaanli/variational-autoencoder" -> "wiseodd/generative-models"
"jaanli/variational-autoencoder" -> "AntixK/PyTorch-VAE" ["e"=1]
"jaanli/variational-autoencoder" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"jaanli/variational-autoencoder" -> "y0ast/VAE-TensorFlow"
"jaanli/variational-autoencoder" -> "openai/iaf"
"jaanli/variational-autoencoder" -> "dpkingma/nips14-ssl" ["e"=1]
"jaanli/variational-autoencoder" -> "bojone/vae"
"jaanli/variational-autoencoder" -> "matthewvowels1/Awesome-VAEs" ["e"=1]
"wagamamaz/tensorflow-tutorial" -> "uclaacmai/Generative-Adversarial-Network-Tutorial" ["e"=1]
"fchollet/keras-resources" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"linhuixiao/CLIP-VG" -> "MightXiong/FedMIT" ["e"=1]
"fchollet/deep-learning-models" -> "eriklindernoren/Keras-GAN" ["e"=1]
"tensorlayer/TensorLayer" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"tensorlayer/TensorLayer" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"tensorlayer/TensorLayer" -> "wiseodd/generative-models" ["e"=1]
"Hironsan/BossSensor" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"Hironsan/BossSensor" -> "alexjc/neural-enhance" ["e"=1]
"atriumlts/subpixel" -> "david-gpu/srez" ["e"=1]
"atriumlts/subpixel" -> "ajbrock/Neural-Photo-Editor" ["e"=1]
"atriumlts/subpixel" -> "alexjc/neural-enhance" ["e"=1]
"xviniette/FlappyLearning" -> "alexjc/neural-enhance" ["e"=1]
"jlsutherland/doc2text" -> "ajbrock/Neural-Photo-Editor" ["e"=1]
"leriomaggio/deep-learning-keras-tensorflow" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "bstriner/keras-adversarial"
"tdeboissiere/DeepLearningImplementations" -> "titu1994/DenseNet" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "jacobgil/keras-dcgan"
"tdeboissiere/DeepLearningImplementations" -> "affinelayer/pix2pix-tensorflow"
"tdeboissiere/DeepLearningImplementations" -> "yenchenlin/pix2pix-tensorflow"
"tdeboissiere/DeepLearningImplementations" -> "martinarjovsky/WassersteinGAN"
"tdeboissiere/DeepLearningImplementations" -> "liuzhuang13/DenseNet" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "fchollet/keras-resources" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "igul222/improved_wgan_training"
"tdeboissiere/DeepLearningImplementations" -> "raghakot/keras-vis" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "openai/improved-gan"
"tdeboissiere/DeepLearningImplementations" -> "keras-team/keras-contrib" ["e"=1]
"tdeboissiere/DeepLearningImplementations" -> "openai/InfoGAN"
"tdeboissiere/DeepLearningImplementations" -> "tjwei/GANotebooks"
"tdeboissiere/DeepLearningImplementations" -> "leriomaggio/deep-learning-keras-tensorflow" ["e"=1]
"farizrahman4u/recurrentshop" -> "bstriner/keras-adversarial" ["e"=1]
"farizrahman4u/recurrentshop" -> "osh/KerasGAN" ["e"=1]
"karpathy/paper-notes" -> "reedscot/nips2016" ["e"=1]
"zhangqianhui/AdversarialNetsPapers" -> "carpedm20/DCGAN-tensorflow"
"zhangqianhui/AdversarialNetsPapers" -> "soumith/ganhacks"
"zhangqianhui/AdversarialNetsPapers" -> "wiseodd/generative-models"
"zhangqianhui/AdversarialNetsPapers" -> "hindupuravinash/the-gan-zoo"
"zhangqianhui/AdversarialNetsPapers" -> "nightrome/really-awesome-gan"
"zhangqianhui/AdversarialNetsPapers" -> "martinarjovsky/WassersteinGAN"
"zhangqianhui/AdversarialNetsPapers" -> "goodfeli/adversarial"
"zhangqianhui/AdversarialNetsPapers" -> "igul222/improved_wgan_training"
"zhangqianhui/AdversarialNetsPapers" -> "hwalsuklee/tensorflow-generative-model-collections"
"zhangqianhui/AdversarialNetsPapers" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"zhangqianhui/AdversarialNetsPapers" -> "tkarras/progressive_growing_of_gans"
"zhangqianhui/AdversarialNetsPapers" -> "yunjey/stargan"
"zhangqianhui/AdversarialNetsPapers" -> "openai/improved-gan"
"zhangqianhui/AdversarialNetsPapers" -> "phillipi/pix2pix"
"zhangqianhui/AdversarialNetsPapers" -> "kjw0612/awesome-deep-vision" ["e"=1]
"LantaoYu/SeqGAN" -> "igul222/improved_wgan_training" ["e"=1]
"LantaoYu/SeqGAN" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"LantaoYu/SeqGAN" -> "wiseodd/generative-models" ["e"=1]
"reedscot/icml2016" -> "reedscot/cvpr2016"
"reedscot/icml2016" -> "hanzhanggit/StackGAN"
"reedscot/icml2016" -> "paarthneekhara/text-to-image"
"reedscot/icml2016" -> "reedscot/nips2016"
"reedscot/icml2016" -> "aelnouby/Text-to-Image-Synthesis"
"reedscot/icml2016" -> "zsdonghao/text-to-image"
"reedscot/icml2016" -> "hanzhanggit/StackGAN-v2"
"reedscot/icml2016" -> "soumith/dcgan.torch"
"reedscot/icml2016" -> "taoxugit/AttnGAN"
"reedscot/icml2016" -> "mansimov/text2image"
"reedscot/icml2016" -> "hanzhanggit/StackGAN-Pytorch"
"reedscot/icml2016" -> "facebookarchive/eyescream"
"reedscot/icml2016" -> "openai/improved-gan"
"reedscot/icml2016" -> "cvondrick/videogan"
"reedscot/icml2016" -> "Evolving-AI-Lab/ppgn"
"HyperGAN/HyperGAN" -> "openai/pixel-cnn"
"HyperGAN/HyperGAN" -> "openai/improved-gan"
"HyperGAN/HyperGAN" -> "martinarjovsky/WassersteinGAN"
"HyperGAN/HyperGAN" -> "guojunq/lsgan"
"HyperGAN/HyperGAN" -> "Evolving-AI-Lab/ppgn"
"HyperGAN/HyperGAN" -> "carpedm20/BEGAN-tensorflow"
"HyperGAN/HyperGAN" -> "cvondrick/videogan"
"HyperGAN/HyperGAN" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"HyperGAN/HyperGAN" -> "openai/InfoGAN"
"HyperGAN/HyperGAN" -> "Evolving-AI-Lab/synthesizing"
"HyperGAN/HyperGAN" -> "hanzhanggit/StackGAN"
"HyperGAN/HyperGAN" -> "buriburisuri/ac-gan"
"HyperGAN/HyperGAN" -> "igul222/improved_wgan_training"
"HyperGAN/HyperGAN" -> "carpedm20/DiscoGAN-pytorch"
"HyperGAN/HyperGAN" -> "yunjey/domain-transfer-network"
"openai/pixel-cnn" -> "carpedm20/pixel-rnn-tensorflow"
"openai/pixel-cnn" -> "anantzoid/Conditional-PixelCNN-decoder"
"openai/pixel-cnn" -> "PrajitR/fast-pixel-cnn"
"openai/pixel-cnn" -> "openai/improved-gan"
"openai/pixel-cnn" -> "tomlepaine/fast-wavenet" ["e"=1]
"openai/pixel-cnn" -> "HyperGAN/HyperGAN"
"openai/pixel-cnn" -> "pclucas14/pixel-cnn-pp" ["e"=1]
"openai/pixel-cnn" -> "openai/InfoGAN"
"openai/pixel-cnn" -> "openai/iaf"
"openai/pixel-cnn" -> "ibab/tensorflow-wavenet" ["e"=1]
"openai/pixel-cnn" -> "martinarjovsky/WassersteinGAN"
"openai/pixel-cnn" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"openai/pixel-cnn" -> "google-deepmind/learning-to-learn" ["e"=1]
"openai/pixel-cnn" -> "pfnet-research/sngan_projection"
"openai/pixel-cnn" -> "openai/glow"
"ml4a/ml4a" -> "robbiebarrat/art-DCGAN" ["e"=1]
"kvfrans/generative-adversial" -> "kvfrans/variational-autoencoder"
"openai/vime" -> "openai/iaf" ["e"=1]
"openai/vime" -> "openai/InfoGAN" ["e"=1]
"Evolving-AI-Lab/synthesizing" -> "Evolving-AI-Lab/ppgn"
"Evolving-AI-Lab/synthesizing" -> "guojunq/lsgan"
"Evolving-AI-Lab/synthesizing" -> "xiaolonw/ss-gan"
"Evolving-AI-Lab/synthesizing" -> "skaae/torch-gan" ["e"=1]
"Evolving-AI-Lab/synthesizing" -> "facebookarchive/eyescream"
"Evolving-AI-Lab/synthesizing" -> "Evolving-AI-Lab/fooling" ["e"=1]
"Evolving-AI-Lab/synthesizing" -> "reedscot/nips2016"
"Evolving-AI-Lab/synthesizing" -> "reedscot/icml2016"
"Evolving-AI-Lab/synthesizing" -> "aleju/cat-generator"
"Evolving-AI-Lab/synthesizing" -> "cvondrick/videogan"
"Evolving-AI-Lab/synthesizing" -> "Guim3/IcGAN"
"Evolving-AI-Lab/synthesizing" -> "tonywu95/eval_gen"
"Evolving-AI-Lab/synthesizing" -> "chuanli11/CNNMRF"
"Evolving-AI-Lab/synthesizing" -> "davidBelanger/SPEN"
"Evolving-AI-Lab/synthesizing" -> "y0ast/VAE-Torch" ["e"=1]
"openai/improved-gan" -> "openai/InfoGAN"
"openai/improved-gan" -> "martinarjovsky/WassersteinGAN"
"openai/improved-gan" -> "igul222/improved_wgan_training"
"openai/improved-gan" -> "Newmu/dcgan_code"
"openai/improved-gan" -> "carpedm20/DCGAN-tensorflow"
"openai/improved-gan" -> "bioinf-jku/TTUR"
"openai/improved-gan" -> "wiseodd/generative-models"
"openai/improved-gan" -> "soumith/ganhacks"
"openai/improved-gan" -> "openai/pixel-cnn"
"openai/improved-gan" -> "goodfeli/adversarial"
"openai/improved-gan" -> "soumith/dcgan.torch"
"openai/improved-gan" -> "tkarras/progressive_growing_of_gans"
"openai/improved-gan" -> "openai/iaf"
"openai/improved-gan" -> "hanzhanggit/StackGAN"
"openai/improved-gan" -> "zhangqianhui/AdversarialNetsPapers"
"bamos/dcgan-completion.tensorflow" -> "carpedm20/DCGAN-tensorflow"
"bamos/dcgan-completion.tensorflow" -> "pathak22/context-encoder" ["e"=1]
"bamos/dcgan-completion.tensorflow" -> "Newmu/dcgan_code"
"bamos/dcgan-completion.tensorflow" -> "carpedm20/BEGAN-tensorflow"
"bamos/dcgan-completion.tensorflow" -> "leehomyc/Faster-High-Res-Neural-Inpainting" ["e"=1]
"bamos/dcgan-completion.tensorflow" -> "openai/improved-gan"
"bamos/dcgan-completion.tensorflow" -> "jacobgil/keras-dcgan"
"bamos/dcgan-completion.tensorflow" -> "soumith/dcgan.torch"
"bamos/dcgan-completion.tensorflow" -> "moodoki/semantic_image_inpainting" ["e"=1]
"bamos/dcgan-completion.tensorflow" -> "affinelayer/pix2pix-tensorflow"
"bamos/dcgan-completion.tensorflow" -> "hanzhanggit/StackGAN"
"bamos/dcgan-completion.tensorflow" -> "shinseung428/GlobalLocalImageCompletion_TF" ["e"=1]
"bamos/dcgan-completion.tensorflow" -> "paarthneekhara/text-to-image"
"bamos/dcgan-completion.tensorflow" -> "junyanz/iGAN"
"bamos/dcgan-completion.tensorflow" -> "martinarjovsky/WassersteinGAN"
"mingyuliutw/CoGAN" -> "andrewliao11/CoGAN-tensorflow"
"mingyuliutw/CoGAN" -> "mingyuliutw/CoGAN_PyTorch"
"mingyuliutw/CoGAN" -> "erictzeng/adda" ["e"=1]
"mingyuliutw/CoGAN" -> "xunhuang1995/SGAN"
"mingyuliutw/CoGAN" -> "mingyuliutw/UNIT"
"mingyuliutw/CoGAN" -> "guojunq/lsgan"
"mingyuliutw/CoGAN" -> "Evolving-AI-Lab/ppgn"
"cdoersch/vae_tutorial" -> "y0ast/VAE-Torch" ["e"=1]
"cdoersch/vae_tutorial" -> "y0ast/Variational-Autoencoder"
"cdoersch/vae_tutorial" -> "y0ast/VAE-TensorFlow"
"cdoersch/vae_tutorial" -> "jaanli/variational-autoencoder"
"cdoersch/vae_tutorial" -> "andersbll/autoencoding_beyond_pixels"
"cdoersch/vae_tutorial" -> "ethanluoyc/pytorch-vae"
"cdoersch/vae_tutorial" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"cdoersch/vae_tutorial" -> "xunhuang1995/SGAN"
"cdoersch/vae_tutorial" -> "hwalsuklee/tensorflow-mnist-CVAE"
"cdoersch/vae_tutorial" -> "dpkingma/nips14-ssl" ["e"=1]
"cdoersch/vae_tutorial" -> "RuiShu/cvae"
"cdoersch/vae_tutorial" -> "openai/InfoGAN"
"cdoersch/vae_tutorial" -> "carpedm20/pixel-rnn-tensorflow"
"cdoersch/vae_tutorial" -> "bojone/vae"
"cdoersch/vae_tutorial" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"facebookresearch/multipathnet" -> "DmitryUlyanov/texture_nets" ["e"=1]
"facebookresearch/multipathnet" -> "soumith/dcgan.torch" ["e"=1]
"Kaixhin/Autoencoders" -> "RuiShu/cvae" ["e"=1]
"thu-ml/zhusuan" -> "igul222/improved_wgan_training" ["e"=1]
"thu-ml/zhusuan" -> "wiseodd/generative-models" ["e"=1]
"thu-ml/zhusuan" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"openai/requests-for-research" -> "openai/improved-gan" ["e"=1]
"openai/requests-for-research" -> "openai/InfoGAN" ["e"=1]
"basveeling/wavenet" -> "bstriner/keras-adversarial" ["e"=1]
"basveeling/wavenet" -> "jacobgil/keras-dcgan" ["e"=1]
"cerndb/dist-keras" -> "bstriner/keras-adversarial" ["e"=1]
"buriburisuri/ebgan" -> "buriburisuri/supervised_infogan"
"buriburisuri/ebgan" -> "buriburisuri/sugartensor"
"buriburisuri/ebgan" -> "shekkizh/EBGAN.tensorflow"
"buriburisuri/ebgan" -> "buriburisuri/ac-gan"
"buriburisuri/ebgan" -> "buriburisuri/SRGAN" ["e"=1]
"buriburisuri/ebgan" -> "buriburisuri/timeseries_gan" ["e"=1]
"reedscot/cvpr2016" -> "reedscot/icml2016"
"reedscot/cvpr2016" -> "reedscot/nips2016"
"reedscot/cvpr2016" -> "aelnouby/Text-to-Image-Synthesis"
"reedscot/cvpr2016" -> "facebookarchive/eyescream"
"reedscot/cvpr2016" -> "hanzhanggit/StackGAN-v2"
"reedscot/cvpr2016" -> "hanzhanggit/StackGAN"
"reedscot/cvpr2016" -> "xunhuang1995/SGAN"
"reedscot/cvpr2016" -> "lzhbrian/arbitrary-text-to-image-papers"
"reedscot/cvpr2016" -> "xcyan/eccv16_attr2img"
"reedscot/cvpr2016" -> "kimiyoung/review_net" ["e"=1]
"reedscot/cvpr2016" -> "zsdonghao/text-to-image"
"cvondrick/videogan" -> "dyelax/Adversarial_Video_Generation" ["e"=1]
"cvondrick/videogan" -> "reedscot/nips2016"
"cvondrick/videogan" -> "GV1028/videogan" ["e"=1]
"cvondrick/videogan" -> "sergeytulyakov/mocogan" ["e"=1]
"cvondrick/videogan" -> "reedscot/icml2016"
"cvondrick/videogan" -> "batsa003/videogan" ["e"=1]
"cvondrick/videogan" -> "facebookarchive/eyescream"
"cvondrick/videogan" -> "coupriec/VideoPredictionICLR2016" ["e"=1]
"cvondrick/videogan" -> "mansimov/text2image"
"cvondrick/videogan" -> "mansimov/unsupervised-videos" ["e"=1]
"cvondrick/videogan" -> "y0ast/VAE-Torch" ["e"=1]
"cvondrick/videogan" -> "bernhard2202/improved-video-gan" ["e"=1]
"cvondrick/videogan" -> "Evolving-AI-Lab/synthesizing"
"cvondrick/videogan" -> "xiaolonw/ss-gan"
"cvondrick/videogan" -> "DmitryUlyanov/texture_nets"
"junyanz/CatPapers" -> "junyanz/iGAN"
"junyanz/CatPapers" -> "Evolving-AI-Lab/ppgn"
"junyanz/CatPapers" -> "junyanz/BicycleGAN"
"junyanz/CatPapers" -> "junyanz/light-field-video" ["e"=1]
"junyanz/CatPapers" -> "yenchenlin/pix2pix-tensorflow"
"junyanz/CatPapers" -> "junyanz/VON" ["e"=1]
"junyanz/CatPapers" -> "AlexiaJM/Deep-learning-with-cats"
"junyanz/CatPapers" -> "junyanz/interactive-deep-colorization" ["e"=1]
"junyanz/CatPapers" -> "soumith/dcgan.torch"
"junyanz/CatPapers" -> "harthur/kittydar" ["e"=1]
"junyanz/CatPapers" -> "tinghuiz/appearance-flow" ["e"=1]
"junyanz/CatPapers" -> "phillipi/pix2pix"
"junyanz/CatPapers" -> "affinelayer/pix2pix-tensorflow"
"junyanz/CatPapers" -> "junyanz/CycleGAN"
"junyanz/CatPapers" -> "openai/improved-gan"
"osh/KerasGAN" -> "bstriner/keras-adversarial"
"osh/KerasGAN" -> "phreeza/keras-GAN"
"osh/KerasGAN" -> "jacobgil/keras-dcgan"
"osh/KerasGAN" -> "osh/kerlym" ["e"=1]
"osh/KerasGAN" -> "jonbruner/generative-adversarial-networks"
"osh/KerasGAN" -> "Zackory/Keras-MNIST-GAN"
"osh/KerasGAN" -> "heuritech/convnets-keras" ["e"=1]
"osh/KerasGAN" -> "mjdietzx/SimGAN"
"osh/KerasGAN" -> "tdeboissiere/DeepLearningImplementations"
"osh/KerasGAN" -> "farizrahman4u/recurrentshop" ["e"=1]
"osh/KerasGAN" -> "carpedm20/BEGAN-tensorflow"
"osh/KerasGAN" -> "adeshpande3/Generative-Adversarial-Networks"
"osh/KerasGAN" -> "r0nn13/conditional-dcgan-keras"
"osh/KerasGAN" -> "coreylynch/async-rl" ["e"=1]
"osh/KerasGAN" -> "clvrai/SSGAN-Tensorflow"
"openai/InfoGAN" -> "openai/improved-gan"
"openai/InfoGAN" -> "JonathanRaiman/tensorflow-infogan" ["e"=1]
"openai/InfoGAN" -> "openai/iaf"
"openai/InfoGAN" -> "Natsu6767/InfoGAN-PyTorch" ["e"=1]
"openai/InfoGAN" -> "openai/imitation" ["e"=1]
"openai/InfoGAN" -> "martinarjovsky/WassersteinGAN"
"openai/InfoGAN" -> "Newmu/dcgan_code"
"openai/InfoGAN" -> "openai/vime" ["e"=1]
"openai/InfoGAN" -> "igul222/improved_wgan_training"
"openai/InfoGAN" -> "openai/pixel-cnn"
"openai/InfoGAN" -> "hanzhanggit/StackGAN"
"openai/InfoGAN" -> "andersbll/autoencoding_beyond_pixels"
"openai/InfoGAN" -> "facebookarchive/eyescream"
"openai/InfoGAN" -> "carpedm20/BEGAN-tensorflow"
"openai/InfoGAN" -> "reedscot/nips2016"
"dilinwang820/Stein-Variational-Gradient-Descent" -> "openai/iaf" ["e"=1]
"KnHuq/Dynamic-Tensorflow-Tutorial" -> "shekkizh/WassersteinGAN.tensorflow" ["e"=1]
"KnHuq/Dynamic-Tensorflow-Tutorial" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW" ["e"=1]
"KnHuq/Dynamic-Tensorflow-Tutorial" -> "carpedm20/pixel-rnn-tensorflow" ["e"=1]
"davidBelanger/SPEN" -> "gyglim/dvn"
"wookayin/tensorflow-talk-debugging" -> "carpedm20/simulated-unsupervised-tensorflow" ["e"=1]
"wookayin/tensorflow-talk-debugging" -> "reedscot/nips2016" ["e"=1]
"AYLIEN/gan-intro" -> "ericjang/genadv_tutorial"
"AYLIEN/gan-intro" -> "shekkizh/WassersteinGAN.tensorflow"
"AYLIEN/gan-intro" -> "devnag/pytorch-generative-adversarial-networks"
"AYLIEN/gan-intro" -> "openai/improved-gan"
"AYLIEN/gan-intro" -> "openai/InfoGAN"
"AYLIEN/gan-intro" -> "Zardinality/WGAN-tensorflow"
"keplr-io/hera" -> "osh/KerasGAN" ["e"=1]
"xiaolonw/ss-gan" -> "cvondrick/torch-starter" ["e"=1]
"xiaolonw/ss-gan" -> "skaae/torch-gan" ["e"=1]
"tomlepaine/fast-wavenet" -> "openai/pixel-cnn" ["e"=1]
"pavelgonchar/color-independent-style-transfer" -> "pavelgonchar/neural-art-mini"
"pavelgonchar/color-independent-style-transfer" -> "awentzonline/keras-rtst"
"openai/imitation" -> "openai/InfoGAN" ["e"=1]
"openai/imitation" -> "openai/iaf" ["e"=1]
"loliverhennigh/Convolutional-LSTM-in-Tensorflow" -> "carpedm20/pixel-rnn-tensorflow" ["e"=1]
"ankurhanda/gvnn" -> "facebookarchive/eyescream" ["e"=1]
"usernaamee/keras-wavenet" -> "phreeza/keras-GAN" ["e"=1]
"pavelgonchar/neural-art-mini" -> "pavelgonchar/color-independent-style-transfer"
"pavelgonchar/neural-art-mini" -> "chuanli11/MGANs"
"coxlab/prednet" -> "cvondrick/videogan" ["e"=1]
"fxia22/PixelDTGAN" -> "Guim3/IcGAN"
"fxia22/PixelDTGAN" -> "SKTBrain/DiscoGAN"
"fxia22/PixelDTGAN" -> "xunhuang1995/SGAN"
"fxia22/PixelDTGAN" -> "guojunq/lsgan"
"openai/iaf" -> "openai/vime" ["e"=1]
"openai/iaf" -> "openai/InfoGAN"
"openai/iaf" -> "jmtomczak/vae_vpflows" ["e"=1]
"openai/iaf" -> "dpkingma/nips14-ssl" ["e"=1]
"openai/iaf" -> "yburda/iwae" ["e"=1]
"openai/iaf" -> "ericjang/normalizing-flows-tutorial" ["e"=1]
"openai/iaf" -> "openai/improved-gan"
"openai/iaf" -> "openai/imitation" ["e"=1]
"openai/iaf" -> "riannevdberg/sylvester-flows" ["e"=1]
"openai/iaf" -> "casperkaae/parmesan" ["e"=1]
"openai/iaf" -> "ermongroup/Variational-Ladder-Autoencoder" ["e"=1]
"openai/iaf" -> "pclucas14/iaf-vae"
"openai/iaf" -> "jmtomczak/vae_vampprior" ["e"=1]
"openai/iaf" -> "carpedm20/variational-text-tensorflow" ["e"=1]
"openai/iaf" -> "openai/pixel-cnn"
"buriburisuri/supervised_infogan" -> "buriburisuri/ebgan"
"buriburisuri/supervised_infogan" -> "buriburisuri/ac-gan"
"buriburisuri/supervised_infogan" -> "JonathanRaiman/tensorflow-infogan" ["e"=1]
"buriburisuri/supervised_infogan" -> "Kyubyong/neural_tokenizer" ["e"=1]
"buriburisuri/supervised_infogan" -> "buriburisuri/sugartensor"
"buriburisuri/supervised_infogan" -> "buriburisuri/timeseries_gan" ["e"=1]
"buriburisuri/sugartensor" -> "buriburisuri/SRGAN" ["e"=1]
"buriburisuri/sugartensor" -> "buriburisuri/supervised_infogan"
"buriburisuri/sugartensor" -> "buriburisuri/ebgan"
"buriburisuri/sugartensor" -> "buriburisuri/ac-gan"
"buriburisuri/sugartensor" -> "buriburisuri/timeseries_gan" ["e"=1]
"buriburisuri/sugartensor" -> "artcg/BEGAN"
"buriburisuri/sugartensor" -> "junhocho/SRGAN" ["e"=1]
"saikatbsk/Vincent-AI-Artist" -> "saikatbsk/Wave"
"dyelax/encore.ai" -> "ivan-liljeqvist/ailyrics"
"dyelax/encore.ai" -> "tonybeltramelli/Deep-Lyrics"
"leongatys/NeuralImageSynthesis" -> "chuanli11/MGANs" ["e"=1]
"drboog/Shifted_Diffusion" -> "drboog/Lafite"
"gafr/chainer-fast-neuralstyle-models" -> "yusuketomoto/chainer-fast-neuralstyle" ["e"=1]
"coupriec/VideoPredictionICLR2016" -> "xiaolonw/ss-gan" ["e"=1]
"llSourcell/Rap_Lyric_Generator" -> "txizzle/MarkovRapGenerator"
"kxytim/DeepPLS" -> "kxytim/DLVM_for_process_monitoring"
"buriburisuri/timeseries_gan" -> "buriburisuri/supervised_infogan" ["e"=1]
"buriburisuri/timeseries_gan" -> "buriburisuri/ebgan" ["e"=1]
"buriburisuri/timeseries_gan" -> "buriburisuri/sugartensor" ["e"=1]
"buriburisuri/timeseries_gan" -> "buriburisuri/ac-gan" ["e"=1]
"kundan2510/pixelCNN" -> "igul222/pixel_rnn"
"kundan2510/pixelCNN" -> "anantzoid/Conditional-PixelCNN-decoder"
"kundan2510/pixelCNN" -> "carpedm20/pixel-rnn-tensorflow"
"kundan2510/pixelCNN" -> "casperkaae/parmesan" ["e"=1]
"JonathanRaiman/tensorflow-infogan" -> "buriburisuri/supervised_infogan" ["e"=1]
"JonathanRaiman/tensorflow-infogan" -> "openai/InfoGAN" ["e"=1]
"JubilantJerry/CNN-Glasses-Remover" -> "lecomte/glasses-removal-gan"
"paperswithcode/ai-deadlines" -> "soumith/ganhacks" ["e"=1]
"google/guetzli" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"flyyufelix/cnn_finetune" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"wiseodd/generative-models" -> "soumith/ganhacks"
"wiseodd/generative-models" -> "zhangqianhui/AdversarialNetsPapers"
"wiseodd/generative-models" -> "carpedm20/DCGAN-tensorflow"
"wiseodd/generative-models" -> "hwalsuklee/tensorflow-generative-model-collections"
"wiseodd/generative-models" -> "martinarjovsky/WassersteinGAN"
"wiseodd/generative-models" -> "hindupuravinash/the-gan-zoo"
"wiseodd/generative-models" -> "nightrome/really-awesome-gan"
"wiseodd/generative-models" -> "znxlwm/pytorch-generative-model-collections"
"wiseodd/generative-models" -> "igul222/improved_wgan_training"
"wiseodd/generative-models" -> "openai/improved-gan"
"wiseodd/generative-models" -> "yfeng95/GAN"
"wiseodd/generative-models" -> "tkarras/progressive_growing_of_gans"
"wiseodd/generative-models" -> "lanpa/tensorboardX" ["e"=1]
"wiseodd/generative-models" -> "yunjey/stargan"
"wiseodd/generative-models" -> "pytorch/examples" ["e"=1]
"soumith/ganhacks" -> "hindupuravinash/the-gan-zoo"
"soumith/ganhacks" -> "wiseodd/generative-models"
"soumith/ganhacks" -> "zhangqianhui/AdversarialNetsPapers"
"soumith/ganhacks" -> "eriklindernoren/PyTorch-GAN"
"soumith/ganhacks" -> "carpedm20/DCGAN-tensorflow"
"soumith/ganhacks" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"soumith/ganhacks" -> "eriklindernoren/Keras-GAN"
"soumith/ganhacks" -> "martinarjovsky/WassersteinGAN"
"soumith/ganhacks" -> "vdumoulin/conv_arithmetic" ["e"=1]
"soumith/ganhacks" -> "nashory/gans-awesome-applications"
"soumith/ganhacks" -> "nightrome/really-awesome-gan"
"soumith/ganhacks" -> "pytorch/examples" ["e"=1]
"soumith/ganhacks" -> "tkarras/progressive_growing_of_gans"
"soumith/ganhacks" -> "junyanz/CycleGAN"
"soumith/ganhacks" -> "lanpa/tensorboardX" ["e"=1]
"andrewliao11/CoGAN-tensorflow" -> "mingyuliutw/CoGAN"
"openai/universe" -> "magenta/magenta" ["e"=1]
"affinelayer/pix2pix-tensorflow" -> "phillipi/pix2pix"
"affinelayer/pix2pix-tensorflow" -> "carpedm20/DCGAN-tensorflow"
"affinelayer/pix2pix-tensorflow" -> "yenchenlin/pix2pix-tensorflow"
"affinelayer/pix2pix-tensorflow" -> "NVIDIA/pix2pixHD"
"affinelayer/pix2pix-tensorflow" -> "junyanz/CycleGAN"
"affinelayer/pix2pix-tensorflow" -> "tkarras/progressive_growing_of_gans"
"affinelayer/pix2pix-tensorflow" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"affinelayer/pix2pix-tensorflow" -> "vanhuyz/CycleGAN-TensorFlow"
"affinelayer/pix2pix-tensorflow" -> "junyanz/iGAN"
"affinelayer/pix2pix-tensorflow" -> "wiseodd/generative-models"
"affinelayer/pix2pix-tensorflow" -> "zhangqianhui/AdversarialNetsPapers"
"affinelayer/pix2pix-tensorflow" -> "martinarjovsky/WassersteinGAN"
"affinelayer/pix2pix-tensorflow" -> "datitran/face2face-demo" ["e"=1]
"affinelayer/pix2pix-tensorflow" -> "soumith/ganhacks"
"affinelayer/pix2pix-tensorflow" -> "tdeboissiere/DeepLearningImplementations"
"pytorch/vision" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"ryanjay0/miles-deep" -> "yahoo/open_nsfw" ["e"=1]
"ryanjay0/miles-deep" -> "bakwc/PornDetector" ["e"=1]
"ryanjay0/miles-deep" -> "david-gpu/srez"
"ryanjay0/miles-deep" -> "porn-vault/porn-vault" ["e"=1]
"ryanjay0/miles-deep" -> "LucasLeandro1204/Pornsearch" ["e"=1]
"ryanjay0/miles-deep" -> "rlleshi/phar" ["e"=1]
"ryanjay0/miles-deep" -> "alexjc/neural-enhance"
"ryanjay0/miles-deep" -> "alexjc/neural-doodle"
"ryanjay0/miles-deep" -> "sbrugman/deep-learning-papers" ["e"=1]
"ryanjay0/miles-deep" -> "pavelgonchar/colornet"
"ryanjay0/miles-deep" -> "AKSHAYUBHAT/DeepVideoAnalytics" ["e"=1]
"ryanjay0/miles-deep" -> "notAI-tech/NudeNet" ["e"=1]
"ryanjay0/miles-deep" -> "crockpotveggies/tinderbox" ["e"=1]
"ryanjay0/miles-deep" -> "jcjohnson/neural-style"
"ryanjay0/miles-deep" -> "curtwagner1984/YAPO" ["e"=1]
"yenchenlin/pix2pix-tensorflow" -> "affinelayer/pix2pix-tensorflow"
"yenchenlin/pix2pix-tensorflow" -> "xiaowei-hu/CycleGAN-tensorflow"
"yenchenlin/pix2pix-tensorflow" -> "vanhuyz/CycleGAN-TensorFlow"
"yenchenlin/pix2pix-tensorflow" -> "carpedm20/BEGAN-tensorflow"
"yenchenlin/pix2pix-tensorflow" -> "Zardinality/WGAN-tensorflow"
"yenchenlin/pix2pix-tensorflow" -> "buriburisuri/ac-gan"
"yenchenlin/pix2pix-tensorflow" -> "yunjey/domain-transfer-network"
"yenchenlin/pix2pix-tensorflow" -> "tdeboissiere/DeepLearningImplementations"
"yenchenlin/pix2pix-tensorflow" -> "hanzhanggit/StackGAN"
"yenchenlin/pix2pix-tensorflow" -> "openai/improved-gan"
"yenchenlin/pix2pix-tensorflow" -> "phillipi/pix2pix"
"yenchenlin/pix2pix-tensorflow" -> "carpedm20/DCGAN-tensorflow"
"yenchenlin/pix2pix-tensorflow" -> "eyyub/tensorflow-pix2pix"
"yenchenlin/pix2pix-tensorflow" -> "leehomyc/cyclegan-1"
"yenchenlin/pix2pix-tensorflow" -> "carpedm20/simulated-unsupervised-tensorflow"
"yunjey/domain-transfer-network" -> "buriburisuri/ac-gan"
"yunjey/domain-transfer-network" -> "taey16/DomainTransferNetwork.pytorch"
"yunjey/domain-transfer-network" -> "SKTBrain/DiscoGAN"
"yunjey/domain-transfer-network" -> "carpedm20/DiscoGAN-pytorch"
"yunjey/domain-transfer-network" -> "yenchenlin/pix2pix-tensorflow"
"yunjey/domain-transfer-network" -> "fxia22/PixelDTGAN"
"yunjey/domain-transfer-network" -> "msracver/Deep-Image-Analogy"
"yunjey/domain-transfer-network" -> "DmitryUlyanov/texture_nets"
"yunjey/domain-transfer-network" -> "carpedm20/BEGAN-tensorflow"
"yunjey/domain-transfer-network" -> "carpedm20/simulated-unsupervised-tensorflow"
"yunjey/domain-transfer-network" -> "sagiebenaim/DistanceGAN"
"yunjey/domain-transfer-network" -> "reedscot/nips2016"
"yunjey/domain-transfer-network" -> "hanzhanggit/StackGAN"
"yunjey/domain-transfer-network" -> "Evolving-AI-Lab/ppgn"
"yunjey/domain-transfer-network" -> "openai/improved-gan"
"AKSHAYUBHAT/DeepVideoAnalytics" -> "MrNothing/AI-Blocks" ["e"=1]
"AKSHAYUBHAT/DeepVideoAnalytics" -> "junyanz/iGAN" ["e"=1]
"AKSHAYUBHAT/DeepVideoAnalytics" -> "yunjey/stargan" ["e"=1]
"totalgood/nlpia" -> "GANs-in-Action/gans-in-action" ["e"=1]
"vi/websocat" -> "websockets/wscat" ["e"=1]
"endymecy/awesome-deeplearning-resources" -> "nightrome/really-awesome-gan" ["e"=1]
"endymecy/awesome-deeplearning-resources" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"phillipi/pix2pix" -> "affinelayer/pix2pix-tensorflow"
"phillipi/pix2pix" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"phillipi/pix2pix" -> "junyanz/CycleGAN"
"phillipi/pix2pix" -> "NVIDIA/pix2pixHD"
"phillipi/pix2pix" -> "carpedm20/DCGAN-tensorflow"
"phillipi/pix2pix" -> "soumith/ganhacks"
"phillipi/pix2pix" -> "junyanz/iGAN"
"phillipi/pix2pix" -> "hindupuravinash/the-gan-zoo"
"phillipi/pix2pix" -> "zhangqianhui/AdversarialNetsPapers"
"phillipi/pix2pix" -> "tkarras/progressive_growing_of_gans"
"phillipi/pix2pix" -> "yunjey/stargan"
"phillipi/pix2pix" -> "martinarjovsky/WassersteinGAN"
"phillipi/pix2pix" -> "jcjohnson/fast-neural-style"
"phillipi/pix2pix" -> "wiseodd/generative-models"
"phillipi/pix2pix" -> "Newmu/dcgan_code"
"kevinhughes27/TensorKart" -> "bamos/dcgan-completion.tensorflow" ["e"=1]
"cysmith/neural-style-tf" -> "anishathalye/neural-style"
"cysmith/neural-style-tf" -> "lengstrom/fast-style-transfer"
"cysmith/neural-style-tf" -> "jcjohnson/fast-neural-style"
"cysmith/neural-style-tf" -> "titu1994/Neural-Style-Transfer"
"cysmith/neural-style-tf" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"cysmith/neural-style-tf" -> "manuelruder/artistic-videos"
"cysmith/neural-style-tf" -> "DmitryUlyanov/texture_nets"
"cysmith/neural-style-tf" -> "jcjohnson/neural-style"
"cysmith/neural-style-tf" -> "hzy46/fast-neural-style-tensorflow"
"cysmith/neural-style-tf" -> "msracver/Deep-Image-Analogy"
"cysmith/neural-style-tf" -> "LouieYang/deep-photo-styletransfer-tf" ["e"=1]
"cysmith/neural-style-tf" -> "chuanli11/CNNMRF"
"cysmith/neural-style-tf" -> "dennybritz/cnn-text-classification-tf" ["e"=1]
"cysmith/neural-style-tf" -> "xunhuang1995/AdaIN-style" ["e"=1]
"cysmith/neural-style-tf" -> "junyanz/iGAN"
"saurabhmathur96/clickbait-detector" -> "peterldowns/clickbait-classifier"
"saurabhmathur96/clickbait-detector" -> "rahulkapoor90/This-is-Clickbait"
"saurabhmathur96/clickbait-detector" -> "abhishekkrthakur/clickbaits_revisited"
"saurabhmathur96/clickbait-detector" -> "bhargaviparanjape/clickbait"
"szagoruyko/attention-transfer" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"PHPixie/Project" -> "david-gpu/srez" ["e"=1]
"tjwei/GANotebooks" -> "igul222/improved_wgan_training"
"tjwei/GANotebooks" -> "caogang/wgan-gp"
"tjwei/GANotebooks" -> "tdeboissiere/DeepLearningImplementations"
"tjwei/GANotebooks" -> "vanhuyz/CycleGAN-TensorFlow"
"tjwei/GANotebooks" -> "eriklindernoren/Keras-GAN"
"tjwei/GANotebooks" -> "martinarjovsky/WassersteinGAN"
"tjwei/GANotebooks" -> "jacobgil/keras-dcgan"
"tjwei/GANotebooks" -> "shaoanlu/faceswap-GAN" ["e"=1]
"tjwei/GANotebooks" -> "zhangqianhui/AdversarialNetsPapers"
"tjwei/GANotebooks" -> "nightrome/really-awesome-gan"
"tjwei/GANotebooks" -> "openai/glow"
"tjwei/GANotebooks" -> "affinelayer/pix2pix-tensorflow"
"tjwei/GANotebooks" -> "znxlwm/pytorch-generative-model-collections"
"tjwei/GANotebooks" -> "carpedm20/DCGAN-tensorflow"
"tjwei/GANotebooks" -> "NVIDIA/pix2pixHD"
"yenchenlin/awesome-adversarial-machine-learning" -> "nightrome/really-awesome-gan" ["e"=1]
"google-deepmind/learning-to-learn" -> "openai/pixel-cnn" ["e"=1]
"burness/tensorflow-101" -> "buriburisuri/ac-gan" ["e"=1]
"burness/tensorflow-101" -> "igul222/improved_wgan_training" ["e"=1]
"buriburisuri/speech-to-text-wavenet" -> "MrNothing/AI-Blocks" ["e"=1]
"buriburisuri/speech-to-text-wavenet" -> "junyanz/iGAN" ["e"=1]
"Mostafa-Samir/DNC-tensorflow" -> "anantzoid/Conditional-PixelCNN-decoder" ["e"=1]
"raghakot/keras-vis" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"raghakot/keras-vis" -> "eriklindernoren/Keras-GAN" ["e"=1]
"adeshpande3/Tensorflow-Programs-and-Tutorials" -> "adeshpande3/Generative-Adversarial-Networks" ["e"=1]
"adeshpande3/Tensorflow-Programs-and-Tutorials" -> "awjuliani/TF-Tutorials" ["e"=1]
"guojunq/lsgan" -> "guojunq/glsgan"
"guojunq/lsgan" -> "xiaolonw/ss-gan"
"guojunq/lsgan" -> "musyoku/LSGAN"
"kaonashi-tyc/Rewrite" -> "kaonashi-tyc/zi2zi" ["e"=1]
"kaonashi-tyc/Rewrite" -> "MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" ["e"=1]
"kaonashi-tyc/Rewrite" -> "DmitryUlyanov/texture_nets" ["e"=1]
"keplr-io/quiver" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"keplr-io/quiver" -> "bstriner/keras-adversarial" ["e"=1]
"tensorflow/fold" -> "openai/pixel-cnn" ["e"=1]
"udacity/deep-learning" -> "lengstrom/fast-style-transfer" ["e"=1]
"ericjang/gumbel-softmax" -> "EmilienDupont/vae-concrete" ["e"=1]
"titu1994/DenseNet" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"googlecreativelab/aiexperiments-ai-duet" -> "magenta/magenta" ["e"=1]
"olofmogren/c-rnn-gan" -> "Zardinality/WGAN-tensorflow" ["e"=1]
"jcjohnson/pytorch-examples" -> "soumith/ganhacks" ["e"=1]
"jcjohnson/pytorch-examples" -> "wiseodd/generative-models" ["e"=1]
"jcjohnson/pytorch-examples" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"0xfuturistic/Twitter-Giveaways-Bot" -> "TobiasPankner/Gleam-giveaway-bot"
"0xfuturistic/Twitter-Giveaways-Bot" -> "robbiebarrat/twitter-contest-enterer"
"tensorlayer/DCGAN" -> "zsdonghao/text-to-image"
"tensorlayer/DCGAN" -> "sugyan/tf-dcgan"
"tensorlayer/DCGAN" -> "buriburisuri/SRGAN" ["e"=1]
"tensorlayer/DCGAN" -> "bamos/dcgan-completion.tensorflow"
"tensorlayer/DCGAN" -> "wagamamaz/tensorlayer-tricks" ["e"=1]
"tensorlayer/DCGAN" -> "xiaowei-hu/CycleGAN-tensorflow"
"tensorlayer/DCGAN" -> "jacobgil/keras-dcgan"
"tensorlayer/DCGAN" -> "titu1994/Super-Resolution-using-Generative-Adversarial-Networks" ["e"=1]
"tensorlayer/DCGAN" -> "buriburisuri/ac-gan"
"hanzhanggit/StackGAN" -> "hanzhanggit/StackGAN-v2"
"hanzhanggit/StackGAN" -> "reedscot/icml2016"
"hanzhanggit/StackGAN" -> "taoxugit/AttnGAN"
"hanzhanggit/StackGAN" -> "hanzhanggit/StackGAN-Pytorch"
"hanzhanggit/StackGAN" -> "paarthneekhara/text-to-image"
"hanzhanggit/StackGAN" -> "zsdonghao/text-to-image"
"hanzhanggit/StackGAN" -> "openai/improved-gan"
"hanzhanggit/StackGAN" -> "igul222/improved_wgan_training"
"hanzhanggit/StackGAN" -> "martinarjovsky/WassersteinGAN"
"hanzhanggit/StackGAN" -> "tkarras/progressive_growing_of_gans"
"hanzhanggit/StackGAN" -> "carpedm20/DCGAN-tensorflow"
"hanzhanggit/StackGAN" -> "google/sg2im" ["e"=1]
"hanzhanggit/StackGAN" -> "openai/InfoGAN"
"hanzhanggit/StackGAN" -> "reedscot/cvpr2016"
"hanzhanggit/StackGAN" -> "junyanz/iGAN"
"zsdonghao/text-to-image" -> "reedscot/icml2016"
"zsdonghao/text-to-image" -> "aelnouby/Text-to-Image-Synthesis"
"zsdonghao/text-to-image" -> "paarthneekhara/text-to-image"
"zsdonghao/text-to-image" -> "hanzhanggit/StackGAN-v2"
"zsdonghao/text-to-image" -> "hanzhanggit/StackGAN"
"zsdonghao/text-to-image" -> "tensorlayer/DCGAN"
"zsdonghao/text-to-image" -> "taoxugit/AttnGAN"
"zsdonghao/text-to-image" -> "btgraham/Batchwise-Dropout" ["e"=1]
"zsdonghao/text-to-image" -> "reedscot/cvpr2016"
"zsdonghao/text-to-image" -> "6004x/jade" ["e"=1]
"zsdonghao/text-to-image" -> "danielkunin/Deeplearning-Visualizations" ["e"=1]
"zsdonghao/text-to-image" -> "liuchen11/CertifyNonuniformBounds" ["e"=1]
"zsdonghao/text-to-image" -> "chen0040/keras-text-to-image"
"zsdonghao/text-to-image" -> "prichemond/ds3" ["e"=1]
"zsdonghao/text-to-image" -> "ee227c/ee227c.github.io" ["e"=1]
"cvondrick/soundnet" -> "xiaolonw/ss-gan" ["e"=1]
"cvondrick/soundnet" -> "Guim3/IcGAN" ["e"=1]
"cvondrick/soundnet" -> "cvondrick/videogan" ["e"=1]
"cvondrick/soundnet" -> "facebookarchive/eyescream" ["e"=1]
"cvondrick/soundnet" -> "reedscot/nips2016" ["e"=1]
"Evolving-AI-Lab/ppgn" -> "Evolving-AI-Lab/synthesizing"
"Evolving-AI-Lab/ppgn" -> "reedscot/nips2016"
"Evolving-AI-Lab/ppgn" -> "xunhuang1995/SGAN"
"Evolving-AI-Lab/ppgn" -> "guojunq/lsgan"
"Evolving-AI-Lab/ppgn" -> "Guim3/IcGAN"
"Evolving-AI-Lab/ppgn" -> "buriburisuri/ebgan"
"Evolving-AI-Lab/ppgn" -> "reedscot/icml2016"
"Evolving-AI-Lab/ppgn" -> "skaae/torch-gan" ["e"=1]
"Evolving-AI-Lab/ppgn" -> "carpedm20/BEGAN-tensorflow"
"Evolving-AI-Lab/ppgn" -> "buriburisuri/ac-gan"
"Evolving-AI-Lab/ppgn" -> "carpedm20/DiscoGAN-pytorch"
"Evolving-AI-Lab/ppgn" -> "IshmaelBelghazi/ALI"
"Evolving-AI-Lab/ppgn" -> "facebookarchive/eyescream"
"Evolving-AI-Lab/ppgn" -> "mingyuliutw/CoGAN"
"Evolving-AI-Lab/ppgn" -> "chuanli11/MGANs"
"OpenNMT/OpenNMT" -> "junyanz/iGAN" ["e"=1]
"OpenNMT/OpenNMT" -> "MrNothing/AI-Blocks" ["e"=1]
"TeamHG-Memex/tensorboard_logger" -> "martinarjovsky/WassersteinGAN" ["e"=1]
"TeamHG-Memex/tensorboard_logger" -> "buriburisuri/sugartensor" ["e"=1]
"rcmalli/keras-squeezenet" -> "bstriner/keras-adversarial" ["e"=1]
"ermongroup/cs228-notes" -> "jaanli/variational-autoencoder" ["e"=1]
"szagoruyko/functional-zoo" -> "carpedm20/BEGAN-pytorch" ["e"=1]
"SKTBrain/awesome-starcraftAI" -> "SKTBrain/DiscoGAN" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "OlavHN/fast-neural-style"
"hzy46/fast-neural-style-tensorflow" -> "jcjohnson/fast-neural-style"
"hzy46/fast-neural-style-tensorflow" -> "wisewong/ImageStyleTransform"
"hzy46/fast-neural-style-tensorflow" -> "anishathalye/neural-style"
"hzy46/fast-neural-style-tensorflow" -> "junrushao/fast-neural-style.tf"
"hzy46/fast-neural-style-tensorflow" -> "cysmith/neural-style-tf"
"hzy46/fast-neural-style-tensorflow" -> "rtqichen/style-swap" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "ghwatson/faststyle" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "yusuketomoto/chainer-fast-neuralstyle"
"hzy46/fast-neural-style-tensorflow" -> "vanhuyz/CycleGAN-TensorFlow"
"hzy46/fast-neural-style-tensorflow" -> "LouieYang/deep-photo-styletransfer-tf" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "LDOUBLEV/style_transfer-perceptual_loss"
"hzy46/fast-neural-style-tensorflow" -> "abhiskk/fast-neural-style" ["e"=1]
"hzy46/fast-neural-style-tensorflow" -> "DmitryUlyanov/texture_nets"
"tobran/StoryImager" -> "tobran/ONE-PIC"
"tobran/StoryImager" -> "tobran/DE-Net"
"keras-team/keras-contrib" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"keras-team/keras-contrib" -> "bstriner/keras-adversarial" ["e"=1]
"keras-team/keras-contrib" -> "eriklindernoren/Keras-GAN" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "osh/KerasGAN"
"roatienza/Deep-Learning-Experiments" -> "jacobgil/keras-dcgan"
"roatienza/Deep-Learning-Experiments" -> "bstriner/keras-adversarial"
"roatienza/Deep-Learning-Experiments" -> "PacktPublishing/Advanced-Deep-Learning-with-Keras" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "roatienza/ml"
"roatienza/Deep-Learning-Experiments" -> "kspilario/AI221"
"roatienza/Deep-Learning-Experiments" -> "rockingdingo/deepnlp" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "ilivans/tf-rnn-attention" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "tdeboissiere/DeepLearningImplementations"
"roatienza/Deep-Learning-Experiments" -> "aurora95/Keras-FCN" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "fchollet/keras-resources" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "tjwei/GANotebooks"
"roatienza/Deep-Learning-Experiments" -> "eriklindernoren/Keras-GAN"
"roatienza/Deep-Learning-Experiments" -> "leriomaggio/deep-learning-keras-tensorflow" ["e"=1]
"roatienza/Deep-Learning-Experiments" -> "meereeum/lda2vec-tf" ["e"=1]
"buriburisuri/ac-gan" -> "buriburisuri/supervised_infogan"
"buriburisuri/ac-gan" -> "buriburisuri/ebgan"
"buriburisuri/ac-gan" -> "buriburisuri/sugartensor"
"buriburisuri/ac-gan" -> "lukedeo/keras-acgan"
"buriburisuri/ac-gan" -> "yunjey/domain-transfer-network"
"buriburisuri/ac-gan" -> "Guim3/IcGAN"
"buriburisuri/ac-gan" -> "Zardinality/WGAN-tensorflow"
"buriburisuri/ac-gan" -> "buriburisuri/SRGAN" ["e"=1]
"buriburisuri/ac-gan" -> "Evolving-AI-Lab/ppgn"
"buriburisuri/ac-gan" -> "openai/improved-gan"
"buriburisuri/ac-gan" -> "yenchenlin/pix2pix-tensorflow"
"buriburisuri/ac-gan" -> "Kyubyong/quasi-rnn"
"buriburisuri/ac-gan" -> "buriburisuri/timeseries_gan" ["e"=1]
"buriburisuri/ac-gan" -> "openai/InfoGAN"
"buriburisuri/ac-gan" -> "clvrai/SSGAN-Tensorflow"
"rtqichen/style-swap" -> "DmitryUlyanov/texture_nets" ["e"=1]
"rtqichen/style-swap" -> "chuanli11/CNNMRF" ["e"=1]
"rtqichen/style-swap" -> "chuanli11/MGANs" ["e"=1]
"rtqichen/style-swap" -> "msracver/Deep-Image-Analogy" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "robbiebarrat/art-DCGAN"
"robbiebarrat/rapping-neural-network" -> "robbiebarrat/plant-art"
"robbiebarrat/rapping-neural-network" -> "robbiebarrat/Bach_AI"
"robbiebarrat/rapping-neural-network" -> "robbiebarrat/twitter-contest-enterer"
"robbiebarrat/rapping-neural-network" -> "ryankiros/neural-storyteller" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "tonybeltramelli/Deep-Lyrics"
"robbiebarrat/rapping-neural-network" -> "johnwmillr/LyricsGenius" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "jsvine/markovify" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "saurabhmathur96/clickbait-detector"
"robbiebarrat/rapping-neural-network" -> "llSourcell/Rap_Lyric_Generator"
"robbiebarrat/rapping-neural-network" -> "samim23/NeuralTalkAnimator"
"robbiebarrat/rapping-neural-network" -> "robbiebarrat/Sculpture-GAN"
"robbiebarrat/rapping-neural-network" -> "megvii-research/neural-painter" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "jostmey/rwa" ["e"=1]
"robbiebarrat/rapping-neural-network" -> "jisungk/deepjazz" ["e"=1]
"JeremyCCHsu/tf-vaegan" -> "anitan0925/vaegan"
"JeremyCCHsu/tf-vaegan" -> "zhangqianhui/vae-gan-tensorflow"
"JeremyCCHsu/tf-vaegan" -> "crmaximo/VAEGAN"
"mpatacchiola/dissecting-reinforcement-learning" -> "awjuliani/oreilly-rl-tutorial" ["e"=1]
"zhangqianhui/Conditional-GAN" -> "znxlwm/tensorflow-MNIST-cGAN-cDCGAN"
"zhangqianhui/Conditional-GAN" -> "buriburisuri/supervised_infogan"
"zhangqianhui/Conditional-GAN" -> "andrewliao11/CoGAN-tensorflow"
"zhangqianhui/Conditional-GAN" -> "val-iisc/deligan"
"zhangqianhui/Conditional-GAN" -> "m516825/Conditional-GAN" ["e"=1]
"zck119/3dgan-release" -> "hanzhanggit/StackGAN" ["e"=1]
"reedscot/nips2016" -> "reedscot/icml2016"
"reedscot/nips2016" -> "reedscot/cvpr2016"
"reedscot/nips2016" -> "xiaolonw/ss-gan"
"reedscot/nips2016" -> "Evolving-AI-Lab/ppgn"
"reedscot/nips2016" -> "Guim3/IcGAN"
"reedscot/nips2016" -> "cvondrick/videogan"
"reedscot/nips2016" -> "iassael/torch-bnlstm" ["e"=1]
"reedscot/nips2016" -> "mansimov/text2image"
"reedscot/nips2016" -> "guojunq/lsgan"
"reedscot/nips2016" -> "y0ast/VAE-Torch" ["e"=1]
"reedscot/nips2016" -> "facebookarchive/eyescream"
"reedscot/nips2016" -> "skaae/torch-gan" ["e"=1]
"reedscot/nips2016" -> "jnhwkim/cbp" ["e"=1]
"reedscot/nips2016" -> "SKTBrain/DiscoGAN"
"reedscot/nips2016" -> "ludc/rltorch" ["e"=1]
"yeyun111/dlcv_for_beginners" -> "vanhuyz/CycleGAN-TensorFlow" ["e"=1]
"yeyun111/dlcv_for_beginners" -> "devnag/pytorch-generative-adversarial-networks" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "kundan2510/pixelCNN"
"anantzoid/Conditional-PixelCNN-decoder" -> "carpedm20/pixel-rnn-tensorflow"
"anantzoid/Conditional-PixelCNN-decoder" -> "openai/pixel-cnn"
"anantzoid/Conditional-PixelCNN-decoder" -> "PrajitR/fast-pixel-cnn"
"anantzoid/Conditional-PixelCNN-decoder" -> "jakebelew/gated-pixel-cnn"
"anantzoid/Conditional-PixelCNN-decoder" -> "Mostafa-Samir/DNC-tensorflow" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "jzbontar/pixelcnn-pytorch" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "jxwufan/AssociativeRetrieval" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"anantzoid/Conditional-PixelCNN-decoder" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"anantzoid/Conditional-PixelCNN-decoder" -> "marcofraccaro/srnn" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "hiwonjoon/tf-vqvae" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "igul222/PixelVAE" ["e"=1]
"anantzoid/Conditional-PixelCNN-decoder" -> "hi-abhi/tensorflow-value-iteration-networks" ["e"=1]
"bstriner/keras-adversarial" -> "jacobgil/keras-dcgan"
"bstriner/keras-adversarial" -> "osh/KerasGAN"
"bstriner/keras-adversarial" -> "tdeboissiere/DeepLearningImplementations"
"bstriner/keras-adversarial" -> "basveeling/wavenet" ["e"=1]
"bstriner/keras-adversarial" -> "farizrahman4u/recurrentshop" ["e"=1]
"bstriner/keras-adversarial" -> "keras-team/keras-contrib" ["e"=1]
"bstriner/keras-adversarial" -> "lukedeo/keras-acgan"
"bstriner/keras-adversarial" -> "maxpumperla/hyperas" ["e"=1]
"bstriner/keras-adversarial" -> "jocicmarko/ultrasound-nerve-segmentation" ["e"=1]
"bstriner/keras-adversarial" -> "bioinf-jku/SNNs"
"bstriner/keras-adversarial" -> "fchollet/keras-resources" ["e"=1]
"bstriner/keras-adversarial" -> "keplr-io/quiver" ["e"=1]
"bstriner/keras-adversarial" -> "yhenon/keras-frcnn" ["e"=1]
"bstriner/keras-adversarial" -> "shekkizh/WassersteinGAN.tensorflow"
"bstriner/keras-adversarial" -> "PacktPublishing/Deep-Learning-with-Keras" ["e"=1]
"Zackory/Keras-MNIST-GAN" -> "osh/KerasGAN"
"lukedeo/keras-acgan" -> "buriburisuri/ac-gan"
"lukedeo/keras-acgan" -> "King-Of-Knights/Keras-ACGAN-CIFAR10" ["e"=1]
"lukedeo/keras-acgan" -> "erilyth/DCGANs"
"lukedeo/keras-acgan" -> "bobchennan/Wasserstein-GAN-Keras"
"xunhuang1995/SGAN" -> "Evolving-AI-Lab/ppgn"
"xunhuang1995/SGAN" -> "jiwoongim/GRAN"
"RuiShu/vae-clustering" -> "RuiShu/cvae" ["e"=1]
"zalandoresearch/spatial_gan" -> "zalandoresearch/psgan"
"carpedm20/simulated-unsupervised-tensorflow" -> "mjdietzx/SimGAN"
"carpedm20/simulated-unsupervised-tensorflow" -> "carpedm20/DiscoGAN-pytorch"
"carpedm20/simulated-unsupervised-tensorflow" -> "carpedm20/BEGAN-tensorflow"
"carpedm20/simulated-unsupervised-tensorflow" -> "AlexHex7/SimGAN_pytorch"
"carpedm20/simulated-unsupervised-tensorflow" -> "shinseung428/simGAN_NYU_Hand"
"carpedm20/simulated-unsupervised-tensorflow" -> "buriburisuri/ac-gan"
"carpedm20/simulated-unsupervised-tensorflow" -> "yunjey/domain-transfer-network"
"carpedm20/simulated-unsupervised-tensorflow" -> "carpedm20/pixel-rnn-tensorflow"
"carpedm20/simulated-unsupervised-tensorflow" -> "wookayin/tensorflow-talk-debugging" ["e"=1]
"carpedm20/simulated-unsupervised-tensorflow" -> "mingyuliutw/CoGAN"
"carpedm20/simulated-unsupervised-tensorflow" -> "cvondrick/videogan"
"carpedm20/simulated-unsupervised-tensorflow" -> "fxia22/PixelDTGAN"
"carpedm20/simulated-unsupervised-tensorflow" -> "Zardinality/WGAN-tensorflow"
"carpedm20/simulated-unsupervised-tensorflow" -> "openai/improved-gan"
"carpedm20/simulated-unsupervised-tensorflow" -> "khanrc/tf.gans-comparison"
"buriburisuri/SRGAN" -> "buriburisuri/sugartensor" ["e"=1]
"buriburisuri/SRGAN" -> "buriburisuri/ebgan" ["e"=1]
"buriburisuri/SRGAN" -> "buriburisuri/supervised_infogan" ["e"=1]
"ramarlina/DenoisingAutoEncoder" -> "rajarsheem/libsdae-autoencoder-tensorflow"
"ramarlina/DenoisingAutoEncoder" -> "MadhumitaSushil/SDAE"
"ramarlina/DenoisingAutoEncoder" -> "wblgers/tensorflow_stacked_denoising_autoencoder"
"junrushao/fast-neural-style.tf" -> "OlavHN/fast-neural-style"
"junrushao/fast-neural-style.tf" -> "junrushao/Final-Fanatic-Facility"
"junrushao/fast-neural-style.tf" -> "junrushao1994/ACM-ICPC-Standard-Code-Library"
"chenhsuanlin/inverse-compositional-STN" -> "chenhsuanlin/spatial-transformer-GAN" ["e"=1]
"poolio/unrolled_gan" -> "andrewliao11/unrolled-gans"
"poolio/unrolled_gan" -> "tonywu95/eval_gen"
"Nat-D/GMVAE" -> "RuiShu/cvae" ["e"=1]
"yhenon/keras-spp" -> "osh/KerasGAN" ["e"=1]
"r0nn13/conditional-dcgan-keras" -> "erilyth/DCGANs"
"erilyth/DCGANs" -> "r0nn13/conditional-dcgan-keras"
"tobran/ONE-PIC" -> "tobran/StoryImager"
"tobran/ONE-PIC" -> "MightXiong/FedMIT"
"OsciiArt/DeepAA" -> "chuanli11/CNNMRF" ["e"=1]
"OsciiArt/DeepAA" -> "awentzonline/image-analogies" ["e"=1]
"luanfujun/deep-photo-styletransfer" -> "lengstrom/fast-style-transfer"
"luanfujun/deep-photo-styletransfer" -> "jcjohnson/neural-style"
"luanfujun/deep-photo-styletransfer" -> "junyanz/CycleGAN"
"luanfujun/deep-photo-styletransfer" -> "NVIDIA/FastPhotoStyle"
"luanfujun/deep-photo-styletransfer" -> "magenta/magenta"
"luanfujun/deep-photo-styletransfer" -> "luanfujun/deep-painterly-harmonization"
"luanfujun/deep-photo-styletransfer" -> "alexjc/neural-doodle"
"luanfujun/deep-photo-styletransfer" -> "jcjohnson/fast-neural-style"
"luanfujun/deep-photo-styletransfer" -> "google-deepmind/sonnet" ["e"=1]
"luanfujun/deep-photo-styletransfer" -> "lllyasviel/style2paints"
"luanfujun/deep-photo-styletransfer" -> "junyanz/iGAN"
"luanfujun/deep-photo-styletransfer" -> "facebookresearch/fastText" ["e"=1]
"luanfujun/deep-photo-styletransfer" -> "DmitryUlyanov/deep-image-prior"
"luanfujun/deep-photo-styletransfer" -> "alexjc/neural-enhance"
"luanfujun/deep-photo-styletransfer" -> "yunjey/stargan"
"jindongwang/transferlearning" -> "eriklindernoren/PyTorch-GAN" ["e"=1]
"jindongwang/transferlearning" -> "hindupuravinash/the-gan-zoo" ["e"=1]
"jindongwang/transferlearning" -> "junyanz/pytorch-CycleGAN-and-pix2pix" ["e"=1]
"junyanz/CycleGAN" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"junyanz/CycleGAN" -> "phillipi/pix2pix"
"junyanz/CycleGAN" -> "soumith/ganhacks"
"junyanz/CycleGAN" -> "hindupuravinash/the-gan-zoo"
"junyanz/CycleGAN" -> "carpedm20/DCGAN-tensorflow"
"junyanz/CycleGAN" -> "luanfujun/deep-photo-styletransfer"
"junyanz/CycleGAN" -> "NVIDIA/pix2pixHD"
"junyanz/CycleGAN" -> "yunjey/stargan"
"junyanz/CycleGAN" -> "tkarras/progressive_growing_of_gans"
"junyanz/CycleGAN" -> "lengstrom/fast-style-transfer"
"junyanz/CycleGAN" -> "wiseodd/generative-models"
"junyanz/CycleGAN" -> "junyanz/iGAN"
"junyanz/CycleGAN" -> "zhangqianhui/AdversarialNetsPapers"
"junyanz/CycleGAN" -> "affinelayer/pix2pix-tensorflow"
"junyanz/CycleGAN" -> "jcjohnson/fast-neural-style"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "junyanz/CycleGAN"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "phillipi/pix2pix"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "eriklindernoren/PyTorch-GAN"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "NVIDIA/pix2pixHD"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "hindupuravinash/the-gan-zoo"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "soumith/ganhacks"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "pytorch/examples" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "open-mmlab/mmdetection" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "huggingface/pytorch-image-models" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "yunjey/stargan"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "facebookresearch/detectron2" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "NVlabs/stylegan"
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "pytorch/vision" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "lucidrains/vit-pytorch" ["e"=1]
"junyanz/pytorch-CycleGAN-and-pix2pix" -> "facebookresearch/Detectron" ["e"=1]
"google-deepmind/dnc" -> "bioinf-jku/SNNs" ["e"=1]
"oarriaga/face_classification" -> "yunjey/stargan" ["e"=1]
"oarriaga/face_classification" -> "junyanz/iGAN" ["e"=1]
"oarriaga/face_classification" -> "MrNothing/AI-Blocks" ["e"=1]
"oarriaga/face_classification" -> "lengstrom/fast-style-transfer" ["e"=1]
"oarriaga/face_classification" -> "DmitryUlyanov/deep-image-prior" ["e"=1]
"ritchieng/the-incredible-pytorch" -> "soumith/ganhacks" ["e"=1]
"google-deepmind/sonnet" -> "magenta/magenta" ["e"=1]
"hindupuravinash/the-gan-zoo" -> "soumith/ganhacks"
"hindupuravinash/the-gan-zoo" -> "eriklindernoren/PyTorch-GAN"
"hindupuravinash/the-gan-zoo" -> "zhangqianhui/AdversarialNetsPapers"
"hindupuravinash/the-gan-zoo" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"hindupuravinash/the-gan-zoo" -> "wiseodd/generative-models"
"hindupuravinash/the-gan-zoo" -> "eriklindernoren/Keras-GAN"
"hindupuravinash/the-gan-zoo" -> "carpedm20/DCGAN-tensorflow"
"hindupuravinash/the-gan-zoo" -> "yfeng95/GAN"
"hindupuravinash/the-gan-zoo" -> "junyanz/CycleGAN"
"hindupuravinash/the-gan-zoo" -> "pytorch/examples" ["e"=1]
"hindupuravinash/the-gan-zoo" -> "nightrome/really-awesome-gan"
"hindupuravinash/the-gan-zoo" -> "nashory/gans-awesome-applications"
"hindupuravinash/the-gan-zoo" -> "extreme-assistant/CVPR2024-Paper-Code-Interpretation" ["e"=1]
"hindupuravinash/the-gan-zoo" -> "phillipi/pix2pix"
"hindupuravinash/the-gan-zoo" -> "tkarras/progressive_growing_of_gans"
"SKTBrain/DiscoGAN" -> "carpedm20/DiscoGAN-pytorch"
"SKTBrain/DiscoGAN" -> "reedscot/nips2016"
"SKTBrain/DiscoGAN" -> "carpedm20/BEGAN-tensorflow"
"SKTBrain/DiscoGAN" -> "yunjey/domain-transfer-network"
"SKTBrain/DiscoGAN" -> "fxia22/PixelDTGAN"
"SKTBrain/DiscoGAN" -> "Guim3/IcGAN"
"SKTBrain/DiscoGAN" -> "Evolving-AI-Lab/ppgn"
"SKTBrain/DiscoGAN" -> "openai/improved-gan"
"SKTBrain/DiscoGAN" -> "duxingren14/DualGAN"
"SKTBrain/DiscoGAN" -> "SKTBrain/awesome-starcraftAI" ["e"=1]
"SKTBrain/DiscoGAN" -> "hanzhanggit/StackGAN"
"SKTBrain/DiscoGAN" -> "mingyuliutw/UNIT"
"SKTBrain/DiscoGAN" -> "torrvision/crayon" ["e"=1]
"SKTBrain/DiscoGAN" -> "martinarjovsky/WassersteinGAN"
"SKTBrain/DiscoGAN" -> "guojunq/lsgan"
"nightrome/really-awesome-gan" -> "zhangqianhui/AdversarialNetsPapers"
"nightrome/really-awesome-gan" -> "wiseodd/generative-models"
"nightrome/really-awesome-gan" -> "soumith/ganhacks"
"nightrome/really-awesome-gan" -> "nashory/gans-awesome-applications"
"nightrome/really-awesome-gan" -> "hindupuravinash/the-gan-zoo"
"nightrome/really-awesome-gan" -> "xinario/awesome-gan-for-medical-imaging" ["e"=1]
"nightrome/really-awesome-gan" -> "openai/improved-gan"
"nightrome/really-awesome-gan" -> "kjw0612/awesome-deep-vision" ["e"=1]
"nightrome/really-awesome-gan" -> "tkarras/progressive_growing_of_gans"
"nightrome/really-awesome-gan" -> "GKalliatakis/Delving-deep-into-GANs"
"nightrome/really-awesome-gan" -> "martinarjovsky/WassersteinGAN"
"nightrome/really-awesome-gan" -> "carpedm20/DCGAN-tensorflow"
"nightrome/really-awesome-gan" -> "znxlwm/pytorch-generative-model-collections"
"nightrome/really-awesome-gan" -> "aikorea/awesome-rl" ["e"=1]
"nightrome/really-awesome-gan" -> "yunjey/stargan"
"xiaowei-hu/CycleGAN-tensorflow" -> "vanhuyz/CycleGAN-TensorFlow"
"xiaowei-hu/CycleGAN-tensorflow" -> "hardikbansal/CycleGAN"
"xiaowei-hu/CycleGAN-tensorflow" -> "yenchenlin/pix2pix-tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "LynnHo/CycleGAN-Tensorflow-2"
"xiaowei-hu/CycleGAN-tensorflow" -> "architrathore/CycleGAN"
"xiaowei-hu/CycleGAN-tensorflow" -> "leehomyc/cyclegan-1"
"xiaowei-hu/CycleGAN-tensorflow" -> "JoinWei-PKU/PTGAN" ["e"=1]
"xiaowei-hu/CycleGAN-tensorflow" -> "carpedm20/BEGAN-tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "affinelayer/pix2pix-tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "yunjey/domain-transfer-network"
"xiaowei-hu/CycleGAN-tensorflow" -> "taki0112/Self-Attention-GAN-Tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "taki0112/MUNIT-Tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "tensorlayer/DCGAN"
"xiaowei-hu/CycleGAN-tensorflow" -> "carpedm20/DCGAN-tensorflow"
"xiaowei-hu/CycleGAN-tensorflow" -> "igul222/improved_wgan_training"
"kaonashi-tyc/zi2zi" -> "kaonashi-tyc/Rewrite" ["e"=1]
"kaonashi-tyc/zi2zi" -> "EuphoriaYan/zi2zi-pytorch" ["e"=1]
"kaonashi-tyc/zi2zi" -> "azadis/MC-GAN" ["e"=1]
"kaonashi-tyc/zi2zi" -> "changebo/HCCG-CycleGAN" ["e"=1]
"kaonashi-tyc/zi2zi" -> "phillipi/pix2pix"
"kaonashi-tyc/zi2zi" -> "clovaai/fewshot-font-generation" ["e"=1]
"kaonashi-tyc/zi2zi" -> "yunjey/domain-transfer-network"
"kaonashi-tyc/zi2zi" -> "yenchenlin/pix2pix-tensorflow"
"kaonashi-tyc/zi2zi" -> "martinarjovsky/WassersteinGAN"
"kaonashi-tyc/zi2zi" -> "carpedm20/DCGAN-tensorflow"
"kaonashi-tyc/zi2zi" -> "affinelayer/pix2pix-tensorflow"
"kaonashi-tyc/zi2zi" -> "ecnuycxie/DG-Font" ["e"=1]
"kaonashi-tyc/zi2zi" -> "ankush-me/SynthText" ["e"=1]
"kaonashi-tyc/zi2zi" -> "pcgreat/zi2zi" ["e"=1]
"kaonashi-tyc/zi2zi" -> "igul222/improved_wgan_training"
"pfnet/PaintsChainer" -> "lllyasviel/style2paints" ["e"=1]
"pfnet/PaintsChainer" -> "phillipi/pix2pix" ["e"=1]
"pfnet/PaintsChainer" -> "affinelayer/pix2pix-tensorflow" ["e"=1]
"devnag/pytorch-generative-adversarial-networks" -> "martinarjovsky/WassersteinGAN"
"devnag/pytorch-generative-adversarial-networks" -> "carpedm20/DiscoGAN-pytorch"
"devnag/pytorch-generative-adversarial-networks" -> "caogang/wgan-gp"
"devnag/pytorch-generative-adversarial-networks" -> "znxlwm/pytorch-generative-model-collections"
"devnag/pytorch-generative-adversarial-networks" -> "wiseodd/generative-models"
"devnag/pytorch-generative-adversarial-networks" -> "goodfeli/adversarial"
"devnag/pytorch-generative-adversarial-networks" -> "openai/improved-gan"
"devnag/pytorch-generative-adversarial-networks" -> "spro/practical-pytorch" ["e"=1]
"devnag/pytorch-generative-adversarial-networks" -> "AYLIEN/gan-intro"
"devnag/pytorch-generative-adversarial-networks" -> "soumith/dcgan.torch"
"devnag/pytorch-generative-adversarial-networks" -> "nightrome/really-awesome-gan"
"devnag/pytorch-generative-adversarial-networks" -> "igul222/improved_wgan_training"
"devnag/pytorch-generative-adversarial-networks" -> "Newmu/dcgan_code"
"devnag/pytorch-generative-adversarial-networks" -> "carpedm20/DCGAN-tensorflow"
"devnag/pytorch-generative-adversarial-networks" -> "jcjohnson/pytorch-examples" ["e"=1]
"carpedm20/DiscoGAN-pytorch" -> "SKTBrain/DiscoGAN"
"carpedm20/DiscoGAN-pytorch" -> "carpedm20/BEGAN-tensorflow"
"carpedm20/DiscoGAN-pytorch" -> "carpedm20/simulated-unsupervised-tensorflow"
"carpedm20/DiscoGAN-pytorch" -> "carpedm20/BEGAN-pytorch"
"carpedm20/DiscoGAN-pytorch" -> "martinarjovsky/WassersteinGAN"
"carpedm20/DiscoGAN-pytorch" -> "sunshineatnoon/Paper-Implementations"
"carpedm20/DiscoGAN-pytorch" -> "openai/improved-gan"
"carpedm20/DiscoGAN-pytorch" -> "Evolving-AI-Lab/ppgn"
"carpedm20/DiscoGAN-pytorch" -> "reedscot/nips2016"
"carpedm20/DiscoGAN-pytorch" -> "yunjey/domain-transfer-network"
"carpedm20/DiscoGAN-pytorch" -> "soumith/dcgan.torch"
"carpedm20/DiscoGAN-pytorch" -> "mingyuliutw/UNIT"
"carpedm20/DiscoGAN-pytorch" -> "fxia22/PixelDTGAN"
"carpedm20/DiscoGAN-pytorch" -> "Newmu/dcgan_code"
"carpedm20/DiscoGAN-pytorch" -> "devnag/pytorch-generative-adversarial-networks"
"fducau/AAE_pytorch" -> "bfarzin/pytorch_aae"
"fducau/AAE_pytorch" -> "musyoku/adversarial-autoencoder"
"fducau/AAE_pytorch" -> "maitek/waae-pytorch"
"fducau/AAE_pytorch" -> "neale/Adversarial-Autoencoder"
"fducau/AAE_pytorch" -> "yoonsanghyu/AAE-PyTorch"
"yfeng95/GAN" -> "hindupuravinash/the-gan-zoo"
"yfeng95/GAN" -> "wiseodd/generative-models"
"yfeng95/GAN" -> "carpedm20/DCGAN-tensorflow"
"yfeng95/GAN" -> "soumith/ganhacks"
"yfeng95/GAN" -> "zhangqianhui/AdversarialNetsPapers"
"yfeng95/GAN" -> "igul222/improved_wgan_training"
"yfeng95/GAN" -> "eriklindernoren/PyTorch-GAN"
"yfeng95/GAN" -> "martinarjovsky/WassersteinGAN"
"yfeng95/GAN" -> "eriklindernoren/Keras-GAN"
"yfeng95/GAN" -> "yfeng95/GAN_Theories"
"yfeng95/GAN" -> "goodfeli/adversarial"
"yfeng95/GAN" -> "openai/improved-gan"
"yfeng95/GAN" -> "heykeetae/Self-Attention-GAN"
"yfeng95/GAN" -> "google/compare_gan"
"yfeng95/GAN" -> "junyanz/CycleGAN"
"martinarjovsky/WassersteinGAN" -> "igul222/improved_wgan_training"
"martinarjovsky/WassersteinGAN" -> "caogang/wgan-gp"
"martinarjovsky/WassersteinGAN" -> "openai/improved-gan"
"martinarjovsky/WassersteinGAN" -> "wiseodd/generative-models"
"martinarjovsky/WassersteinGAN" -> "zhangqianhui/AdversarialNetsPapers"
"martinarjovsky/WassersteinGAN" -> "soumith/ganhacks"
"martinarjovsky/WassersteinGAN" -> "Zardinality/WGAN-tensorflow"
"martinarjovsky/WassersteinGAN" -> "carpedm20/DCGAN-tensorflow"
"martinarjovsky/WassersteinGAN" -> "Newmu/dcgan_code"
"martinarjovsky/WassersteinGAN" -> "goodfeli/adversarial"
"martinarjovsky/WassersteinGAN" -> "LantaoYu/SeqGAN" ["e"=1]
"martinarjovsky/WassersteinGAN" -> "tkarras/progressive_growing_of_gans"
"martinarjovsky/WassersteinGAN" -> "soumith/dcgan.torch"
"martinarjovsky/WassersteinGAN" -> "shekkizh/WassersteinGAN.tensorflow"
"martinarjovsky/WassersteinGAN" -> "pfnet-research/sngan_projection"
"igul222/improved_wgan_training" -> "martinarjovsky/WassersteinGAN"
"igul222/improved_wgan_training" -> "caogang/wgan-gp"
"igul222/improved_wgan_training" -> "openai/improved-gan"
"igul222/improved_wgan_training" -> "Zardinality/WGAN-tensorflow"
"igul222/improved_wgan_training" -> "carpedm20/DCGAN-tensorflow"
"igul222/improved_wgan_training" -> "pfnet-research/sngan_projection"
"igul222/improved_wgan_training" -> "LantaoYu/SeqGAN" ["e"=1]
"igul222/improved_wgan_training" -> "wiseodd/generative-models"
"igul222/improved_wgan_training" -> "tkarras/progressive_growing_of_gans"
"igul222/improved_wgan_training" -> "zhangqianhui/AdversarialNetsPapers"
"igul222/improved_wgan_training" -> "soumith/ganhacks"
"igul222/improved_wgan_training" -> "shekkizh/WassersteinGAN.tensorflow"
"igul222/improved_wgan_training" -> "google/compare_gan"
"igul222/improved_wgan_training" -> "heykeetae/Self-Attention-GAN"
"igul222/improved_wgan_training" -> "hanzhanggit/StackGAN"
"jayleicn/animeGAN" -> "sunshineatnoon/Paper-Implementations" ["e"=1]
"mil-tokyo/webdnn" -> "bioinf-jku/SNNs" ["e"=1]
"guojunq/glsgan" -> "guojunq/lsgan"
"joeddav/devol" -> "bstriner/keras-adversarial" ["e"=1]
"joeddav/devol" -> "bioinf-jku/SNNs" ["e"=1]
"jettan/tikz_cnn" -> "poolio/unrolled_gan" ["e"=1]
"kvfrans/deepcolor" -> "yenchenlin/pix2pix-tensorflow" ["e"=1]
"kvfrans/deepcolor" -> "carpedm20/BEGAN-tensorflow" ["e"=1]
"kvfrans/deepcolor" -> "kvfrans/generative-adversial" ["e"=1]
"wookayin/tensorflow-plot" -> "shaohua0116/Activation-Visualization-Histogram" ["e"=1]
"vanhuyz/CycleGAN-TensorFlow" -> "xiaowei-hu/CycleGAN-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "hardikbansal/CycleGAN"
"vanhuyz/CycleGAN-TensorFlow" -> "LynnHo/CycleGAN-Tensorflow-2"
"vanhuyz/CycleGAN-TensorFlow" -> "leehomyc/cyclegan-1"
"vanhuyz/CycleGAN-TensorFlow" -> "architrathore/CycleGAN"
"vanhuyz/CycleGAN-TensorFlow" -> "yenchenlin/pix2pix-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "affinelayer/pix2pix-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "junyanz/CycleGAN"
"vanhuyz/CycleGAN-TensorFlow" -> "carpedm20/DCGAN-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "carpedm20/BEGAN-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "tjwei/GANotebooks"
"vanhuyz/CycleGAN-TensorFlow" -> "igul222/improved_wgan_training"
"vanhuyz/CycleGAN-TensorFlow" -> "taki0112/StarGAN-Tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "Zardinality/WGAN-tensorflow"
"vanhuyz/CycleGAN-TensorFlow" -> "pfnet-research/sngan_projection"
"KupynOrest/DeblurGAN" -> "yunjey/stargan" ["e"=1]
"mingyuliutw/UNIT" -> "NVlabs/MUNIT"
"mingyuliutw/UNIT" -> "HsinYingLee/DRIT"
"mingyuliutw/UNIT" -> "junyanz/BicycleGAN"
"mingyuliutw/UNIT" -> "NVlabs/FUNIT"
"mingyuliutw/UNIT" -> "yunjey/stargan"
"mingyuliutw/UNIT" -> "NVIDIA/pix2pixHD"
"mingyuliutw/UNIT" -> "tkarras/progressive_growing_of_gans"
"mingyuliutw/UNIT" -> "mingyuliutw/CoGAN"
"mingyuliutw/UNIT" -> "NVlabs/imaginaire" ["e"=1]
"mingyuliutw/UNIT" -> "AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation"
"mingyuliutw/UNIT" -> "lzhbrian/image-to-image-papers"
"mingyuliutw/UNIT" -> "sangwoomo/instagan"
"mingyuliutw/UNIT" -> "carpedm20/DiscoGAN-pytorch"
"mingyuliutw/UNIT" -> "Ha0Tang/AttentionGAN" ["e"=1]
"mingyuliutw/UNIT" -> "znxlwm/UGATIT-pytorch" ["e"=1]
"carpedm20/BEGAN-tensorflow" -> "hmi88/BEGAN-tensorflow"
"carpedm20/BEGAN-tensorflow" -> "carpedm20/BEGAN-pytorch"
"carpedm20/BEGAN-tensorflow" -> "carpedm20/DiscoGAN-pytorch"
"carpedm20/BEGAN-tensorflow" -> "artcg/BEGAN"
"carpedm20/BEGAN-tensorflow" -> "carpedm20/DCGAN-tensorflow"
"carpedm20/BEGAN-tensorflow" -> "igul222/improved_wgan_training"
"carpedm20/BEGAN-tensorflow" -> "carpedm20/simulated-unsupervised-tensorflow"
"carpedm20/BEGAN-tensorflow" -> "Zardinality/WGAN-tensorflow"
"carpedm20/BEGAN-tensorflow" -> "openai/improved-gan"
"carpedm20/BEGAN-tensorflow" -> "khanrc/tf.gans-comparison"
"carpedm20/BEGAN-tensorflow" -> "SKTBrain/DiscoGAN"
"carpedm20/BEGAN-tensorflow" -> "yenchenlin/pix2pix-tensorflow"
"carpedm20/BEGAN-tensorflow" -> "bamos/dcgan-completion.tensorflow"
"carpedm20/BEGAN-tensorflow" -> "Evolving-AI-Lab/ppgn"
"carpedm20/BEGAN-tensorflow" -> "shekkizh/WassersteinGAN.tensorflow"
"leehomyc/Faster-High-Res-Neural-Inpainting" -> "bamos/dcgan-completion.tensorflow" ["e"=1]
"leehomyc/Faster-High-Res-Neural-Inpainting" -> "chuanli11/CNNMRF" ["e"=1]
"kootenpv/neural_complete" -> "bioinf-jku/SNNs" ["e"=1]
"xiaolonw/adversarial-frcnn" -> "guojunq/lsgan" ["e"=1]
"xiaolonw/adversarial-frcnn" -> "xiaolonw/ss-gan" ["e"=1]
"shekkizh/WassersteinGAN.tensorflow" -> "Zardinality/WGAN-tensorflow"
"shekkizh/WassersteinGAN.tensorflow" -> "martinarjovsky/WassersteinGAN"
"shekkizh/WassersteinGAN.tensorflow" -> "igul222/improved_wgan_training"
"shekkizh/WassersteinGAN.tensorflow" -> "jiamings/wgan"
"shekkizh/WassersteinGAN.tensorflow" -> "carpedm20/BEGAN-tensorflow"
"shekkizh/WassersteinGAN.tensorflow" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"shekkizh/WassersteinGAN.tensorflow" -> "guojunq/lsgan"
"shekkizh/WassersteinGAN.tensorflow" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"shekkizh/WassersteinGAN.tensorflow" -> "openai/improved-gan"
"shekkizh/WassersteinGAN.tensorflow" -> "andrewliao11/CoGAN-tensorflow"
"shekkizh/WassersteinGAN.tensorflow" -> "KnHuq/Dynamic-Tensorflow-Tutorial" ["e"=1]
"shekkizh/WassersteinGAN.tensorflow" -> "khanrc/tf.gans-comparison"
"shekkizh/WassersteinGAN.tensorflow" -> "awjuliani/TF-Tutorials"
"shekkizh/WassersteinGAN.tensorflow" -> "sugyan/tf-dcgan"
"shekkizh/WassersteinGAN.tensorflow" -> "buriburisuri/SRGAN" ["e"=1]
"adeshpande3/Generative-Adversarial-Networks" -> "adeshpande3/Tensorflow-Programs-and-Tutorials" ["e"=1]
"adeshpande3/Generative-Adversarial-Networks" -> "awjuliani/TF-Tutorials"
"adeshpande3/Generative-Adversarial-Networks" -> "uclaacmai/Generative-Adversarial-Network-Tutorial"
"adeshpande3/Generative-Adversarial-Networks" -> "jonbruner/generative-adversarial-networks"
"adeshpande3/Generative-Adversarial-Networks" -> "adeshpande3/MachineLearningReimplementations" ["e"=1]
"adeshpande3/Generative-Adversarial-Networks" -> "osh/KerasGAN"
"xunhuang1995/AdaIN-style" -> "DmitryUlyanov/texture_nets" ["e"=1]
"xunhuang1995/AdaIN-style" -> "NVlabs/MUNIT" ["e"=1]
"xunhuang1995/AdaIN-style" -> "jcjohnson/fast-neural-style" ["e"=1]
"xunhuang1995/AdaIN-style" -> "HsinYingLee/DRIT" ["e"=1]
"xunhuang1995/AdaIN-style" -> "msracver/Deep-Image-Analogy" ["e"=1]
"xunhuang1995/AdaIN-style" -> "NVlabs/FUNIT" ["e"=1]
"sunshineatnoon/Paper-Implementations" -> "carpedm20/DiscoGAN-pytorch"
"sunshineatnoon/Paper-Implementations" -> "caogang/wgan-gp"
"sunshineatnoon/Paper-Implementations" -> "taey16/pix2pixBEGAN.pytorch"
"sunshineatnoon/Paper-Implementations" -> "carpedm20/BEGAN-pytorch"
"sunshineatnoon/Paper-Implementations" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"sunshineatnoon/Paper-Implementations" -> "GKalliatakis/Delving-deep-into-GANs"
"sunshineatnoon/Paper-Implementations" -> "znxlwm/pytorch-generative-model-collections"
"sunshineatnoon/Paper-Implementations" -> "carpedm20/BEGAN-tensorflow"
"sunshineatnoon/Paper-Implementations" -> "yunjey/mnist-svhn-transfer"
"sunshineatnoon/Paper-Implementations" -> "felixgwu/mask_rcnn_pytorch" ["e"=1]
"sunshineatnoon/Paper-Implementations" -> "martinarjovsky/WassersteinGAN"
"sunshineatnoon/Paper-Implementations" -> "devnag/pytorch-generative-adversarial-networks"
"sunshineatnoon/Paper-Implementations" -> "switchablenorms/Switchable-Normalization" ["e"=1]
"sunshineatnoon/Paper-Implementations" -> "SKTBrain/DiscoGAN"
"sunshineatnoon/Paper-Implementations" -> "1zb/deformable-convolution-pytorch" ["e"=1]
"PacktPublishing/Deep-Learning-with-Keras" -> "bstriner/keras-adversarial" ["e"=1]
"pathak22/unsupervised-video" -> "xiaolonw/ss-gan" ["e"=1]
"wagamamaz/tensorlayer-tricks" -> "tensorlayer/DCGAN" ["e"=1]
"manumathewthomas/ImageDenoisingGAN" -> "MingtaoGuo/Calligraphic-Images-Denoising-by-GAN" ["e"=1]
"PrajitR/fast-pixel-cnn" -> "anantzoid/Conditional-PixelCNN-decoder"
"PrajitR/fast-pixel-cnn" -> "openai/pixel-cnn"
"PrajitR/fast-pixel-cnn" -> "kundan2510/pixelCNN"
"PrajitR/fast-pixel-cnn" -> "tomlepaine/fast-wavenet" ["e"=1]
"PrajitR/fast-pixel-cnn" -> "pclucas14/pixel-cnn-pp" ["e"=1]
"PrajitR/fast-pixel-cnn" -> "kkleidal/GatedPixelCNNPyTorch" ["e"=1]
"PrajitR/fast-pixel-cnn" -> "carpedm20/pixel-rnn-tensorflow"
"PrajitR/fast-pixel-cnn" -> "tonywu95/eval_gen"
"PrajitR/fast-pixel-cnn" -> "nilboy/pixel-recursive-super-resolution" ["e"=1]
"jiamings/wgan" -> "Zardinality/WGAN-tensorflow"
"jiamings/wgan" -> "shekkizh/WassersteinGAN.tensorflow"
"jiamings/wgan" -> "kuleshov/tf-wgan"
"jiamings/wgan" -> "igul222/improved_wgan_training"
"jiamings/wgan" -> "cameronfabbri/Improved-Wasserstein-GAN"
"jiamings/wgan" -> "ermongroup/markov-chain-gan" ["e"=1]
"jiamings/wgan" -> "jakezhaojb/ARAE" ["e"=1]
"GKalliatakis/Delving-deep-into-GANs" -> "khanrc/tf.gans-comparison"
"GKalliatakis/Delving-deep-into-GANs" -> "nightrome/really-awesome-gan"
"GKalliatakis/Delving-deep-into-GANs" -> "openai/improved-gan"
"GKalliatakis/Delving-deep-into-GANs" -> "carpedm20/BEGAN-tensorflow"
"GKalliatakis/Delving-deep-into-GANs" -> "hollobit/All-About-the-GAN"
"GKalliatakis/Delving-deep-into-GANs" -> "wiseodd/generative-models"
"GKalliatakis/Delving-deep-into-GANs" -> "dongb5/GAN-Timeline"
"GKalliatakis/Delving-deep-into-GANs" -> "buriburisuri/ac-gan"
"GKalliatakis/Delving-deep-into-GANs" -> "tdeboissiere/DeepLearningImplementations"
"GKalliatakis/Delving-deep-into-GANs" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"GKalliatakis/Delving-deep-into-GANs" -> "sunshineatnoon/Paper-Implementations"
"GKalliatakis/Delving-deep-into-GANs" -> "zhangqianhui/AdversarialNetsPapers"
"GKalliatakis/Delving-deep-into-GANs" -> "poolio/unrolled_gan"
"GKalliatakis/Delving-deep-into-GANs" -> "carpedm20/simulated-unsupervised-tensorflow"
"GKalliatakis/Delving-deep-into-GANs" -> "Newmu/dcgan_code"
"adventuresinML/adventures-in-ml-code" -> "roatienza/Deep-Learning-Experiments" ["e"=1]
"abhiskk/fast-neural-style" -> "DmitryUlyanov/texture_nets" ["e"=1]
"abhiskk/fast-neural-style" -> "yusuketomoto/chainer-fast-neuralstyle" ["e"=1]
"abhiskk/fast-neural-style" -> "hzy46/fast-neural-style-tensorflow" ["e"=1]
"despoisj/LatentSpaceVisualization" -> "despoisj/ConvolutionalAutoencoder"
"taey16/DomainTransferNetwork.pytorch" -> "davrempe/domain-transfer-net"
"Zardinality/WGAN-tensorflow" -> "jiamings/wgan"
"Zardinality/WGAN-tensorflow" -> "igul222/improved_wgan_training"
"Zardinality/WGAN-tensorflow" -> "martinarjovsky/WassersteinGAN"
"Zardinality/WGAN-tensorflow" -> "shekkizh/WassersteinGAN.tensorflow"
"Zardinality/WGAN-tensorflow" -> "carpedm20/BEGAN-tensorflow"
"Zardinality/WGAN-tensorflow" -> "buriburisuri/ac-gan"
"Zardinality/WGAN-tensorflow" -> "yenchenlin/pix2pix-tensorflow"
"Zardinality/WGAN-tensorflow" -> "guojunq/lsgan"
"Zardinality/WGAN-tensorflow" -> "openai/improved-gan"
"Zardinality/WGAN-tensorflow" -> "ericjang/genadv_tutorial"
"Zardinality/WGAN-tensorflow" -> "caogang/wgan-gp"
"Zardinality/WGAN-tensorflow" -> "hmi88/BEGAN-tensorflow"
"Zardinality/WGAN-tensorflow" -> "awjuliani/TF-Tutorials"
"Zardinality/WGAN-tensorflow" -> "carpedm20/DCGAN-tensorflow"
"Zardinality/WGAN-tensorflow" -> "LantaoYu/SeqGAN" ["e"=1]
"tatsy/keras-generative" -> "tkazusa/CVAE-GAN"
"tatsy/keras-generative" -> "takat0m0/CVAE_GAN"
"mrzhu-cool/pix2pix-pytorch" -> "znxlwm/pytorch-pix2pix"
"mrzhu-cool/pix2pix-pytorch" -> "taey16/pix2pix.pytorch"
"mrzhu-cool/pix2pix-pytorch" -> "togheppi/pix2pix"
"mrzhu-cool/pix2pix-pytorch" -> "taey16/pix2pixBEGAN.pytorch"
"mrzhu-cool/pix2pix-pytorch" -> "aitorzip/PyTorch-CycleGAN"
"mrzhu-cool/pix2pix-pytorch" -> "yunjey/mnist-svhn-transfer"
"mrzhu-cool/pix2pix-pytorch" -> "sunshineatnoon/Paper-Implementations"
"mrzhu-cool/pix2pix-pytorch" -> "TeeyoHuang/pix2pix-pytorch"
"zhangqianhui/vae-gan-tensorflow" -> "JeremyCCHsu/tf-vaegan"
"zhangqianhui/vae-gan-tensorflow" -> "baudm/vaegan-celebs-keras"
"zhangqianhui/vae-gan-tensorflow" -> "anitan0925/vaegan"
"zhangqianhui/vae-gan-tensorflow" -> "lucabergamini/VAEGAN-PYTORCH"
"zhangqianhui/vae-gan-tensorflow" -> "andersbll/autoencoding_beyond_pixels"
"zhangqianhui/vae-gan-tensorflow" -> "timsainb/Tensorflow-MultiGPU-VAE-GAN"
"zhangqianhui/vae-gan-tensorflow" -> "crmaximo/VAEGAN"
"hardikbansal/CycleGAN" -> "vanhuyz/CycleGAN-TensorFlow"
"hardikbansal/CycleGAN" -> "xiaowei-hu/CycleGAN-tensorflow"
"hardikbansal/CycleGAN" -> "LynnHo/CycleGAN-Tensorflow-2"
"hardikbansal/CycleGAN" -> "architrathore/CycleGAN"
"hardikbansal/CycleGAN" -> "leehomyc/cyclegan-1"
"hardikbansal/CycleGAN" -> "taki0112/MUNIT-Tensorflow"
"hardikbansal/CycleGAN" -> "Zardinality/WGAN-tensorflow"
"hardikbansal/CycleGAN" -> "yenchenlin/pix2pix-tensorflow"
"hardikbansal/CycleGAN" -> "hiwonjoon/cycle-gan-tf"
"artcg/BEGAN" -> "hmi88/BEGAN-tensorflow"
"artcg/BEGAN" -> "carpedm20/BEGAN-tensorflow"
"artcg/BEGAN" -> "carpedm20/BEGAN-pytorch"
"uclaacmai/Generative-Adversarial-Network-Tutorial" -> "jonbruner/generative-adversarial-networks"
"uclaacmai/Generative-Adversarial-Network-Tutorial" -> "adeshpande3/Generative-Adversarial-Networks"
"uclaacmai/Generative-Adversarial-Network-Tutorial" -> "awjuliani/TF-Tutorials"
"ycjing/Neural-Style-Transfer-Papers" -> "jcjohnson/fast-neural-style" ["e"=1]
"ycjing/Neural-Style-Transfer-Papers" -> "titu1994/Neural-Style-Transfer" ["e"=1]
"ycjing/Neural-Style-Transfer-Papers" -> "DmitryUlyanov/texture_nets" ["e"=1]
"ycjing/Neural-Style-Transfer-Papers" -> "msracver/Deep-Image-Analogy" ["e"=1]
"ycjing/Neural-Style-Transfer-Papers" -> "cysmith/neural-style-tf" ["e"=1]
"zhanghang1989/PyTorch-Multi-Style-Transfer" -> "DmitryUlyanov/texture_nets" ["e"=1]
"ZZUTK/Face-Aging-CAAE" -> "Prinsphield/ELEGANT" ["e"=1]
"hmi88/Fast_Multi_Style_Transfer-tensorflow" -> "joelmoniz/gogh-figure"
"hmi88/Fast_Multi_Style_Transfer-tensorflow" -> "Kyubyong/quasi-rnn"
"dongb5/GAN-Timeline" -> "shawnyuen/gans_paper_collection"
"dongb5/GAN-Timeline" -> "layumi/Person-reID_GAN" ["e"=1]
"dongb5/GAN-Timeline" -> "hollobit/All-About-the-GAN"
"dongb5/GAN-Timeline" -> "LMescheder/GAN_stability"
"dongb5/GAN-Timeline" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"dongb5/GAN-Timeline" -> "xuqiantong/GAN-Metrics"
"dongb5/GAN-Timeline" -> "GKalliatakis/Delving-deep-into-GANs"
"cycleuser/Duke-STA-663-CN" -> "adeshpande3/Generative-Adversarial-Networks" ["e"=1]
"nightrome/really-awesome-semantic-segmentation" -> "nightrome/really-awesome-gan" ["e"=1]
"hwalsuklee/tensorflow-mnist-VAE" -> "hwalsuklee/tensorflow-mnist-CVAE"
"hwalsuklee/tensorflow-mnist-VAE" -> "y0ast/VAE-TensorFlow"
"hwalsuklee/tensorflow-mnist-VAE" -> "hwalsuklee/tensorflow-mnist-AAE"
"hwalsuklee/tensorflow-mnist-VAE" -> "shaohua0116/VAE-Tensorflow"
"hwalsuklee/tensorflow-mnist-VAE" -> "kvfrans/variational-autoencoder"
"hwalsuklee/tensorflow-mnist-VAE" -> "Chung-I/Variational-Recurrent-Autoencoder-Tensorflow" ["e"=1]
"hwalsuklee/tensorflow-mnist-VAE" -> "jaanli/variational-autoencoder"
"hwalsuklee/tensorflow-mnist-VAE" -> "ikostrikov/TensorFlow-VAE-GAN-DRAW"
"hwalsuklee/tensorflow-mnist-VAE" -> "oduerr/dl_tutorial"
"hwalsuklee/tensorflow-mnist-VAE" -> "minhnhat93/tf-SNDCGAN"
"hwalsuklee/tensorflow-mnist-VAE" -> "chaitanya100100/VAE-for-Image-Generation"
"hwalsuklee/tensorflow-mnist-VAE" -> "saemundsson/semisupervised_vae" ["e"=1]
"hwalsuklee/tensorflow-mnist-VAE" -> "Nat-D/GMVAE" ["e"=1]
"hwalsuklee/tensorflow-mnist-VAE" -> "cdoersch/vae_tutorial"
"hwalsuklee/tensorflow-mnist-VAE" -> "y0ast/Variational-Autoencoder"
"seangal/dcgan_vae_pytorch" -> "rohithreddy024/VAE-GAN-Pytorch"
"seangal/dcgan_vae_pytorch" -> "escuccim/vaegan-pytorch"
"seangal/dcgan_vae_pytorch" -> "a514514772/Pytorch-VAE-GAN"
"infocusp/tf_cnnvis" -> "yunjey/domain-transfer-network" ["e"=1]
"Yijunmaverick/GenerativeFaceCompletion" -> "Zhongdao/FaceAttributeManipulation" ["e"=1]
"Yijunmaverick/GenerativeFaceCompletion" -> "Guim3/IcGAN" ["e"=1]
"hmi88/BEGAN-tensorflow" -> "carpedm20/BEGAN-tensorflow"
"hmi88/BEGAN-tensorflow" -> "artcg/BEGAN"
"hmi88/BEGAN-tensorflow" -> "carpedm20/BEGAN-pytorch"
"hmi88/BEGAN-tensorflow" -> "khanrc/tf.gans-comparison"
"hmi88/BEGAN-tensorflow" -> "guojunq/lsgan"
"hmi88/BEGAN-tensorflow" -> "DmitryUlyanov/AGE"
"mjdietzx/SimGAN" -> "carpedm20/simulated-unsupervised-tensorflow"
"mjdietzx/SimGAN" -> "AlexHex7/SimGAN_pytorch"
"mjdietzx/SimGAN" -> "mjdietzx/GAN-Sandbox"
"mjdietzx/SimGAN" -> "shinseung428/simGAN_NYU_Hand"
"mjdietzx/SimGAN" -> "0b01/SimGAN-Captcha" ["e"=1]
"mjdietzx/SimGAN" -> "osh/KerasGAN"
"mjdietzx/SimGAN" -> "buriburisuri/ac-gan"
"mjdietzx/SimGAN" -> "moodoki/semantic_image_inpainting" ["e"=1]
"mjdietzx/SimGAN" -> "khanrc/tf.gans-comparison"
"hwalsuklee/tensorflow-mnist-CVAE" -> "hwalsuklee/tensorflow-mnist-AAE"
"hwalsuklee/tensorflow-mnist-CVAE" -> "hwalsuklee/tensorflow-mnist-VAE"
"hwalsuklee/tensorflow-mnist-CVAE" -> "RuiShu/cvae"
"Kyubyong/quasi-rnn" -> "rdipietro/mist-rnns"
"mjdietzx/GAN-Sandbox" -> "codyznash/GANs_for_Credit_Card_Data"
"mjdietzx/GAN-Sandbox" -> "mjdietzx/SimGAN"
"mjdietzx/GAN-Sandbox" -> "erilyth/DCGANs"
"yfeng95/GAN_Theories" -> "yfeng95/GAN_Applications"
"yfeng95/GAN_Theories" -> "yfeng95/GAN"
"duxingren14/DualGAN" -> "togheppi/DualGAN"
"duxingren14/DualGAN" -> "SKTBrain/DiscoGAN"
"duxingren14/DualGAN" -> "andrewliao11/CoGAN-tensorflow"
"duxingren14/DualGAN" -> "mingyuliutw/CoGAN"
"duxingren14/DualGAN" -> "lidan1/PhotoSketchMAN" ["e"=1]
"duxingren14/DualGAN" -> "yunjey/domain-transfer-network"
"MadhumitaSushil/SDAE" -> "vlukiyanov/pt-sdae"
"MadhumitaSushil/SDAE" -> "ramarlina/DenoisingAutoEncoder"
"MadhumitaSushil/SDAE" -> "hello-world-zsp/SDAE_tensorflow"
"ermongroup/Variational-Ladder-Autoencoder" -> "openai/iaf" ["e"=1]
"GunhoChoi/Kind-PyTorch-Tutorial" -> "stormraiser/GAN-weight-norm" ["e"=1]
"carpedm20/BEGAN-pytorch" -> "carpedm20/BEGAN-tensorflow"
"carpedm20/BEGAN-pytorch" -> "hmi88/BEGAN-tensorflow"
"carpedm20/BEGAN-pytorch" -> "carpedm20/DiscoGAN-pytorch"
"carpedm20/BEGAN-pytorch" -> "guojunq/lsgan"
"carpedm20/BEGAN-pytorch" -> "HiiYL/BEGAN-PyTorch"
"carpedm20/BEGAN-pytorch" -> "artcg/BEGAN"
"carpedm20/BEGAN-pytorch" -> "GunhoChoi/LSGAN-TF"
"carpedm20/BEGAN-pytorch" -> "taey16/pix2pixBEGAN.pytorch"
"Seratna/TensorFlow-Convolutional-AutoEncoder" -> "arashsaber/Deep-Convolutional-AutoEncoder"
"Seratna/TensorFlow-Convolutional-AutoEncoder" -> "nanopony/keras-convautoencoder"
"Seratna/TensorFlow-Convolutional-AutoEncoder" -> "despoisj/ConvolutionalAutoencoder"
"DmitryUlyanov/AGE" -> "stormraiser/GAN-weight-norm"
"DmitryUlyanov/AGE" -> "guojunq/lsgan"
"DmitryUlyanov/AGE" -> "kimhc6028/forward-thinking-pytorch" ["e"=1]
"DmitryUlyanov/AGE" -> "victor-shepardson/alpha-GAN"
"abhishekkrthakur/clickbaits_revisited" -> "zhouyiwei/cc"
"zhenxuan00/triple-gan" -> "taki0112/TripleGAN-Tensorflow"
"zhenxuan00/triple-gan" -> "taufikxu/Triple-GAN"
"zhenxuan00/triple-gan" -> "LiqunChen0606/Triangle-GAN"
"zhenxuan00/triple-gan" -> "clvrai/SSGAN-Tensorflow"
"zhenxuan00/triple-gan" -> "kimiyoung/ssl_bad_gan" ["e"=1]
"zhenxuan00/triple-gan" -> "samrussell/ssgan"
"mkeid/Texture-Synthesis" -> "Kyubyong/texture_generation"
"hzy46/Char-RNN-TensorFlow" -> "hzy46/fast-neural-style-tensorflow" ["e"=1]
"PAIR-code/facets" -> "MrNothing/AI-Blocks" ["e"=1]
"lanpa/tensorboardX" -> "soumith/ganhacks" ["e"=1]
"lanpa/tensorboardX" -> "wiseodd/generative-models" ["e"=1]
"adeshpande3/LSTM-Sentiment-Analysis" -> "adeshpande3/Generative-Adversarial-Networks" ["e"=1]
"googlecreativelab/quickdraw-dataset" -> "magenta/magenta"
"googlecreativelab/quickdraw-dataset" -> "phillipi/pix2pix"
"googlecreativelab/quickdraw-dataset" -> "affinelayer/pix2pix-tensorflow"
"googlecreativelab/quickdraw-dataset" -> "soumith/ganhacks"
"googlecreativelab/quickdraw-dataset" -> "tkarras/progressive_growing_of_gans"
"googlecreativelab/quickdraw-dataset" -> "junyanz/CycleGAN"
"googlecreativelab/quickdraw-dataset" -> "danmacnish/cartoonify" ["e"=1]
"googlecreativelab/quickdraw-dataset" -> "carpedm20/DCGAN-tensorflow"
"googlecreativelab/quickdraw-dataset" -> "PAIR-code/facets" ["e"=1]
"googlecreativelab/quickdraw-dataset" -> "lengstrom/fast-style-transfer"
"googlecreativelab/quickdraw-dataset" -> "fossasia/visdom" ["e"=1]
"googlecreativelab/quickdraw-dataset" -> "yunjey/stargan"
"googlecreativelab/quickdraw-dataset" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"googlecreativelab/quickdraw-dataset" -> "junyanz/iGAN"
"googlecreativelab/quickdraw-dataset" -> "karpathy/char-rnn" ["e"=1]
"datitran/face2face-demo" -> "affinelayer/pix2pix-tensorflow" ["e"=1]
"datitran/face2face-demo" -> "albertpumarola/GANimation" ["e"=1]
"lllyasviel/style2paints" -> "nagadomi/waifu2x" ["e"=1]
"lllyasviel/style2paints" -> "luanfujun/deep-photo-styletransfer"
"lllyasviel/style2paints" -> "pfnet/PaintsChainer" ["e"=1]
"lllyasviel/style2paints" -> "bloc97/Anime4K" ["e"=1]
"lllyasviel/style2paints" -> "lllyasviel/ControlNet" ["e"=1]
"lllyasviel/style2paints" -> "deeppomf/DeepCreamPy" ["e"=1]
"lllyasviel/style2paints" -> "lengstrom/fast-style-transfer"
"lllyasviel/style2paints" -> "magenta/magenta"
"lllyasviel/style2paints" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"lllyasviel/style2paints" -> "NVlabs/stylegan"
"lllyasviel/style2paints" -> "yunjey/stargan"
"lllyasviel/style2paints" -> "Mikubill/sd-webui-controlnet" ["e"=1]
"lllyasviel/style2paints" -> "junyanz/CycleGAN"
"lllyasviel/style2paints" -> "makegirlsmoe/makegirlsmoe_web" ["e"=1]
"lllyasviel/style2paints" -> "taki0112/UGATIT" ["e"=1]
"tonybeltramelli/pix2code" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"tonybeltramelli/pix2code" -> "junyanz/CycleGAN" ["e"=1]
"tonybeltramelli/pix2code" -> "NVIDIA/FastPhotoStyle" ["e"=1]
"L1aoXingyu/pytorch-beginner" -> "wiseodd/generative-models" ["e"=1]
"zackthoutt/got-book-6" -> "AlexiaJM/Deep-learning-with-cats" ["e"=1]
"zackthoutt/got-book-6" -> "paarthneekhara/text-to-image" ["e"=1]
"msracver/Deep-Image-Analogy" -> "chuanli11/CNNMRF"
"msracver/Deep-Image-Analogy" -> "Ben-Louis/Deep-Image-Analogy-PyTorch"
"msracver/Deep-Image-Analogy" -> "ycjing/Neural-Style-Transfer-Papers" ["e"=1]
"msracver/Deep-Image-Analogy" -> "rtqichen/style-swap" ["e"=1]
"msracver/Deep-Image-Analogy" -> "msracver/Deep-Exemplar-based-Colorization" ["e"=1]
"msracver/Deep-Image-Analogy" -> "DmitryUlyanov/texture_nets"
"msracver/Deep-Image-Analogy" -> "Yijunmaverick/UniversalStyleTransfer" ["e"=1]
"msracver/Deep-Image-Analogy" -> "xunhuang1995/AdaIN-style" ["e"=1]
"msracver/Deep-Image-Analogy" -> "harveyslash/Deep-Image-Analogy-PyTorch"
"msracver/Deep-Image-Analogy" -> "awentzonline/image-analogies"
"msracver/Deep-Image-Analogy" -> "yunjey/domain-transfer-network"
"msracver/Deep-Image-Analogy" -> "LouieYang/deep-photo-styletransfer-tf" ["e"=1]
"msracver/Deep-Image-Analogy" -> "martinbenson/deep-photo-styletransfer" ["e"=1]
"msracver/Deep-Image-Analogy" -> "bobbens/sketch_simplification" ["e"=1]
"msracver/Deep-Image-Analogy" -> "YuvalNirkin/face_swap" ["e"=1]
"eriklindernoren/Keras-GAN" -> "hindupuravinash/the-gan-zoo"
"eriklindernoren/Keras-GAN" -> "eriklindernoren/PyTorch-GAN"
"eriklindernoren/Keras-GAN" -> "soumith/ganhacks"
"eriklindernoren/Keras-GAN" -> "wiseodd/generative-models"
"eriklindernoren/Keras-GAN" -> "carpedm20/DCGAN-tensorflow"
"eriklindernoren/Keras-GAN" -> "zhangqianhui/AdversarialNetsPapers"
"eriklindernoren/Keras-GAN" -> "nashory/gans-awesome-applications"
"eriklindernoren/Keras-GAN" -> "tkarras/progressive_growing_of_gans"
"eriklindernoren/Keras-GAN" -> "junyanz/CycleGAN"
"eriklindernoren/Keras-GAN" -> "NVlabs/stylegan"
"eriklindernoren/Keras-GAN" -> "junyanz/pytorch-CycleGAN-and-pix2pix"
"eriklindernoren/Keras-GAN" -> "keras-rl/keras-rl" ["e"=1]
"eriklindernoren/Keras-GAN" -> "yfeng95/GAN"
"eriklindernoren/Keras-GAN" -> "fchollet/deep-learning-models" ["e"=1]
"eriklindernoren/Keras-GAN" -> "qqwweee/keras-yolo3" ["e"=1]
"philipperemy/keract" -> "bstriner/keras-adversarial" ["e"=1]
"MorvanZhou/Tensorflow-Tutorial" -> "carpedm20/DCGAN-tensorflow" ["e"=1]
"MorvanZhou/Tensorflow-Tutorial" -> "zhangqianhui/AdversarialNetsPapers" ["e"=1]
"MorvanZhou/Tensorflow-Tutorial" -> "wiseodd/generative-models" ["e"=1]
"sony/nnabla" -> "bioinf-jku/SNNs" ["e"=1]
"parasdahal/deepnet" -> "awjuliani/oreilly-rl-tutorial"
"shaohua0116/Activation-Visualization-Histogram" -> "bioinf-jku/SNNs"
"shaohua0116/Activation-Visualization-Histogram" -> "wookayin/tensorflow-plot" ["e"=1]
"shaohua0116/Activation-Visualization-Histogram" -> "clvrai/SSGAN-Tensorflow"
"junyanz/interactive-deep-colorization" -> "junyanz/BicycleGAN" ["e"=1]
"junyanz/interactive-deep-colorization" -> "msracver/Deep-Image-Analogy" ["e"=1]
"junyanz/interactive-deep-colorization" -> "junyanz/iGAN" ["e"=1]
"junyanz/interactive-deep-colorization" -> "jcjohnson/fast-neural-style" ["e"=1]
"junyanz/interactive-deep-colorization" -> "junyanz/CycleGAN" ["e"=1]
"junyanz/interactive-deep-colorization" -> "junyanz/CatPapers" ["e"=1]
"junyanz/interactive-deep-colorization" -> "ajbrock/Neural-Photo-Editor" ["e"=1]
"bioinf-jku/TTUR" -> "mseitzer/pytorch-fid" ["e"=1]
"bioinf-jku/TTUR" -> "sbarratt/inception-score-pytorch"
"bioinf-jku/TTUR" -> "openai/improved-gan"
"bioinf-jku/TTUR" -> "pfnet-research/sngan_projection"
"bioinf-jku/TTUR" -> "taki0112/GAN_Metrics-Tensorflow"
"bioinf-jku/TTUR" -> "google/compare_gan"
"bioinf-jku/TTUR" -> "brain-research/self-attention-gan"
"bioinf-jku/TTUR" -> "LMescheder/GAN_stability"
"bioinf-jku/TTUR" -> "igul222/improved_wgan_training"
"bioinf-jku/TTUR" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"bioinf-jku/TTUR" -> "HelenMao/MSGAN"
"bioinf-jku/TTUR" -> "HsinYingLee/DRIT"
"bioinf-jku/TTUR" -> "hanzhanggit/StackGAN-v2"
"bioinf-jku/TTUR" -> "xuqiantong/GAN-Metrics"
"bioinf-jku/TTUR" -> "tsc2017/Inception-Score"
"bioinf-jku/SNNs" -> "shaohua0116/Activation-Visualization-Histogram"
"bioinf-jku/SNNs" -> "kimhc6028/relational-networks" ["e"=1]
"bioinf-jku/SNNs" -> "google-deepmind/dnc" ["e"=1]
"bioinf-jku/SNNs" -> "google-deepmind/learning-to-learn" ["e"=1]
"bioinf-jku/SNNs" -> "NickShahML/tensorflow_with_latest_papers" ["e"=1]
"bioinf-jku/SNNs" -> "openai/pixel-cnn"
"bioinf-jku/SNNs" -> "martinarjovsky/WassersteinGAN"
"bioinf-jku/SNNs" -> "miyosuda/async_deep_reinforce" ["e"=1]
"bioinf-jku/SNNs" -> "pauli-space/foundations_for_deep_learning" ["e"=1]
"bioinf-jku/SNNs" -> "openai/evolution-strategies-starter" ["e"=1]
"bioinf-jku/SNNs" -> "facebookresearch/fairseq-lua" ["e"=1]
"bioinf-jku/SNNs" -> "chrisranderson/beholder" ["e"=1]
"bioinf-jku/SNNs" -> "bstriner/keras-adversarial"
"bioinf-jku/SNNs" -> "openai/improved-gan"
"bioinf-jku/SNNs" -> "blei-lab/edward" ["e"=1]
"rkjones4/GANGogh" -> "robbiebarrat/art-DCGAN" ["e"=1]
"nyaadevs/nyaa" -> "AlexiaJM/Deep-learning-with-cats" ["e"=1]
"nyaadevs/nyaa" -> "httpcats/http.cat" ["e"=1]
"johnwmillr/LyricsGenius" -> "robbiebarrat/rapping-neural-network" ["e"=1]
"wkentaro/pytorch-for-numpy-users" -> "smilli/research-advice" ["e"=1]
"wkentaro/pytorch-for-numpy-users" -> "cybertronai/imagenet18_old"
"wkentaro/pytorch-for-numpy-users" -> "linksense/LightNet" ["e"=1]
"wkentaro/pytorch-for-numpy-users" -> "nitrain/nitrain" ["e"=1]
"wkentaro/pytorch-for-numpy-users" -> "pytorchbearer/torchbearer" ["e"=1]
"Po-Hsun-Su/pytorch-ssim" -> "heykeetae/Self-Attention-GAN" ["e"=1]
"Po-Hsun-Su/pytorch-ssim" -> "NVlabs/MUNIT" ["e"=1]
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "togheppi/cDCGAN"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "malzantot/Pytorch-conditional-GANs"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "znxlwm/tensorflow-MNIST-cGAN-cDCGAN"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "znxlwm/pytorch-generative-model-collections"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "Yangyangii/GAN-Tutorial"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "znxlwm/pytorch-pix2pix"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "caogang/wgan-gp"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "clvrai/ACGAN-PyTorch"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "yfeng95/GAN"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "LynnHo/Conditional-GANs-Pytorch"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "hezhangsprinter/ID-CGAN" ["e"=1]
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "Zeleni9/pytorch-wgan"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "znxlwm/tensorflow-MNIST-GAN-DCGAN"
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" -> "martinarjovsky/WassersteinGAN"
"CQFIO/PhotographicImageSynthesis" -> "hanzhanggit/StackGAN"
"CQFIO/PhotographicImageSynthesis" -> "CQFIO/FastImageProcessing" ["e"=1]
"CQFIO/PhotographicImageSynthesis" -> "junyanz/BicycleGAN"
"CQFIO/PhotographicImageSynthesis" -> "msracver/FCIS" ["e"=1]
"CQFIO/PhotographicImageSynthesis" -> "reedscot/icml2016"
"CQFIO/PhotographicImageSynthesis" -> "hanzhanggit/StackGAN-v2"
"CQFIO/PhotographicImageSynthesis" -> "carpedm20/BEGAN-tensorflow"
"CQFIO/PhotographicImageSynthesis" -> "mingyuliutw/UNIT"
"CQFIO/PhotographicImageSynthesis" -> "igul222/improved_wgan_training"
"CQFIO/PhotographicImageSynthesis" -> "martinarjovsky/WassersteinGAN"
"CQFIO/PhotographicImageSynthesis" -> "xjqicuhk/SIMS"
"CQFIO/PhotographicImageSynthesis" -> "leehomyc/Faster-High-Res-Neural-Inpainting" ["e"=1]
"CQFIO/PhotographicImageSynthesis" -> "tkarras/progressive_growing_of_gans"
"CQFIO/PhotographicImageSynthesis" -> "cvondrick/videogan"
"CQFIO/PhotographicImageSynthesis" -> "affinelayer/pix2pix-tensorflow"
"robbiebarrat/art-DCGAN" -> "soumith/dcgan.torch"
"robbiebarrat/art-DCGAN" -> "rkjones4/GANGogh" ["e"=1]
"robbiebarrat/art-DCGAN" -> "robbiebarrat/rapping-neural-network"
"robbiebarrat/art-DCGAN" -> "robbiebarrat/plant-art"
"robbiebarrat/art-DCGAN" -> "ml4a/ml4a" ["e"=1]
"robbiebarrat/art-DCGAN" -> "vibertthio/awesome-machine-learning-art" ["e"=1]
"robbiebarrat/art-DCGAN" -> "dvschultz/ml-art-colabs" ["e"=1]
"robbiebarrat/art-DCGAN" -> "kosmos/awesome-generative-art" ["e"=1]
"robbiebarrat/art-DCGAN" -> "Puzer/stylegan-encoder" ["e"=1]
"robbiebarrat/art-DCGAN" -> "joel-simon/ganbreeder" ["e"=1]
"robbiebarrat/art-DCGAN" -> "aaronpenne/generative_art" ["e"=1]
"robbiebarrat/art-DCGAN" -> "tkarras/progressive_growing_of_gans"
"robbiebarrat/art-DCGAN" -> "Newmu/dcgan_code"
"robbiebarrat/art-DCGAN" -> "tensorflow/lucid" ["e"=1]
"robbiebarrat/art-DCGAN" -> "eps696/aphantasia" ["e"=1]
"stormraiser/GAN-weight-norm" -> "ptrblck/prog_gans_pytorch_inference"
"Naresh1318/Adversarial_Autoencoder" -> "musyoku/adversarial-autoencoder"
"Naresh1318/Adversarial_Autoencoder" -> "conan7882/adversarial-autoencoders"
"Naresh1318/Adversarial_Autoencoder" -> "neale/Adversarial-Autoencoder"
"Naresh1318/Adversarial_Autoencoder" -> "bfarzin/pytorch_aae"
"Naresh1318/Adversarial_Autoencoder" -> "fducau/AAE_pytorch"
"Naresh1318/Adversarial_Autoencoder" -> "podgorskiy/GPND" ["e"=1]
"Naresh1318/Adversarial_Autoencoder" -> "hwalsuklee/tensorflow-mnist-AAE"
"Naresh1318/Adversarial_Autoencoder" -> "jakezhaojb/ARAE" ["e"=1]
"Naresh1318/Adversarial_Autoencoder" -> "yoonsanghyu/AAE-PyTorch"
"Naresh1318/Adversarial_Autoencoder" -> "danieltan07/dagmm" ["e"=1]
"Naresh1318/Adversarial_Autoencoder" -> "layerwise/AAE-tensorflow"
"Naresh1318/Adversarial_Autoencoder" -> "tolstikhin/wae" ["e"=1]
"Naresh1318/Adversarial_Autoencoder" -> "andersbll/autoencoding_beyond_pixels"
"Naresh1318/Adversarial_Autoencoder" -> "sixitingting/Adversarial_Autoencoder_Tina"
"Naresh1318/Adversarial_Autoencoder" -> "kvfrans/variational-autoencoder"
"adeshpande3/Machine-Learning-Links-And-Lessons-Learned" -> "adeshpande3/Generative-Adversarial-Networks" ["e"=1]
"mind/wheels" -> "bioinf-jku/SNNs" ["e"=1]
"ssusnic/Machine-Learning-Flappy-Bird" -> "kaishengtai/neuralart" ["e"=1]
"AlexiaJM/Deep-learning-with-cats" -> "AlexiaJM/RelativisticGAN"
"AlexiaJM/Deep-learning-with-cats" -> "nyaadevs/nyaa" ["e"=1]
"AlexiaJM/Deep-learning-with-cats" -> "websockets/wscat"
"AlexiaJM/Deep-learning-with-cats" -> "Endava/cats" ["e"=1]
"AlexiaJM/Deep-learning-with-cats" -> "typelevel/cats-effect" ["e"=1]
"AlexiaJM/Deep-learning-with-cats" -> "carpedm20/BEGAN-tensorflow"
"AlexiaJM/Deep-learning-with-cats" -> "httpcats/http.cat"
"AlexiaJM/Deep-learning-with-cats" -> "openai/improved-gan"
"AlexiaJM/Deep-learning-with-cats" -> "martinarjovsky/WassersteinGAN"
"AlexiaJM/Deep-learning-with-cats" -> "hanzhanggit/StackGAN"
"AlexiaJM/Deep-learning-with-cats" -> "bioinf-jku/SNNs"
"AlexiaJM/Deep-learning-with-cats" -> "CQFIO/PhotographicImageSynthesis"
"AlexiaJM/Deep-learning-with-cats" -> "carpedm20/DiscoGAN-pytorch"
"AlexiaJM/Deep-learning-with-cats" -> "pfnet-research/chainer-gan-lib" ["e"=1]
"AlexiaJM/Deep-learning-with-cats" -> "caogang/wgan-gp"
"makegirlsmoe/makegirlsmoe_web" -> "lllyasviel/style2paints" ["e"=1]
"magenta/magenta-demos" -> "magenta/magenta" ["e"=1]
"sergeytulyakov/mocogan" -> "cvondrick/videogan" ["e"=1]
"sergeytulyakov/mocogan" -> "pfnet-research/sngan_projection" ["e"=1]
"sergeytulyakov/mocogan" -> "HsinYingLee/DRIT" ["e"=1]
"ethanluoyc/pytorch-vae" -> "bhpfelix/Variational-Autoencoder-PyTorch"
"ethanluoyc/pytorch-vae" -> "timbmg/VAE-CVAE-MNIST"
"ethanluoyc/pytorch-vae" -> "sksq96/pytorch-vae"
"ethanluoyc/pytorch-vae" -> "1Konny/Beta-VAE" ["e"=1]
"ethanluoyc/pytorch-vae" -> "1Konny/FactorVAE" ["e"=1]
"ethanluoyc/pytorch-vae" -> "miyosuda/disentangled_vae" ["e"=1]
"ethanluoyc/pytorch-vae" -> "Jackson-Kang/Pytorch-VAE-tutorial"
"ethanluoyc/pytorch-vae" -> "jaanli/variational-autoencoder"
"ethanluoyc/pytorch-vae" -> "cdoersch/vae_tutorial"
"ethanluoyc/pytorch-vae" -> "schelotto/Wasserstein-AutoEncoders" ["e"=1]
"ethanluoyc/pytorch-vae" -> "nadavbh12/VQ-VAE" ["e"=1]
"ethanluoyc/pytorch-vae" -> "kvfrans/variational-autoencoder"
"ethanluoyc/pytorch-vae" -> "seangal/dcgan_vae_pytorch"
"ethanluoyc/pytorch-vae" -> "ritheshkumar95/pytorch-vqvae" ["e"=1]
"ethanluoyc/pytorch-vae" -> "timbmg/Sentence-VAE" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "LDOUBLEV/semi-supervised-GAN" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "zhenxuan00/triple-gan"
"clvrai/SSGAN-Tensorflow" -> "openai/improved-gan"
"clvrai/SSGAN-Tensorflow" -> "shaohua0116/Activation-Visualization-Histogram"
"clvrai/SSGAN-Tensorflow" -> "buriburisuri/ac-gan"
"clvrai/SSGAN-Tensorflow" -> "khanrc/tf.gans-comparison"
"clvrai/SSGAN-Tensorflow" -> "jacobgil/keras-dcgan"
"clvrai/SSGAN-Tensorflow" -> "saemundsson/semisupervised_vae" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "kimiyoung/ssl_bad_gan" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "carpedm20/BEGAN-tensorflow"
"clvrai/SSGAN-Tensorflow" -> "dpkingma/nips14-ssl" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "tmadl/semisup-learn" ["e"=1]
"clvrai/SSGAN-Tensorflow" -> "taki0112/Self-Attention-GAN-Tensorflow"
"clvrai/SSGAN-Tensorflow" -> "artcg/BEGAN"
"clvrai/SSGAN-Tensorflow" -> "Zardinality/WGAN-tensorflow"
"pauli-space/foundations_for_deep_learning" -> "bioinf-jku/SNNs" ["e"=1]
"znxlwm/tensorflow-MNIST-GAN-DCGAN" -> "znxlwm/tensorflow-MNIST-cGAN-cDCGAN"
"znxlwm/tensorflow-MNIST-GAN-DCGAN" -> "shaohua0116/DCGAN-Tensorflow"
"paulu/deepfeatinterp" -> "dvlab-research/Facelet_Bank"
"paulu/deepfeatinterp" -> "xcyan/eccv16_attr2img"
"paulu/deepfeatinterp" -> "Prinsphield/ELEGANT"
"facebookresearch/FaderNetworks" -> "Guim3/IcGAN"
"facebookresearch/FaderNetworks" -> "LynnHo/AttGAN-Tensorflow"
"facebookresearch/FaderNetworks" -> "Prinsphield/ELEGANT"
"facebookresearch/FaderNetworks" -> "csmliu/STGAN"
"facebookresearch/FaderNetworks" -> "paulu/deepfeatinterp"
"facebookresearch/FaderNetworks" -> "elvisyjlin/AttGAN-PyTorch"
"facebookresearch/FaderNetworks" -> "LynnHo/HD-CelebA-Cropper"
"facebookresearch/FaderNetworks" -> "wdyin/GeoGAN"
"facebookresearch/FaderNetworks" -> "xcyan/eccv16_attr2img"
"facebookresearch/FaderNetworks" -> "facebookresearch/adaptive-softmax" ["e"=1]
"facebookresearch/FaderNetworks" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"wbhu/DnCNN-tensorflow" -> "MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" ["e"=1]
"kozistr/Awesome-GANs" -> "nightrome/really-awesome-gan"
"kozistr/Awesome-GANs" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"kozistr/Awesome-GANs" -> "google/compare_gan"
"kozistr/Awesome-GANs" -> "taki0112/Self-Attention-GAN-Tensorflow"
"kozistr/Awesome-GANs" -> "Faldict/awesome-GAN"
"kozistr/Awesome-GANs" -> "GANs-in-Action/gans-in-action"
"kozistr/Awesome-GANs" -> "GKalliatakis/Delving-deep-into-GANs"
"kozistr/Awesome-GANs" -> "taki0112/BigGAN-Tensorflow"
"kozistr/Awesome-GANs" -> "MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow"
"kozistr/Awesome-GANs" -> "khanrc/tf.gans-comparison"
"kozistr/Awesome-GANs" -> "hwalsuklee/tensorflow-generative-model-collections"
"kozistr/Awesome-GANs" -> "carpedm20/BEGAN-tensorflow"
"kozistr/Awesome-GANs" -> "pfnet-research/sngan_projection"
"kozistr/Awesome-GANs" -> "taki0112/GAN_Metrics-Tensorflow"
"kozistr/Awesome-GANs" -> "justinpinkney/awesome-pretrained-stylegan2" ["e"=1]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "LynnHo/AttGAN-Tensorflow"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "LynnHo/CycleGAN-Tensorflow-2"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "taki0112/Self-Attention-GAN-Tensorflow"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "archsyscall/GANs-TensorFlow2"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "kozistr/Awesome-GANs"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "kuleshov/tf-wgan"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "cameronfabbri/cWGANs"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "taki0112/GAN_Metrics-Tensorflow"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "Zardinality/WGAN-tensorflow"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "jesse1029/Fake-Face-Images-Detection-Tensorflow" ["e"=1]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "igul222/improved_wgan_training"
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "ChengBinJin/WGAN-GP-tensorflow" ["e"=1]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" -> "zhangqianhui/Conditional-GAN"
"LynnHo/CycleGAN-Tensorflow-2" -> "vanhuyz/CycleGAN-TensorFlow"
"LynnHo/CycleGAN-Tensorflow-2" -> "hardikbansal/CycleGAN"
"LynnHo/CycleGAN-Tensorflow-2" -> "xiaowei-hu/CycleGAN-tensorflow"
"LynnHo/CycleGAN-Tensorflow-2" -> "architrathore/CycleGAN"
"LynnHo/CycleGAN-Tensorflow-2" -> "leehomyc/cyclegan-1"
"LynnHo/CycleGAN-Tensorflow-2" -> "LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2"
"LynnHo/CycleGAN-Tensorflow-2" -> "simontomaskarlsson/CycleGAN-Keras" ["e"=1]
"LynnHo/CycleGAN-Tensorflow-2" -> "LynnHo/AttGAN-Tensorflow"
"LynnHo/CycleGAN-Tensorflow-2" -> "timsainb/tensorflow2-generative-models"
"LynnHo/CycleGAN-Tensorflow-2" -> "manicman1999/StyleGAN2-Tensorflow-2.0" ["e"=1]
"caogang/wgan-gp" -> "igul222/improved_wgan_training"
"caogang/wgan-gp" -> "martinarjovsky/WassersteinGAN"
"caogang/wgan-gp" -> "jalola/improved-wgan-pytorch"
"caogang/wgan-gp" -> "Zeleni9/pytorch-wgan"
"caogang/wgan-gp" -> "heykeetae/Self-Attention-GAN"
"caogang/wgan-gp" -> "pfnet-research/sngan_projection"
"caogang/wgan-gp" -> "znxlwm/pytorch-generative-model-collections"
"caogang/wgan-gp" -> "christiancosgrove/pytorch-spectral-normalization-gan"
"caogang/wgan-gp" -> "openai/improved-gan"
"caogang/wgan-gp" -> "ajbrock/BigGAN-PyTorch"
"caogang/wgan-gp" -> "wiseodd/generative-models"
"caogang/wgan-gp" -> "github-pengge/PyTorch-progressive_growing_of_gans"
"caogang/wgan-gp" -> "sbarratt/inception-score-pytorch"
"caogang/wgan-gp" -> "EmilienDupont/wgan-gp"
"caogang/wgan-gp" -> "google/compare_gan"
"chrisranderson/beholder" -> "bioinf-jku/SNNs" ["e"=1]
"yunjey/mnist-svhn-transfer" -> "taey16/pix2pixBEGAN.pytorch"
"yunjey/mnist-svhn-transfer" -> "jhoffman/cycada_release" ["e"=1]
"yunjey/mnist-svhn-transfer" -> "SKTBrain/DiscoGAN"
"yunjey/mnist-svhn-transfer" -> "erictzeng/adda" ["e"=1]
"yunjey/mnist-svhn-transfer" -> "SSARCandy/DeepCORAL" ["e"=1]
"yunjey/mnist-svhn-transfer" -> "eveningglow/multitask-CycleGAN"
"yunjey/mnist-svhn-transfer" -> "mrzhu-cool/pix2pix-pytorch"
"yunjey/mnist-svhn-transfer" -> "carpedm20/DiscoGAN-pytorch"
"yunjey/mnist-svhn-transfer" -> "mingyuliutw/CoGAN"
"yunjey/mnist-svhn-transfer" -> "Britefury/self-ensemble-visual-domain-adapt" ["e"=1]
"yunjey/mnist-svhn-transfer" -> "HsinYingLee/DRIT"
"yunjey/mnist-svhn-transfer" -> "sunshineatnoon/Paper-Implementations"
"yunjey/mnist-svhn-transfer" -> "zhenxuan00/triple-gan"
"yunjey/mnist-svhn-transfer" -> "mil-tokyo/MCD_DA" ["e"=1]
"0b01/SimGAN-Captcha" -> "mjdietzx/SimGAN" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "msracver/Deep-Image-Analogy" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "luanfujun/deep-photo-styletransfer" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "cysmith/neural-style-tf" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "yunjey/domain-transfer-network" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "hzy46/fast-neural-style-tensorflow" ["e"=1]
"LouieYang/deep-photo-styletransfer-tf" -> "Ben-Louis/Deep-Image-Analogy-PyTorch" ["e"=1]
"kodalinaveen3/DRAGAN" -> "minhnhat93/tf-SNDCGAN" ["e"=1]
"jonbruner/generative-adversarial-networks" -> "uclaacmai/Generative-Adversarial-Network-Tutorial"
"jonbruner/generative-adversarial-networks" -> "osh/KerasGAN"
"jonbruner/generative-adversarial-networks" -> "jonbruner/ezgan"
"jonbruner/generative-adversarial-networks" -> "adeshpande3/Generative-Adversarial-Networks"
"jonbruner/generative-adversarial-networks" -> "ericjang/genadv_tutorial"
"jonbruner/generative-adversarial-networks" -> "mjdietzx/GAN-Sandbox"
"jonbruner/generative-adversarial-networks" -> "AYLIEN/gan-intro"
"jonbruner/generative-adversarial-networks" -> "awjuliani/dfp" ["e"=1]
"jonbruner/generative-adversarial-networks" -> "Newmu/dcgan_code"
"jonbruner/generative-adversarial-networks" -> "devnag/pytorch-generative-adversarial-networks"
"znxlwm/pytorch-pix2pix" -> "TeeyoHuang/pix2pix-pytorch"
"znxlwm/pytorch-pix2pix" -> "togheppi/pix2pix"
"znxlwm/pytorch-pix2pix" -> "znxlwm/pytorch-CycleGAN"
"znxlwm/pytorch-pix2pix" -> "mrzhu-cool/pix2pix-pytorch"
"znxlwm/pytorch-pix2pix" -> "znxlwm/pytorch-Conditional-image-to-image-translation"
"znxlwm/tensorflow-MNIST-cGAN-cDCGAN" -> "znxlwm/tensorflow-MNIST-GAN-DCGAN"
"znxlwm/tensorflow-MNIST-cGAN-cDCGAN" -> "zhangqianhui/Conditional-GAN"
"znxlwm/tensorflow-MNIST-cGAN-cDCGAN" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"znxlwm/tensorflow-MNIST-cGAN-cDCGAN" -> "gaborvecsei/CDCGAN-Keras"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "caogang/wgan-gp"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "togheppi/DCGAN"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "Zeleni9/pytorch-wgan"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "bioinf-jku/TTUR"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "znxlwm/pytorch-generative-model-collections"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "igul222/improved_wgan_training"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "znxlwm/tensorflow-MNIST-GAN-DCGAN"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "malzantot/Pytorch-conditional-GANs"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "soumith/dcgan.torch"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "jalola/improved-wgan-pytorch"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "znxlwm/tensorflow-MNIST-cGAN-cDCGAN"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "znxlwm/pytorch-CycleGAN"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "tomguluson92/StyleGAN_PyTorch"
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" -> "sbarratt/inception-score-pytorch"
"leehomyc/cyclegan-1" -> "architrathore/CycleGAN"
"leehomyc/cyclegan-1" -> "vanhuyz/CycleGAN-TensorFlow"
"leehomyc/cyclegan-1" -> "hardikbansal/CycleGAN"
"leehomyc/cyclegan-1" -> "LynnHo/CycleGAN-Tensorflow-2"
"leehomyc/cyclegan-1" -> "xiaowei-hu/CycleGAN-tensorflow"
"pfnet-research/chainer-gan-lib" -> "minhnhat93/tf-SNDCGAN" ["e"=1]
"pfnet-research/chainer-gan-lib" -> "pfnet-research/sngan_projection" ["e"=1]
"pfnet-research/chainer-gan-lib" -> "bioinf-jku/TTUR" ["e"=1]
"jeffdonahue/bigan" -> "9310gaurav/ali-pytorch"
"jeffdonahue/bigan" -> "IshmaelBelghazi/ALI"
"jeffdonahue/bigan" -> "manicman1999/Keras-BiGAN" ["e"=1]
"jeffdonahue/bigan" -> "fmu2/Wasserstein-BiGAN"
"jeffdonahue/bigan" -> "WilliBee/bigan_SRL"
"zalandoresearch/psgan" -> "zalandoresearch/spatial_gan"
"zalandoresearch/psgan" -> "zalandoresearch/famos"
"sourcedexter/tfClassifier" -> "cysmith/neural-style-tf" ["e"=1]
"sagiebenaim/DistanceGAN" -> "sagiebenaim/OneShotTranslation"
"wisewong/ImageStyleTransform" -> "OlavHN/fast-neural-style"
"vsyw/Keras-OpenFace" -> "log0/neural-style-painting" ["e"=1]
"AlexHex7/SimGAN_pytorch" -> "daniel-merrick/Learning-from-Simulated-and-Unsupervised-Images-through-Adversarial-Training-SimGAN-PyTorch"
"arashsaber/Deep-Convolutional-AutoEncoder" -> "Seratna/TensorFlow-Convolutional-AutoEncoder"
"bojone/gan" -> "MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow"
"bojone/gan" -> "musikisomorphie/wgan-div"
"bojone/gan" -> "Zardinality/WGAN-tensorflow"
"bojone/gan" -> "bojone/gan-qp"
"kimhc6028/acgan-pytorch" -> "clvrai/ACGAN-PyTorch"
"awjuliani/oreilly-rl-tutorial" -> "awjuliani/TF-Tutorials"
"awjuliani/oreilly-rl-tutorial" -> "awjuliani/Meta-RL" ["e"=1]
"taey16/pix2pixBEGAN.pytorch" -> "taey16/pix2pix.pytorch"
"taey16/pix2pixBEGAN.pytorch" -> "carpedm20/BEGAN-pytorch"
"taey16/pix2pixBEGAN.pytorch" -> "mrzhu-cool/pix2pix-pytorch"
"flyyufelix/DenseNet-Keras" -> "tdeboissiere/DeepLearningImplementations" ["e"=1]
"Prinsphield/GeneGAN" -> "Prinsphield/ELEGANT"
"Prinsphield/GeneGAN" -> "Prinsphield/DNA-GAN"
"Prinsphield/GeneGAN" -> "xcyan/eccv16_attr2img"
"cameronfabbri/Improved-Wasserstein-GAN" -> "cameronfabbri/Wasserstein-GAN-Tensorflow"
"gyglim/dvn" -> "philqc/deep-value-networks-pytorch"
"clvrai/BicycleGAN-Tensorflow" -> "kvmanohar22/img2imgGAN"
"clvrai/BicycleGAN-Tensorflow" -> "clvrai/FeatureControlHRL-Tensorflow"
"clvrai/BicycleGAN-Tensorflow" -> "clvrai/CycleGAN-Tensorflow"
"andrewliao11/dni.pytorch" -> "koz4k/dni-pytorch"
"andrewliao11/dni.pytorch" -> "vyraun/DNI-tensorflow"
"MightXiong/FedMIT" -> "tobran/ONE-PIC"
"taki0112/GAN-Tensorflow" -> "taki0112/DCGAN-Tensorflow"
"taki0112/GAN-Tensorflow" -> "taki0112/CycleGAN-Tensorflow"
"taki0112/GAN-Tensorflow" -> "taki0112/pix2pix-Tensorflow"
"taki0112/DiscoGAN-Tensorflow" -> "taki0112/DCGAN-Tensorflow"
"maxchehab/CSS-Keylogging" ["l"="-0.866,-26.687", "c"=814]
"NVIDIA/FastPhotoStyle" ["l"="45.547,29.157"]
"zalandoresearch/fashion-mnist" ["l"="45.919,25.78", "c"=68]
"lengstrom/fast-style-transfer" ["l"="45.585,29.275"]
"junyanz/pytorch-CycleGAN-and-pix2pix" ["l"="45.639,29.106"]
"tensorflow/lucid" ["l"="51.048,29.542", "c"=83]
"soumith/ganhacks" ["l"="45.764,29.133"]
"microsoft/tensorwatch" ["l"="51.022,29.765", "c"=83]
"timsainb/tensorflow2-generative-models" ["l"="45.975,29.091"]
"luanfujun/deep-photo-styletransfer" ["l"="45.529,29.244"]
"NVIDIA/vid2vid" ["l"="45.652,29.047"]
"luanfujun/deep-painterly-harmonization" ["l"="45.592,29.089"]
"NVIDIA/pix2pixHD" ["l"="45.682,29.122"]
"esimov/caire" ["l"="-0.968,-26.721", "c"=814]
"yunjey/stargan" ["l"="45.699,29.098"]
"facebookresearch/Detectron" ["l"="50.57,29.767", "c"=83]
"junyanz/CycleGAN" ["l"="45.672,29.194"]
"tkarras/progressive_growing_of_gans" ["l"="45.767,29.1"]
"jcjohnson/fast-neural-style" ["l"="45.636,29.33"]
"NVlabs/SPADE" ["l"="45.631,29.001"]
"NVlabs/stylegan" ["l"="45.605,29.047"]
"jcjohnson/neural-style" ["l"="45.54,29.367"]
"DmitryUlyanov/deep-image-prior" ["l"="45.575,29.199"]
"deeppomf/DeepCreamPy" ["l"="-36.441,20.886", "c"=597]
"lllyasviel/style2paints" ["l"="45.451,29.173"]
"HarisIqbal88/PlotNeuralNet" ["l"="50.721,29.525", "c"=83]
"eriklindernoren/PyTorch-GAN" ["l"="45.694,29.02"]
"NVlabs/stylegan2" ["l"="45.007,30.739", "c"=243]
"NVlabs/ffhq-dataset" ["l"="44.971,30.699", "c"=243]
"NVlabs/stylegan2-ada-pytorch" ["l"="44.972,30.644", "c"=243]
"hindupuravinash/the-gan-zoo" ["l"="45.729,29.122"]
"NVlabs/stylegan3" ["l"="44.996,30.625", "c"=243]
"eriklindernoren/Keras-GAN" ["l"="45.733,29.058"]
"run-youngjoo/SC-FEGAN" ["l"="45.622,28.959"]
"JiahuiYu/generative_inpainting" ["l"="44.682,29.375", "c"=912]
"switchablenorms/CelebAMask-HQ" ["l"="44.863,30.665", "c"=243]
"knazeri/edge-connect" ["l"="44.701,29.355", "c"=912]
"clovaai/stargan-v2" ["l"="44.927,30.686", "c"=243]
"shaoanlu/faceswap-GAN" ["l"="31.209,30.67", "c"=634]
"NVIDIA/partialconv" ["l"="44.681,29.342", "c"=912]
"NVlabs/FUNIT" ["l"="45.787,28.958"]
"zllrunning/face-parsing.PyTorch" ["l"="44.898,30.711", "c"=243]
"SummitKwan/transparent_latent_gan" ["l"="45.748,28.961"]
"genforce/interfacegan" ["l"="44.919,30.601", "c"=243]
"Puzer/stylegan-encoder" ["l"="44.999,30.599", "c"=243]
"emilwallner/Screenshot-to-code" ["l"="-4.341,-33.109", "c"=30]
"utkuozbulak/pytorch-cnn-visualizations" ["l"="50.822,29.762", "c"=83]
"Gsllchb/Handright" ["l"="47.044,7.602", "c"=148]
"kaonashi-tyc/zi2zi" ["l"="45.814,29.278"]
"pytorch/examples" ["l"="50.825,29.621", "c"=83]
"huggingface/pytorch-image-models" ["l"="50.672,29.653", "c"=83]
"lucidrains/vit-pytorch" ["l"="50.683,29.606", "c"=83]
"AntixK/PyTorch-VAE" ["l"="45.877,31.629", "c"=605]
"yunjey/pytorch-tutorial" ["l"="50.738,28.451", "c"=104]
"wiseodd/generative-models" ["l"="45.835,29.145"]
"open-mmlab/mmdetection" ["l"="50.617,29.783", "c"=83]
"pytorch/vision" ["l"="50.737,29.759", "c"=83]
"Cadene/pretrained-models.pytorch" ["l"="50.832,29.881", "c"=83]
"lucidrains/denoising-diffusion-pytorch" ["l"="45.812,31.565", "c"=605]
"jindongwang/transferlearning" ["l"="51.257,37.675", "c"=678]
"facebookresearch/DensePose" ["l"="31.696,28.046", "c"=352]
"nashory/gans-awesome-applications" ["l"="45.761,29.072"]
"nightrome/really-awesome-gan" ["l"="45.835,29.115"]
"zhangqianhui/AdversarialNetsPapers" ["l"="45.797,29.146"]
"kjw0612/awesome-deep-vision" ["l"="47.831,28.792", "c"=89]
"znxlwm/pytorch-generative-model-collections" ["l"="45.866,29.088"]
"lucabergamini/VAEGAN-PYTORCH" ["l"="46.208,29.302"]
"ry85/VAE-GAN" ["l"="46.27,29.284"]
"andersbll/autoencoding_beyond_pixels" ["l"="46.072,29.315"]
"zhangqianhui/vae-gan-tensorflow" ["l"="46.117,29.292"]
"anitan0925/vaegan" ["l"="46.133,29.302"]
"crmaximo/VAEGAN" ["l"="46.125,29.261"]
"rohithreddy024/VAE-GAN-Pytorch" ["l"="46.266,29.308"]
"seangal/dcgan_vae_pytorch" ["l"="46.274,29.329"]
"rishabhd786/VAE-GAN-PYTORCH" ["l"="46.252,29.286"]
"escuccim/vaegan-pytorch" ["l"="46.249,29.314"]
"JeremyCCHsu/tf-vaegan" ["l"="46.147,29.292"]
"tkazusa/CVAE-GAN" ["l"="46.408,29.276"]
"MrNothing/AI-Blocks" ["l"="45.615,29.223"]
"AKSHAYUBHAT/DeepVideoAnalytics" ["l"="46.202,7.121", "c"=148]
"andabi/deep-voice-conversion" ["l"="37.144,2.58", "c"=117]
"buriburisuri/speech-to-text-wavenet" ["l"="37.042,2.54", "c"=117]
"junyanz/iGAN" ["l"="45.716,29.249"]
"OpenNMT/OpenNMT" ["l"="53.765,24.675", "c"=492]
"PAIR-code/facets" ["l"="45.488,25.987", "c"=68]
"oarriaga/face_classification" ["l"="55.996,27.258", "c"=486]
"facebookresearch/fairseq-lua" ["l"="53.204,25.644", "c"=172]
"google-deepmind/sonnet" ["l"="57.431,17.873", "c"=45]
"tensorflow/tfjs-core" ["l"="-32.63,-35.84", "c"=1115]
"pyro-ppl/pyro" ["l"="45.709,26.076", "c"=68]
"google/tangent" ["l"="45.152,20.435", "c"=20]
"bioinf-jku/SNNs" ["l"="46.04,29.197"]
"google/compare_gan" ["l"="45.858,29.039"]
"ajbrock/BigGAN-PyTorch" ["l"="45.825,29.003"]
"pfnet-research/sngan_projection" ["l"="45.904,29.038"]
"bioinf-jku/TTUR" ["l"="45.89,29.029"]
"heykeetae/Self-Attention-GAN" ["l"="45.876,29.048"]
"igul222/improved_wgan_training" ["l"="45.897,29.126"]
"facebookresearch/pytorch_GAN_zoo" ["l"="45.846,28.979"]
"LMescheder/GAN_stability" ["l"="45.856,29.003"]
"openai/improved-gan" ["l"="45.896,29.177"]
"CSAILVision/gandissect" ["l"="45.758,28.987"]
"openai/glow" ["l"="45.798,29.058"]
"hwalsuklee/tensorflow-generative-model-collections" ["l"="45.809,29.105"]
"brain-research/self-attention-gan" ["l"="45.887,29.008"]
"christiancosgrove/pytorch-spectral-normalization-gan" ["l"="45.923,29.017"]
"NVlabs/MUNIT" ["l"="45.791,29.003"]
"mingyuliutw/UNIT" ["l"="45.833,29.052"]
"HsinYingLee/DRIT" ["l"="45.859,28.964"]
"junyanz/BicycleGAN" ["l"="45.797,29.031"]
"taki0112/MUNIT-Tensorflow" ["l"="45.927,28.967"]
"lzhbrian/image-to-image-papers" ["l"="45.839,28.955"]
"xunhuang1995/AdaIN-style" ["l"="44.995,28.773", "c"=771]
"NVlabs/imaginaire" ["l"="44.955,30.67", "c"=243]
"taesungp/contrastive-unpaired-translation" ["l"="44.867,30.623", "c"=243]
"google/gin-config" ["l"="21.661,14.029", "c"=267]
"rosinality/vq-vae-2-pytorch" ["l"="23.162,14.311", "c"=505]
"rosinality/style-based-gan-pytorch" ["l"="45.86,28.946"]
"IBM/MAX-Image-Resolution-Enhancer" ["l"="-35.012,21.791", "c"=127]
"alexjc/neural-enhance" ["l"="45.527,29.302"]
"xinario/awesome-gan-for-medical-imaging" ["l"="61.873,36.908", "c"=178]
"luuuyi/CBAM.PyTorch" ["l"="53.506,31.089", "c"=155]
"sjvasquez/handwriting-synthesis" ["l"="46.45,7.547", "c"=148]
"poloclub/ganlab" ["l"="23.649,14.866", "c"=728]
"davidADSP/GDL_code" ["l"="47.826,26.531", "c"=323]
"GANs-in-Action/gans-in-action" ["l"="45.822,29.031"]
"podgorskiy/ALAE" ["l"="44.932,30.718", "c"=243]
"chaitanya100100/VAE-for-Image-Generation" ["l"="46.317,29.302"]
"SashaMalysheva/Pytorch-VAE" ["l"="46.325,29.263"]
"EmilienDupont/vae-concrete" ["l"="46.368,29.288"]
"ksharsha/CifarVAE" ["l"="46.361,29.305"]
"cgarciae/pypeln" ["l"="45.144,20.955", "c"=20]
"cybertronai/imagenet18_old" ["l"="45.639,28.869"]
"Pulkit-Khandelwal/Reinforcement-Learning-Notebooks" ["l"="45.662,28.9"]
"RedditSota/state-of-the-art-result-for-machine-learning-problems" ["l"="47.648,28.737", "c"=89]
"notAI-tech/NudeNet" ["l"="-10.099,-8.099", "c"=5]
"ryanjay0/miles-deep" ["l"="45.473,29.392"]
"goodfeli/dlbook_notation" ["l"="47.618,28.875", "c"=89]
"goodfeli/adversarial" ["l"="45.833,29.174"]
"milesial/Pytorch-UNet" ["l"="50.605,29.655", "c"=83]
"Externalizable/bongo.cat" ["l"="-53.181,-17.501", "c"=374]
"httpcats/http.cat" ["l"="46.181,29.12"]
"phillipi/pix2pix" ["l"="45.719,29.207"]
"affinelayer/pix2pix-tensorflow" ["l"="45.777,29.2"]
"taki0112/UGATIT" ["l"="44.91,30.766", "c"=243]
"znxlwm/UGATIT-pytorch" ["l"="44.844,30.701", "c"=243]
"jantic/DeOldify" ["l"="45.141,30.94", "c"=243]
"rohitrango/automatic-watermark-detection" ["l"="-34.192,22.472", "c"=429]
"NVlabs/noise2noise" ["l"="-34.373,22.505", "c"=429]
"kennyledet/Algorithm-Implementations" ["l"="-21.62,-22.611", "c"=390]
"kaishengtai/neuralart" ["l"="45.668,29.433"]
"google-research/disentanglement_lib" ["l"="23.031,14.283", "c"=505]
"pytorch/hub" ["l"="50.937,30.005", "c"=83]
"diego-vicente/som-tsp" ["l"="47.7,26.404", "c"=323]
"elvisyjlin/SpatialAttentionGAN" ["l"="46.001,28.889"]
"wdyin/GeoGAN" ["l"="46.004,28.908"]
"elvisyjlin/AttGAN-PyTorch" ["l"="46.006,28.874"]
"bluestyle97/STGAN-pytorch" ["l"="45.984,28.883"]
"wb14123/seq2seq-couplet" ["l"="-5.034,17.743", "c"=316]
"tensorspace-team/tensorspace" ["l"="51.004,29.723", "c"=83]
"benedekrozemberczki/awesome-decision-tree-papers" ["l"="51.649,15.707", "c"=1152]
"NVlabs/few-shot-vid2vid" ["l"="31.08,30.559", "c"=634]
"albertpumarola/GANimation" ["l"="45.707,28.979"]
"hzwer/ICCV2019-LearningToPaint" ["l"="44.653,30.728", "c"=243]
"rosinality/stylegan2-pytorch" ["l"="44.932,30.615", "c"=243]
"tamarott/SinGAN" ["l"="44.796,30.681", "c"=243]
"zllrunning/video-object-removal" ["l"="44.769,29.416", "c"=912]
"cybertronai/gradient-checkpointing" ["l"="45.737,25.766", "c"=68]
"mseitzer/pytorch-fid" ["l"="45.808,31.452", "c"=605]
"sbarratt/inception-score-pytorch" ["l"="45.903,29.018"]
"tengshaofeng/ResidualAttentionNetwork-pytorch" ["l"="53.494,31.14", "c"=155]
"huggingface/pytorch-pretrained-BigGAN" ["l"="45.818,28.981"]
"sxhxliang/BigGAN-pytorch" ["l"="45.87,28.974"]
"mit-han-lab/data-efficient-gans" ["l"="44.931,30.537", "c"=243]
"epfml/attention-cnn" ["l"="53.56,31.039", "c"=155]
"carpedm20/DCGAN-tensorflow" ["l"="45.808,29.187"]
"martinarjovsky/WassersteinGAN" ["l"="45.883,29.153"]
"vahidk/EffectiveTensorflow" ["l"="47.659,28.7", "c"=89]
"anopara/texture-synthesis-nonparametric-sampling" ["l"="45.353,29.698"]
"anopara/patch-based-texture-synthesis" ["l"="45.363,29.713"]
"anopara/multi-resolution-texture-synthesis" ["l"="45.333,29.714"]
"yuanxiaosc/DeepImage-an-Image-to-Image-technology" ["l"="31.373,30.604", "c"=634]
"porn-vault/porn-vault" ["l"="-60.712,15.74", "c"=330]
"hanzhanggit/StackGAN-Pytorch" ["l"="45.738,29.166"]
"hanzhanggit/StackGAN-v2" ["l"="45.76,29.184"]
"taoxugit/AttnGAN" ["l"="45.714,29.169"]
"hanzhanggit/StackGAN" ["l"="45.835,29.211"]
"aelnouby/Text-to-Image-Synthesis" ["l"="45.751,29.219"]
"reedscot/icml2016" ["l"="45.818,29.242"]
"lzhbrian/arbitrary-text-to-image-papers" ["l"="45.683,29.169"]
"hanzhanggit/StackGAN-inception-model" ["l"="45.668,29.158"]
"mrlibw/ControlGAN" ["l"="45.625,29.148"]
"ypxie/HDGan" ["l"="45.682,29.157"]
"MinfengZhu/DM-GAN" ["l"="45.638,29.146"]
"google/sg2im" ["l"="47.505,32.052", "c"=1070]
"qiaott/MirrorGAN" ["l"="45.656,29.153"]
"tohinz/multiple-objects-gan" ["l"="45.653,29.172"]
"davidstap/AttnGAN" ["l"="45.625,29.169"]
"kongyanye/cwgan-gp" ["l"="46.098,28.931"]
"cameronfabbri/cWGANs" ["l"="46.069,28.96"]
"naoto0804/pytorch-AdaIN" ["l"="45.041,28.726", "c"=771]
"tomguluson92/StyleGAN_PyTorch" ["l"="45.88,28.933"]
"hzy46/Deep-Learning-21-Examples" ["l"="50.612,28.231", "c"=104]
"bojone/vae" ["l"="46.174,29.286"]
"bojone/attention" ["l"="53.649,27.27", "c"=60]
"bojone/gan" ["l"="46.215,29.091"]
"slim1017/VaDE" ["l"="53.1,29.826", "c"=547]
"jaanli/variational-autoencoder" ["l"="46.151,29.319"]
"y0ast/VAE-TensorFlow" ["l"="46.157,29.339"]
"cdoersch/vae_tutorial" ["l"="46.125,29.329"]
"tkipf/gae" ["l"="52.776,16.011", "c"=100]
"timbmg/VAE-CVAE-MNIST" ["l"="46.233,29.354"]
"bojone/seq2seq" ["l"="53.761,27.233", "c"=60]
"timbmg/Sentence-VAE" ["l"="57.705,29.351", "c"=1082]
"hwalsuklee/tensorflow-mnist-VAE" ["l"="46.176,29.322"]
"bojone/flow" ["l"="23.109,14.467", "c"=505]
"ethanluoyc/pytorch-vae" ["l"="46.235,29.334"]
"chaiyujin/glow-pytorch" ["l"="23.007,14.469", "c"=505]
"rosinality/glow-pytorch" ["l"="23.049,14.465", "c"=505]
"caogang/wgan-gp" ["l"="45.921,29.06"]
"swapagarwal/swag-for-dev" ["l"="26.562,-26.061", "c"=32]
"cchen156/Learning-to-See-in-the-Dark" ["l"="-33.627,23.123", "c"=616]
"torch/torch7" ["l"="47.926,29.033", "c"=89]
"jorge-pessoa/pytorch-msssim" ["l"="45.771,31.275", "c"=605]
"nashory/pggan-pytorch" ["l"="45.889,28.965"]
"MrGemy95/Tensorflow-Project-Template" ["l"="47.618,28.765", "c"=89]
"reiinakano/arbitrary-image-stylization-tfjs" ["l"="44.908,28.748", "c"=771]
"reiinakano/fast-style-transfer-deeplearnjs" ["l"="45.706,29.355"]
"lexfridman/deeptraffic" ["l"="57.438,17.935", "c"=45]
"keras-team/keras-applications" ["l"="50.567,30.063", "c"=83]
"TwistedW/tensorflow-GANs" ["l"="45.896,28.743"]
"TwistedW/pytorch-GANs" ["l"="45.893,28.7"]
"taki0112/RelativisticGAN-Tensorflow" ["l"="45.911,28.867"]
"diegoalejogm/gans" ["l"="46.013,29.178"]
"devnag/pytorch-generative-adversarial-networks" ["l"="45.92,29.163"]
"higgsfield/Capsule-Network-Tutorial" ["l"="50.893,33.237", "c"=314]
"luisguiserrano/gans" ["l"="46.169,29.181"]
"diegoalejogm/deep-q-learning" ["l"="57.743,17.669", "c"=45]
"savan77/The-GAN-World" ["l"="46.151,29.164"]
"astorfi/TensorFlow-World-Resources" ["l"="47.481,28.69", "c"=89]
"yunjey/mnist-svhn-transfer" ["l"="46.016,29.086"]
"shayneobrien/generative-models" ["l"="45.984,29.07"]
"adeshpande3/Generative-Adversarial-Networks" ["l"="46.107,29.219"]
"kvfrans/variational-autoencoder" ["l"="46.144,29.352"]
"taki0112/Self-Attention-GAN-Tensorflow" ["l"="45.943,29.005"]
"junfu1115/DANet" ["l"="53.435,30.991", "c"=155]
"bendangnuksung/Image-OutPainting" ["l"="45.668,28.948"]
"donydchen/ganimation_replicate" ["l"="31.172,30.493", "c"=634]
"apchenstu/Facial_Details_Synthesis" ["l"="31.845,29.356", "c"=124]
"nyoki-mtl/pytorch-EverybodyDanceNow" ["l"="43.55,31.016", "c"=318]
"grey-eye/talking-heads" ["l"="31.121,30.556", "c"=634]
"tranluan/Nonlinear_Face_3DMM" ["l"="31.819,29.342", "c"=124]
"yfeng95/face3d" ["l"="31.782,29.389", "c"=124]
"cleardusk/3DDFA" ["l"="31.754,29.371", "c"=124]
"github-pengge/PyTorch-progressive_growing_of_gans" ["l"="45.911,28.984"]
"akanimax/pro_gan_pytorch" ["l"="45.828,28.938"]
"torchgan/torchgan" ["l"="45.87,28.996"]
"POSTECH-CVLab/PyTorch-StudioGAN" ["l"="44.99,30.571", "c"=243]
"avinashpaliwal/Super-SloMo" ["l"="-36.037,20.865", "c"=597]
"cosme12/SimpleCoin" ["l"="45.862,5.021", "c"=1062]
"joshua-wu/deepfakes_faceswap" ["l"="31.257,30.687", "c"=634]
"tjwei/GANotebooks" ["l"="45.862,29.12"]
"tipsy/bubbly-bg" ["l"="22.7,-29.574", "c"=36]
"tensorlayer/SRGAN" ["l"="-34.937,21.659", "c"=127]
"KupynOrest/DeblurGAN" ["l"="-34.895,21.517", "c"=127]
"XPixelGroup/BasicSR" ["l"="-34.956,21.539", "c"=127]
"cszn/KAIR" ["l"="-34.992,21.488", "c"=127]
"naturomics/CapsNet-Tensorflow" ["l"="50.785,33.237", "c"=314]
"Ha0Tang/AttentionGAN" ["l"="44.711,30.557", "c"=243]
"AlamiMejjati/Unsupervised-Attention-guided-Image-to-Image-Translation" ["l"="45.865,28.915"]
"alokwhitewolf/Pytorch-Attention-Guided-CycleGAN" ["l"="45.863,28.863"]
"sangwoomo/instagan" ["l"="45.809,28.941"]
"Luolc/AdaBound" ["l"="50.941,29.967", "c"=83]
"SharpAI/DeepCamera" ["l"="42.309,7.494", "c"=818]
"karpathy/pytorch-made" ["l"="23.181,14.414", "c"=505]
"ptrblck/prog_gans_pytorch_inference" ["l"="45.958,28.933"]
"stacklikemind/deepnude_official" ["l"="31.423,30.543", "c"=634]
"LynnHo/AttGAN-Tensorflow" ["l"="45.971,28.96"]
"pbaylies/stylegan-encoder" ["l"="45.013,30.588", "c"=243]
"csmliu/STGAN" ["l"="45.96,28.905"]
"davidcpage/cifar10-fast" ["l"="45.58,28.836"]
"fastai/imagenet-fast" ["l"="45.588,28.814"]
"f-dangel/cockpit" ["l"="21.613,14.015", "c"=267]
"rwightman/gen-efficientnet-pytorch" ["l"="50.853,30.081", "c"=83]
"anokland/local-loss" ["l"="49.378,32.889", "c"=401]
"codyogden/killedbygoogle" ["l"="-52.164,12.208", "c"=266]
"bernhard2202/improved-video-gan" ["l"="41.49,25.598", "c"=537]
"cvondrick/videogan" ["l"="45.873,29.296"]
"jamesli1618/Obj-GAN" ["l"="45.639,29.159"]
"tobran/DF-GAN" ["l"="45.568,29.127"]
"zsdonghao/text-to-image" ["l"="45.785,29.226"]
"harveyslash/Deep-Image-Analogy-PyTorch" ["l"="45.777,29.459"]
"Ben-Louis/Deep-Image-Analogy-PyTorch" ["l"="45.772,29.439"]
"google-research/tensor2robot" ["l"="59.578,16.474", "c"=234]
"danmacnish/cartoonify" ["l"="45.954,5.029", "c"=1062]
"googlecreativelab/quickdraw-dataset" ["l"="45.655,29.236"]
"elgris/microservice-app-example" ["l"="-1.217,-26.777", "c"=814]
"salu133445/musegan" ["l"="38.645,4.053", "c"=201]
"magenta/magenta" ["l"="45.441,29.307"]
"akanimax/BMSG-GAN" ["l"="45.815,28.961"]
"akanimax/pro_gan_pytorch-examples" ["l"="45.794,28.872"]
"akanimax/msg-gan-v1" ["l"="45.792,28.907"]
"lernapparat/lernapparat" ["l"="45.046,30.535", "c"=243]
"akanimax/T2F" ["l"="45.731,29.09"]
"akanimax/msg-stylegan-tf" ["l"="45.77,28.922"]
"huangzh13/StyleGAN.pytorch" ["l"="45.019,30.533", "c"=243]
"tomguluson92/StyleGAN2_PyTorch" ["l"="45.84,28.881"]
"youyuge34/PI-REC" ["l"="-34.913,20.374", "c"=1031]
"idealo/image-super-resolution" ["l"="-34.921,21.625", "c"=127]
"PacktPublishing/Generative-Adversarial-Networks-Projects" ["l"="45.744,28.895"]
"PacktPublishing/Generative-Adversarial-Networks-Cookbook" ["l"="45.751,28.912"]
"PacktPublishing/Hands-On-Generative-Adversarial-Networks-with-Keras" ["l"="45.734,28.915"]
"PacktPublishing/Learning-Generative-Adversarial-Networks" ["l"="45.726,28.887"]
"tensorflow/adanet" ["l"="45.54,26.002", "c"=68]
"ybayle/awesome-deep-learning-music" ["l"="38.484,4.084", "c"=201]
"erikaduan/r_tips" ["l"="40.381,35.481", "c"=51]
"Jongchan/attention-module" ["l"="53.525,31.101", "c"=155]
"PacktPublishing/Advanced-Deep-Learning-with-Keras" ["l"="47.359,28.48", "c"=89]
"roatienza/Deep-Learning-Experiments" ["l"="45.978,29.143"]
"bstriner/keras-adversarial" ["l"="46.019,29.224"]
"remicnrd/ml_cheatsheet" ["l"="47.614,28.518", "c"=89]
"taki0112/GAN_Metrics-Tensorflow" ["l"="45.933,28.951"]
"lzhbrian/metrics" ["l"="45.951,28.951"]
"xuqiantong/GAN-Metrics" ["l"="45.93,28.985"]
"tsc2017/Frechet-Inception-Distance" ["l"="45.931,28.913"]
"tsc2017/Inception-Score" ["l"="45.927,28.935"]
"nnUyi/Inception-Score" ["l"="45.948,28.878"]
"taki0112/BigGAN-Tensorflow" ["l"="45.91,28.95"]
"taki0112/SphereGAN-Tensorflow" ["l"="45.901,28.895"]
"abdulfatir/gan-metrics-pytorch" ["l"="45.947,28.859"]
"ericjang/normalizing-flows-tutorial" ["l"="23.066,14.424", "c"=505]
"openai/iaf" ["l"="46.004,29.288"]
"janesjanes/Pytorch-TextureGAN" ["l"="45.444,29.74"]
"Cuiyirui/TextureGAN" ["l"="45.448,29.765"]
"AlexiaJM/RelativisticGAN" ["l"="45.913,29.001"]
"AlexiaJM/relativistic-f-divergences" ["l"="45.913,28.909"]
"roimehrez/contextualLoss" ["l"="-35.046,21.535", "c"=127]
"godisboy/SN-GAN" ["l"="45.969,29.008"]
"AlexiaJM/Deep-learning-with-cats" ["l"="45.999,29.126"]
"weihaox/awesome-image-translation" ["l"="44.798,30.575", "c"=243]
"HelenMao/MSGAN" ["l"="45.842,28.931"]
"Ha0Tang/SelectionGAN" ["l"="44.625,30.529", "c"=243]
"Prinsphield/ELEGANT" ["l"="45.981,28.929"]
"bojone/gan-qp" ["l"="46.356,29.068"]
"bojone/o-gan" ["l"="46.39,29.072"]
"bojone/T-GANs" ["l"="46.385,29.048"]
"RahulBhalley/gan-qp.pytorch" ["l"="46.409,29.057"]
"akanimax/big-discriminator-batch-spoofing-gan" ["l"="45.784,28.889"]
"kam1107/RealnessGAN" ["l"="44.765,30.495", "c"=243]
"weilinie/RelGAN" ["l"="57.78,29.322", "c"=1082]
"elvisyjlin/RelGAN-PyTorch" ["l"="46.045,28.806"]
"mkocabas/EpipolarPose" ["l"="31.704,28.302", "c"=352]
"shaoanlu/fewshot-face-translation-GAN" ["l"="31.142,30.616", "c"=634]
"autonomousvision/graf" ["l"="63.71,1.53", "c"=134]
"kewellcjj/pytorch-multiple-style-transfer" ["l"="46.324,28.941"]
"MingtaoGuo/Conditional-Instance-Norm-for-n-Style-Transfer" ["l"="46.276,28.944"]
"joel-simon/ganbreeder" ["l"="44.997,30.66", "c"=243]
"robbiebarrat/art-DCGAN" ["l"="45.875,29.424"]
"MingtaoGuo/Chinese-Character-and-Calligraphic-Image-Processing" ["l"="46.359,28.891"]
"MingtaoGuo/CNN-for-Chinese-Calligraphy-Styles-classification" ["l"="46.318,28.909"]
"MingtaoGuo/Calligraphic-Images-Denoising-by-GAN" ["l"="46.335,28.907"]
"yunchenlo/Font2Font" ["l"="46.389,28.888"]
"iamsohard/ChineseCalligraphyGenerator" ["l"="46.406,28.864"]
"zhuojg/chinese-calligraphy-dataset" ["l"="46.395,28.85"]
"MingtaoGuo/Residual-Dense-Network-Trained-with-cGAN-for-Super-Resolution" ["l"="46.276,28.929"]
"jiqizhixin/ML-Tutorial-Experiment" ["l"="50.354,28.218", "c"=104]
"nathanhubens/Autoencoders" ["l"="46.375,29.528"]
"Nana0606/autoencoder" ["l"="46.345,29.498"]
"wblgers/tensorflow_stacked_denoising_autoencoder" ["l"="46.406,29.545"]
"Xiaoming-Yu/DMIT" ["l"="45.839,28.857"]
"WonwoongCho/GDWCT" ["l"="44.564,30.594", "c"=243]
"HsinYingLee/MDMM" ["l"="45.845,28.895"]
"egorzakharov/PerceptualGAN" ["l"="45.816,28.831"]
"maga33/DSGAN" ["l"="45.801,28.847"]
"kkanshul/finegan" ["l"="44.773,30.609", "c"=243]
"koz4k/dni-pytorch" ["l"="45.977,28.82"]
"andrewliao11/dni.pytorch" ["l"="45.984,28.765"]
"slowbull/DDG" ["l"="45.988,28.785"]
"taehoonlee/tensornets" ["l"="50.348,33.114", "c"=314]
"yunjey/domain-transfer-network" ["l"="45.9,29.268"]
"aitorzip/PyTorch-CycleGAN" ["l"="45.988,28.987"]
"arnab39/cycleGAN-PyTorch" ["l"="46.069,28.903"]
"mrzhu-cool/pix2pix-pytorch" ["l"="46.07,29.038"]
"Lornatang/CycleGAN-PyTorch" ["l"="46.11,28.859"]
"togheppi/CycleGAN" ["l"="46.077,28.972"]
"Po-Hsun-Su/pytorch-ssim" ["l"="45.785,31.332", "c"=605]
"yu4u/noise2noise" ["l"="-34.3,22.475", "c"=429]
"1Konny/FactorVAE" ["l"="23.048,14.259", "c"=505]
"bhpfelix/Variational-Autoencoder-PyTorch" ["l"="46.297,29.341"]
"1Konny/Beta-VAE" ["l"="23.07,14.259", "c"=505]
"yhlleo/uaggan" ["l"="45.87,28.848"]
"Xiaoming-Yu/SingleGAN" ["l"="45.846,28.821"]
"brownvc/ganimorph" ["l"="45.816,28.873"]
"hyperplane-lab/ACL-GAN" ["l"="44.65,30.572", "c"=243]
"alpc91/NICE-GAN-pytorch" ["l"="44.659,30.556", "c"=243]
"magenta/magenta-js" ["l"="39.993,3.984", "c"=394]
"CortexFoundation/StyleTransferTrilogy" ["l"="45.013,28.758", "c"=771]
"hzy46/fast-neural-style-tensorflow" ["l"="45.597,29.417"]
"jsn5/dancenet" ["l"="30.599,28.372", "c"=94]
"googlecreativelab/open-nsynth-super" ["l"="38.545,3.904", "c"=201]
"minimaxir/person-blocker" ["l"="45.494,25.922", "c"=68]
"hzy46/TensorFlow-Time-Series-Examples" ["l"="-9.319,12.521", "c"=105]
"voletiv/self-attention-GAN-pytorch" ["l"="45.89,28.876"]
"adobe/antialiased-cnns" ["l"="51.025,30.168", "c"=83]
"willylulu/celeba-hq-modified" ["l"="46.016,28.831"]
"willylulu/RelGAN" ["l"="46.053,28.784"]
"nperraud/download-celebA-HQ" ["l"="46.028,28.79"]
"LynnHo/HD-CelebA-Cropper" ["l"="45.989,28.9"]
"imlixinyang/HiSD" ["l"="44.836,30.487", "c"=243]
"younesbelkada/interfacegan" ["l"="46.069,28.81"]
"khanrc/tf.gans-comparison" ["l"="46.006,29.159"]
"hmi88/BEGAN-tensorflow" ["l"="46.04,29.146"]
"GKalliatakis/Delving-deep-into-GANs" ["l"="45.941,29.151"]
"carpedm20/BEGAN-tensorflow" ["l"="45.962,29.183"]
"minhnhat93/tf-SNDCGAN" ["l"="46.026,29.055"]
"kodalinaveen3/DRAGAN" ["l"="-34.723,20.362", "c"=1031]
"clvrai/SSGAN-Tensorflow" ["l"="46.029,29.158"]
"shekkizh/WassersteinGAN.tensorflow" ["l"="45.991,29.202"]
"pfnet-research/chainer-gan-lib" ["l"="-34.723,20.405", "c"=1031]
"ikostrikov/TensorFlow-VAE-GAN-DRAW" ["l"="46.036,29.287"]
"carpedm20/simulated-unsupervised-tensorflow" ["l"="45.974,29.225"]
"sanghoon/tf-exercise-gan" ["l"="46.115,29.159"]
"mjdietzx/SimGAN" ["l"="46.056,29.231"]
"fairytale0011/Conditional-WassersteinGAN" ["l"="46.083,29.14"]
"artix41/awesome-transfer-learning" ["l"="51.309,37.61", "c"=678]
"Kyfafyd/MirrorGAN" ["l"="45.544,29.188"]
"lucidrains/stylegan2-pytorch" ["l"="45.022,30.64", "c"=243]
"eladrich/pixel2style2pixel" ["l"="44.901,30.655", "c"=243]
"YixinChen-AI/CVAE-GAN-zoos-PyTorch-Beginner" ["l"="-52.232,-15.04", "c"=1184]
"hujinsen/pytorch_VAE_CVAE" ["l"="46.277,29.378"]
"sksq96/pytorch-vae" ["l"="46.31,29.361"]
"unnir/cVAE" ["l"="46.287,29.393"]
"hwalsuklee/tensorflow-mnist-CVAE" ["l"="46.189,29.366"]
"emited/VariationalRecurrentNeuralNetwork" ["l"="45.048,27.582", "c"=789]
"ucals/cvae" ["l"="46.264,29.397"]
"YannDubs/disentangling-vae" ["l"="23.073,14.285", "c"=505]
"marcbelmont/cnn-watermark-removal" ["l"="-34.215,22.455", "c"=429]
"google-research/exoplanet-ml" ["l"="20.429,14.772", "c"=719]
"reiinakano/gan-playground" ["l"="50.97,31.01", "c"=83]
"yusuketomoto/chainer-fast-neuralstyle" ["l"="45.645,29.431"]
"pauli-space/foundations_for_deep_learning" ["l"="47.584,28.695", "c"=89]
"awentzonline/image-analogies" ["l"="45.679,29.376"]
"ajbrock/Neural-Photo-Editor" ["l"="45.764,29.325"]
"tomepel/Technical_Book_DL" ["l"="47.532,28.735", "c"=89]
"msracver/Deep-Image-Analogy" ["l"="45.751,29.393"]
"kaonashi-tyc/Rewrite" ["l"="46.605,7.606", "c"=148]
"eridgd/WCT-TF" ["l"="44.952,28.749", "c"=771]
"sunshineatnoon/PytorchWCT" ["l"="45.002,28.722", "c"=771]
"ProGamerGov/neural-style-pt" ["l"="44.898,28.722", "c"=771]
"titu1994/Neural-Style-Transfer" ["l"="45.617,29.387"]
"cysmith/neural-style-tf" ["l"="45.643,29.367"]
"salesforce/decaNLP" ["l"="53.027,25.606", "c"=172]
"higgsfield-ai/higgsfield" ["l"="57.619,18.064", "c"=45]
"NVIDIA/waveglow" ["l"="37.21,2.503", "c"=117]
"AppliedDataSciencePartners/DeepReinforcementLearning" ["l"="58.481,17.189", "c"=803]
"IntelLabs/nlp-architect" ["l"="52.943,25.66", "c"=172]
"pytorchbearer/torchbearer" ["l"="23.733,15.07", "c"=728]
"cgnorthcutt/benchmarking-keras-pytorch" ["l"="45.625,28.816"]
"zhangqianhui/progressive_growing_of_gans_tensorflow" ["l"="45.921,28.883"]
"dongjun-Lee/text-classification-models-tf" ["l"="53.421,28.822", "c"=1200]
"ShinyCode/image-outpainting" ["l"="45.605,28.9"]
"nadavbh12/VQ-VAE" ["l"="23.154,14.287", "c"=505]
"hsinyilin19/ResNetVAE" ["l"="46.378,29.393"]
"julianstastny/VAE-ResNet18-PyTorch" ["l"="46.417,29.408"]
"jan-xu/autoencoders" ["l"="46.451,29.415"]
"kozistr/Awesome-GANs" ["l"="45.941,29.042"]
"totalgood/nlpia" ["l"="48.321,27.913", "c"=89]
"kwotsin/mimicry" ["l"="44.931,30.503", "c"=243]
"StacyYang/gluoncv-torch" ["l"="53.444,31.022", "c"=155]
"SiskonEmilia/StyleGAN-PyTorch" ["l"="45.073,30.496", "c"=243]
"jalola/improved-wgan-pytorch" ["l"="45.986,29.028"]
"Zeleni9/pytorch-wgan" ["l"="45.967,29.052"]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Pytorch" ["l"="46.013,28.995"]
"EmilienDupont/wgan-gp" ["l"="46.004,29.012"]
"clvrai/ACGAN-PyTorch" ["l"="46.056,28.986"]
"znxlwm/pytorch-MNIST-CelebA-GAN-DCGAN" ["l"="46.002,29.048"]
"eveningglow/multitask-CycleGAN" ["l"="46.084,29.017"]
"taey16/pix2pixBEGAN.pytorch" ["l"="46.05,29.072"]
"carpedm20/BEGAN-pytorch" ["l"="46.019,29.116"]
"aysunrhn/Adaptive-Soft-Sensor-Design" ["l"="46.539,29.726"]
"hkaneko1985/adaptive_soft_sensors" ["l"="46.534,29.705"]
"JustusvLiebig/Inferential_Sensor_Experiment" ["l"="46.549,29.748"]
"Yijunmaverick/UniversalStyleTransfer" ["l"="44.995,28.739", "c"=771]
"jerryli27/TwinGAN" ["l"="-34.907,20.445", "c"=1031]
"jhoffman/cycada_release" ["l"="51.577,37.19", "c"=1244]
"Natsu6767/InfoGAN-PyTorch" ["l"="23.015,14.171", "c"=505]
"openai/InfoGAN" ["l"="45.954,29.255"]
"tengteng95/Pose-Transfer" ["l"="43.516,30.938", "c"=318]
"ZPdesu/SEAN" ["l"="44.792,30.553", "c"=243]
"taki0112/StarGAN-Tensorflow" ["l"="45.873,29.021"]
"vanhuyz/CycleGAN-TensorFlow" ["l"="45.876,29.136"]
"taki0112/DRIT-Tensorflow" ["l"="45.9,28.938"]
"taki0112/StarGAN_v2-Tensorflow" ["l"="47.699,27.134", "c"=323]
"xiaowei-hu/CycleGAN-tensorflow" ["l"="45.92,29.13"]
"leehomyc/cyclegan-1" ["l"="45.921,29.106"]
"pclucas14/pixel-cnn-pp" ["l"="23.119,14.369", "c"=505]
"openai/pixel-cnn" ["l"="45.952,29.278"]
"PrajitR/fast-pixel-cnn" ["l"="45.989,29.351"]
"woozzu/tagan" ["l"="45.609,29.131"]
"woozzu/dong_iccv_2017" ["l"="45.53,29.091"]
"vtddggg/BilinearGAN_for_LBIE" ["l"="45.548,29.096"]
"qiaott/LeicaGAN" ["l"="45.594,29.152"]
"mrlibw/ManiGAN" ["l"="45.584,29.14"]
"kmkolasinski/deep-learning-notes" ["l"="22.939,14.539", "c"=505]
"w86763777/pytorch-gan-collections" ["l"="45.303,31.293", "c"=605]
"znxlwm/pytorch-MNIST-CelebA-cGAN-cDCGAN" ["l"="46.045,29.046"]
"yfeng95/GAN" ["l"="45.832,29.088"]
"znxlwm/pytorch-CartoonGAN" ["l"="44.698,30.745", "c"=243]
"znxlwm/pytorch-Conditional-image-to-image-translation" ["l"="46.175,28.993"]
"zhuofupan/Pytorch-Deep-Neural-Networks" ["l"="51.093,31.02", "c"=83]
"JustusvLiebig/Soft_Sensor_Experiments" ["l"="46.561,29.731"]
"lllyasviel/MangaCraft" ["l"="-34.963,20.37", "c"=1031]
"aaronpenne/generative_art" ["l"="36.075,23.976", "c"=98]
"quolc/neural-collage" ["l"="-35.066,20.288", "c"=1031]
"LynnHo/DCGAN-LSGAN-WGAN-GP-DRAGAN-Tensorflow-2" ["l"="46.025,29.023"]
"facebookresearch/FaderNetworks" ["l"="45.995,28.955"]
"Guim3/IcGAN" ["l"="45.958,29.137"]
"zhangqianhui/Sparsely-Grouped-GAN" ["l"="46.033,28.892"]
"LynnHo/CycleGAN-Tensorflow-2" ["l"="45.957,29.075"]
"vlukiyanov/pt-dec" ["l"="53.072,29.759", "c"=547]
"vlukiyanov/pt-sdae" ["l"="46.434,29.583"]
"baudm/vaegan-celebs-keras" ["l"="46.141,29.275"]
"texturedesign/texturize" ["l"="44.754,31.556", "c"=1003]
"afruehstueck/tileGAN" ["l"="45.391,29.697"]
"yitong91/StoryGAN" ["l"="45.629,29.183"]
"CrickWu/Clevr-for-StoryGAN" ["l"="33.143,30.857", "c"=109]
"uvavision/Text2Scene" ["l"="45.604,29.176"]
"adymaharana/VLCStoryGan" ["l"="33.158,30.922", "c"=109]
"HRLTY/TP-GAN" ["l"="-35.41,21.033", "c"=127]
"jessemelpolio/non-stationary_texture_syn" ["l"="45.424,29.697"]
"MingtaoGuo/PatchMatch" ["l"="50.522,31.947", "c"=83]
"MingtaoGuo/Deep-image-analogy-TensorFlow" ["l"="46.256,28.929"]
"MingtaoGuo/sngan_projection_TensorFlow" ["l"="46.227,28.94"]
"rohitrango/Image-Quilting-for-Texture-Synthesis" ["l"="45.357,29.773"]
"afrozalm/Patch-Based-Texture-Synthesis" ["l"="45.378,29.749"]
"vigorfif/Soft-Sensor-Modelling" ["l"="46.555,29.717"]
"tonyzyl/Semisupervised-VAE-for-Regression-Application-on-Soft-Sensor" ["l"="46.573,29.716"]
"MingweiJia/GCN-based_soft_sensor" ["l"="46.578,29.73"]
"iamownt/LSTM-DeepFM" ["l"="46.561,29.706"]
"zalandoresearch/famos" ["l"="45.414,29.743"]
"zalandoresearch/psgan" ["l"="45.407,29.763"]
"dvlab-research/Facelet_Bank" ["l"="46.04,28.917"]
"paulu/deepfeatinterp" ["l"="46.039,28.935"]
"Zhongdao/FaceAttributeManipulation" ["l"="46.035,29.007"]
"Yijunmaverick/CartoonGAN-Test-Pytorch-Torch" ["l"="44.71,30.767", "c"=243]
"taki0112/UNIT-Tensorflow" ["l"="46.076,28.92"]
"shaoanlu/MUNIT-keras" ["l"="45.94,28.892"]
"clvrai/BicycleGAN-Tensorflow" ["l"="45.933,28.802"]
"taki0112/Spectral_Normalization-Tensorflow" ["l"="46.11,28.967"]
"harveyslash/PatchMatch" ["l"="50.539,31.967", "c"=83]
"y0ast/VAE-Torch" ["l"="45.963,27.658", "c"=277]
"y0ast/Variational-Autoencoder" ["l"="46.219,29.378"]
"RuiShu/cvae" ["l"="46.195,29.386"]
"preritj/progressive_growing_of_GANs" ["l"="45.926,28.83"]
"nnUyi/PGGAN" ["l"="45.92,28.842"]
"akanimax/fagan" ["l"="45.972,28.871"]
"ANIME305/Anime-GAN-tensorflow" ["l"="-34.805,20.498", "c"=1031]
"mansimov/text2image" ["l"="45.853,29.279"]
"reedscot/cvpr2016" ["l"="45.816,29.223"]
"LukeDitria/CNN-VAE" ["l"="46.345,29.366"]
"lyeoni/pytorch-mnist-VAE" ["l"="46.39,29.362"]
"foamliu/Autoencoder" ["l"="46.341,29.439"]
"coolvision/vae_conv" ["l"="46.341,29.386"]
"o-tawab/Variational-Autoencoder-pytorch" ["l"="46.341,29.401"]
"chenxi116/PNASNet.pytorch" ["l"="52.954,34.063", "c"=708]
"shrubb/box-convolutions" ["l"="50.845,30.616", "c"=83]
"fastai/fastai_old" ["l"="49.383,28.538", "c"=1136]
"20100507/emotional_analysis" ["l"="-1.678,16.671", "c"=406]
"cleardusk/MeGlass" ["l"="33.175,29.292", "c"=57]
"tducret/amazon-scraper-python" ["l"="47,23.502", "c"=1065]
"schelotto/Wasserstein-AutoEncoders" ["l"="22.921,14.25", "c"=505]
"neale/Adversarial-Autoencoder" ["l"="46.184,29.483"]
"maitek/waae-pytorch" ["l"="46.185,29.503"]
"dragen1860/pytorch-mnist-vae" ["l"="46.419,29.375"]
"lyeoni/pytorch-mnist-CVAE" ["l"="46.433,29.366"]
"ShayanPersonal/stacked-autoencoder-pytorch" ["l"="46.412,29.584"]
"zhangxu0307/stack-autoencoder" ["l"="46.477,29.649"]
"pranjaldatta/Denoising-Autoencoder-in-Pytorch" ["l"="46.419,29.616"]
"MadhumitaSushil/SDAE" ["l"="46.436,29.561"]
"haohlin/SDAE_pytorch" ["l"="46.453,29.608"]
"crcrpar/pytorch.sngan_projection" ["l"="45.958,28.989"]
"MingtaoGuo/Deep-Feature-Interporlation-Face-Attribute-manipulation-Glasses-Remove-Youth2Senior-etc.-TensorFlow" ["l"="46.307,28.872"]
"MingtaoGuo/CapsuleNet_Tensorflow" ["l"="46.283,28.914"]
"MingtaoGuo/ContextEncoder_Cat-s_head_Inpainting_TensorFlow" ["l"="46.283,28.893"]
"lecomte/glasses-removal-gan" ["l"="46.371,28.805"]
"JubilantJerry/CNN-Glasses-Remover" ["l"="46.383,28.79"]
"ash11sh/remove-glass" ["l"="46.419,28.759"]
"ctallec/pyvarinf" ["l"="22.366,15.284", "c"=977]
"tohinz/semantic-object-accuracy-for-generative-text-to-image-synthesis" ["l"="45.614,29.157"]
"robbiebarrat/plant-art" ["l"="45.937,29.587"]
"robbiebarrat/Bach_AI" ["l"="45.96,29.64"]
"robbiebarrat/Sculpture-GAN" ["l"="45.948,29.624"]
"chenhsuanlin/spatial-transformer-GAN" ["l"="46.016,28.935"]
"chenhsuanlin/inverse-compositional-STN" ["l"="45.795,27.724", "c"=277]
"azadis/CompositionalGAN" ["l"="46.066,28.879"]
"jwyang/lr-gan.pytorch" ["l"="46.079,28.859"]
"xiaolonw/ss-gan" ["l"="45.951,29.231"]
"Prinsphield/GeneGAN" ["l"="46.016,28.917"]
"kimhc6028/acgan-pytorch" ["l"="46.093,28.953"]
"Hydrino/ACGAN_cifar10" ["l"="46.115,28.946"]
"LynnHo/Conditional-GANs-Pytorch" ["l"="46.093,28.993"]
"ustclby/Unsupervised-Domain-Specific-Deblurring" ["l"="-34.806,21.331", "c"=127]
"taki0112/Switchable_Normalization-Tensorflow" ["l"="46.165,28.933"]
"taki0112/pix2pix-Tensorflow" ["l"="46.15,28.951"]
"taki0112/Group_Normalization-Tensorflow" ["l"="46.148,28.93"]
"chen0040/keras-text-to-image" ["l"="45.731,29.184"]
"hellochick/text-to-image" ["l"="45.692,29.23"]
"vibertthio/awesome-machine-learning-art" ["l"="32.996,24.051", "c"=662]
"toodef/neural-pipeline" ["l"="50.855,30.695", "c"=83]
"conan7882/adversarial-autoencoders" ["l"="46.178,29.444"]
"Naresh1318/Adversarial_Autoencoder" ["l"="46.161,29.427"]
"hwalsuklee/tensorflow-mnist-AAE" ["l"="46.176,29.399"]
"bfarzin/pytorch_aae" ["l"="46.192,29.468"]
"mingukkang/Adversarial-AutoEncoder" ["l"="46.202,29.431"]
"musyoku/adversarial-autoencoder" ["l"="46.138,29.429"]
"llSourcell/Pokemon_GAN" ["l"="49.877,26.811", "c"=791]
"uclaacmai/Generative-Adversarial-Network-Tutorial" ["l"="46.138,29.213"]
"gsurma/image_generator" ["l"="45.91,29.607"]
"gsurma/face_generator" ["l"="45.911,29.575"]
"tensorflow/gan" ["l"="45.892,28.992"]
"justinpinkney/awesome-pretrained-stylegan2" ["l"="44.939,30.589", "c"=243]
"dongb5/GAN-Timeline" ["l"="45.958,29.037"]
"yhlleo/GAN-Metrics" ["l"="45.944,28.92"]
"wxs/subjective-functions" ["l"="45.394,29.724"]
"Yijunmaverick/MultiTextureSynthesis" ["l"="45.357,29.745"]
"manuelruder/fast-artistic-videos" ["l"="44.908,28.694", "c"=771]
"manuelruder/artistic-videos" ["l"="45.673,29.408"]
"zeruniverse/fast-artistic-videos" ["l"="45.635,29.485"]
"leongatys/DeepTextures" ["l"="45.541,29.577"]
"dashayushman/TAC-GAN" ["l"="45.585,29.011"]
"gazijarin/AdamAI" ["l"="45.523,29.778"]
"gazijarin/OdinBot" ["l"="45.54,29.775"]
"dpkingma/nips14-ssl" ["l"="45.021,27.691", "c"=789]
"casperkaae/parmesan" ["l"="44.965,27.651", "c"=789]
"jych/nips2015_vrnn" ["l"="45.001,27.623", "c"=789]
"caglar/autoencoders" ["l"="46.296,29.452"]
"mikesj-public/convolutional_autoencoder" ["l"="46.385,29.457"]
"y0ast/Variational-Recurrent-Autoencoder" ["l"="45.018,27.578", "c"=789]
"jbornschein/draw" ["l"="44.914,27.67", "c"=789]
"jych/cle" ["l"="44.974,27.633", "c"=789]
"yburda/iwae" ["l"="44.992,27.647", "c"=789]
"skaae/lasagne-draw" ["l"="44.9,27.647", "c"=789]
"mila-iqia/blocks" ["l"="44.867,27.695", "c"=789]
"cientgu/Mask_Guided_Portrait_Editing" ["l"="46.016,28.754"]
"baoqianyue/GANCalligraphy" ["l"="46.425,28.842"]
"MingtaoGuo/DCGAN_WGAN_WGAN-GP_LSGAN_SNGAN_RSGAN_BEGAN_ACGAN_PGGAN_TensorFlow" ["l"="46.202,28.969"]
"he-zh/vibration_gan" ["l"="51.382,38.016", "c"=545]
"MingtaoGuo/CycleGAN" ["l"="46.267,28.924"]
"MingtaoGuo/Summary-of-deep-learning-papers" ["l"="46.266,28.935"]
"MingtaoGuo/DnCNN-Denoise-Gaussian-noise-TensorFlow" ["l"="46.249,28.922"]
"MingtaoGuo/Learning-Residual-Images-for-Face-Attribute-Manipulation" ["l"="46.267,28.913"]
"MingtaoGuo/Semantic-Image-Inpainting-face-inpainting-TensorFlow" ["l"="46.257,28.945"]
"MingtaoGuo/FormResNet-Denoise-Gaussian-noise-TensorFlow" ["l"="46.246,28.939"]
"LitoNeo/pytorch-AutoEncoders" ["l"="46.345,29.538"]
"CLaraRR/autoencoder_practice" ["l"="46.378,29.503"]
"Kaixhin/Autoencoders" ["l"="45.99,27.652", "c"=277]
"zhangxiaoling/Bearing-fault-detection" ["l"="51.546,37.982", "c"=545]
"erickrf/autoencoder" ["l"="52.522,14.637", "c"=569]
"taki0112/SPADE-Tensorflow" ["l"="44.684,30.645", "c"=243]
"azadis/MC-GAN" ["l"="46.691,7.623", "c"=148]
"Prinsphield/DNA-GAN" ["l"="46.035,28.869"]
"zhangqianhui/GazeAnimationV2" ["l"="44.426,30.471", "c"=243]
"rosinality/sagan-pytorch" ["l"="45.872,28.888"]
"LDOUBLEV/style_transfer-perceptual_loss" ["l"="45.536,29.459"]
"ShafeenTejani/fast-style-transfer" ["l"="44.8,28.791", "c"=771]
"stormraiser/GAN-weight-norm" ["l"="46.046,28.959"]
"diux-dev/cluster" ["l"="45.547,28.784"]
"tolstikhin/wae" ["l"="22.975,14.265", "c"=505]
"xjqicuhk/SIMS" ["l"="45.875,29.347"]
"xcyan/neurips18_hierchical_image_manipulation" ["l"="45.875,29.391"]
"PaperWeeklyCode/GAN-discussions" ["l"="46.028,29.073"]
"guojunq/lsgan" ["l"="45.996,29.184"]
"kimiyoung/ssl_bad_gan" ["l"="51.503,30.292", "c"=83]
"mafda/generative_adversarial_networks_101" ["l"="46.237,29.031"]
"znxlwm/tensorflow-MNIST-cGAN-cDCGAN" ["l"="46.13,29.046"]
"simontomaskarlsson/CycleGAN-Keras" ["l"="61.998,36.524", "c"=178]
"malzantot/Pytorch-conditional-GANs" ["l"="46.062,29.023"]
"sgugger/Deep-Learning" ["l"="49.374,28.622", "c"=1136]
"ranahanocka/MeshCNN" ["l"="63.652,1.289", "c"=134]
"timsainb/Tensorflow-MultiGPU-VAE-GAN" ["l"="46.028,29.27"]
"TDAmeritrade/stumpy" ["l"="45.458,26.319", "c"=68]
"interpretml/interpret" ["l"="45.309,26.145", "c"=68]
"mesolitica/NLP-Models-Tensorflow" ["l"="53.525,27.257", "c"=60]
"timsainb/GAIA" ["l"="46.066,29.088"]
"znxlwm/pytorch-CycleGAN" ["l"="46.077,29.001"]
"Yangyangii/GAN-Tutorial" ["l"="46.15,29.067"]
"Yangyangii/pytorch-practice" ["l"="46.199,29.052"]
"WICWIU/WICWIU" ["l"="-5.005,-22.928", "c"=164]
"csinva/gan-vae-pretrained-pytorch" ["l"="46.274,29.158"]
"JPlin/Relabeled-HELEN-Dataset" ["l"="46.042,28.699"]
"Eskender-B/roi-tanh" ["l"="46.025,28.703"]
"Eskender-B/icnn" ["l"="46.03,28.684"]
"aod321/Face-parsing-via-tanh-warping" ["l"="46.055,28.672"]
"enomotokenji/pytorch-Neural-Style-Transfer" ["l"="46.334,28.857"]
"MingtaoGuo/Style-transfer-with-neural-algorithm" ["l"="46.303,28.893"]
"dongdongdong666/CPGAN" ["l"="45.605,29.145"]
"Sleepychord/ImprovedGAN-pytorch" ["l"="51.524,30.282", "c"=83]
"zhenxuan00/triple-gan" ["l"="46.121,29.064"]
"eveningglow/BicycleGAN-pytorch" ["l"="46.158,28.972"]
"CQFIO/FastImageProcessing" ["l"="-33.867,23.094", "c"=616]
"CQFIO/PhotographicImageSynthesis" ["l"="45.862,29.183"]
"crisbodnar/text-to-image" ["l"="45.746,29.282"]
"paarthneekhara/text-to-image" ["l"="45.781,29.258"]
"reedscot/nips2016" ["l"="45.889,29.247"]
"Rakshith-Manandi/text-to-image-using-GAN" ["l"="45.727,29.287"]
"tatsy/keras-generative" ["l"="46.451,29.258"]
"One-sixth/CVAE-GAN_tensorlayer" ["l"="46.426,29.256"]
"yanzhicong/VAE-GAN" ["l"="46.443,29.292"]
"chloeguoqing/Towards-Open-Set-Identity-Preserving-Face-Synthesis" ["l"="46.439,29.275"]
"ToniCreswell/attribute-cVAEGAN" ["l"="46.466,29.282"]
"arturml/pytorch-wgan-gp" ["l"="46.039,28.984"]
"hollobit/All-About-the-GAN" ["l"="45.934,29.077"]
"shawnyuen/gans_paper_collection" ["l"="46.008,29.032"]
"xinario/SAGAN" ["l"="-35.539,23.529", "c"=630]
"sjchoi86/bayes-nn" ["l"="22.403,15.348", "c"=977]
"albarqouni/Deep-Learning-for-Medical-Applications" ["l"="61.943,36.874", "c"=178]
"togheppi/cDCGAN" ["l"="46.096,29.033"]
"dansuh17/alexnet-pytorch" ["l"="46.236,28.686"]
"Lornatang/AlexNet-PyTorch" ["l"="46.208,28.727"]
"fducau/AAE_pytorch" ["l"="46.167,29.471"]
"yoonsanghyu/AAE-PyTorch" ["l"="46.179,29.46"]
"shaohua0116/VAE-Tensorflow" ["l"="46.185,29.346"]
"Chung-I/Variational-Recurrent-Autoencoder-Tensorflow" ["l"="57.731,29.32", "c"=1082]
"gaborvecsei/CDCGAN-Keras" ["l"="46.208,29.021"]
"sarahwolf32/conditional-DCGAN-for-MNIST" ["l"="46.247,29.01"]
"taki0112/Tensorflow-DatasetAPI" ["l"="46.128,28.924"]
"taki0112/TripleGAN-Tensorflow" ["l"="46.15,28.997"]
"taki0112/DiscoGAN-Tensorflow" ["l"="46.142,28.939"]
"taki0112/CycleGAN-Tensorflow" ["l"="46.155,28.943"]
"ramarlina/DenoisingAutoEncoder" ["l"="46.433,29.534"]
"rajarsheem/libsdae-autoencoder-tensorflow" ["l"="46.461,29.555"]
"9310gaurav/ali-pytorch" ["l"="46.225,29.452"]
"jeffdonahue/bigan" ["l"="46.186,29.42"]
"fmu2/Wasserstein-BiGAN" ["l"="46.23,29.438"]
"WilliBee/bigan_SRL" ["l"="46.222,29.468"]
"mperezcarrasco/PyTorch-BiGAN" ["l"="46.249,29.476"]
"MingtaoGuo/Real-Time-Arbitrary-Style-Transfer-AdaIN-TensorFlow" ["l"="46.327,28.878"]
"changebo/HCCG-CycleGAN" ["l"="46.641,7.573", "c"=148]
"Hyeokreal/ali_bigan_mnist_pytorch" ["l"="46.237,29.494"]
"codyznash/GANs_for_Credit_Card_Data" ["l"="46.209,29.234"]
"mjdietzx/GAN-Sandbox" ["l"="46.145,29.239"]
"krantirk/Credit-GANS" ["l"="46.247,29.232"]
"taki0112/FusionGAN-Tensorflow" ["l"="45.896,28.82"]
"MingtaoGuo/CartoonGAN-tensorflow" ["l"="46.3,28.928"]
"yzwxx/vae-celebA" ["l"="46.286,29.299"]
"houxianxu/DFC-VAE" ["l"="46.341,29.286"]
"architrathore/CycleGAN" ["l"="45.94,29.114"]
"hardikbansal/CycleGAN" ["l"="45.947,29.103"]
"goldkim92/StarGAN-tensorflow" ["l"="46.002,29.099"]
"LingDong-/edges2calligraphy" ["l"="46.417,28.877"]
"herrkaefer/chinese-calligraphy-vectorization" ["l"="46.429,28.862"]
"komiya-m/MirrorGAN" ["l"="45.591,29.125"]
"LDOUBLEV/semi-supervised-GAN" ["l"="51.545,30.295", "c"=83]
"taki0112/DCGAN-Tensorflow" ["l"="46.155,28.92"]
"LynnHo/f-GAN-Tensorflow" ["l"="44.004,31.381", "c"=1277]
"kvmanohar22/img2imgGAN" ["l"="45.94,28.774"]
"podgorskiy/VAE" ["l"="46.359,29.351"]
"zhangqianhui/Residual_Image_Learning_GAN" ["l"="46.062,28.833"]
"utsav-195/text-to-image-generator-gan" ["l"="45.726,29.315"]
"shaohua0116/DCGAN-Tensorflow" ["l"="46.225,28.996"]
"4thgen/DCGAN-CIFAR10" ["l"="46.263,28.987"]
"dannysdeng/selu" ["l"="46.026,28.959"]
"christiancosgrove/pytorch-sagan" ["l"="46.025,28.975"]
"davrempe/domain-transfer-net" ["l"="45.909,29.385"]
"taey16/DomainTransferNetwork.pytorch" ["l"="45.907,29.356"]
"akanimax/attn_gan_pytorch" ["l"="45.986,28.838"]
"HelenMao/SAVI2I" ["l"="45.835,28.77"]
"LiqunChen0606/Triangle-GAN" ["l"="46.174,29.021"]
"togheppi/pix2pix" ["l"="46.133,29.01"]
"znxlwm/pytorch-pix2pix" ["l"="46.111,29.015"]
"TeeyoHuang/pix2pix-pytorch" ["l"="46.12,29.001"]
"taki0112/Batch_Instance_Normalization-Tensorflow" ["l"="46.198,28.898"]
"taki0112/StableGAN-Tensorflow" ["l"="46.168,28.922"]
"rahulbhalley/turing-gan" ["l"="46.437,29.052"]
"deezer/spleeter" ["l"="38.304,1.386", "c"=54]
"AliaksandrSiarohin/first-order-model" ["l"="45.006,30.941", "c"=243]
"alex-damian/pulse" ["l"="45.044,30.834", "c"=243]
"openai/jukebox" ["l"="38.669,1.782", "c"=54]
"karpathy/neuraltalk" ["l"="47.92,28.94", "c"=89]
"Newmu/dcgan_code" ["l"="45.835,29.256"]
"cs231n/cs231n.github.io" ["l"="48.069,28.667", "c"=89]
"keras-team/keras-io" ["l"="45.781,25.699", "c"=68]
"Ha0Tang/BiGraphGAN" ["l"="44.579,30.499", "c"=243]
"TachibanaYoshino/AnimeGANv2" ["l"="44.846,30.779", "c"=243]
"nagadomi/lbpcascade_animeface" ["l"="-34.885,20.441", "c"=1031]
"websockets/wscat" ["l"="46.121,29.132"]
"vi/websocat" ["l"="-9.939,-5.942", "c"=5]
"typelevel/cats-effect" ["l"="-2.643,18.762", "c"=38]
"Endava/cats" ["l"="-13.451,-5.876", "c"=86]
"nyaadevs/nyaa" ["l"="-36.455,20.834", "c"=597]
"owenthereal/ccat" ["l"="22.793,-26.496", "c"=28]
"websockets/ws" ["l"="-0.177,-34.101", "c"=110]
"typelevel/cats" ["l"="-2.672,18.613", "c"=38]
"Luohuayu/CatServer" ["l"="-54.411,-14.578", "c"=301]
"absolute-quantum/cats-blender-plugin" ["l"="-32.799,-28.018", "c"=185]
"harthur/kittydar" ["l"="23.515,14.259", "c"=505]
"websocket-client/websocket-client" ["l"="44.441,20.934", "c"=20]
"aws-samples/simple-websockets-chat-app" ["l"="10.559,-2.969", "c"=129]
"junyanz/CatPapers" ["l"="45.862,29.204"]
"aladdinpersson/Machine-Learning-Collection" ["l"="47.866,26.156", "c"=323]
"NervanaSystems/neon" ["l"="47.851,29.03", "c"=89]
"andersbll/deeppy" ["l"="48.009,28.516", "c"=89]
"andersbll/neural_artistic_style" ["l"="45.619,29.444"]
"bloc97/Anime4K" ["l"="-36.308,20.857", "c"=597]
"junhyukoh/caffe-lstm" ["l"="47.75,34.06", "c"=168]
"Russell91/apollocaffe" ["l"="45.814,29.612"]
"toshas/torch-fidelity" ["l"="45.76,31.483", "c"=605]
"zhangqianhui/GazeAnimation" ["l"="44.496,30.479", "c"=243]
"amperser/proselint" ["l"="22.985,-26.636", "c"=28]
"soumith/dcgan.torch" ["l"="45.866,29.246"]
"KaimingHe/deep-residual-networks" ["l"="50.538,33.165", "c"=314]
"karpathy/recurrentjs" ["l"="23.411,14.391", "c"=505]
"facebookarchive/eyescream" ["l"="45.858,29.323"]
"Lasagne/Lasagne" ["l"="47.886,29.002", "c"=89]
"LingDong-/cope" ["l"="53.536,28.156", "c"=60]
"VITA-Group/AutoGAN" ["l"="52.903,34.054", "c"=708]
"oreillymedia/t-SNE-tutorial" ["l"="44.904,26.17", "c"=68]
"WisconsinAIVision/MixNMatch" ["l"="44.859,30.606", "c"=243]
"clovaai/tunit" ["l"="44.744,30.524", "c"=243]
"EuphoriaYan/zi2zi-pytorch" ["l"="46.756,7.578", "c"=148]
"Xtra-Computing/thundersvm" ["l"="45.427,26.182", "c"=68]
"jsvine/markovify" ["l"="53.404,25.739", "c"=172]
"robbiebarrat/rapping-neural-network" ["l"="45.921,29.646"]
"advimman/HiDT" ["l"="44.749,30.573", "c"=243]
"manicman1999/StyleGAN2-Tensorflow-2.0" ["l"="45.056,30.582", "c"=243]
"LingDong-/skeleton-tracing" ["l"="46.522,28.832"]
"navis-org/skeletor" ["l"="64.069,0.878", "c"=134]
"mmkamani7/SkeletonMatching" ["l"="46.554,28.841"]
"FlorisSteenkamp/MAT" ["l"="46.546,28.8"]
"LingDong-/chinese-hershey-font" ["l"="46.572,28.82"]
"LingDong-/linedraw" ["l"="37.418,25.051", "c"=1123]
"SHI-Labs/SGL-Retinal-Vessel-Segmentation" ["l"="61.542,37.603", "c"=1043]
"crockpotveggies/tinderbox" ["l"="22.527,-26.375", "c"=28]
"Lornatang/pytorch-alexnet-cifar100" ["l"="46.165,28.786"]
"gazijarin/TDSBHomeworkManagement" ["l"="45.557,29.773"]
"google-research/lag" ["l"="45.73,28.827"]
"nccuviplab/CursiveChineseCalligraphyDataset" ["l"="46.405,28.831"]
"Jackson-Kang/Pytorch-VAE-tutorial" ["l"="46.345,29.334"]
"Jackson-Kang/Pytorch-Diffusion-Model-Tutorial" ["l"="46.427,29.343"]
"HGU-DLLAB/Korean-FastSpeech2-Pytorch" ["l"="-5.18,-22.999", "c"=164]
"williamFalcon/pytorch-lightning-vae" ["l"="46.41,29.324"]
"zalandoresearch/pytorch-vq-vae" ["l"="23.144,14.265", "c"=505]
"peterldowns/clickbait-classifier" ["l"="46.002,29.796"]
"saurabhmathur96/clickbait-detector" ["l"="46.005,29.768"]
"siefkenj/2020-MAT-335-webpage" ["l"="45.557,29.677"]
"slakh96/no-mans-land" ["l"="45.565,29.66"]
"jd-opensource/lapa-dataset" ["l"="44.412,31.339", "c"=1277]
"mit-han-lab/gan-compression" ["l"="44.956,30.534", "c"=243]
"boschresearch/unetgan" ["l"="44.871,30.437", "c"=243]
"Ha0Tang/XingGAN" ["l"="44.567,30.492", "c"=243]
"IIGROUP/TediGAN" ["l"="44.911,30.498", "c"=243]
"maincarry/R-Precision" ["l"="45.55,29.125"]
"google-research/trecs_image_generation" ["l"="45.533,29.131"]
"lisadunlap/VAE-GAN" ["l"="46.301,29.271"]
"tobran/GALIP" ["l"="45.438,29.089"]
"wtliao/text2image" ["l"="45.49,29.098"]
"senmaoy/RAT-GAN" ["l"="45.456,29.081"]
"google-research/xmcgan_image_generation" ["l"="45.533,29.114"]
"Ha0Tang/GestureGAN" ["l"="44.567,30.51", "c"=243]
"mrlibw/Lightweight-Manipulation" ["l"="45.516,29.125"]
"huiyegit/T2I_CL" ["l"="45.557,29.111"]
"BCV-Uniandes/SMIT" ["l"="46.076,28.749"]
"junrushao1994/ACM-ICPC-Standard-Code-Library" ["l"="45.524,29.523"]
"junrushao/Final-Fanatic-Facility" ["l"="45.536,29.514"]
"karpathy/char-rnn" ["l"="47.953,28.898", "c"=89]
"nagadomi/waifu2x" ["l"="-36.363,20.889", "c"=597]
"google/deepdream" ["l"="48.004,28.963", "c"=89]
"graphific/DeepDreamVideo" ["l"="45.714,29.502"]
"alexjc/neural-doodle" ["l"="45.573,29.338"]
"gazijarin/Gazi" ["l"="45.543,29.746"]
"gazijarin/Truth" ["l"="45.519,29.759"]
"hardikvasa/google-images-download" ["l"="50.641,29.827", "c"=83]
"VITA-Group/TransGAN" ["l"="45.009,30.516", "c"=243]
"tonybaloney/vscode-pets" ["l"="40.531,5.657", "c"=1506]
"soumith/cvpr2015" ["l"="46.053,27.648", "c"=277]
"jcjohnson/cnn-vis" ["l"="45.789,29.543"]
"jrosebr1/bat-country" ["l"="45.767,29.568"]
"317070/Twitch-plays-LSD-neural-net" ["l"="45.782,29.588"]
"samim23/DeepDreamAnim" ["l"="45.753,29.597"]
"wojciechz/learning_to_execute" ["l"="46.029,27.692", "c"=277]
"Russell91/apollo" ["l"="45.818,29.589"]
"ajtulloch/dnngraph" ["l"="-20.643,-20.065", "c"=118]
"auduno/deepdraw" ["l"="47.81,33.97", "c"=168]
"VISIONAI/clouddream" ["l"="45.74,29.575"]
"facebookarchive/fb-caffe-exts" ["l"="45.897,27.647", "c"=277]
"aravindhm/deep-goggle" ["l"="45.809,29.658"]
"stitchfix/fauxtograph" ["l"="44.981,27.613", "c"=789]
"skaae/recurrent-spatial-transformer-code" ["l"="45.832,27.683", "c"=277]
"fyu/lsun" ["l"="45.9,29.074"]
"leVirve/lsun-room" ["l"="64.598,2.303", "c"=649]
"GaParmar/clean-fid" ["l"="44.942,30.487", "c"=243]
"phizaz/diffae" ["l"="45.704,31.507", "c"=605]
"yosinski/deep-visualization-toolbox" ["l"="50.466,33.227", "c"=314]
"kelvinxu/arctic-captions" ["l"="48.524,31.903", "c"=300]
"ryankiros/skip-thoughts" ["l"="46.18,27.768", "c"=277]
"Lasagne/Recipes" ["l"="44.799,27.618", "c"=789]
"skaae/torch-gan" ["l"="45.979,27.637", "c"=277]
"twitter-archive/torch-autograd" ["l"="45.999,27.666", "c"=277]
"siemanko/tf-adversarial" ["l"="45.938,27.531", "c"=277]
"vivanov879/draw" ["l"="45.965,27.672", "c"=277]
"DmitryUlyanov/texture_nets" ["l"="45.704,29.409"]
"Evolving-AI-Lab/synthesizing" ["l"="45.9,29.312"]
"kesara/deepdreamer" ["l"="45.719,29.591"]
"ryankennedyio/deep-dream-generator" ["l"="45.714,29.572"]
"JohnMount/CaffeECSExample" ["l"="45.723,29.549"]
"chjj/ttystudio" ["l"="22.764,-26.572", "c"=28]
"tmadl/semisup-learn" ["l"="45.093,27.738", "c"=789]
"kxytim/DLVM_for_process_monitoring" ["l"="46.582,29.751"]
"teradeep/demo-apps" ["l"="45.813,27.569", "c"=277]
"CuriousAI/ladder" ["l"="44.988,27.703", "c"=789]
"Dhar/image-dreamer" ["l"="45.757,29.647"]
"mtyka/neural_artistic_style" ["l"="45.753,29.672"]
"samim23/NeuralTalkAnimator" ["l"="45.843,29.639"]
"samim23/GitXiv" ["l"="45.719,29.676"]
"ericjang/draw" ["l"="45.937,29.323"]
"bearpaw/clothing-co-parsing" ["l"="43.537,30.803", "c"=318]
"mjibson/ddd" ["l"="45.734,29.626"]
"graphific/dl-machine" ["l"="45.716,29.614"]
"herval/deepdream-docker" ["l"="45.703,29.635"]
"OverStruck/deep-dream-maker" ["l"="45.78,29.616"]
"EderSantana/seya" ["l"="44.839,27.696", "c"=789]
"phreeza/keras-GAN" ["l"="46.043,29.249"]
"Jackson-Kang/VQVC-Pytorch" ["l"="46.464,29.346"]
"Russell91/nlpcaffe" ["l"="47.715,34.1", "c"=168]
"jbmpark/image_invert" ["l"="45.805,29.683"]
"donglaiw/mNeuron" ["l"="45.825,29.705"]
"bharath272/sds_eccv2014" ["l"="45.798,29.706"]
"aravindhm/nnpreimage" ["l"="45.825,29.683"]
"Russell91/ReInspect" ["l"="50.615,33.083", "c"=314]
"an-kumar/caffe-theano-conversion" ["l"="44.843,27.612", "c"=789]
"yaole0720/VTR-based-Soft-Sensor" ["l"="46.554,29.768"]
"saturnism/deepdream-docker" ["l"="45.685,29.66"]
"nanopony/keras-convautoencoder" ["l"="46.478,29.492"]
"mikesj-public/dcgan-autoencoder" ["l"="46.466,29.459"]
"johnbuluba/Yatcobot" ["l"="45.938,29.909"]
"AuxProc/twitter-contest" ["l"="45.934,29.895"]
"bamos/dcgan-completion.tensorflow" ["l"="45.88,29.225"]
"MrGlockenspiel/activate-linux" ["l"="-16.446,-6.276", "c"=469]
"Discord-Datamining/Discord-Datamining" ["l"="-54.512,6.053", "c"=291]
"PrismLauncher/PrismLauncher" ["l"="-35.679,-11.838", "c"=136]
"mkrl/misbrands" ["l"="-16.519,-6.338", "c"=469]
"karpathy/neuraltalk2" ["l"="47.958,28.94", "c"=89]
"schollz/find" ["l"="23.334,-26.636", "c"=28]
"pavelgonchar/colornet" ["l"="45.547,29.409"]
"jazzsaxmafia/show_attend_and_tell.tensorflow" ["l"="48.521,31.967", "c"=300]
"jacobgil/keras-dcgan" ["l"="45.945,29.213"]
"mattya/chainer-DCGAN" ["l"="-34.747,20.426", "c"=1031]
"carpedm20/awesome-torch" ["l"="46.013,27.652", "c"=277]
"torch/nn" ["l"="46.061,27.628", "c"=277]
"Element-Research/rnn" ["l"="46.055,27.692", "c"=277]
"facebookarchive/fb.resnet.torch" ["l"="50.567,33.19", "c"=314]
"soumith/imagenet-multiGPU.torch" ["l"="45.989,27.619", "c"=277]
"ckmarkoh/neuralart_tensorflow" ["l"="45.659,29.551"]
"log0/neural-style-painting" ["l"="45.641,29.597"]
"woodrush/neural-art-tf" ["l"="45.689,29.454"]
"ckmarkoh/AcrosticPoem" ["l"="53.627,28.025", "c"=60]
"abalone0204/Clairvoyance" ["l"="22.286,1.923", "c"=208]
"ryankiros/visual-semantic-embedding" ["l"="58.327,8.321", "c"=1240]
"jiasenlu/AdaptiveAttention" ["l"="48.531,31.928", "c"=300]
"jcjohnson/densecap" ["l"="48.563,31.866", "c"=300]
"DeepRNN/image_captioning" ["l"="48.538,31.885", "c"=300]
"anishathalye/neural-style" ["l"="45.602,29.36"]
"BVLC/caffe" ["l"="48.066,29.002", "c"=89]
"apache/mxnet" ["l"="47.989,29.03", "c"=89]
"brendenlake/BPL" ["l"="46.082,27.87", "c"=277]
"szcom/rnnlib" ["l"="46.494,7.642", "c"=148]
"carpedm20/pixel-rnn-tensorflow" ["l"="46.002,29.322"]
"google/inception" ["l"="50.686,33.174", "c"=314]
"fzliu/style-transfer" ["l"="45.622,29.413"]
"ycjing/Neural-Style-Transfer-Papers" ["l"="44.978,28.75", "c"=771]
"ethereon/caffe-tensorflow" ["l"="50.47,33.139", "c"=314]
"robertsdionne/neural-network-papers" ["l"="47.868,28.908", "c"=89]
"jazzsaxmafia/show_and_tell.tensorflow" ["l"="48.496,31.964", "c"=300]
"Ivaylo-Popov/Theano-Lights" ["l"="44.911,27.656", "c"=789]
"siemanko/tensorflow-deepq" ["l"="57.297,18.086", "c"=45]
"chuanli11/MGANs" ["l"="45.72,29.436"]
"google/prettytensor" ["l"="47.797,28.994", "c"=89]
"coreylynch/async-rl" ["l"="57.327,18.126", "c"=45]
"NickShahML/tensorflow_with_latest_papers" ["l"="46.15,27.801", "c"=277]
"aleju/face-generator" ["l"="45.914,29.503"]
"aleju/cat-generator" ["l"="45.911,29.422"]
"achael/eht-imaging" ["l"="5.967,-20.25", "c"=96]
"andersbll/cudarray" ["l"="36.564,0.784", "c"=112]
"ryankiros/neural-storyteller" ["l"="46.237,27.713", "c"=277]
"mbartoli/neural-animation" ["l"="45.597,29.554"]
"chuanli11/CNNMRF" ["l"="45.716,29.387"]
"SergeyMorugin/ostagram" ["l"="45.643,29.404"]
"DmitryUlyanov/fast-neural-doodle" ["l"="45.677,29.472"]
"gabrieleangeletti/Deep-Learning-TensorFlow" ["l"="51.057,30.901", "c"=83]
"cmgreen210/TensorFlowDeepAutoencoder" ["l"="46.493,29.575"]
"tensorpack/tensorpack" ["l"="50.5,33.165", "c"=314]
"dschep/ntfy" ["l"="45.278,20.649", "c"=20]
"david-gpu/srez" ["l"="45.673,29.313"]
"davidADSP/Generative_Deep_Learning_2nd_Edition" ["l"="47.712,26.439", "c"=323]
"s9xie/hed" ["l"="53.108,30.749", "c"=155]
"zer0n/deepframeworks" ["l"="47.817,28.97", "c"=89]
"autumnai/leaf" ["l"="-8.132,-4.429", "c"=407]
"karpathy/arxiv-sanity-preserver" ["l"="47.807,28.898", "c"=89]
"oneThousand1000/HairMapper" ["l"="44.181,31.441", "c"=1277]
"StoryMY/take-off-eyeglasses" ["l"="46.461,28.718"]
"mansimov/unsupervised-videos" ["l"="41.476,25.711", "c"=537]
"IshmaelBelghazi/ALI" ["l"="46.084,29.341"]
"fogleman/ln" ["l"="37.295,25.122", "c"=1123]
"danieldjohnson/biaxial-rnn-music-composition" ["l"="38.642,3.966", "c"=201]
"ericjang/genadv_tutorial" ["l"="46.072,29.189"]
"AYLIEN/gan-intro" ["l"="46.009,29.203"]
"ry/tensorflow-vgg16" ["l"="50.37,33.222", "c"=314]
"lucidrains/nuwa-pytorch" ["l"="33.738,31.321", "c"=109]
"drboog/Lafite" ["l"="45.361,29.049"]
"tonywu95/eval_gen" ["l"="45.951,29.364"]
"rtqichen/style-swap" ["l"="44.972,28.781", "c"=771]
"leongatys/NeuralImageSynthesis" ["l"="44.939,28.804", "c"=771]
"qassemoquab/stnbhwd" ["l"="45.884,27.673", "c"=277]
"leehomyc/Faster-High-Res-Neural-Inpainting" ["l"="44.621,29.368", "c"=912]
"HFAiLab/clip-gen" ["l"="45.337,29.022"]
"hardmaru/sketch-rnn" ["l"="46.484,7.699", "c"=148]
"hardmaru/cppn-gan-vae-tensorflow" ["l"="46.053,29.336"]
"kurozael/twitter-contest-bot" ["l"="45.926,29.874"]
"robbiebarrat/twitter-contest-enterer" ["l"="45.935,29.816"]
"raulrene/twitter-contest-js-bot" ["l"="45.91,29.903"]
"robbiebarrat/Stock_advisor" ["l"="45.934,29.838"]
"erikbern/deep-fonts" ["l"="20.654,-0.583", "c"=557]
"DmitryUlyanov/online-neural-doodle" ["l"="45.632,29.51"]
"Evolving-AI-Lab/ppgn" ["l"="45.931,29.254"]
"drboog/Shifted_Diffusion" ["l"="45.32,29.037"]
"zhihengli-UR/StyleT2I" ["l"="45.325,29.055"]
"pystruct/pystruct" ["l"="53.172,27.664", "c"=60]
"cientgu/VQ-Diffusion" ["l"="46.573,30.538", "c"=367]
"mantasu/glasses-detector" ["l"="46.477,28.688"]
"Bingwen-Hu/ERGAN-Pytorch" ["l"="46.49,28.709"]
"jhayes14/GAN" ["l"="45.937,29.481"]
"mkeid/Texture-Synthesis" ["l"="45.505,29.618"]
"LabForComputationalVision/textureSynth" ["l"="45.516,29.6"]
"buriburisuri/ebgan" ["l"="46.056,29.277"]
"CasualGANPapers/Make-A-Scene" ["l"="46.615,30.503", "c"=367]
"avealle/dcgan-denosing-autoencoder" ["l"="46.518,29.455"]
"kundan2510/pixelCNN" ["l"="46.018,29.365"]
"pfnet-research/chainer-gogh" ["l"="-34.603,20.429", "c"=1031]
"osh/KerasGAN" ["l"="46.053,29.213"]
"AgnezIO/agnez" ["l"="44.792,27.703", "c"=789]
"hardmaru/write-rnn-tensorflow" ["l"="46.453,7.65", "c"=148]
"bamos/dream-art" ["l"="45.578,29.598"]
"LabForComputationalVision/matlabPyrTools" ["l"="62.676,35.594", "c"=1044]
"mtyka/neural-style" ["l"="45.751,29.699"]
"clementapa/CelebFaces_Attributes_Classification" ["l"="46.096,28.779"]
"analog-nico/twitter-reply-bot" ["l"="45.901,29.933"]
"takerum/adversarial_autoencoder" ["l"="46.128,29.475"]
"hjweide/adversarial-autoencoder" ["l"="46.142,29.482"]
"LouieYang/deep-photo-styletransfer-tf" ["l"="44.956,28.768", "c"=771]
"vdumoulin/conv_arithmetic" ["l"="50.771,29.68", "c"=83]
"maxpumperla/hyperas" ["l"="45.631,26.158", "c"=68]
"ibab/tensorflow-wavenet" ["l"="37.086,2.543", "c"=117]
"tensorflow/models" ["l"="48.134,28.884", "c"=89]
"facebookresearch/fastText" ["l"="53.043,25.835", "c"=172]
"jtoy/awesome-tensorflow" ["l"="47.814,28.742", "c"=89]
"openai/gym" ["l"="57.598,17.87", "c"=45]
"keras-team/keras" ["l"="48.067,28.867", "c"=89]
"tensorflow/tensor2tensor" ["l"="53.167,25.8", "c"=172]
"librosa/librosa" ["l"="38.441,4.098", "c"=201]
"terryum/awesome-deep-learning-papers" ["l"="47.852,28.669", "c"=89]
"Rochester-NRT/RocAlphaGo" ["l"="58.581,17.309", "c"=803]
"heuritech/convnets-keras" ["l"="24.163,14.512", "c"=1010]
"bijection/g9" ["l"="22.968,-27.149", "c"=28]
"somewacko/deconvfaces" ["l"="45.822,29.326"]
"dxa4481/Pastejacking" ["l"="-47.167,-34.475", "c"=204]
"PRML/PRMLT" ["l"="50.732,27.983", "c"=104]
"satoshiiizuka/siggraph2016_colorization" ["l"="-33.691,20.427", "c"=1190]
"carpedm20/variational-text-tensorflow" ["l"="53.382,26.364", "c"=993]
"tflearn/tflearn" ["l"="47.841,28.826", "c"=89]
"richzhang/colorization" ["l"="-33.719,20.398", "c"=1190]
"jisungk/deepjazz" ["l"="38.654,3.934", "c"=201]
"yenchenlin/DeepLearningFlappyBird" ["l"="57.339,17.946", "c"=45]
"IonicaBizau/scrape-it" ["l"="22.785,-26.933", "c"=28]
"tensorflow/playground" ["l"="47.991,28.864", "c"=89]
"ml4a/ml4a.github.io" ["l"="33.119,24.066", "c"=662]
"jcjohnson/torch-rnn" ["l"="46.17,27.698", "c"=277]
"blei-lab/edward" ["l"="45.764,26.126", "c"=68]
"czm0/draw_pytorch" ["l"="45.948,29.387"]
"kvfrans/draw-color" ["l"="45.931,29.375"]
"carpedm20/NTM-tensorflow" ["l"="46.105,27.882", "c"=277]
"saemundsson/semisupervised_vae" ["l"="45.066,27.69", "c"=789]
"fastforwardlabs/vae-tf" ["l"="46.167,29.376"]
"antontarasenko/smq" ["l"="23.092,-26.72", "c"=28]
"piiswrong/deep3d" ["l"="64.946,4.368", "c"=263]
"machrisaa/tensorflow-vgg" ["l"="50.428,33.162", "c"=314]
"szagoruyko/loadcaffe" ["l"="45.968,27.614", "c"=277]
"facebookarchive/torchnet" ["l"="46,27.679", "c"=277]
"keplr-io/quiver" ["l"="50.406,33.282", "c"=314]
"facebookresearch/CommAI-env" ["l"="46.099,27.844", "c"=277]
"saikatbsk/Vincent-AI-Artist" ["l"="45.828,29.427"]
"atriumlts/subpixel" ["l"="-34.948,21.747", "c"=127]
"basveeling/wavenet" ["l"="37.083,2.58", "c"=117]
"tomlepaine/fast-wavenet" ["l"="37.112,2.568", "c"=117]
"aleju/papers" ["l"="47.653,28.791", "c"=89]
"tdeboissiere/DeepLearningImplementations" ["l"="45.92,29.202"]
"nicklhy/AdversarialAutoEncoder" ["l"="46.125,29.459"]
"layerwise/AAE-tensorflow" ["l"="46.147,29.454"]
"dsanno/chainer-vae-gan" ["l"="46.189,29.307"]
"goodfeli/dlbook_exercises" ["l"="47.798,28.787", "c"=89]
"rhsimplex/image-match" ["l"="58.244,9.129", "c"=744]
"ibaaj/dijkstra-cartography" ["l"="23.276,-26.52", "c"=28]
"amygdala/tensorflow-workshop" ["l"="47.571,28.878", "c"=89]
"anantzoid/Conditional-PixelCNN-decoder" ["l"="46.019,29.334"]
"raghakot/keras-resnet" ["l"="50.501,33.22", "c"=314]
"yhenon/keras-frcnn" ["l"="50.494,33.143", "c"=314]
"tysam-code/hlb-CIFAR10" ["l"="38.736,-0.274", "c"=39]
"gafr/chainer-fast-neuralstyle-models" ["l"="-34.461,20.453", "c"=1031]
"OlavHN/fast-neural-style" ["l"="45.59,29.481"]
"genekogan/CubistMirror" ["l"="-34.43,20.442", "c"=1031]
"titu1994/Fast-Neural-Style" ["l"="44.725,28.846", "c"=771]
"pavelgonchar/neural-art-mini" ["l"="45.665,29.501"]
"junrushao/fast-neural-style.tf" ["l"="45.564,29.492"]
"pathak22/context-encoder" ["l"="44.636,29.347", "c"=912]
"traverseda/pycraft" ["l"="45.186,20.513", "c"=20]
"Cloud-CV/Fabrik" ["l"="48.496,32.344", "c"=300]
"awjuliani/TF-Tutorials" ["l"="46.093,29.204"]
"awjuliani/oreilly-rl-tutorial" ["l"="46.216,29.193"]
"Zardinality/WGAN-tensorflow" ["l"="45.979,29.162"]
"awjuliani/DeepRL-Agents" ["l"="57.415,18.078", "c"=45]
"ry/tensorflow-resnet" ["l"="50.473,33.187", "c"=314]
"awjuliani/Pix2Pix-Film" ["l"="46.192,29.208"]
"oduerr/dl_tutorial" ["l"="46.202,29.26"]
"sjchoi86/advanced-tensorflow" ["l"="-4.803,-23.024", "c"=164]
"terryum/TensorFlow_Exercises" ["l"="-4.653,-23.044", "c"=164]
"staturecrane/dcgan_vae_torch" ["l"="46.013,27.554", "c"=277]
"defaultnamehere/zzzzz" ["l"="22.914,-26.601", "c"=28]
"hardmaru/cppn-tensorflow" ["l"="46.375,7.803", "c"=148]
"hardmaru/resnet-cppn-gan-tensorflow" ["l"="46.083,29.404"]
"hardmaru/cppn-gan-vae-cifar-tensorflow" ["l"="46.076,29.377"]
"hochthom/cppn-keras" ["l"="46.348,7.828", "c"=148]
"edgarriba/ali-pytorch" ["l"="46.103,29.38"]
"yujiali/gmmn" ["l"="51.563,37.708", "c"=678]
"coupriec/VideoPredictionICLR2016" ["l"="41.498,25.678", "c"=537]
"Seratna/TensorFlow-Convolutional-AutoEncoder" ["l"="46.525,29.502"]
"jcklie/keras-autoencoder" ["l"="46.508,29.487"]
"despoisj/ConvolutionalAutoencoder" ["l"="46.541,29.522"]
"keunwoochoi/residual_block_keras" ["l"="46.502,29.519"]
"tobran/DE-Net" ["l"="45.356,29.081"]
"mattjj/svae" ["l"="45.096,27.608", "c"=789]
"sugyan/tf-dcgan" ["l"="45.974,29.268"]
"sugyan/face-generator" ["l"="45.978,29.312"]
"tensorlayer/DCGAN" ["l"="45.909,29.229"]
"clinicalml/structuredinference" ["l"="45.079,27.596", "c"=789]
"burness/neural_style_tensorflow" ["l"="45.56,29.515"]
"wisewong/ImageStyleTransform" ["l"="45.561,29.472"]
"awentzonline/keras-rtst" ["l"="45.571,29.541"]
"WenchenLi/PhotoRestoration" ["l"="46.545,29.454"]
"xcyan/eccv16_attr2img" ["l"="45.972,29.023"]
"buriburisuri/ac-gan" ["l"="45.995,29.236"]
"fxia22/PixelDTGAN" ["l"="45.968,29.208"]
"SKTBrain/DiscoGAN" ["l"="45.943,29.193"]
"jramapuram/CVAE" ["l"="46.233,29.413"]
"igul222/pixel_rnn" ["l"="46.023,29.398"]
"igul222/speech" ["l"="46.029,29.435"]
"facebookresearch/deepmask" ["l"="53.615,30.685", "c"=155]
"pytorch/tutorials" ["l"="50.679,28.562", "c"=104]
"artcg/BEGAN" ["l"="46.038,29.177"]
"jeffheaton/t81_558_deep_learning" ["l"="47.644,28.497", "c"=89]
"mzucker/noteshrink" ["l"="-0.843,-26.635", "c"=814]
"tonybeltramelli/Deep-Lyrics" ["l"="45.918,29.73"]
"enriqueav/lstm_lyrics" ["l"="45.928,29.759"]
"llSourcell/Rap_Lyric_Generator" ["l"="45.93,29.7"]
"cleverhans-lab/cleverhans" ["l"="38.958,-7.394", "c"=232]
"fogleman/primitive" ["l"="-0.765,-26.648", "c"=814]
"kootenpv/whereami" ["l"="23.535,-26.629", "c"=28]
"a1studmuffin/SpaceshipGenerator" ["l"="-32.544,-27.61", "c"=185]
"shirgur/PixelRNN" ["l"="46.026,29.378"]
"yueatsprograms/Stochastic_Depth" ["l"="45.963,27.643", "c"=277]
"ryankiros/layer-norm" ["l"="45.985,27.719", "c"=277]
"fyu/dilation" ["l"="53.516,30.777", "c"=155]
"dyelax/Adversarial_Video_Generation" ["l"="41.493,25.658", "c"=537]
"yahoo/open_nsfw" ["l"="-10.045,-8.098", "c"=5]
"cmusatyalab/openface" ["l"="33.525,29.32", "c"=57]
"dailenson/SDT" ["l"="46.902,7.559", "c"=148]
"kvfrans/generative-adversial" ["l"="46.145,29.393"]
"PHPixie/Project" ["l"="-40.839,-34.461", "c"=917]
"YapengTian/Single-Image-Super-Resolution" ["l"="-34.983,21.635", "c"=127]
"dropbox/lepton" ["l"="-39.395,20.945", "c"=563]
"matthewvowels1/Awesome-VAEs" ["l"="23.066,14.339", "c"=505]
"wagamamaz/tensorflow-tutorial" ["l"="50.212,28.069", "c"=104]
"fchollet/keras-resources" ["l"="47.697,28.66", "c"=89]
"linhuixiao/CLIP-VG" ["l"="49.053,31.935", "c"=300]
"MightXiong/FedMIT" ["l"="45.247,29.065"]
"fchollet/deep-learning-models" ["l"="50.375,33.173", "c"=314]
"tensorlayer/TensorLayer" ["l"="57.52,17.843", "c"=45]
"Hironsan/BossSensor" ["l"="47.473,28.573", "c"=89]
"xviniette/FlappyLearning" ["l"="-32.537,-35.967", "c"=1115]
"jlsutherland/doc2text" ["l"="46.074,7.147", "c"=148]
"leriomaggio/deep-learning-keras-tensorflow" ["l"="47.743,28.67", "c"=89]
"titu1994/DenseNet" ["l"="50.482,33.284", "c"=314]
"yenchenlin/pix2pix-tensorflow" ["l"="45.896,29.203"]
"liuzhuang13/DenseNet" ["l"="50.531,33.199", "c"=314]
"raghakot/keras-vis" ["l"="50.472,33.257", "c"=314]
"keras-team/keras-contrib" ["l"="53.878,27.193", "c"=60]
"farizrahman4u/recurrentshop" ["l"="55.877,28.51", "c"=513]
"karpathy/paper-notes" ["l"="46.054,27.765", "c"=277]
"LantaoYu/SeqGAN" ["l"="57.813,29.4", "c"=1082]
"HyperGAN/HyperGAN" ["l"="45.931,29.237"]
"carpedm20/DiscoGAN-pytorch" ["l"="45.938,29.177"]
"google-deepmind/learning-to-learn" ["l"="47.672,28.819", "c"=89]
"ml4a/ml4a" ["l"="33.079,24.054", "c"=662]
"openai/vime" ["l"="57.39,18.273", "c"=45]
"Evolving-AI-Lab/fooling" ["l"="-43.575,-33.624", "c"=865]
"davidBelanger/SPEN" ["l"="45.948,29.438"]
"moodoki/semantic_image_inpainting" ["l"="44.59,29.35", "c"=912]
"shinseung428/GlobalLocalImageCompletion_TF" ["l"="44.604,29.314", "c"=912]
"mingyuliutw/CoGAN" ["l"="45.979,29.182"]
"andrewliao11/CoGAN-tensorflow" ["l"="46.049,29.166"]
"mingyuliutw/CoGAN_PyTorch" ["l"="46.038,29.228"]
"erictzeng/adda" ["l"="51.407,37.573", "c"=678]
"xunhuang1995/SGAN" ["l"="45.977,29.288"]
"facebookresearch/multipathnet" ["l"="53.621,30.716", "c"=155]
"thu-ml/zhusuan" ["l"="45.851,26.084", "c"=68]
"openai/requests-for-research" ["l"="57.37,18.041", "c"=45]
"cerndb/dist-keras" ["l"="-2.661,17.166", "c"=455]
"buriburisuri/supervised_infogan" ["l"="46.073,29.239"]
"buriburisuri/sugartensor" ["l"="46.07,29.257"]
"shekkizh/EBGAN.tensorflow" ["l"="46.093,29.303"]
"buriburisuri/SRGAN" ["l"="-34.968,21.763", "c"=127]
"buriburisuri/timeseries_gan" ["l"="-9.777,12.877", "c"=105]
"kimiyoung/review_net" ["l"="48.436,31.985", "c"=300]
"GV1028/videogan" ["l"="41.44,25.523", "c"=537]
"sergeytulyakov/mocogan" ["l"="41.559,25.625", "c"=537]
"batsa003/videogan" ["l"="41.461,25.55", "c"=537]
"junyanz/light-field-video" ["l"="-35.596,21.821", "c"=127]
"junyanz/VON" ["l"="63.722,1.256", "c"=134]
"junyanz/interactive-deep-colorization" ["l"="-33.737,20.347", "c"=1190]
"tinghuiz/appearance-flow" ["l"="63.848,1.187", "c"=134]
"osh/kerlym" ["l"="57.282,18.125", "c"=45]
"jonbruner/generative-adversarial-networks" ["l"="46.077,29.223"]
"Zackory/Keras-MNIST-GAN" ["l"="46.124,29.195"]
"r0nn13/conditional-dcgan-keras" ["l"="46.158,29.223"]
"JonathanRaiman/tensorflow-infogan" ["l"="22.985,14.075", "c"=505]
"openai/imitation" ["l"="57.47,18.292", "c"=45]
"dilinwang820/Stein-Variational-Gradient-Descent" ["l"="21.74,14.322", "c"=267]
"KnHuq/Dynamic-Tensorflow-Tutorial" ["l"="46.16,27.86", "c"=277]
"gyglim/dvn" ["l"="45.974,29.497"]
"wookayin/tensorflow-talk-debugging" ["l"="46.196,27.905", "c"=277]
"keplr-io/hera" ["l"="44.751,27.682", "c"=789]
"cvondrick/torch-starter" ["l"="46.021,27.535", "c"=277]
"pavelgonchar/color-independent-style-transfer" ["l"="45.622,29.54"]
"loliverhennigh/Convolutional-LSTM-in-Tensorflow" ["l"="41.507,25.75", "c"=537]
"ankurhanda/gvnn" ["l"="45.901,27.673", "c"=277]
"usernaamee/keras-wavenet" ["l"="37.039,2.6", "c"=117]
"coxlab/prednet" ["l"="41.495,25.701", "c"=537]
"jmtomczak/vae_vpflows" ["l"="23.102,14.343", "c"=505]
"riannevdberg/sylvester-flows" ["l"="23.066,14.408", "c"=505]
"ermongroup/Variational-Ladder-Autoencoder" ["l"="23.107,14.241", "c"=505]
"pclucas14/iaf-vae" ["l"="46.043,29.357"]
"jmtomczak/vae_vampprior" ["l"="23.063,14.311", "c"=505]
"Kyubyong/neural_tokenizer" ["l"="52.622,27.294", "c"=60]
"junhocho/SRGAN" ["l"="-34.972,21.793", "c"=127]
"saikatbsk/Wave" ["l"="45.832,29.462"]
"dyelax/encore.ai" ["l"="45.899,29.786"]
"ivan-liljeqvist/ailyrics" ["l"="45.887,29.811"]
"txizzle/MarkovRapGenerator" ["l"="45.948,29.717"]
"kxytim/DeepPLS" ["l"="46.599,29.765"]
"paperswithcode/ai-deadlines" ["l"="-3.842,23.573", "c"=827]
"google/guetzli" ["l"="-39.456,20.917", "c"=563]
"flyyufelix/cnn_finetune" ["l"="50.439,33.234", "c"=314]
"lanpa/tensorboardX" ["l"="50.919,29.781", "c"=83]
"openai/universe" ["l"="57.439,17.977", "c"=45]
"datitran/face2face-demo" ["l"="31.213,30.643", "c"=634]
"bakwc/PornDetector" ["l"="-61.596,15.042", "c"=920]
"LucasLeandro1204/Pornsearch" ["l"="-61.528,15.053", "c"=920]
"rlleshi/phar" ["l"="-60.465,15.837", "c"=330]
"sbrugman/deep-learning-papers" ["l"="47.685,28.734", "c"=89]
"curtwagner1984/YAPO" ["l"="-60.716,15.889", "c"=330]
"eyyub/tensorflow-pix2pix" ["l"="45.991,29.265"]
"sagiebenaim/DistanceGAN" ["l"="45.958,29.41"]
"endymecy/awesome-deeplearning-resources" ["l"="47.723,28.709", "c"=89]
"kevinhughes27/TensorKart" ["l"="61.469,12.445", "c"=774]
"dennybritz/cnn-text-classification-tf" ["l"="53.153,25.633", "c"=172]
"rahulkapoor90/This-is-Clickbait" ["l"="46.036,29.797"]
"abhishekkrthakur/clickbaits_revisited" ["l"="46.03,29.825"]
"bhargaviparanjape/clickbait" ["l"="46.042,29.775"]
"szagoruyko/attention-transfer" ["l"="53.549,33.612", "c"=1263]
"yenchenlin/awesome-adversarial-machine-learning" ["l"="38.99,-7.401", "c"=232]
"burness/tensorflow-101" ["l"="46.249,7.286", "c"=148]
"Mostafa-Samir/DNC-tensorflow" ["l"="46.109,27.904", "c"=277]
"adeshpande3/Tensorflow-Programs-and-Tutorials" ["l"="47.615,28.706", "c"=89]
"guojunq/glsgan" ["l"="46.056,29.177"]
"musyoku/LSGAN" ["l"="46.074,29.164"]
"tensorflow/fold" ["l"="46.192,27.87", "c"=277]
"udacity/deep-learning" ["l"="47.61,28.586", "c"=89]
"ericjang/gumbel-softmax" ["l"="53.219,29.886", "c"=547]
"googlecreativelab/aiexperiments-ai-duet" ["l"="38.542,3.865", "c"=201]
"olofmogren/c-rnn-gan" ["l"="-9.852,12.862", "c"=105]
"jcjohnson/pytorch-examples" ["l"="50.691,28.51", "c"=104]
"0xfuturistic/Twitter-Giveaways-Bot" ["l"="45.968,29.865"]
"TobiasPankner/Gleam-giveaway-bot" ["l"="45.986,29.897"]
"wagamamaz/tensorlayer-tricks" ["l"="50.082,28.066", "c"=104]
"titu1994/Super-Resolution-using-Generative-Adversarial-Networks" ["l"="-34.973,21.75", "c"=127]
"btgraham/Batchwise-Dropout" ["l"="23.572,14.886", "c"=728]
"6004x/jade" ["l"="23.595,14.871", "c"=728]
"danielkunin/Deeplearning-Visualizations" ["l"="23.557,14.899", "c"=728]
"liuchen11/CertifyNonuniformBounds" ["l"="23.558,14.896", "c"=728]
"prichemond/ds3" ["l"="23.57,14.886", "c"=728]
"ee227c/ee227c.github.io" ["l"="23.574,14.847", "c"=728]
"cvondrick/soundnet" ["l"="39.701,5.56", "c"=593]
"TeamHG-Memex/tensorboard_logger" ["l"="51.276,29.901", "c"=83]
"rcmalli/keras-squeezenet" ["l"="50.426,33.318", "c"=314]
"ermongroup/cs228-notes" ["l"="45.817,26.067", "c"=68]
"szagoruyko/functional-zoo" ["l"="51.274,29.945", "c"=83]
"SKTBrain/awesome-starcraftAI" ["l"="58.73,18.083", "c"=885]
"ghwatson/faststyle" ["l"="44.807,28.861", "c"=771]
"abhiskk/fast-neural-style" ["l"="44.939,28.784", "c"=771]
"tobran/StoryImager" ["l"="45.293,29.074"]
"tobran/ONE-PIC" ["l"="45.266,29.069"]
"roatienza/ml" ["l"="46.043,29.121"]
"kspilario/AI221" ["l"="46.056,29.127"]
"rockingdingo/deepnlp" ["l"="53.39,27.446", "c"=60]
"ilivans/tf-rnn-attention" ["l"="53.357,28.838", "c"=1200]
"aurora95/Keras-FCN" ["l"="53.479,30.682", "c"=155]
"meereeum/lda2vec-tf" ["l"="53.229,26.328", "c"=993]
"lukedeo/keras-acgan" ["l"="46.096,29.254"]
"Kyubyong/quasi-rnn" ["l"="46.055,29.423"]
"johnwmillr/LyricsGenius" ["l"="-51.437,8.966", "c"=19]
"megvii-research/neural-painter" ["l"="44.972,28.867", "c"=771]
"jostmey/rwa" ["l"="47.456,28.842", "c"=89]
"mpatacchiola/dissecting-reinforcement-learning" ["l"="57.443,18.096", "c"=45]
"zhangqianhui/Conditional-GAN" ["l"="46.127,29.096"]
"val-iisc/deligan" ["l"="46.222,29.068"]
"m516825/Conditional-GAN" ["l"="-34.784,20.528", "c"=1031]
"zck119/3dgan-release" ["l"="63.737,1.15", "c"=134]
"iassael/torch-bnlstm" ["l"="45.949,27.667", "c"=277]
"jnhwkim/cbp" ["l"="48.745,32.12", "c"=300]
"ludc/rltorch" ["l"="45.96,27.686", "c"=277]
"yeyun111/dlcv_for_beginners" ["l"="51.313,29.733", "c"=83]
"jakebelew/gated-pixel-cnn" ["l"="46.045,29.381"]
"jzbontar/pixelcnn-pytorch" ["l"="23.184,14.361", "c"=505]
"jxwufan/AssociativeRetrieval" ["l"="45.969,27.914", "c"=277]
"marcofraccaro/srnn" ["l"="45.03,27.62", "c"=789]
"hiwonjoon/tf-vqvae" ["l"="23.181,14.237", "c"=505]
"igul222/PixelVAE" ["l"="23.154,14.12", "c"=505]
"hi-abhi/tensorflow-value-iteration-networks" ["l"="57.361,18.233", "c"=45]
"jocicmarko/ultrasound-nerve-segmentation" ["l"="61.994,37.003", "c"=178]
"PacktPublishing/Deep-Learning-with-Keras" ["l"="47.398,28.471", "c"=89]
"King-Of-Knights/Keras-ACGAN-CIFAR10" ["l"="-34.723,20.519", "c"=1031]
"erilyth/DCGANs" ["l"="46.165,29.241"]
"bobchennan/Wasserstein-GAN-Keras" ["l"="46.152,29.26"]
"jiwoongim/GRAN" ["l"="45.994,29.377"]
"RuiShu/vae-clustering" ["l"="53.162,29.861", "c"=547]
"zalandoresearch/spatial_gan" ["l"="45.398,29.791"]
"AlexHex7/SimGAN_pytorch" ["l"="46.05,29.263"]
"shinseung428/simGAN_NYU_Hand" ["l"="46.025,29.25"]
"poolio/unrolled_gan" ["l"="45.962,29.336"]
"andrewliao11/unrolled-gans" ["l"="45.978,29.392"]
"Nat-D/GMVAE" ["l"="53.161,29.843", "c"=547]
"yhenon/keras-spp" ["l"="50.619,33.15", "c"=314]
"OsciiArt/DeepAA" ["l"="-34.953,20.401", "c"=1031]
"facebookresearch/detectron2" ["l"="50.571,29.698", "c"=83]
"google-deepmind/dnc" ["l"="46.152,27.91", "c"=277]
"ritchieng/the-incredible-pytorch" ["l"="47.978,26.259", "c"=323]
"extreme-assistant/CVPR2024-Paper-Code-Interpretation" ["l"="50.767,29.784", "c"=83]
"duxingren14/DualGAN" ["l"="45.992,29.221"]
"torrvision/crayon" ["l"="51.239,29.958", "c"=83]
"aikorea/awesome-rl" ["l"="57.507,17.95", "c"=45]
"JoinWei-PKU/PTGAN" ["l"="56.026,32.717", "c"=355]
"clovaai/fewshot-font-generation" ["l"="46.769,7.542", "c"=148]
"ecnuycxie/DG-Font" ["l"="46.763,7.564", "c"=148]
"ankush-me/SynthText" ["l"="46.341,7.223", "c"=148]
"pcgreat/zi2zi" ["l"="46.65,7.604", "c"=148]
"pfnet/PaintsChainer" ["l"="-34.869,20.36", "c"=1031]
"spro/practical-pytorch" ["l"="53.121,25.666", "c"=172]
"sunshineatnoon/Paper-Implementations" ["l"="45.969,29.114"]
"yfeng95/GAN_Theories" ["l"="45.893,29.091"]
"jayleicn/animeGAN" ["l"="-34.838,20.442", "c"=1031]
"mil-tokyo/webdnn" ["l"="-32.531,-35.884", "c"=1115]
"joeddav/devol" ["l"="49.854,26.25", "c"=759]
"jettan/tikz_cnn" ["l"="45.776,27.603", "c"=277]
"kvfrans/deepcolor" ["l"="-34.929,20.349", "c"=1031]
"wookayin/tensorflow-plot" ["l"="48.268,31.887", "c"=300]
"shaohua0116/Activation-Visualization-Histogram" ["l"="46.096,29.172"]
"kootenpv/neural_complete" ["l"="47.542,28.829", "c"=89]
"xiaolonw/adversarial-frcnn" ["l"="51.654,33.466", "c"=354]
"jiamings/wgan" ["l"="46.026,29.136"]
"adeshpande3/MachineLearningReimplementations" ["l"="47.53,28.756", "c"=89]
"felixgwu/mask_rcnn_pytorch" ["l"="51.093,30.063", "c"=83]
"switchablenorms/Switchable-Normalization" ["l"="53.428,31.11", "c"=155]
"1zb/deformable-convolution-pytorch" ["l"="51.052,30.099", "c"=83]
"pathak22/unsupervised-video" ["l"="48.104,33.455", "c"=373]
"manumathewthomas/ImageDenoisingGAN" ["l"="-34.38,22.479", "c"=429]
"kkleidal/GatedPixelCNNPyTorch" ["l"="23.162,14.357", "c"=505]
"nilboy/pixel-recursive-super-resolution" ["l"="-34.99,21.763", "c"=127]
"kuleshov/tf-wgan" ["l"="46.076,29.069"]
"cameronfabbri/Improved-Wasserstein-GAN" ["l"="46.098,29.116"]
"ermongroup/markov-chain-gan" ["l"="45.346,31.682", "c"=605]
"jakezhaojb/ARAE" ["l"="57.732,29.378", "c"=1082]
"adventuresinML/adventures-in-ml-code" ["l"="47.517,28.601", "c"=89]
"despoisj/LatentSpaceVisualization" ["l"="46.586,29.54"]
"takat0m0/CVAE_GAN" ["l"="46.483,29.252"]
"taey16/pix2pix.pytorch" ["l"="46.097,29.052"]
"hiwonjoon/cycle-gan-tf" ["l"="46.042,29.099"]
"zhanghang1989/PyTorch-Multi-Style-Transfer" ["l"="44.935,28.738", "c"=771]
"ZZUTK/Face-Aging-CAAE" ["l"="45.176,30.554", "c"=243]
"hmi88/Fast_Multi_Style_Transfer-tensorflow" ["l"="46.086,29.515"]
"joelmoniz/gogh-figure" ["l"="46.101,29.552"]
"layumi/Person-reID_GAN" ["l"="56,32.707", "c"=355]
"cycleuser/Duke-STA-663-CN" ["l"="50.395,28.004", "c"=104]
"nightrome/really-awesome-semantic-segmentation" ["l"="53.442,30.739", "c"=155]
"a514514772/Pytorch-VAE-GAN" ["l"="46.314,29.328"]
"infocusp/tf_cnnvis" ["l"="50.432,33.196", "c"=314]
"Yijunmaverick/GenerativeFaceCompletion" ["l"="44.545,29.328", "c"=912]
"DmitryUlyanov/AGE" ["l"="46.098,29.084"]
"0b01/SimGAN-Captcha" ["l"="47.796,22.291", "c"=380]
"rdipietro/mist-rnns" ["l"="46.066,29.465"]
"yfeng95/GAN_Applications" ["l"="45.914,29.089"]
"togheppi/DualGAN" ["l"="46.009,29.26"]
"lidan1/PhotoSketchMAN" ["l"="-35.191,20.633", "c"=1031]
"hello-world-zsp/SDAE_tensorflow" ["l"="46.457,29.58"]
"GunhoChoi/Kind-PyTorch-Tutorial" ["l"="-4.842,-23.069", "c"=164]
"HiiYL/BEGAN-PyTorch" ["l"="46.067,29.111"]
"GunhoChoi/LSGAN-TF" ["l"="46.083,29.106"]
"arashsaber/Deep-Convolutional-AutoEncoder" ["l"="46.555,29.503"]
"kimhc6028/forward-thinking-pytorch" ["l"="58.404,23.685", "c"=161]
"victor-shepardson/alpha-GAN" ["l"="46.182,29.068"]
"zhouyiwei/cc" ["l"="46.042,29.845"]
"taufikxu/Triple-GAN" ["l"="46.181,29.044"]
"samrussell/ssgan" ["l"="46.162,29.048"]
"Kyubyong/texture_generation" ["l"="45.485,29.641"]
"hzy46/Char-RNN-TensorFlow" ["l"="53.462,27.478", "c"=60]
"adeshpande3/LSTM-Sentiment-Analysis" ["l"="53.04,25.414", "c"=172]
"fossasia/visdom" ["l"="51.116,29.383", "c"=83]
"lllyasviel/ControlNet" ["l"="38.358,1.011", "c"=54]
"Mikubill/sd-webui-controlnet" ["l"="32.226,31.739", "c"=88]
"makegirlsmoe/makegirlsmoe_web" ["l"="-34.866,20.4", "c"=1031]
"tonybeltramelli/pix2code" ["l"="-4.447,-33.091", "c"=30]
"L1aoXingyu/pytorch-beginner" ["l"="50.616,28.448", "c"=104]
"zackthoutt/got-book-6" ["l"="47.517,28.787", "c"=89]
"msracver/Deep-Exemplar-based-Colorization" ["l"="-33.757,20.365", "c"=1190]
"martinbenson/deep-photo-styletransfer" ["l"="44.839,28.842", "c"=771]
"bobbens/sketch_simplification" ["l"="-35.068,20.386", "c"=1031]
"YuvalNirkin/face_swap" ["l"="31.178,30.669", "c"=634]
"keras-rl/keras-rl" ["l"="57.489,18.005", "c"=45]
"qqwweee/keras-yolo3" ["l"="50.584,29.898", "c"=83]
"philipperemy/keract" ["l"="53.963,27.185", "c"=60]
"MorvanZhou/Tensorflow-Tutorial" ["l"="50.52,28.354", "c"=104]
"sony/nnabla" ["l"="5.776,-41.264", "c"=259]
"parasdahal/deepnet" ["l"="46.318,29.185"]
"kimhc6028/relational-networks" ["l"="23.489,14.801", "c"=728]
"miyosuda/async_deep_reinforce" ["l"="57.348,18.157", "c"=45]
"openai/evolution-strategies-starter" ["l"="57.409,18.235", "c"=45]
"chrisranderson/beholder" ["l"="51.408,29.883", "c"=83]
"rkjones4/GANGogh" ["l"="27.143,-27.837", "c"=32]
"wkentaro/pytorch-for-numpy-users" ["l"="45.585,28.764"]
"smilli/research-advice" ["l"="-3.763,23.3", "c"=827]
"linksense/LightNet" ["l"="53.44,30.897", "c"=155]
"nitrain/nitrain" ["l"="51.086,29.846", "c"=83]
"hezhangsprinter/ID-CGAN" ["l"="-35.171,22.279", "c"=992]
"znxlwm/tensorflow-MNIST-GAN-DCGAN" ["l"="46.133,29.024"]
"msracver/FCIS" ["l"="53.537,30.757", "c"=155]
"dvschultz/ml-art-colabs" ["l"="44.786,31.493", "c"=1003]
"kosmos/awesome-generative-art" ["l"="36.081,23.998", "c"=98]
"eps696/aphantasia" ["l"="44.749,31.474", "c"=1003]
"podgorskiy/GPND" ["l"="23.585,14.856", "c"=728]
"danieltan07/dagmm" ["l"="52.863,14.724", "c"=689]
"sixitingting/Adversarial_Autoencoder_Tina" ["l"="46.196,29.449"]
"adeshpande3/Machine-Learning-Links-And-Lessons-Learned" ["l"="47.618,28.679", "c"=89]
"mind/wheels" ["l"="50.185,33.165", "c"=314]
"ssusnic/Machine-Learning-Flappy-Bird" ["l"="57.051,17.888", "c"=45]
"magenta/magenta-demos" ["l"="38.572,3.952", "c"=201]
"miyosuda/disentangled_vae" ["l"="23.059,14.232", "c"=505]
"ritheshkumar95/pytorch-vqvae" ["l"="23.171,14.269", "c"=505]
"facebookresearch/adaptive-softmax" ["l"="46.003,27.711", "c"=277]
"wbhu/DnCNN-tensorflow" ["l"="-34.347,22.483", "c"=429]
"Faldict/awesome-GAN" ["l"="45.856,29.02"]
"archsyscall/GANs-TensorFlow2" ["l"="46.111,28.985"]
"jesse1029/Fake-Face-Images-Detection-Tensorflow" ["l"="31.058,30.201", "c"=836]
"ChengBinJin/WGAN-GP-tensorflow" ["l"="62.087,36.504", "c"=178]
"SSARCandy/DeepCORAL" ["l"="51.444,37.591", "c"=678]
"Britefury/self-ensemble-visual-domain-adapt" ["l"="51.373,37.536", "c"=678]
"mil-tokyo/MCD_DA" ["l"="51.379,37.57", "c"=678]
"jonbruner/ezgan" ["l"="46.124,29.241"]
"awjuliani/dfp" ["l"="57.127,18.305", "c"=45]
"togheppi/DCGAN" ["l"="46.057,29.007"]
"manicman1999/Keras-BiGAN" ["l"="23.575,14.907", "c"=728]
"sourcedexter/tfClassifier" ["l"="53.37,25.568", "c"=172]
"sagiebenaim/OneShotTranslation" ["l"="45.989,29.47"]
"vsyw/Keras-OpenFace" ["l"="33.172,29.515", "c"=57]
"daniel-merrick/Learning-from-Simulated-and-Unsupervised-Images-through-Adversarial-Training-SimGAN-PyTorch" ["l"="46.086,29.284"]
"musikisomorphie/wgan-div" ["l"="46.256,29.088"]
"awjuliani/Meta-RL" ["l"="57.327,18.215", "c"=45]
"flyyufelix/DenseNet-Keras" ["l"="50.5,33.267", "c"=314]
"cameronfabbri/Wasserstein-GAN-Tensorflow" ["l"="46.147,29.107"]
"philqc/deep-value-networks-pytorch" ["l"="45.986,29.525"]
"clvrai/FeatureControlHRL-Tensorflow" ["l"="45.943,28.755"]
"clvrai/CycleGAN-Tensorflow" ["l"="45.923,28.763"]
"vyraun/DNI-tensorflow" ["l"="45.988,28.725"]
"taki0112/GAN-Tensorflow" ["l"="46.178,28.93"]
}