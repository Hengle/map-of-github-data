digraph G {
"aishoot/Sound_Localization_Algorithms" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"aishoot/Sound_Localization_Algorithms" -> "xiaoli1368/Microphone-sound-source-localization"
"aishoot/Sound_Localization_Algorithms" -> "ZitengWang/MASP"
"aishoot/Sound_Localization_Algorithms" -> "jorgengrythe/beamforming"
"aishoot/Sound_Localization_Algorithms" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"aishoot/Sound_Localization_Algorithms" -> "wangwei2009/DOA"
"aishoot/Sound_Localization_Algorithms" -> "xanguera/BeamformIt"
"aishoot/Sound_Localization_Algorithms" -> "huangzhenyu/beamforming"
"aishoot/Sound_Localization_Algorithms" -> "xiongyihui/tdoa"
"aishoot/Sound_Localization_Algorithms" -> "kkumatani/distant_speech_recognition"
"aishoot/Sound_Localization_Algorithms" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"aishoot/Sound_Localization_Algorithms" -> "LCAV/pyroomacoustics"
"aishoot/Sound_Localization_Algorithms" -> "chenwj1989/Beamforming_Examples"
"aishoot/Sound_Localization_Algorithms" -> "athena-team/athena-signal"
"aishoot/Sound_Localization_Algorithms" -> "funcwj/setk"
"xiaoli1368/Microphone-sound-source-localization" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"xiaoli1368/Microphone-sound-source-localization" -> "wangwei2009/DOA"
"xiaoli1368/Microphone-sound-source-localization" -> "aishoot/Sound_Localization_Algorithms"
"xiaoli1368/Microphone-sound-source-localization" -> "xiongyihui/tdoa"
"xiaoli1368/Microphone-sound-source-localization" -> "introlab/manyears"
"xiaoli1368/Microphone-sound-source-localization" -> "ishaaniwani/GCC-PHAT-SSL"
"xiaoli1368/Microphone-sound-source-localization" -> "LeeTaewoo/fast_sound_source_localization_using_TLSSC"
"xiaoli1368/Microphone-sound-source-localization" -> "sindhurach94/Sound-source-localization"
"xiaoli1368/Microphone-sound-source-localization" -> "ZitengWang/MASP"
"xiaoli1368/Microphone-sound-source-localization" -> "polarch/Spherical-Array-Processing" ["e"=1]
"xiaoli1368/Microphone-sound-source-localization" -> "BrownsugarZeer/Multi_SSL"
"xiaoli1368/Microphone-sound-source-localization" -> "morriswmz/doa-tools"
"marsyas/marsyas" -> "Yaafe/Yaafe"
"marsyas/marsyas" -> "CPJKU/madmom" ["e"=1]
"marsyas/marsyas" -> "MTG/gaia"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "xiaoli1368/Microphone-sound-source-localization"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "aishoot/Sound_Localization_Algorithms"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "wangwei2009/DOA"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "morriswmz/doa-tools"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "ZitengWang/MASP"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "xiongyihui/tdoa"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "seanwood/gcc-nmf"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "Ryuk17/SpeechAlgorithms"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "huangzhenyu/beamforming"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "xuchenglin28/WSCM-MUSIC"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "polarch/Spherical-Array-Processing" ["e"=1]
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "KyleZhang1118/Voice-Separation-and-Enhancement"
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" -> "athena-team/athena-signal"
"kaituoxu/Conv-TasNet" -> "naplab/Conv-TasNet"
"kaituoxu/Conv-TasNet" -> "JusperLee/Conv-TasNet"
"kaituoxu/Conv-TasNet" -> "funcwj/conv-tasnet"
"kaituoxu/Conv-TasNet" -> "JusperLee/Dual-Path-RNN-Pytorch"
"kaituoxu/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"kaituoxu/Conv-TasNet" -> "yluo42/TAC"
"kaituoxu/Conv-TasNet" -> "asteroid-team/asteroid"
"kaituoxu/Conv-TasNet" -> "kaituoxu/TasNet"
"kaituoxu/Conv-TasNet" -> "huyanxin/DeepComplexCRN"
"kaituoxu/Conv-TasNet" -> "gemengtju/Tutorial_Separation"
"kaituoxu/Conv-TasNet" -> "aishoot/LSTM_PIT_Speech_Separation"
"kaituoxu/Conv-TasNet" -> "Audio-WestlakeU/FullSubNet"
"kaituoxu/Conv-TasNet" -> "maum-ai/voicefilter"
"kaituoxu/Conv-TasNet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"kaituoxu/Conv-TasNet" -> "microsoft/DNS-Challenge"
"YangangCao/WebRTC-3A1V" -> "xiaochunxin/OMLSA-MCRA"
"YangangCao/WebRTC-3A1V" -> "cpuimage/WebRTC_AGC"
"YangangCao/WebRTC-3A1V" -> "ewan-xu/AEC3"
"YangangCao/WebRTC-3A1V" -> "cpuimage/WebRTC_AECM"
"YangangCao/WebRTC-3A1V" -> "DoubangoTelecom/webrtc-audioproc"
"YangangCao/WebRTC-3A1V" -> "lbcgi/webrtc_agc_matlab"
"ludlows/PESQ" -> "mpariente/pystoi"
"ludlows/PESQ" -> "vBaiCai/python-pesq"
"ludlows/PESQ" -> "aliutkus/speechmetrics"
"ludlows/PESQ" -> "schmiph2/pysepm"
"ludlows/PESQ" -> "google/visqol"
"ludlows/PESQ" -> "gabrielmittag/NISQA"
"ludlows/PESQ" -> "microsoft/DNS-Challenge"
"ludlows/PESQ" -> "DavidDiazGuerra/gpuRIR"
"ludlows/PESQ" -> "Audio-WestlakeU/FullSubNet"
"ludlows/PESQ" -> "huyanxin/DeepComplexCRN"
"ludlows/PESQ" -> "microsoft/MS-SNSD"
"ludlows/PESQ" -> "kaituoxu/Conv-TasNet"
"ludlows/PESQ" -> "Ryuk17/SpeechAlgorithms"
"ludlows/PESQ" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"ludlows/PESQ" -> "jzi040941/PercepNet"
"pseeth/torch-stft" -> "huyanxin/phasen"
"pseeth/torch-stft" -> "KinWaiCheuk/nnAudio" ["e"=1]
"pseeth/torch-stft" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"pseeth/torch-stft" -> "yluo42/TAC"
"pseeth/torch-stft" -> "vBaiCai/python-pesq"
"pseeth/torch-stft" -> "funcwj/setk"
"pseeth/torch-stft" -> "naplab/Conv-TasNet"
"pseeth/torch-stft" -> "kaituoxu/Conv-TasNet"
"pseeth/torch-stft" -> "facebookresearch/WavAugment" ["e"=1]
"pseeth/torch-stft" -> "DavidDiazGuerra/gpuRIR"
"pseeth/torch-stft" -> "speechLabBcCuny/onssen"
"pseeth/torch-stft" -> "mpariente/pytorch_stoi"
"pseeth/torch-stft" -> "ConferencingSpeech/ConferencingSpeech2021"
"Akki369/Generalised-Side-Lobe-Canceller" -> "satyanamuduri/Speech-Enhancement-Using-GSC"
"Akki369/Generalised-Side-Lobe-Canceller" -> "jgarciagimenez/GSC_beamforming"
"Akki369/Generalised-Side-Lobe-Canceller" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "morriswmz/doatools.py"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "yump/doamusic"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "morriswmz/doa-tools"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "msamsami/doa-estimation-music"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "LahiruJayasinghe/DeepDOA"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "GAMMA-UMD/doa-release"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "vslobody/MUSIC"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "Navigine/Direction-of-Arrival-DoA-Estimation-Algorithm" ["e"=1]
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "scivision/signal_subspace"
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" -> "lewsilver/radar_doa"
"shichaog/WebRTC-audio-processing" -> "athena-team/athena-signal"
"shichaog/WebRTC-audio-processing" -> "ewan-xu/AEC3"
"shichaog/WebRTC-audio-processing" -> "jzi040941/PercepNet"
"shichaog/WebRTC-audio-processing" -> "microsoft/AEC-Challenge"
"shichaog/WebRTC-audio-processing" -> "wavesaudio/Speex-AEC-matlab"
"shichaog/WebRTC-audio-processing" -> "shichaog/RNNAec"
"shichaog/WebRTC-audio-processing" -> "robin1001/beamforming"
"shichaog/WebRTC-audio-processing" -> "ZitengWang/MASP"
"shichaog/WebRTC-audio-processing" -> "ewan-xu/pyaec"
"shichaog/WebRTC-audio-processing" -> "xanguera/BeamformIt"
"shichaog/WebRTC-audio-processing" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"shichaog/WebRTC-audio-processing" -> "anicolson/DeepXi"
"shichaog/WebRTC-audio-processing" -> "fjiang9/NKF-AEC"
"shichaog/WebRTC-audio-processing" -> "huyanxin/DeepComplexCRN"
"shichaog/WebRTC-audio-processing" -> "YangangCao/WebRTC-3A1V"
"vBaiCai/python-pesq" -> "mpariente/pystoi"
"vBaiCai/python-pesq" -> "ludlows/PESQ"
"vBaiCai/python-pesq" -> "aliutkus/speechmetrics"
"vBaiCai/python-pesq" -> "schmiph2/pysepm"
"vBaiCai/python-pesq" -> "santi-pdp/segan_pytorch"
"vBaiCai/python-pesq" -> "huyanxin/phasen"
"vBaiCai/python-pesq" -> "anicolson/DeepXi"
"vBaiCai/python-pesq" -> "DavidDiazGuerra/gpuRIR"
"vBaiCai/python-pesq" -> "funcwj/setk"
"vBaiCai/python-pesq" -> "fgnt/nara_wpe"
"vBaiCai/python-pesq" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"vBaiCai/python-pesq" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"vBaiCai/python-pesq" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"vBaiCai/python-pesq" -> "JasonSWFu/MetricGAN"
"vBaiCai/python-pesq" -> "ehabets/RIR-Generator"
"tsurumeso/vocal-remover" -> "Anjok07/ultimatevocalremovergui" ["e"=1]
"tsurumeso/vocal-remover" -> "nomadkaraoke/python-audio-separator"
"tsurumeso/vocal-remover" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"tsurumeso/vocal-remover" -> "haoheliu/voicefixer"
"tsurumeso/vocal-remover" -> "facebookresearch/demucs"
"tsurumeso/vocal-remover" -> "ZFTurbo/Music-Source-Separation-Training"
"tsurumeso/vocal-remover" -> "kuielab/mdx-net"
"tsurumeso/vocal-remover" -> "kuielab/mdx-net-submission"
"tsurumeso/vocal-remover" -> "resemble-ai/resemble-enhance"
"tsurumeso/vocal-remover" -> "sigsep/open-unmix-pytorch"
"tsurumeso/vocal-remover" -> "adefossez/demucs"
"tsurumeso/vocal-remover" -> "lucidrains/BS-RoFormer"
"tsurumeso/vocal-remover" -> "NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover"
"tsurumeso/vocal-remover" -> "Rikorose/DeepFilterNet"
"tsurumeso/vocal-remover" -> "jarredou/MVSEP-MDX23-Colab_v2"
"voice-engine/make-a-smart-speaker" -> "voice-engine/ec"
"voice-engine/make-a-smart-speaker" -> "mindorii/kws" ["e"=1]
"voice-engine/make-a-smart-speaker" -> "respeaker/mic_array"
"voice-engine/make-a-smart-speaker" -> "fgnt/nn-gev"
"voice-engine/make-a-smart-speaker" -> "voice-engine/voice-engine"
"voice-engine/make-a-smart-speaker" -> "colinsongf/keyword_spotting" ["e"=1]
"voice-engine/make-a-smart-speaker" -> "introlab/odas"
"voice-engine/make-a-smart-speaker" -> "wangwei2009/DOA"
"voice-engine/make-a-smart-speaker" -> "funcwj/CGMM-MVDR"
"voice-engine/make-a-smart-speaker" -> "xanguera/BeamformIt"
"voice-engine/make-a-smart-speaker" -> "microsoft/AEC-Challenge"
"voice-engine/make-a-smart-speaker" -> "funcwj/setk"
"voice-engine/make-a-smart-speaker" -> "xiongyihui/python-webrtc-audio-processing"
"voice-engine/make-a-smart-speaker" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"voice-engine/make-a-smart-speaker" -> "athena-team/athena-signal"
"sigsep/open-unmix-pytorch" -> "f90/Wave-U-Net"
"sigsep/open-unmix-pytorch" -> "asteroid-team/asteroid"
"sigsep/open-unmix-pytorch" -> "KinWaiCheuk/nnAudio" ["e"=1]
"sigsep/open-unmix-pytorch" -> "sigsep/sigsep-mus-db"
"sigsep/open-unmix-pytorch" -> "sigsep/sigsep-mus-eval"
"sigsep/open-unmix-pytorch" -> "bytedance/music_source_separation"
"sigsep/open-unmix-pytorch" -> "facebookresearch/demucs"
"sigsep/open-unmix-pytorch" -> "csteinmetz1/auraloss" ["e"=1]
"sigsep/open-unmix-pytorch" -> "nussl/nussl"
"sigsep/open-unmix-pytorch" -> "sigsep/norbert"
"sigsep/open-unmix-pytorch" -> "CPJKU/madmom" ["e"=1]
"sigsep/open-unmix-pytorch" -> "f90/Wave-U-Net-Pytorch"
"sigsep/open-unmix-pytorch" -> "magenta/ddsp" ["e"=1]
"sigsep/open-unmix-pytorch" -> "marl/crepe" ["e"=1]
"sigsep/open-unmix-pytorch" -> "francesclluis/source-separation-wavenet"
"cyz7758520/Android_audio_talkback_demo_program" -> "cyz7758520/Windows_audio_talkback_demo_program"
"cyz7758520/Android_audio_talkback_demo_program" -> "yhthu/intercom"
"cyz7758520/Android_audio_talkback_demo_program" -> "cpuimage/WebRTC_AECM"
"cyz7758520/Android_audio_talkback_demo_program" -> "theeasiestway/android-webrtc-aecm"
"cyz7758520/Android_audio_talkback_demo_program" -> "mail2chromium/Android-Audio-Processing-Using-WebRTC"
"cyz7758520/Android_audio_talkback_demo_program" -> "waterfoxfox/Audio3AProcess"
"cyz7758520/Android_audio_talkback_demo_program" -> "xia-chu/webrtc_apm"
"cyz7758520/Android_audio_talkback_demo_program" -> "shenbengit/WebRTCExtension"
"bastamon/sound_signal_process-matlab-" -> "busyyang/python_sound_open"
"bastamon/sound_signal_process-matlab-" -> "JackHCC/Audio-Digital-Processing"
"bastamon/sound_signal_process-matlab-" -> "veenveenveen/SpeechSignalProcessingCourse"
"bastamon/sound_signal_process-matlab-" -> "taw19960426/-Speech-signal-processing-experiment-tutorial-_python"
"bastamon/sound_signal_process-matlab-" -> "PandoraLS/traditional-speech-enhancement"
"bastamon/sound_signal_process-matlab-" -> "peak1995/Speech-enhancement-dsp"
"ivannz/cplxmodule" -> "MRSRL/complex-networks-release"
"ivannz/cplxmodule" -> "zhaoymn/cubelearn"
"ivannz/cplxmodule" -> "wavefrontshaping/complexPyTorch"
"ivannz/cplxmodule" -> "JesperDramsch/keras-complex"
"ivannz/cplxmodule" -> "ChihebTrabelsi/deep_complex_networks"
"wavefrontshaping/complexPyTorch" -> "ChihebTrabelsi/deep_complex_networks"
"wavefrontshaping/complexPyTorch" -> "litcoderr/ComplexCNN"
"wavefrontshaping/complexPyTorch" -> "NEGU93/cvnn"
"wavefrontshaping/complexPyTorch" -> "ivannz/cplxmodule"
"wavefrontshaping/complexPyTorch" -> "MRSRL/complex-networks-release"
"wavefrontshaping/complexPyTorch" -> "JesperDramsch/keras-complex"
"wavefrontshaping/complexPyTorch" -> "sweetcocoa/DeepComplexUNetPyTorch"
"wavefrontshaping/complexPyTorch" -> "omrijsharon/torchlex"
"wavefrontshaping/complexPyTorch" -> "williamFalcon/pytorch-complex-tensor"
"wavefrontshaping/complexPyTorch" -> "mmuckley/torchkbnufft" ["e"=1]
"wavefrontshaping/complexPyTorch" -> "computational-imaging/neural-holography" ["e"=1]
"wavefrontshaping/complexPyTorch" -> "huyanxin/DeepComplexCRN"
"wavefrontshaping/complexPyTorch" -> "XinyuanLiao/ComplexNN"
"wavefrontshaping/complexPyTorch" -> "mehdihosseinimoghadam/Complex-Neural-Networks"
"wavefrontshaping/complexPyTorch" -> "maggie0830/DCCRN"
"sweetcocoa/DeepComplexUNetPyTorch" -> "chanil1218/DCUnet.pytorch"
"sweetcocoa/DeepComplexUNetPyTorch" -> "AppleHolic/source_separation"
"sweetcocoa/DeepComplexUNetPyTorch" -> "russellgeum/Phase-aware-Deep-Complex-UNet"
"sweetcocoa/DeepComplexUNetPyTorch" -> "litcoderr/ComplexCNN"
"sweetcocoa/DeepComplexUNetPyTorch" -> "huyanxin/DeepComplexCRN"
"sweetcocoa/DeepComplexUNetPyTorch" -> "pheepa/DCUnet"
"sweetcocoa/DeepComplexUNetPyTorch" -> "maggie0830/DCCRN"
"Baidu-AIP/speech-vad-demo" -> "cpuimage/WebRTC_VAD"
"Baidu-AIP/speech-vad-demo" -> "dpirch/libfvad"
"Baidu-AIP/speech-vad-demo" -> "cpuimage/WebRTC_NS"
"Baidu-AIP/speech-vad-demo" -> "xiangxyq/kaldi" ["e"=1]
"Baidu-AIP/speech-vad-demo" -> "open-speech/speech-aligner" ["e"=1]
"Baidu-AIP/speech-vad-demo" -> "robin1001/nn-vad"
"Baidu-AIP/speech-vad-demo" -> "ZhengkunTian/OpenTransformer" ["e"=1]
"Baidu-AIP/speech-vad-demo" -> "xiongyihui/python-webrtc-audio-processing"
"Baidu-AIP/speech-vad-demo" -> "jtkim-kaist/VAD"
"Baidu-AIP/speech-vad-demo" -> "marsbroshok/VAD-python"
"Baidu-AIP/speech-vad-demo" -> "funcwj/cgmm-mask-estimator"
"Baidu-AIP/speech-vad-demo" -> "XiaoMi/kaldi-onnx" ["e"=1]
"Baidu-AIP/speech-vad-demo" -> "shichaog/WebRTC-audio-processing"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_NS" -> "cpuimage/rnnoise"
"cpuimage/WebRTC_NS" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/WebRTC_NS" -> "cpuimage/SimpleAudioDenoise"
"cpuimage/WebRTC_NS" -> "cpuimage/resampler"
"cpuimage/WebRTC_NS" -> "jagger2048/WebRtc_noise_suppression"
"cpuimage/WebRTC_NS" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_NS" -> "ewan-xu/AEC3"
"cpuimage/WebRTC_NS" -> "Baidu-AIP/speech-vad-demo"
"cpuimage/WebRTC_NS" -> "cpuimage/FFTResampler"
"cpuimage/WebRTC_NS" -> "jagger2048/rnnoise-windows"
"cpuimage/WebRTC_NS" -> "wavesaudio/Speex-AEC-matlab"
"cpuimage/WebRTC_NS" -> "garyyu/WebRTC_VoiceEngine"
"jagger2048/WebRtc_noise_suppression" -> "jagger2048/WebRtc_AGC1"
"jagger2048/WebRtc_noise_suppression" -> "TracyJichuan/webrtc_noise_suppression"
"jagger2048/WebRtc_noise_suppression" -> "cpuimage/WebRTC_NS"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "jgarciagimenez/GSC_beamforming"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "satyanamuduri/Speech-Enhancement-Using-GSC"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "XiaoxiangGao/Dual_mic_phase_based_speech_enhancement"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "funcwj/cgmm-mask-estimator"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "Akki369/Generalised-Side-Lobe-Canceller"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "wangwei2009/Microphone-Array-postfilter"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "wangwei2009/coherence"
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" -> "chenwj1989/Beamforming_Examples"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "sandprddy/Active-Noise-Cancellation-System"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "markostam/active-noise-cancellation"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "YangangCao/AdaptiveFilter"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "mohitmewara/Noise-cancellation-LMS-adaptive-filter"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "ewan-xu/pyaec"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "SShirleyy/Adaptive-audio-filter-design"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "rohitner/adaptive-filters"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "xiezhq-hermann/ANC_signal-system_project"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "Spritea/AEC"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "Aketirani/active-noise-cancellation"
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" -> "psykulsk/RpiANC"
"funcwj/setk" -> "fgnt/nn-gev"
"funcwj/setk" -> "funcwj/CGMM-MVDR"
"funcwj/setk" -> "fgnt/pb_bss"
"funcwj/setk" -> "anicolson/DeepXi"
"funcwj/setk" -> "seanwood/gcc-nmf"
"funcwj/setk" -> "fgnt/nara_wpe"
"funcwj/setk" -> "athena-team/athena-signal"
"funcwj/setk" -> "ZitengWang/MASP"
"funcwj/setk" -> "DavidDiazGuerra/gpuRIR"
"funcwj/setk" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"funcwj/setk" -> "funcwj/aps"
"funcwj/setk" -> "funcwj/cgmm-mask-estimator"
"funcwj/setk" -> "kkumatani/distant_speech_recognition"
"funcwj/setk" -> "fgnt/pb_chime5"
"funcwj/setk" -> "xanguera/BeamformIt"
"speechLabBcCuny/onssen" -> "funcwj/conv-tasnet"
"speechLabBcCuny/onssen" -> "ujscjj/DPTNet"
"speechLabBcCuny/onssen" -> "chenzhuo1011/libri_css"
"speechLabBcCuny/onssen" -> "funcwj/setk"
"speechLabBcCuny/onssen" -> "etzinis/two_step_mask_learning"
"speechLabBcCuny/onssen" -> "yluo42/TAC"
"Sato-Kunihiko/audio-SNR" -> "speechLabBcCuny/onssen"
"gabrielmittag/NISQA" -> "aliutkus/speechmetrics"
"gabrielmittag/NISQA" -> "lochenchou/MOSNet"
"gabrielmittag/NISQA" -> "google/visqol"
"gabrielmittag/NISQA" -> "ludlows/PESQ"
"gabrielmittag/NISQA" -> "microsoft/DNS-Challenge"
"gabrielmittag/NISQA" -> "NVIDIA/BigVGAN" ["e"=1]
"gabrielmittag/NISQA" -> "schmiph2/pysepm"
"gabrielmittag/NISQA" -> "sarulab-speech/UTMOS22" ["e"=1]
"gabrielmittag/NISQA" -> "sp-uhh/sgmse"
"gabrielmittag/NISQA" -> "JasonSWFu/Quality-Net"
"gabrielmittag/NISQA" -> "mpariente/pystoi"
"gabrielmittag/NISQA" -> "facebookresearch/Noresqa"
"gabrielmittag/NISQA" -> "jik876/hifi-gan" ["e"=1]
"gabrielmittag/NISQA" -> "tarepan/SpeechMOS" ["e"=1]
"gabrielmittag/NISQA" -> "microsoft/P.808"
"detly/gammatone" -> "bingo-todd/Gammatone-filters"
"detly/gammatone" -> "ZhihaoDU/speech_feature_extractor"
"LahiruJayasinghe/DeepDOA" -> "GAMMA-UMD/doa-release"
"LahiruJayasinghe/DeepDOA" -> "chenhui07c8/DOA-AOA-algorithms"
"LahiruJayasinghe/DeepDOA" -> "morriswmz/doatools.py"
"LahiruJayasinghe/DeepDOA" -> "Soumitro-Chakrabarty/Single-speaker-localization"
"wangwei2009/DOA" -> "xiaoli1368/Microphone-sound-source-localization"
"wangwei2009/DOA" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"wangwei2009/DOA" -> "xiongyihui/tdoa"
"wangwei2009/DOA" -> "morriswmz/doa-tools"
"wangwei2009/DOA" -> "aishoot/Sound_Localization_Algorithms"
"wangwei2009/DOA" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"wangwei2009/DOA" -> "robin1001/beamforming"
"wangwei2009/DOA" -> "ZitengWang/MASP"
"wangwei2009/DOA" -> "xuchenglin28/WSCM-MUSIC"
"wangwei2009/DOA" -> "kkumatani/distant_speech_recognition"
"morriswmz/doatools.py" -> "morriswmz/doa-tools"
"morriswmz/doatools.py" -> "GAMMA-UMD/doa-release"
"morriswmz/doatools.py" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"morriswmz/doatools.py" -> "petotamas/pyArgus" ["e"=1]
"morriswmz/doatools.py" -> "LahiruJayasinghe/DeepDOA"
"morriswmz/doatools.py" -> "msamsami/doa-estimation-music"
"morriswmz/doatools.py" -> "LCAV/FRIDA"
"morriswmz/doatools.py" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"morriswmz/doatools.py" -> "wangwei2009/DOA"
"morriswmz/doatools.py" -> "yump/doamusic"
"morriswmz/doatools.py" -> "sharathadavanne/doa-net"
"morriswmz/doatools.py" -> "m2wagner/Alternating_Projections_Gridless_DOA_Estimation"
"morriswmz/doatools.py" -> "ge99210/DeepNetworks-for-DoA-estimation-in-low-SNR"
"morriswmz/doatools.py" -> "chenhui07c8/DOA-AOA-algorithms"
"morriswmz/doatools.py" -> "lewsilver/radar_doa"
"thesofproject/sof" -> "thesofproject/linux"
"thesofproject/sof" -> "xiph/speexdsp"
"thesofproject/sof" -> "alsa-project/alsa-lib" ["e"=1]
"thesofproject/sof" -> "thesofproject/sof-test"
"thesofproject/sof" -> "thesofproject/sof-docs"
"thesofproject/sof" -> "nxp-mcuxpresso/rpmsg-lite" ["e"=1]
"thesofproject/sof" -> "foss-xtensa/nnlib-hifi4"
"thesofproject/sof" -> "google/liblc3" ["e"=1]
"thesofproject/sof" -> "athena-team/athena-signal"
"voice-engine/ec" -> "respeaker/mic_array"
"voice-engine/ec" -> "voice-engine/make-a-smart-speaker"
"voice-engine/ec" -> "xiph/speexdsp"
"voice-engine/ec" -> "breizhn/DTLN-aec"
"voice-engine/ec" -> "respeaker/seeed-voicecard"
"voice-engine/ec" -> "xiongyihui/speexdsp-python"
"voice-engine/ec" -> "voice-engine/voice-engine"
"voice-engine/ec" -> "Spritea/AEC"
"voice-engine/ec" -> "ewan-xu/AEC3"
"voice-engine/ec" -> "HinTak/seeed-voicecard"
"voice-engine/ec" -> "microsoft/AEC-Challenge"
"voice-engine/ec" -> "lschilli/wav-aec"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "funcwj/CGMM-MVDR"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "Enny1991/beamformers"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "fgnt/nn-gev"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "ZitengWang/MASP"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "funcwj/setk"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "DistantSpeechRecognition/mcse"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "snsun/cgmm_mvdr"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "chenwj1989/Beamforming_Examples"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "tencent-ailab/FRA-RIR"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "xanguera/BeamformIt"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "jzi040941/PercepNet"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "aishoot/Sound_Localization_Algorithms"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "yluo42/TAC"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "huangzhenyu/beamforming"
"AkojimaSLP/Beamforming-for-speech-enhancement" -> "robin1001/beamforming"
"haoxiangsnr/SNR-Based-Progressive-Learning-of-Deep-Neural-Network-for-Speech-Enhancement" -> "haoxiangsnr/Speech_Enhancement_Tools"
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" -> "d-kitamura/ILRMA"
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" -> "d-kitamura/AuxIVA-ISS"
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" -> "XianruiWang/AuxIVA"
"mohitmewara/Noise-cancellation-LMS-adaptive-filter" -> "AmitProspeed/LMS-Adaptive-Filter"
"mohitmewara/Noise-cancellation-LMS-adaptive-filter" -> "SShirleyy/Adaptive-audio-filter-design"
"kaituoxu/TasNet" -> "funcwj/conv-tasnet"
"kaituoxu/TasNet" -> "kaituoxu/Conv-TasNet"
"kaituoxu/TasNet" -> "runninging/TASNET"
"kaituoxu/TasNet" -> "Moplast/TasNet-tensorflow"
"kaituoxu/TasNet" -> "funcwj/uPIT-for-speech-separation"
"kaituoxu/TasNet" -> "snsun/pit-speech-separation"
"kaituoxu/TasNet" -> "jaideeppatel/Training-Targets-for-Speech-Separation-Neural-Networks"
"xuchenglin28/WSCM-MUSIC" -> "chenhui07c8/DOA-AOA-algorithms"
"msamsami/doa-estimation-music" -> "morriswmz/doa-tools"
"msamsami/doa-estimation-music" -> "chenhui07c8/DOA-AOA-algorithms"
"msamsami/doa-estimation-music" -> "xuchenglin28/WSCM-MUSIC"
"msamsami/doa-estimation-music" -> "morriswmz/doatools.py"
"msamsami/doa-estimation-music" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"msamsami/doa-estimation-music" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"msamsami/doa-estimation-music" -> "LahiruJayasinghe/DeepDOA"
"msamsami/doa-estimation-music" -> "m2wagner/Alternating_Projections_Gridless_DOA_Estimation"
"chenhui07c8/DOA-AOA-algorithms" -> "m2wagner/Alternating_Projections_Gridless_DOA_Estimation"
"chenhui07c8/DOA-AOA-algorithms" -> "yujianyuanhaha/DoA-ML"
"chenhui07c8/DOA-AOA-algorithms" -> "TANG16/DAE4mulDOA"
"chenhui07c8/DOA-AOA-algorithms" -> "ge99210/DeepNetworks-for-DoA-estimation-in-low-SNR"
"Spritea/AEC" -> "wavesaudio/Speex-AEC-matlab"
"Spritea/AEC" -> "EthanLifeGreat/Mono_AEC"
"Spritea/AEC" -> "vaaiibhav/LMS-echo-cancellation"
"Spritea/AEC" -> "xiongyihui/speexdsp-python"
"Spritea/AEC" -> "linksense/NNAEC-NeuralNetworkbasedAcousticEchoCancellation"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "f90/Wave-U-Net-Pytorch"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "anicolson/DeepXi"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "santi-pdp/segan_pytorch"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "schmiph2/pysepm"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "huyanxin/DeepComplexCRN"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "huyanxin/phasen"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "yongxuUSTC/sednn"
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" -> "maggie0830/DCCRN"
"fudanxu/CV-CNN" -> "liuxuvip/PolSF"
"fudanxu/CV-CNN" -> "PROoshio/CRPM-Net"
"fudanxu/CV-CNN" -> "Jowekk/SAR-Image-Recognition"
"fudanxu/CV-CNN" -> "NEGU93/polsar_cvnn"
"fudanxu/CV-CNN" -> "liuxuvip/Polarimetric-Scattering-Coding"
"fudanxu/CV-CNN" -> "Alien9427/XAI4SAR-PGIL"
"Jowekk/SAR-Image-Recognition" -> "puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks"
"PROoshio/CRPM-Net" -> "liuxuvip/PolSF"
"PROoshio/CRPM-Net" -> "NEGU93/polsar_cvnn"
"PROoshio/CRPM-Net" -> "Shaunakde/deep-learning-polsar-book"
"Alien9427/SAR_specific_models" -> "XAI4SAR/SAR-HUB"
"Alien9427/SAR_specific_models" -> "Alien9427/DSN"
"Alien9427/SAR_specific_models" -> "Alien9427/XAI4SAR-PGIL"
"Alien9427/SAR_specific_models" -> "XAI4SAR/PIHA"
"naplab/DANet" -> "funcwj/deep-clustering"
"naplab/DANet" -> "funcwj/uPIT-for-speech-separation"
"naplab/DANet" -> "khaotik/DaNet-Tensorflow"
"leftthomas/SEGAN" -> "santi-pdp/segan_pytorch"
"leftthomas/SEGAN" -> "JasonSWFu/MetricGAN"
"leftthomas/SEGAN" -> "dansuh17/segan-pytorch"
"leftthomas/SEGAN" -> "santi-pdp/segan"
"leftthomas/SEGAN" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"leftthomas/SEGAN" -> "Zihang97/PAGAN"
"leftthomas/SEGAN" -> "chanil1218/DCUnet.pytorch"
"leftthomas/SEGAN" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"leftthomas/SEGAN" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"leftthomas/SEGAN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"leftthomas/SEGAN" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" -> "haoxiangsnr/SNR-Based-Progressive-Learning-of-Deep-Neural-Network-for-Speech-Enhancement"
"thesofproject/linux" -> "plbossart/sound"
"thesofproject/linux" -> "thesofproject/sof"
"f90/Wave-U-Net" -> "f90/Wave-U-Net-Pytorch"
"f90/Wave-U-Net" -> "kaituoxu/Conv-TasNet"
"f90/Wave-U-Net" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"f90/Wave-U-Net" -> "santi-pdp/segan"
"f90/Wave-U-Net" -> "santi-pdp/segan_pytorch"
"f90/Wave-U-Net" -> "sigsep/open-unmix-pytorch"
"f90/Wave-U-Net" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"f90/Wave-U-Net" -> "francesclluis/source-separation-wavenet"
"f90/Wave-U-Net" -> "asteroid-team/asteroid"
"f90/Wave-U-Net" -> "MTG/DeepConvSep"
"f90/Wave-U-Net" -> "andabi/music-source-separation"
"f90/Wave-U-Net" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"f90/Wave-U-Net" -> "drethage/speech-denoising-wavenet"
"f90/Wave-U-Net" -> "aliutkus/speechmetrics"
"f90/Wave-U-Net" -> "maum-ai/voicefilter"
"JesperDramsch/keras-complex" -> "NEGU93/cvnn"
"JesperDramsch/keras-complex" -> "JesperDramsch/Complex-CNN-Seismic"
"JesperDramsch/keras-complex" -> "MRSRL/complex-networks-release"
"JesperDramsch/keras-complex" -> "ChihebTrabelsi/deep_complex_networks"
"JesperDramsch/keras-complex" -> "russellgeum/Deep-Complex-Networks"
"JesperDramsch/keras-complex" -> "ivannz/cplxmodule"
"JesperDramsch/keras-complex" -> "litcoderr/ComplexCNN"
"lucianodato/speech-denoiser" -> "lucianodato/noise-repellent" ["e"=1]
"lucianodato/speech-denoiser" -> "GregorR/rnnoise-nu"
"lucianodato/speech-denoiser" -> "jagger2048/rnnoise-windows"
"lucianodato/speech-denoiser" -> "drethage/speech-denoising-wavenet"
"respeaker/pixel_ring" -> "respeaker/usb_4_mic_array"
"respeaker/usb_4_mic_array" -> "respeaker/pixel_ring"
"respeaker/usb_4_mic_array" -> "furushchev/respeaker_ros"
"respeaker/usb_4_mic_array" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"respeaker/usb_4_mic_array" -> "respeaker/mic_array"
"gionanide/Speech_Signal_Processing_and_Classification" -> "ZhihaoDU/speech_feature_extractor"
"gionanide/Speech_Signal_Processing_and_Classification" -> "aishoot/Speech_Feature_Extraction"
"gionanide/Speech_Signal_Processing_and_Classification" -> "gionanide/Neural_Machine_Translation"
"timsainb/noisereduce" -> "facebookresearch/denoiser"
"timsainb/noisereduce" -> "xiph/rnnoise"
"timsainb/noisereduce" -> "vbelz/Speech-enhancement"
"timsainb/noisereduce" -> "aliutkus/speechmetrics"
"timsainb/noisereduce" -> "microsoft/DNS-Challenge"
"timsainb/noisereduce" -> "Rikorose/DeepFilterNet"
"timsainb/noisereduce" -> "wiseman/py-webrtcvad"
"timsainb/noisereduce" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"timsainb/noisereduce" -> "breizhn/DTLN"
"timsainb/noisereduce" -> "iver56/audiomentations" ["e"=1]
"timsainb/noisereduce" -> "snakers4/silero-vad" ["e"=1]
"timsainb/noisereduce" -> "LCAV/pyroomacoustics"
"timsainb/noisereduce" -> "csteinmetz1/pyloudnorm"
"timsainb/noisereduce" -> "nanahou/Awesome-Speech-Enhancement"
"timsainb/noisereduce" -> "jik876/hifi-gan" ["e"=1]
"eesungkim/Speech_Enhancement_DNN_NMF" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/sednn"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "eesungkim/Speech_Enhancement_MMSE-STSA"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/DNN-for-speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "seanwood/gcc-nmf"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "jtkim-kaist/Speech-enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "santi-pdp/segan_pytorch"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "anicolson/DeepXi"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "hyli666/DNN-SpeechEnhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "santi-pdp/segan"
"eesungkim/Speech_Enhancement_DNN_NMF" -> "speechLabBcCuny/onssen"
"jsingh811/pyAudioProcessing" -> "SuperKogito/spafe"
"csteinmetz1/pyloudnorm" -> "csteinmetz1/auraloss" ["e"=1]
"csteinmetz1/pyloudnorm" -> "audiolabs/webMUSHRA"
"csteinmetz1/pyloudnorm" -> "KinWaiCheuk/nnAudio" ["e"=1]
"csteinmetz1/pyloudnorm" -> "LCAV/pyroomacoustics"
"csteinmetz1/pyloudnorm" -> "gemelo-ai/vocos" ["e"=1]
"csteinmetz1/pyloudnorm" -> "descriptinc/descript-audio-codec" ["e"=1]
"csteinmetz1/pyloudnorm" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"csteinmetz1/pyloudnorm" -> "DavidDiazGuerra/gpuRIR"
"csteinmetz1/pyloudnorm" -> "facebookresearch/WavAugment" ["e"=1]
"csteinmetz1/pyloudnorm" -> "justinsalamon/scaper" ["e"=1]
"csteinmetz1/pyloudnorm" -> "iver56/audiomentations" ["e"=1]
"csteinmetz1/pyloudnorm" -> "aliutkus/speechmetrics"
"csteinmetz1/pyloudnorm" -> "asteroid-team/torch-audiomentations" ["e"=1]
"csteinmetz1/pyloudnorm" -> "microsoft/DNS-Challenge"
"csteinmetz1/pyloudnorm" -> "mpariente/pystoi"
"puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks" -> "Jowekk/SAR-Image-Recognition"
"puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks" -> "hunterlew/mstar_with_machine_learning"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_NS"
"cpuimage/rnnoise" -> "cpuimage/SimpleAudioDenoise"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_VAD"
"cpuimage/rnnoise" -> "cpuimage/resampler"
"cpuimage/rnnoise" -> "jagger2048/rnnoise-windows"
"cpuimage/rnnoise" -> "cpuimage/AudioDenoise"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_AECM"
"cpuimage/rnnoise" -> "YongyuG/rnnoise_16k"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_AGC"
"cpuimage/rnnoise" -> "cpuimage/FFTResampler"
"cpuimage/rnnoise" -> "athena-team/athena-signal"
"cpuimage/rnnoise" -> "ouyangkk/speech_enhancement_rnnoise_mcra"
"cpuimage/rnnoise" -> "kkumatani/distant_speech_recognition"
"cpuimage/rnnoise" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/rnnoise" -> "YangangCao/WebRTC-3A1V"
"introlab/odas_web" -> "introlab/odas"
"introlab/odas_web" -> "introlab/odas_ros"
"introlab/odas_web" -> "introlab/16SoundsUSB"
"introlab/odas_web" -> "respeaker/usb_4_mic_array"
"introlab/odas_web" -> "xiongyihui/tdoa"
"introlab/odas_web" -> "furushchev/respeaker_ros"
"introlab/odas_web" -> "respeaker/4mics_hat"
"JacobWang95/mWDN" -> "yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch"
"JacobWang95/mWDN" -> "chenfei0328/mWDN-RCF"
"yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch" -> "JacobWang95/mWDN"
"yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch" -> "chenfei0328/mWDN-RCF"
"yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch" -> "liuyox/AnomalyDetection.MWDN"
"5bentz/linux-asus-t100" -> "jfwells/linux-asus-t100ta"
"jfwells/linux-asus-t100ta" -> "5bentz/linux-asus-t100"
"jfwells/linux-asus-t100ta" -> "AdamWill/baytrail-m"
"jfwells/linux-asus-t100ta" -> "plbossart/UCM"
"jfwells/linux-asus-t100ta" -> "hirotakaster/baytail-bootia32.efi"
"jfwells/linux-asus-t100ta" -> "Asus-T100/kernel"
"jfwells/linux-asus-t100ta" -> "hadess/rtl8723bs"
"sunits/rir_simulator_python" -> "jonashaag/RealRIRs"
"sunits/rir_simulator_python" -> "ehabets/RIR-Generator"
"DavidDiazGuerra/gpuRIR" -> "ehabets/RIR-Generator"
"DavidDiazGuerra/gpuRIR" -> "tencent-ailab/FRA-RIR"
"DavidDiazGuerra/gpuRIR" -> "LCAV/pyroomacoustics"
"DavidDiazGuerra/gpuRIR" -> "fgnt/nara_wpe"
"DavidDiazGuerra/gpuRIR" -> "yluo42/TAC"
"DavidDiazGuerra/gpuRIR" -> "funcwj/setk"
"DavidDiazGuerra/gpuRIR" -> "RoyJames/room-impulse-responses"
"DavidDiazGuerra/gpuRIR" -> "Audio-WestlakeU/NBSS"
"DavidDiazGuerra/gpuRIR" -> "Enny1991/beamformers"
"DavidDiazGuerra/gpuRIR" -> "microsoft/DNS-Challenge"
"DavidDiazGuerra/gpuRIR" -> "microsoft/AEC-Challenge"
"DavidDiazGuerra/gpuRIR" -> "JorisCos/LibriMix"
"DavidDiazGuerra/gpuRIR" -> "fgnt/nn-gev"
"DavidDiazGuerra/gpuRIR" -> "aliutkus/speechmetrics"
"DavidDiazGuerra/gpuRIR" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"aishoot/LSTM_PIT_Speech_Separation" -> "snsun/pit-speech-separation"
"aishoot/LSTM_PIT_Speech_Separation" -> "funcwj/uPIT-for-speech-separation"
"aishoot/LSTM_PIT_Speech_Separation" -> "seanwood/gcc-nmf"
"aishoot/LSTM_PIT_Speech_Separation" -> "funcwj/deep-clustering"
"aishoot/LSTM_PIT_Speech_Separation" -> "kaituoxu/Conv-TasNet"
"aishoot/LSTM_PIT_Speech_Separation" -> "posenhuang/deeplearningsourceseparation"
"aishoot/LSTM_PIT_Speech_Separation" -> "zhr1201/deep-clustering"
"aishoot/LSTM_PIT_Speech_Separation" -> "speechLabBcCuny/onssen"
"aishoot/LSTM_PIT_Speech_Separation" -> "khaotik/DaNet-Tensorflow"
"aishoot/LSTM_PIT_Speech_Separation" -> "funcwj/conv-tasnet"
"aishoot/LSTM_PIT_Speech_Separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"aishoot/LSTM_PIT_Speech_Separation" -> "funcwj/setk"
"aishoot/LSTM_PIT_Speech_Separation" -> "yongxuUSTC/sednn"
"aishoot/LSTM_PIT_Speech_Separation" -> "kaituoxu/TasNet"
"aishoot/LSTM_PIT_Speech_Separation" -> "yluo42/TAC"
"naplab/Conv-TasNet" -> "funcwj/conv-tasnet"
"naplab/Conv-TasNet" -> "kaituoxu/Conv-TasNet"
"naplab/Conv-TasNet" -> "JusperLee/Conv-TasNet"
"naplab/Conv-TasNet" -> "yluo42/TAC"
"naplab/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"naplab/Conv-TasNet" -> "Enny1991/beamformers"
"naplab/Conv-TasNet" -> "huyanxin/DeepComplexCRN"
"naplab/Conv-TasNet" -> "JorisCos/LibriMix"
"naplab/Conv-TasNet" -> "jzi040941/PercepNet"
"naplab/Conv-TasNet" -> "tky823/DNN-based_source_separation"
"naplab/Conv-TasNet" -> "ujscjj/DPTNet"
"naplab/Conv-TasNet" -> "JusperLee/Dual-Path-RNN-Pytorch"
"naplab/Conv-TasNet" -> "DavidDiazGuerra/gpuRIR"
"naplab/Conv-TasNet" -> "microsoft/DNS-Challenge"
"naplab/Conv-TasNet" -> "huyanxin/phasen"
"jtkim-kaist/Speech-enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"jtkim-kaist/Speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/DNN-for-speech-enhancement"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/sednn"
"jtkim-kaist/Speech-enhancement" -> "jtkim-kaist/VAD"
"jtkim-kaist/Speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"jtkim-kaist/Speech-enhancement" -> "seanwood/gcc-nmf"
"jtkim-kaist/Speech-enhancement" -> "anicolson/DeepXi"
"jtkim-kaist/Speech-enhancement" -> "ZitengWang/MASP"
"jtkim-kaist/Speech-enhancement" -> "DistantSpeechRecognition/mcse"
"jtkim-kaist/Speech-enhancement" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"jtkim-kaist/Speech-enhancement" -> "jdonley/SoundZone_Tools" ["e"=1]
"jtkim-kaist/Speech-enhancement" -> "santi-pdp/segan"
"jtkim-kaist/Speech-enhancement" -> "santi-pdp/segan_pytorch"
"jtkim-kaist/Speech-enhancement" -> "auspicious3000/WaveNet-Enhancement"
"yongxuUSTC/sednn" -> "yongxuUSTC/DNN-for-speech-enhancement"
"yongxuUSTC/sednn" -> "santi-pdp/segan"
"yongxuUSTC/sednn" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"yongxuUSTC/sednn" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"yongxuUSTC/sednn" -> "funcwj/setk"
"yongxuUSTC/sednn" -> "fgnt/nn-gev"
"yongxuUSTC/sednn" -> "anicolson/DeepXi"
"yongxuUSTC/sednn" -> "santi-pdp/segan_pytorch"
"yongxuUSTC/sednn" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"yongxuUSTC/sednn" -> "jtkim-kaist/Speech-enhancement"
"yongxuUSTC/sednn" -> "drethage/speech-denoising-wavenet"
"yongxuUSTC/sednn" -> "seanwood/gcc-nmf"
"yongxuUSTC/sednn" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"yongxuUSTC/sednn" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"yongxuUSTC/sednn" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"CharlesThaCat/acoustic-interference-cancellation" -> "linksense/NNAEC-NeuralNetworkbasedAcousticEchoCancellation"
"CharlesThaCat/acoustic-interference-cancellation" -> "EthanLifeGreat/Mono_AEC"
"lochenchou/MOSNet" -> "aliutkus/speechmetrics"
"lochenchou/MOSNet" -> "gabrielmittag/NISQA"
"lochenchou/MOSNet" -> "sarulab-speech/UTMOS22" ["e"=1]
"lochenchou/MOSNet" -> "JasonSWFu/Quality-Net"
"lochenchou/MOSNet" -> "nii-yamagishilab/mos-finetune-ssl" ["e"=1]
"lochenchou/MOSNet" -> "sky1456723/Pytorch-MBNet" ["e"=1]
"lochenchou/MOSNet" -> "ZhangXInFD/SpeechTokenizer" ["e"=1]
"lochenchou/MOSNet" -> "k2kobayashi/crank" ["e"=1]
"lochenchou/MOSNet" -> "maxrmorrison/torchcrepe" ["e"=1]
"lochenchou/MOSNet" -> "r9y9/pysptk" ["e"=1]
"lochenchou/MOSNet" -> "nii-yamagishilab/multi-speaker-tacotron" ["e"=1]
"sigsep/sigsep-mus-eval" -> "sigsep/sigsep-mus-db"
"sigsep/sigsep-mus-eval" -> "mir-evaluation/mir_eval" ["e"=1]
"sigsep/sigsep-mus-eval" -> "fgnt/pb_bss"
"jagger2048/rnnoise-windows" -> "GregorR/rnnoise-nu"
"jagger2048/rnnoise-windows" -> "cpuimage/rnnoise"
"jagger2048/rnnoise-windows" -> "ZitengWang/MASP"
"jagger2048/rnnoise-windows" -> "ewan-xu/AEC3"
"jagger2048/rnnoise-windows" -> "YongyuG/rnnoise_16k"
"hello-sea/DeepLearning_Wavelet-LSTM" -> "yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch"
"hello-sea/DeepLearning_Wavelet-LSTM" -> "GaigeY/DSP"
"santi-pdp/segan_pytorch" -> "santi-pdp/segan"
"santi-pdp/segan_pytorch" -> "leftthomas/SEGAN"
"santi-pdp/segan_pytorch" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"santi-pdp/segan_pytorch" -> "yongxuUSTC/sednn"
"santi-pdp/segan_pytorch" -> "drethage/speech-denoising-wavenet"
"santi-pdp/segan_pytorch" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"santi-pdp/segan_pytorch" -> "vBaiCai/python-pesq"
"santi-pdp/segan_pytorch" -> "anicolson/DeepXi"
"santi-pdp/segan_pytorch" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"santi-pdp/segan_pytorch" -> "Audio-WestlakeU/FullSubNet"
"santi-pdp/segan_pytorch" -> "vbelz/Speech-enhancement"
"santi-pdp/segan_pytorch" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"santi-pdp/segan_pytorch" -> "kaituoxu/Conv-TasNet"
"santi-pdp/segan_pytorch" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"santi-pdp/segan_pytorch" -> "ruizhecao96/CMGAN"
"eesungkim/Voice_Activity_Detector" -> "mounalab/LSTM-RNN-VAD"
"eesungkim/Voice_Activity_Detector" -> "nicklashansen/voice-activity-detection"
"eesungkim/Voice_Activity_Detector" -> "jtkim-kaist/VAD"
"eesungkim/Voice_Activity_Detector" -> "filippogiruzzi/voice_activity_detection"
"eesungkim/Voice_Activity_Detector" -> "marsbroshok/VAD-python"
"nicklashansen/voice-activity-detection" -> "filippogiruzzi/voice_activity_detection"
"nicklashansen/voice-activity-detection" -> "hcmlab/vadnet"
"nicklashansen/voice-activity-detection" -> "eesungkim/Voice_Activity_Detector"
"nicklashansen/voice-activity-detection" -> "jtkim-kaist/VAD"
"nicklashansen/voice-activity-detection" -> "voithru/voice-activity-detection"
"nicklashansen/voice-activity-detection" -> "jymsuper/VAD_tutorial"
"nicklashansen/voice-activity-detection" -> "marsbroshok/VAD-python"
"nicklashansen/voice-activity-detection" -> "SIP-Lab/CNN-VAD"
"nicklashansen/voice-activity-detection" -> "mounalab/LSTM-RNN-VAD"
"nicklashansen/voice-activity-detection" -> "RicherMans/GPV"
"hunterlew/mstar_deeplearning_project" -> "hunterlew/mstar_with_machine_learning"
"hunterlew/mstar_deeplearning_project" -> "azy1988/ML-CV"
"hunterlew/mstar_deeplearning_project" -> "hamza-latif/MSTAR_tensorflow"
"hunterlew/mstar_deeplearning_project" -> "puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks"
"hunterlew/mstar_deeplearning_project" -> "fudanxu/MSTAR-AConvNet"
"hunterlew/mstar_deeplearning_project" -> "jangsoopark/AConvNet-pytorch"
"hunterlew/mstar_deeplearning_project" -> "hunterlew/convolution_network_on_FPGA" ["e"=1]
"hunterlew/mstar_deeplearning_project" -> "huangshaoyin/MSTAR_data_deal"
"hunterlew/mstar_deeplearning_project" -> "ngageoint/MATLAB_SAR" ["e"=1]
"hunterlew/mstar_deeplearning_project" -> "Alien9427/SAR_specific_models"
"hunterlew/mstar_deeplearning_project" -> "joeyos/SAR-imaging" ["e"=1]
"maum-ai/voicefilter" -> "kaituoxu/Conv-TasNet"
"maum-ai/voicefilter" -> "asteroid-team/asteroid"
"maum-ai/voicefilter" -> "Edresson/VoiceSplit"
"maum-ai/voicefilter" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"maum-ai/voicefilter" -> "JorisCos/LibriMix"
"maum-ai/voicefilter" -> "xuchenglin28/speaker_extraction"
"maum-ai/voicefilter" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"maum-ai/voicefilter" -> "microsoft/DNS-Challenge"
"maum-ai/voicefilter" -> "gemengtju/Tutorial_Separation"
"maum-ai/voicefilter" -> "aliutkus/speechmetrics"
"maum-ai/voicefilter" -> "anicolson/DeepXi"
"maum-ai/voicefilter" -> "aishoot/LSTM_PIT_Speech_Separation"
"maum-ai/voicefilter" -> "JusperLee/Conv-TasNet"
"maum-ai/voicefilter" -> "funcwj/voice-filter"
"maum-ai/voicefilter" -> "JusperLee/Dual-Path-RNN-Pytorch"
"xmtggh/VideoCalling" -> "LostStarTvT/PhoneCall"
"xmtggh/VideoCalling" -> "liuqm/Android-VideoChat-master"
"xmtggh/VideoCalling" -> "yhthu/intercom"
"xmtggh/VideoCalling" -> "OboBear/AndroidPoint2PointFaceChat"
"xmtggh/VideoCalling" -> "ddssingsong/webrtc_android" ["e"=1]
"xmtggh/VideoCalling" -> "wbaizx/VideoLive"
"xmtggh/VideoCalling" -> "linsir6/webRTC-android-demo-and-Server"
"xmtggh/VideoCalling" -> "ddssingsong/webrtc_server_java" ["e"=1]
"LostStarTvT/PhoneCall" -> "xmtggh/VideoCalling"
"LostStarTvT/PhoneCall" -> "liuqm/Android-VideoChat-master"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_AECM" -> "ewan-xu/AEC3"
"cpuimage/WebRTC_AECM" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_AECM" -> "cpuimage/resampler"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/WebRTC_AECM" -> "LXP-Never/AEC_DeepModel"
"cpuimage/WebRTC_AECM" -> "LuoZhongYao/webrtcaecm"
"cpuimage/WebRTC_AECM" -> "DoubangoTelecom/webrtc-audioproc"
"cpuimage/WebRTC_AECM" -> "wavesaudio/Speex-AEC-matlab"
"cpuimage/WebRTC_AECM" -> "fjiang9/NKF-AEC"
"cpuimage/WebRTC_AECM" -> "SuperAI211/Realtime_AudioDenoise_EchoCancellation"
"cpuimage/WebRTC_AECM" -> "xia-chu/webrtc_apm"
"cpuimage/WebRTC_AECM" -> "cpuimage/WebRTC_CNG"
"fgnt/nara_wpe" -> "DavidDiazGuerra/gpuRIR"
"fgnt/nara_wpe" -> "ehabets/RIR-Generator"
"fgnt/nara_wpe" -> "funcwj/setk"
"fgnt/nara_wpe" -> "fgnt/nn-gev"
"fgnt/nara_wpe" -> "fgnt/pb_bss"
"fgnt/nara_wpe" -> "helianvine/fdndlp"
"fgnt/nara_wpe" -> "aliutkus/speechmetrics"
"fgnt/nara_wpe" -> "nttcslab-sp/dnn_wpe"
"fgnt/nara_wpe" -> "kkumatani/distant_speech_recognition"
"fgnt/nara_wpe" -> "xanguera/BeamformIt"
"fgnt/nara_wpe" -> "microsoft/DNS-Challenge"
"fgnt/nara_wpe" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"fgnt/nara_wpe" -> "athena-team/athena-signal"
"fgnt/nara_wpe" -> "LCAV/pyroomacoustics"
"fgnt/nara_wpe" -> "anicolson/DeepXi"
"voice-engine/voice-engine" -> "respeaker/mic_array"
"voice-engine/voice-engine" -> "respeaker/seeed-voicecard"
"voice-engine/voice-engine" -> "respeaker/avs"
"voice-engine/voice-engine" -> "respeaker/4mics_hat"
"voice-engine/voice-engine" -> "voice-engine/ec"
"voice-engine/voice-engine" -> "voice-engine/make-a-smart-speaker"
"voice-engine/voice-engine" -> "respeaker/respeaker_for_raspberrypi"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_VAD"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_AGC" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_AGC" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/WebRTC_AGC" -> "cpuimage/resampler"
"cpuimage/WebRTC_AGC" -> "ewan-xu/AEC3"
"cpuimage/WebRTC_AGC" -> "ctwgL/webrtc_agc2"
"cpuimage/WebRTC_AGC" -> "jorgehatccrma/pyagc"
"cpuimage/WebRTC_AGC" -> "wavesaudio/Speex-AEC-matlab"
"cpuimage/WebRTC_AGC" -> "kkumatani/distant_speech_recognition"
"cpuimage/WebRTC_AGC" -> "robin1001/beamforming"
"cpuimage/WebRTC_AGC" -> "athena-team/athena-signal"
"theeasiestway/android-webrtc-aecm" -> "iarray/android-webrtc-aec"
"theeasiestway/android-webrtc-aecm" -> "zzugyl/webrtc-based-android-aecm"
"theeasiestway/android-webrtc-aecm" -> "qiangqiang681/audioRecoder"
"theeasiestway/android-webrtc-aecm" -> "monkey1992/HWAudioProcessSDK"
"JasonSWFu/MetricGAN" -> "Zihang97/PAGAN"
"JasonSWFu/MetricGAN" -> "jonlu0602/DeepDenoisingAutoencoder"
"JasonSWFu/MetricGAN" -> "aleXiehta/PhoneFortifiedPerceptualLoss"
"JasonSWFu/MetricGAN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"JasonSWFu/MetricGAN" -> "pquochuy/idsegan"
"funcwj/CGMM-MVDR" -> "funcwj/cgmm-mask-estimator"
"funcwj/CGMM-MVDR" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"funcwj/CGMM-MVDR" -> "fgnt/nn-gev"
"funcwj/CGMM-MVDR" -> "snsun/cgmm_mvdr"
"funcwj/CGMM-MVDR" -> "DistantSpeechRecognition/mcse"
"funcwj/CGMM-MVDR" -> "xanguera/BeamformIt"
"funcwj/CGMM-MVDR" -> "funcwj/setk"
"funcwj/CGMM-MVDR" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"funcwj/CGMM-MVDR" -> "chenwj1989/Beamforming_Examples"
"xiezhq-hermann/ANC_signal-system_project" -> "markostam/active-noise-cancellation"
"ImperialCollegeLondon/sap-voicebox" -> "jtkim-kaist/Speech-enhancement"
"ImperialCollegeLondon/sap-voicebox" -> "athena-team/athena-signal"
"ImperialCollegeLondon/sap-voicebox" -> "DavidDiazGuerra/gpuRIR"
"ImperialCollegeLondon/sap-voicebox" -> "ZitengWang/MASP"
"ImperialCollegeLondon/sap-voicebox" -> "jfsantos/SRMRpy"
"ImperialCollegeLondon/sap-voicebox" -> "ehabets/RIR-Generator"
"ImperialCollegeLondon/sap-voicebox" -> "polarch/Spherical-Array-Processing" ["e"=1]
"ImperialCollegeLondon/sap-voicebox" -> "fgnt/nara_wpe"
"ImperialCollegeLondon/sap-voicebox" -> "sofacoustics/SOFAtoolbox" ["e"=1]
"ImperialCollegeLondon/sap-voicebox" -> "funcwj/setk"
"ImperialCollegeLondon/sap-voicebox" -> "wavesaudio/Speex-AEC-matlab"
"ImperialCollegeLondon/sap-voicebox" -> "orchidas/Pitch-Tracking"
"funcwj/cgmm-mask-estimator" -> "funcwj/CGMM-MVDR"
"funcwj/cgmm-mask-estimator" -> "snsun/cgmm_mvdr"
"funcwj/cgmm-mask-estimator" -> "Tungluai/RTF-based-LCMV-GSC"
"funcwj/cgmm-mask-estimator" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"funcwj/cgmm-mask-estimator" -> "ZitengWang/nn_mask"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_NS"
"cpuimage/WebRTC_VAD" -> "cpuimage/resampler"
"cpuimage/WebRTC_VAD" -> "YangangCao/WebRTC-3A1V"
"cpuimage/WebRTC_VAD" -> "cpuimage/FFTResampler"
"cpuimage/WebRTC_VAD" -> "cpuimage/rnnoise"
"cpuimage/WebRTC_VAD" -> "lbcgi/webrtc_agc_matlab"
"cpuimage/WebRTC_VAD" -> "cpuimage/AudioDenoise"
"cpuimage/WebRTC_VAD" -> "wavesaudio/Speex-AEC-matlab"
"cpuimage/WebRTC_VAD" -> "cpuimage/WebRTC_NS_CPP"
"anicolson/DeepXi" -> "funcwj/setk"
"anicolson/DeepXi" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"anicolson/DeepXi" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"anicolson/DeepXi" -> "microsoft/DNS-Challenge"
"anicolson/DeepXi" -> "yongxuUSTC/sednn"
"anicolson/DeepXi" -> "huyanxin/phasen"
"anicolson/DeepXi" -> "huyanxin/DeepComplexCRN"
"anicolson/DeepXi" -> "breizhn/DTLN"
"anicolson/DeepXi" -> "jzi040941/PercepNet"
"anicolson/DeepXi" -> "nanahou/Awesome-Speech-Enhancement"
"anicolson/DeepXi" -> "Audio-WestlakeU/FullSubNet"
"anicolson/DeepXi" -> "aliutkus/speechmetrics"
"anicolson/DeepXi" -> "microsoft/MS-SNSD"
"anicolson/DeepXi" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"anicolson/DeepXi" -> "schmiph2/pysepm"
"GregorR/rnnoise-nu" -> "GregorR/rnnoise-models"
"GregorR/rnnoise-nu" -> "YongyuG/rnnoise_16k"
"GregorR/rnnoise-nu" -> "jagger2048/rnnoise-windows"
"GregorR/rnnoise-nu" -> "robin1001/beamforming"
"GregorR/rnnoise-nu" -> "funcwj/cgmm-mask-estimator"
"sigsep/sigsep-mus-db" -> "sigsep/sigsep-mus-eval"
"sigsep/sigsep-mus-db" -> "sigsep/open-unmix-pytorch"
"mpariente/pystoi" -> "ludlows/PESQ"
"mpariente/pystoi" -> "vBaiCai/python-pesq"
"mpariente/pystoi" -> "schmiph2/pysepm"
"mpariente/pystoi" -> "aliutkus/speechmetrics"
"mpariente/pystoi" -> "jfsantos/SRMRpy"
"mpariente/pystoi" -> "DavidDiazGuerra/gpuRIR"
"mpariente/pystoi" -> "huyanxin/phasen"
"mpariente/pystoi" -> "mpariente/pytorch_stoi"
"mpariente/pystoi" -> "gabrielmittag/NISQA"
"mpariente/pystoi" -> "ehabets/RIR-Generator"
"mpariente/pystoi" -> "JorisCos/LibriMix"
"mpariente/pystoi" -> "funcwj/conv-tasnet"
"mpariente/pystoi" -> "anicolson/DeepXi"
"mpariente/pystoi" -> "huyanxin/DeepComplexCRN"
"mpariente/pystoi" -> "Audio-WestlakeU/FullSubNet"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "santi-pdp/segan_pytorch"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "anicolson/DeepXi"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "JasonSWFu/MetricGAN"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "speechLabBcCuny/onssen"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "vBaiCai/python-pesq"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "jonlu0602/DeepDenoisingAutoencoder"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "ododoyo/EHNet"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "auspicious3000/WaveNet-Enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "yongxuUSTC/sednn"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" -> "f90/Wave-U-Net"
"waveshareteam/WM8960-Audio-HAT" -> "pguyot/wm8960"
"GregorR/rnnoise-models" -> "GregorR/rnnoise-nu"
"GregorR/rnnoise-models" -> "richardpl/arnndn-models"
"GregorR/rnnoise-models" -> "CedArctic/rnnoise-ex"
"GregorR/rnnoise-models" -> "jagger2048/rnnoise-windows"
"GregorR/rnnoise-models" -> "YongyuG/rnnoise_16k"
"GregorR/rnnoise-models" -> "smallmuou/wavutils"
"fudanxu/MSTAR-AConvNet" -> "jangsoopark/AConvNet-pytorch"
"fudanxu/MSTAR-AConvNet" -> "hunterlew/mstar_with_machine_learning"
"furushchev/respeaker_ros" -> "respeaker/usb_4_mic_array"
"orctom/vad4j" -> "debmalya/JavaVAD"
"orctom/vad4j" -> "jitsi/jitsi-webrtc-vad-wrapper"
"akcarsten/Independent_Component_Analysis" -> "alvarouc/ica"
"akcarsten/Independent_Component_Analysis" -> "Felix-Yan/FastICA"
"akcarsten/Independent_Component_Analysis" -> "vsubhashini/ica"
"akcarsten/Independent_Component_Analysis" -> "pbrakel/anica"
"garyyu/WebRTC_VoiceEngine" -> "DoubangoTelecom/webrtc-audioproc"
"garyyu/WebRTC_VoiceEngine" -> "xshl5/KOTI_AEC"
"garyyu/WebRTC_VoiceEngine" -> "lschilli/wav-aec"
"Enny1991/beamformers" -> "yluo42/TAC"
"Enny1991/beamformers" -> "fgnt/nn-gev"
"Enny1991/beamformers" -> "Andong-Li-speech/EaBNet"
"Enny1991/beamformers" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"Enny1991/beamformers" -> "yoonsanghyu/FaSNet-TAC-PyTorch"
"Enny1991/beamformers" -> "hangtingchen/Beam-Guided-TasNet"
"Enny1991/beamformers" -> "Audio-WestlakeU/NBSS"
"Enny1991/beamformers" -> "AkojimaSLP/Neural-mask-estimation"
"Enny1991/beamformers" -> "Audio-WestlakeU/McNet"
"Enny1991/beamformers" -> "sp-uhh/deep-non-linear-filter"
"Enny1991/beamformers" -> "fgnt/sms_wsj"
"nttcslab-sp/dnn_wpe" -> "DiegoLeon96/Neural-Speech-Dereverberation"
"Hardcorehobel/Binaural_Localization" -> "nicolasobin/binauralLocalization"
"Hardcorehobel/Binaural_Localization" -> "LeeTaewoo/fast_sound_source_localization_using_TLSSC"
"AppleHolic/source_separation" -> "sweetcocoa/DeepComplexUNetPyTorch"
"AppleHolic/source_separation" -> "chanil1218/DCUnet.pytorch"
"AppleHolic/source_separation" -> "speechLabBcCuny/onssen"
"AppleHolic/source_separation" -> "tky823/DNN-based_source_separation"
"AppleHolic/source_separation" -> "huyanxin/phasen"
"AppleHolic/source_separation" -> "funcwj/conv-tasnet"
"AppleHolic/source_separation" -> "AppleHolic/pytorch_sound"
"AppleHolic/source_separation" -> "funcwj/setk"
"AppleHolic/source_separation" -> "huyanxin/DeepComplexCRN"
"AppleHolic/source_separation" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"AppleHolic/source_separation" -> "funcwj/aps"
"AppleHolic/source_separation" -> "ujscjj/DPTNet"
"AppleHolic/source_separation" -> "microsoft/P.808"
"AppleHolic/source_separation" -> "pheepa/DCUnet"
"AppleHolic/source_separation" -> "bill9800/speech_separation" ["e"=1]
"xia-chu/webrtc_apm" -> "dengzikun/WebRTC-APM-for-Android"
"xia-chu/webrtc_apm" -> "cpuimage/WebRTC_AECM"
"MTG/gaia" -> "MTG/DeepConvSep"
"MTG/gaia" -> "MTG/essentia" ["e"=1]
"MTG/gaia" -> "MTG/pycompmusic" ["e"=1]
"MTG/gaia" -> "dominikschnitzer/musly"
"MTG/gaia" -> "metabrainz/acousticbrainz-server" ["e"=1]
"xuchenglin28/speaker_extraction" -> "xuchenglin28/speaker_extraction_SpEx"
"xuchenglin28/speaker_extraction" -> "gemengtju/SpEx_Plus"
"xuchenglin28/speaker_extraction" -> "BUTSpeechFIT/speakerbeam"
"xuchenglin28/speaker_extraction" -> "gemengtju/L-SpEx"
"xuchenglin28/speaker_extraction" -> "haoxiangsnr/SpEx"
"xuchenglin28/speaker_extraction" -> "xuchenglin28/speech_separation"
"xuchenglin28/speaker_extraction" -> "chenzhuo1011/libri_css"
"xuchenglin28/speaker_extraction" -> "JorisCos/LibriMix"
"xuchenglin28/speaker_extraction" -> "yluo42/TAC"
"xuchenglin28/speaker_extraction" -> "gemengtju/Tutorial_Separation"
"xuchenglin28/speaker_extraction" -> "xuchenglin28/target_speaker_verification"
"azy1988/ML-CV" -> "hamza-latif/MSTAR_tensorflow"
"azy1988/ML-CV" -> "hunterlew/mstar_deeplearning_project"
"azy1988/ML-CV" -> "hunterlew/mstar_with_machine_learning"
"azy1988/ML-CV" -> "Alien9427/SAR_specific_models"
"azy1988/ML-CV" -> "PolarisShi/distillation"
"GaigeY/DSP" -> "ruixv/DSP_CourseDesign"
"m-r-s/hearingaid-prototype" -> "HoerTech-gGmbH/openMHA"
"m-r-s/hearingaid-prototype" -> "Tympan/Tympan_Library"
"m-r-s/hearingaid-prototype" -> "HoerTech-gGmbH/Cape4all"
"m-r-s/hearingaid-prototype" -> "audioplastic/BioAid"
"peak1995/Speech-enhancement-dsp" -> "vipchengrui/traditional-speech-enhancement"
"peak1995/Speech-enhancement-dsp" -> "RodneyHK/Speechenhancement"
"peak1995/Speech-enhancement-dsp" -> "PandoraLS/traditional-speech-enhancement"
"JasonSWFu/Quality-Net" -> "MuSAELab/SRMRToolbox"
"JasonSWFu/Quality-Net" -> "lochenchou/MOSNet"
"francesclluis/source-separation-wavenet" -> "MTG/DeepConvSep"
"francesclluis/source-separation-wavenet" -> "andabi/music-source-separation"
"francesclluis/source-separation-wavenet" -> "f90/Wave-U-Net"
"francesclluis/source-separation-wavenet" -> "SConsul/audio-source-separation"
"francesclluis/source-separation-wavenet" -> "ShichengChen/Audio-Source-Separation"
"ninja3697/Kernel-Adaptive-Filtering-in-Python" -> "rohitner/adaptive-filters"
"Yaafe/Yaafe" -> "jamiebullock/LibXtract"
"eesungkim/Speech_Enhancement_MMSE-STSA" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"eesungkim/Speech_Enhancement_MMSE-STSA" -> "rajivpoddar/mmse-port"
"chenwj1989/Beamforming_Examples" -> "wangwei2009/Microphone-Array-postfilter"
"chenwj1989/Beamforming_Examples" -> "jgarciagimenez/GSC_beamforming"
"chenwj1989/Beamforming_Examples" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"chenwj1989/Beamforming_Examples" -> "snsun/cgmm_mvdr"
"jeremyxu177/active-noise-control" -> "YosukeSugiura/ActiveNoiseControl"
"YosukeSugiura/ActiveNoiseControl" -> "jeremyxu177/active-noise-control"
"YosukeSugiura/ActiveNoiseControl" -> "adithyasunil26/Active-Noise-Control"
"funcwj/deep-clustering" -> "zhr1201/deep-clustering"
"funcwj/deep-clustering" -> "funcwj/uPIT-for-speech-separation"
"funcwj/deep-clustering" -> "naplab/DANet"
"funcwj/deep-clustering" -> "snsun/pit-speech-separation"
"funcwj/deep-clustering" -> "khaotik/DaNet-Tensorflow"
"funcwj/deep-clustering" -> "aishoot/LSTM_PIT_Speech_Separation"
"zzugyl/webrtc-based-android-aecm" -> "theeasiestway/android-webrtc-aecm"
"zzugyl/webrtc-based-android-aecm" -> "iarray/android-webrtc-aec"
"lhc180/webrtc-based-android-aecm" -> "theeasiestway/android-webrtc-aecm"
"lhc180/webrtc-based-android-aecm" -> "tata88k/webrtc-android-jni"
"hcmlab/vadnet" -> "jtkim-kaist/VAD"
"hcmlab/vadnet" -> "marsbroshok/VAD-python"
"hcmlab/vadnet" -> "filippogiruzzi/voice_activity_detection"
"hcmlab/vadnet" -> "nicklashansen/voice-activity-detection"
"hcmlab/vadnet" -> "mindorii/kws" ["e"=1]
"hcmlab/vadnet" -> "wiseman/py-webrtcvad"
"hcmlab/vadnet" -> "wangshub/python-vad"
"hcmlab/vadnet" -> "anicolson/DeepXi"
"hcmlab/vadnet" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"hcmlab/vadnet" -> "yongxuUSTC/sednn"
"hcmlab/vadnet" -> "funcwj/setk"
"hcmlab/vadnet" -> "zeroQiaoba/ivector-xvector" ["e"=1]
"hcmlab/vadnet" -> "eesungkim/Voice_Activity_Detector"
"hcmlab/vadnet" -> "amsehili/auditok"
"hcmlab/vadnet" -> "speechLabBcCuny/onssen"
"psykulsk/RpiANC" -> "xiezhq-hermann/ANC_signal-system_project"
"psykulsk/RpiANC" -> "markostam/active-noise-cancellation"
"psykulsk/RpiANC" -> "masilvabustos/TMS320C6748-ANC"
"psykulsk/RpiANC" -> "YosukeSugiura/ActiveNoiseControl"
"psykulsk/RpiANC" -> "CharlieHouse/RPi_SISO_ANC"
"psykulsk/RpiANC" -> "LiXirong/AdaptiveFilterandActiveNoiseCancellation"
"psykulsk/RpiANC" -> "Quantisan/nullwave"
"haoxiangsnr/Speech_Enhancement_Tools" -> "haoxiangsnr/Build-SE-Dataset"
"hunterlew/mstar_with_machine_learning" -> "hunterlew/mstar_deeplearning_project"
"hunterlew/mstar_with_machine_learning" -> "puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks"
"hunterlew/mstar_with_machine_learning" -> "hamza-latif/MSTAR_tensorflow"
"hunterlew/mstar_with_machine_learning" -> "fudanxu/MSTAR-AConvNet"
"hunterlew/mstar_with_machine_learning" -> "huangshaoyin/MSTAR_data_deal"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "linan2/TensorFlow-speech-enhancement"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "haoxiangsnr/Speech_Enhancement_Tools"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"linan2/TensorFlow-speech-enhancement-Chinese" -> "boozyguo/ClearWave"
"gionanide/Neural_Machine_Translation" -> "gionanide/OpiRec"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/FFTResampler"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/AudioDenoise"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/WebRTC_NS_CPP"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/WebRTC_NS"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/rnnoise"
"cpuimage/SimpleAudioDenoise" -> "cpuimage/resampler"
"robical/StatisticalSignalProcessing" -> "mohitmewara/Noise-cancellation-LMS-adaptive-filter"
"iarray/android-webrtc-aec" -> "theeasiestway/android-webrtc-aecm"
"iarray/android-webrtc-aec" -> "zzugyl/webrtc-based-android-aecm"
"iarray/android-webrtc-aec" -> "monkey1992/HWAudioProcessSDK"
"ZitengWang/MASP" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"ZitengWang/MASP" -> "fgnt/nn-gev"
"ZitengWang/MASP" -> "funcwj/setk"
"ZitengWang/MASP" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"ZitengWang/MASP" -> "tencent-ailab/FRA-RIR"
"ZitengWang/MASP" -> "MiguelBlancoGalindo/MicArrayBeamforming"
"kkumatani/distant_speech_recognition" -> "robin1001/beamforming"
"kkumatani/distant_speech_recognition" -> "xanguera/BeamformIt"
"kkumatani/distant_speech_recognition" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"kkumatani/distant_speech_recognition" -> "athena-team/athena-signal"
"kkumatani/distant_speech_recognition" -> "helianvine/fdndlp"
"kkumatani/distant_speech_recognition" -> "funcwj/setk"
"kkumatani/distant_speech_recognition" -> "fgnt/nn-gev"
"kkumatani/distant_speech_recognition" -> "Tungluai/RTF-based-LCMV-GSC"
"kkumatani/distant_speech_recognition" -> "wavesaudio/Speex-AEC-matlab"
"kkumatani/distant_speech_recognition" -> "ZitengWang/MASP"
"kkumatani/distant_speech_recognition" -> "fgnt/nara_wpe"
"kkumatani/distant_speech_recognition" -> "chenwj1989/Beamforming_Examples"
"kkumatani/distant_speech_recognition" -> "snsun/cgmm_mvdr"
"kkumatani/distant_speech_recognition" -> "funcwj/CGMM-MVDR"
"kkumatani/distant_speech_recognition" -> "wangwei2009/Microphone-Array-postfilter"
"litcoderr/ComplexCNN" -> "ChihebTrabelsi/deep_complex_networks"
"litcoderr/ComplexCNN" -> "sweetcocoa/DeepComplexUNetPyTorch"
"litcoderr/ComplexCNN" -> "wavefrontshaping/complexPyTorch"
"litcoderr/ComplexCNN" -> "JesperDramsch/keras-complex"
"litcoderr/ComplexCNN" -> "MRSRL/complex-networks-release"
"litcoderr/ComplexCNN" -> "russellgeum/Phase-aware-Deep-Complex-UNet"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "drethage/speech-denoising-wavenet"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "mosheman5/DNP"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "anicolson/DeepXi"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "speechLabBcCuny/onssen"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "JasonSWFu/MetricGAN"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "auspicious3000/WaveNet-Enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "AppleHolic/source_separation"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "boozyguo/ClearWave"
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"d-kitamura/ILRMA" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"d-kitamura/ILRMA" -> "d-kitamura/AuxIVA-ISS"
"d-kitamura/ILRMA" -> "XianruiWang/AuxIVA"
"d-kitamura/ILRMA" -> "d-kitamura/multichannelNMF"
"sekiguchi92/SoundSourceSeparation" -> "nttcslab-sp/dnn_wpe"
"sekiguchi92/SoundSourceSeparation" -> "nay0648/unified2021"
"sekiguchi92/SoundSourceSeparation" -> "fgnt/pb_bss"
"sekiguchi92/SoundSourceSeparation" -> "seanwood/gcc-nmf"
"sekiguchi92/SoundSourceSeparation" -> "d-kitamura/ILRMA"
"sekiguchi92/SoundSourceSeparation" -> "tky823/audio_source_separation"
"sekiguchi92/SoundSourceSeparation" -> "KyleZhang1118/Voice-Separation-and-Enhancement"
"sekiguchi92/SoundSourceSeparation" -> "fgnt/nn-gev"
"helrewaidy/deep-complex-convolutional-network" -> "MRSRL/complex-networks-release"
"rohitner/adaptive-filters" -> "rohitner/ERP-BDAY" ["e"=1]
"mounalab/LSTM-RNN-VAD" -> "Cocoxili/VAD"
"MRSRL/dl-cs" -> "evanlev/cpd"
"sigsep/norbert" -> "pfnet-research/meta-tasnet"
"sigsep/norbert" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"jymsuper/VAD_tutorial" -> "xashru/robust-vad"
"hyli666/DNN-SpeechEnhancement" -> "funcwj/nn-ideal-mask"
"hyli666/DNN-SpeechEnhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"hyli666/DNN-SpeechEnhancement" -> "yongxuUSTC/DNN-for-speech-enhancement"
"YangangCao/AdaptiveFilter" -> "braton/fadapt"
"YangangCao/AdaptiveFilter" -> "CharlesThaCat/acoustic-interference-cancellation"
"introlab/16SoundsUSB" -> "eez-open/xmos-eval-board"
"dansuh17/segan-pytorch" -> "leftthomas/SEGAN"
"dansuh17/segan-pytorch" -> "santi-pdp/segan_pytorch"
"dansuh17/segan-pytorch" -> "peak1995/segan"
"wbaizx/VideoLive" -> "yhthu/intercom"
"mosheman5/DNP" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"f90/AdversarialAudioSeparation" -> "soobinseo/wavenet"
"andre442/Acoustic-feedback-detection" -> "Agustin-Picard/DSP-Feedback-Suppression"
"andre442/Acoustic-feedback-detection" -> "ssprl/Noise-Injection-Based-Acoustic-Feedback-Cancellation"
"helianvine/fdndlp" -> "fgnt/nara_wpe"
"helianvine/fdndlp" -> "kkumatani/distant_speech_recognition"
"helianvine/fdndlp" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"helianvine/fdndlp" -> "DistantSpeechRecognition/mcse"
"helianvine/fdndlp" -> "snsun/gwpe-speech-dereverb"
"helianvine/fdndlp" -> "wangkenpu/Adaptive-Dereverberation-Algorithm"
"wangwei2009/Microphone-Array-postfilter" -> "wangwei2009/coherence"
"ruixv/DSP_CourseDesign" -> "spyyes/Image4Matlab"
"cpuimage/resampler" -> "cpuimage/FFTResampler"
"cpuimage/resampler" -> "cpuimage/WebRTC_AECM"
"cpuimage/resampler" -> "cpuimage/WebRTC_VAD"
"cpuimage/resampler" -> "cpuimage/WebRTC_AGC"
"cpuimage/resampler" -> "chenwj1989/python_howling_suppression" ["e"=1]
"cpuimage/resampler" -> "cpuimage/WebRTC_NS"
"cpuimage/resampler" -> "YangangCao/WebRTC-3A1V"
"cpuimage/resampler" -> "cpuimage/rnnoise"
"cpuimage/resampler" -> "cpuimage/SimpleAudioDenoise"
"funcwj/conv-tasnet" -> "naplab/Conv-TasNet"
"funcwj/conv-tasnet" -> "kaituoxu/Conv-TasNet"
"funcwj/conv-tasnet" -> "kaituoxu/TasNet"
"funcwj/conv-tasnet" -> "speechLabBcCuny/onssen"
"funcwj/conv-tasnet" -> "yluo42/TAC"
"funcwj/conv-tasnet" -> "Enny1991/beamformers"
"funcwj/conv-tasnet" -> "huyanxin/phasen"
"funcwj/conv-tasnet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"funcwj/conv-tasnet" -> "huyanxin/DeepComplexCRN"
"funcwj/conv-tasnet" -> "funcwj/CGMM-MVDR"
"funcwj/conv-tasnet" -> "funcwj/uPIT-for-speech-separation"
"funcwj/conv-tasnet" -> "fgnt/nn-gev"
"funcwj/conv-tasnet" -> "jzi040941/PercepNet"
"jitsi/jitsi-webrtc-vad-wrapper" -> "orctom/vad4j"
"jitsi/jitsi-webrtc-vad-wrapper" -> "debmalya/JavaVAD"
"aishoot/Speech_Feature_Extraction" -> "ZhihaoDU/speech_feature_extractor"
"Js-Mim/mss_pytorch" -> "dr-costas/mad-twinnet"
"Js-Mim/mss_pytorch" -> "andabi/music-source-separation"
"funcwj/uPIT-for-speech-separation" -> "snsun/pit-speech-separation"
"funcwj/uPIT-for-speech-separation" -> "funcwj/deep-clustering"
"funcwj/uPIT-for-speech-separation" -> "aishoot/LSTM_PIT_Speech_Separation"
"funcwj/uPIT-for-speech-separation" -> "naplab/DANet"
"funcwj/uPIT-for-speech-separation" -> "funcwj/conv-tasnet"
"satyanamuduri/Speech-Enhancement-Using-GSC" -> "jgarciagimenez/GSC_beamforming"
"satyanamuduri/Speech-Enhancement-Using-GSC" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"satyanamuduri/Speech-Enhancement-Using-GSC" -> "Akki369/Generalised-Side-Lobe-Canceller"
"Tungluai/RTF-based-LCMV-GSC" -> "wangwei2009/spatial-temporal-LCMV"
"scpark20/universal-music-translation" -> "ShichengChen/Audio-Source-Separation"
"funcwj/nn-ideal-mask" -> "IMLHF/WFb_SE"
"funcwj/aps" -> "yluo42/GC3"
"funcwj/aps" -> "funcwj/setk"
"funcwj/aps" -> "felixfuyihui/Uformer"
"haoxiangsnr/Build-SE-Dataset" -> "haoxiangsnr/Speech_Enhancement_Tools"
"linsir6/git-commit-emoji" -> "linsir6/BaseDevelop"
"linsir6/git-commit-emoji" -> "linsir6/WebRTC-Voice"
"linsir6/git-commit-emoji" -> "linsir6/MacNote"
"auspicious3000/deepbeam" -> "zhr1201/Multi-channel-speech-extraction-using-DNN"
"auspicious3000/deepbeam" -> "auspicious3000/WaveNet-Enhancement"
"wslihgt/pyfasst" -> "openBliSSART/openBliSSART"
"peak1995/segan" -> "PandoraLS/SpeechEnhancement"
"fgnt/pb_chime5" -> "fgnt/nn-gev"
"fgnt/pb_chime5" -> "desh2608/gss" ["e"=1]
"fgnt/pb_chime5" -> "funcwj/cgmm-mask-estimator"
"fgnt/pb_chime5" -> "fgnt/pb_bss"
"fgnt/pb_chime5" -> "funcwj/setk"
"xuchenglin28/speech_separation" -> "haoxiangsnr/SpEx"
"Agustin-Picard/DSP-Feedback-Suppression" -> "ssprl/Noise-Injection-Based-Acoustic-Feedback-Cancellation"
"ShichengChen/Audio-Source-Separation" -> "scpark20/universal-music-translation"
"ShichengChen/Audio-Source-Separation" -> "soobinseo/wavenet"
"jonlu0602/DeepDenoisingAutoencoder" -> "WilliamYu1993/ICSE"
"gionanide/OpiRec" -> "gionanide/Neural_Machine_Translation"
"facebookresearch/demucs" -> "deezer/spleeter" ["e"=1]
"facebookresearch/demucs" -> "adefossez/demucs"
"facebookresearch/demucs" -> "Anjok07/ultimatevocalremovergui" ["e"=1]
"facebookresearch/demucs" -> "sigsep/open-unmix-pytorch"
"facebookresearch/demucs" -> "spotify/basic-pitch" ["e"=1]
"facebookresearch/demucs" -> "asteroid-team/asteroid"
"facebookresearch/demucs" -> "speechbrain/speechbrain" ["e"=1]
"facebookresearch/demucs" -> "facebookresearch/encodec" ["e"=1]
"facebookresearch/demucs" -> "magenta/ddsp" ["e"=1]
"facebookresearch/demucs" -> "espnet/espnet" ["e"=1]
"facebookresearch/demucs" -> "facebookresearch/audiocraft" ["e"=1]
"facebookresearch/demucs" -> "microsoft/muzic" ["e"=1]
"facebookresearch/demucs" -> "facebookresearch/denoiser"
"facebookresearch/demucs" -> "pyannote/pyannote-audio" ["e"=1]
"facebookresearch/demucs" -> "librosa/librosa" ["e"=1]
"slhck/ffmpeg-normalize" -> "csteinmetz1/pyloudnorm"
"slhck/ffmpeg-normalize" -> "lordmulder/DynamicAudioNormalizer"
"slhck/ffmpeg-normalize" -> "wiseman/py-webrtcvad"
"slhck/ffmpeg-normalize" -> "aliutkus/speechmetrics"
"slhck/ffmpeg-normalize" -> "asteroid-team/asteroid"
"slhck/ffmpeg-normalize" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"slhck/ffmpeg-normalize" -> "faroit/awesome-python-scientific-audio" ["e"=1]
"slhck/ffmpeg-normalize" -> "amiaopensource/ffmprovisr" ["e"=1]
"slhck/ffmpeg-normalize" -> "bootphon/phonemizer" ["e"=1]
"slhck/ffmpeg-normalize" -> "LCAV/pyroomacoustics"
"slhck/ffmpeg-normalize" -> "microsoft/DNS-Challenge"
"slhck/ffmpeg-normalize" -> "descriptinc/descript-audio-codec" ["e"=1]
"slhck/ffmpeg-normalize" -> "bavc/qctools" ["e"=1]
"slhck/ffmpeg-normalize" -> "fgnt/nara_wpe"
"slhck/ffmpeg-normalize" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"asteroid-team/asteroid" -> "microsoft/DNS-Challenge"
"asteroid-team/asteroid" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"asteroid-team/asteroid" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"asteroid-team/asteroid" -> "kaituoxu/Conv-TasNet"
"asteroid-team/asteroid" -> "LCAV/pyroomacoustics"
"asteroid-team/asteroid" -> "facebookresearch/denoiser"
"asteroid-team/asteroid" -> "JorisCos/LibriMix"
"asteroid-team/asteroid" -> "DavidDiazGuerra/gpuRIR"
"asteroid-team/asteroid" -> "nanahou/Awesome-Speech-Enhancement"
"asteroid-team/asteroid" -> "huyanxin/DeepComplexCRN"
"asteroid-team/asteroid" -> "gemengtju/Tutorial_Separation"
"asteroid-team/asteroid" -> "maum-ai/voicefilter"
"asteroid-team/asteroid" -> "Audio-WestlakeU/FullSubNet"
"asteroid-team/asteroid" -> "fgnt/nara_wpe"
"asteroid-team/asteroid" -> "speechbrain/speechbrain" ["e"=1]
"gkonovalov/android-vad" -> "dpirch/libfvad"
"gkonovalov/android-vad" -> "nyadla-sys/whisper.tflite" ["e"=1]
"gkonovalov/android-vad" -> "modelscope/kws-training-suite" ["e"=1]
"gkonovalov/android-vad" -> "vilassn/whisper_android" ["e"=1]
"gkonovalov/android-vad" -> "k2-fsa/sherpa-ncnn" ["e"=1]
"google/visqol" -> "gabrielmittag/NISQA"
"google/visqol" -> "ludlows/PESQ"
"google/visqol" -> "aliutkus/speechmetrics"
"google/visqol" -> "descriptinc/descript-audio-codec" ["e"=1]
"google/visqol" -> "microsoft/DNS-Challenge"
"google/visqol" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"google/visqol" -> "yangdongchao/AcademiCodec" ["e"=1]
"google/visqol" -> "mpariente/pystoi"
"google/visqol" -> "wesbz/SoundStream" ["e"=1]
"google/visqol" -> "jik876/hifi-gan" ["e"=1]
"google/visqol" -> "lochenchou/MOSNet"
"google/visqol" -> "schmiph2/pysepm"
"google/visqol" -> "audiolabs/webMUSHRA"
"google/visqol" -> "microsoft/AEC-Challenge"
"google/visqol" -> "sp-uhh/sgmse"
"aliutkus/speechmetrics" -> "lochenchou/MOSNet"
"aliutkus/speechmetrics" -> "gabrielmittag/NISQA"
"aliutkus/speechmetrics" -> "schmiph2/pysepm"
"aliutkus/speechmetrics" -> "ludlows/PESQ"
"aliutkus/speechmetrics" -> "vBaiCai/python-pesq"
"aliutkus/speechmetrics" -> "microsoft/DNS-Challenge"
"aliutkus/speechmetrics" -> "mpariente/pystoi"
"aliutkus/speechmetrics" -> "nanahou/Awesome-Speech-Enhancement"
"aliutkus/speechmetrics" -> "google/visqol"
"aliutkus/speechmetrics" -> "fgnt/nara_wpe"
"aliutkus/speechmetrics" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"aliutkus/speechmetrics" -> "DavidDiazGuerra/gpuRIR"
"aliutkus/speechmetrics" -> "anicolson/DeepXi"
"aliutkus/speechmetrics" -> "JorisCos/LibriMix"
"aliutkus/speechmetrics" -> "Ryuk17/SpeechAlgorithms"
"RicherMans/GPV" -> "RicherMans/Datadriven-GPVAD"
"RicherMans/GPV" -> "RicherMans/Dcase2018_pooling"
"busyyang/python_sound_open" -> "bastamon/sound_signal_process-matlab-"
"busyyang/python_sound_open" -> "PandoraLS/traditional-speech-enhancement"
"busyyang/python_sound_open" -> "Ryuk17/SpeechAlgorithms"
"busyyang/python_sound_open" -> "athena-team/athena-signal"
"busyyang/python_sound_open" -> "ewan-xu/pyaec"
"busyyang/python_sound_open" -> "CharlesThaCat/acoustic-interference-cancellation"
"busyyang/python_sound_open" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"busyyang/python_sound_open" -> "YongyuG/rnnoise_16k"
"busyyang/python_sound_open" -> "anicolson/DeepXi"
"busyyang/python_sound_open" -> "SeventeenChen/Python_Speech_SZY"
"busyyang/python_sound_open" -> "LXP-Never/Speech-signal-processing"
"busyyang/python_sound_open" -> "SuperKogito/spafe"
"busyyang/python_sound_open" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"busyyang/python_sound_open" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"busyyang/python_sound_open" -> "echocatzh/MTFAA-Net"
"breizhn/DTLN" -> "breizhn/DTLN-aec"
"breizhn/DTLN" -> "jzi040941/PercepNet"
"breizhn/DTLN" -> "Audio-WestlakeU/FullSubNet"
"breizhn/DTLN" -> "huyanxin/DeepComplexCRN"
"breizhn/DTLN" -> "microsoft/DNS-Challenge"
"breizhn/DTLN" -> "microsoft/AEC-Challenge"
"breizhn/DTLN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"breizhn/DTLN" -> "anicolson/DeepXi"
"breizhn/DTLN" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"breizhn/DTLN" -> "maggie0830/DCCRN"
"breizhn/DTLN" -> "facebookresearch/denoiser"
"breizhn/DTLN" -> "fjiang9/NKF-AEC"
"breizhn/DTLN" -> "SuperAI211/Realtime_AudioDenoise_EchoCancellation"
"breizhn/DTLN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"breizhn/DTLN" -> "Xiaobin-Rong/gtcrn"
"microsoft/DNS-Challenge" -> "huyanxin/DeepComplexCRN"
"microsoft/DNS-Challenge" -> "Audio-WestlakeU/FullSubNet"
"microsoft/DNS-Challenge" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"microsoft/DNS-Challenge" -> "microsoft/AEC-Challenge"
"microsoft/DNS-Challenge" -> "asteroid-team/asteroid"
"microsoft/DNS-Challenge" -> "breizhn/DTLN"
"microsoft/DNS-Challenge" -> "microsoft/MS-SNSD"
"microsoft/DNS-Challenge" -> "aliutkus/speechmetrics"
"microsoft/DNS-Challenge" -> "facebookresearch/denoiser"
"microsoft/DNS-Challenge" -> "nanahou/Awesome-Speech-Enhancement"
"microsoft/DNS-Challenge" -> "DavidDiazGuerra/gpuRIR"
"microsoft/DNS-Challenge" -> "jzi040941/PercepNet"
"microsoft/DNS-Challenge" -> "anicolson/DeepXi"
"microsoft/DNS-Challenge" -> "LCAV/pyroomacoustics"
"microsoft/DNS-Challenge" -> "ehabets/RIR-Generator"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "gemengtju/Tutorial_Separation"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JusperLee/Dual-Path-RNN-Pytorch"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "asteroid-team/asteroid"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "nanahou/Awesome-Speech-Enhancement"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JusperLee/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "kaituoxu/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "yluo42/TAC"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "JorisCos/LibriMix"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "microsoft/DNS-Challenge"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "naplab/Conv-TasNet"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "DavidDiazGuerra/gpuRIR"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "Ryuk17/SpeechAlgorithms"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "aliutkus/speechmetrics"
"JusperLee/Speech-Separation-Paper-Tutorial" -> "funcwj/setk"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "microsoft/DNS-Challenge"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "Ryuk17/SpeechAlgorithms"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "huyanxin/DeepComplexCRN"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "vbelz/Speech-enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "Audio-WestlakeU/FullSubNet"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "asteroid-team/asteroid"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "anicolson/DeepXi"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "jzi040941/PercepNet"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "aliutkus/speechmetrics"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "facebookresearch/denoiser"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "schmiph2/pysepm"
"WenzheLiu-Speech/awesome-speech-enhancement" -> "DavidDiazGuerra/gpuRIR"
"YongyuG/rnnoise_16k" -> "jzi040941/PercepNet"
"YongyuG/rnnoise_16k" -> "CedArctic/rnnoise-ex"
"YongyuG/rnnoise_16k" -> "GregorR/rnnoise-nu"
"acoular/acoular" -> "xanguera/BeamformIt"
"acoular/acoular" -> "LCAV/pyroomacoustics"
"acoular/acoular" -> "jorgengrythe/beamforming"
"acoular/acoular" -> "robin1001/beamforming"
"acoular/acoular" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"acoular/acoular" -> "aishoot/Sound_Localization_Algorithms"
"acoular/acoular" -> "ZitengWang/MASP"
"acoular/acoular" -> "introlab/odas"
"acoular/acoular" -> "kkumatani/distant_speech_recognition"
"acoular/acoular" -> "huangzhenyu/beamforming"
"acoular/acoular" -> "athena-team/athena-signal"
"acoular/acoular" -> "fgnt/nara_wpe"
"acoular/acoular" -> "funcwj/CGMM-MVDR"
"acoular/acoular" -> "respeaker/mic_array"
"acoular/acoular" -> "eac-ufsm/beamforming-tools"
"wangwei2009/coherence" -> "wangwei2009/Microphone-Array-postfilter"
"wangwei2009/coherence" -> "mmmgalleria/Dual-Microphone-Noise-Reduction-by-PLD-Technique"
"xiaochunxin/OMLSA-MCRA" -> "yuzhouhe2000/OMLSA-IMCRA"
"xiaochunxin/OMLSA-MCRA" -> "ouyangkk/speech_enhancement_rnnoise_mcra"
"athena-team/athena-signal" -> "funcwj/setk"
"athena-team/athena-signal" -> "kkumatani/distant_speech_recognition"
"athena-team/athena-signal" -> "jzi040941/PercepNet"
"athena-team/athena-signal" -> "microsoft/AEC-Challenge"
"athena-team/athena-signal" -> "ZitengWang/MASP"
"athena-team/athena-signal" -> "huyanxin/DeepComplexCRN"
"athena-team/athena-signal" -> "fjiang9/NKF-AEC"
"athena-team/athena-signal" -> "fgnt/nara_wpe"
"athena-team/athena-signal" -> "robin1001/beamforming"
"athena-team/athena-signal" -> "Ryuk17/SpeechAlgorithms"
"athena-team/athena-signal" -> "ehabets/RIR-Generator"
"athena-team/athena-signal" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"athena-team/athena-signal" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"athena-team/athena-signal" -> "ewan-xu/pyaec"
"athena-team/athena-signal" -> "shichaog/WebRTC-audio-processing"
"google-research/sound-separation" -> "kaituoxu/Conv-TasNet"
"google-research/sound-separation" -> "JorisCos/LibriMix"
"google-research/sound-separation" -> "asteroid-team/asteroid"
"google-research/sound-separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"google-research/sound-separation" -> "yluo42/TAC"
"google-research/sound-separation" -> "naplab/Conv-TasNet"
"google-research/sound-separation" -> "tky823/DNN-based_source_separation"
"google-research/sound-separation" -> "DavidDiazGuerra/gpuRIR"
"google-research/sound-separation" -> "gemengtju/Tutorial_Separation"
"google-research/sound-separation" -> "chenzhuo1011/libri_css"
"google-research/sound-separation" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"google-research/sound-separation" -> "Audio-WestlakeU/FullSubNet"
"google-research/sound-separation" -> "csteinmetz1/auraloss" ["e"=1]
"google-research/sound-separation" -> "etzinis/sudo_rm_rf"
"google-research/sound-separation" -> "microsoft/DNS-Challenge"
"xiph/speexdsp" -> "xiph/speex" ["e"=1]
"xiph/speexdsp" -> "wavesaudio/Speex-AEC-matlab"
"xiph/speexdsp" -> "xiongyihui/speexdsp-python"
"xiph/speexdsp" -> "microsoft/AEC-Challenge"
"xiph/speexdsp" -> "ewan-xu/pyaec"
"xiph/speexdsp" -> "athena-team/athena-signal"
"xiph/speexdsp" -> "ZitengWang/MASP"
"xiph/speexdsp" -> "ewan-xu/AEC3"
"xiph/speexdsp" -> "robin1001/beamforming"
"xiph/speexdsp" -> "jzi040941/PercepNet"
"xiph/speexdsp" -> "fjiang9/NKF-AEC"
"xiph/speexdsp" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"xiph/speexdsp" -> "voice-engine/ec"
"xiph/speexdsp" -> "cpuimage/WebRTC_AECM"
"xiph/speexdsp" -> "xanguera/BeamformIt"
"huyanxin/phasen" -> "huyanxin/DeepComplexCRN"
"huyanxin/phasen" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"huyanxin/phasen" -> "jzi040941/PercepNet"
"huyanxin/phasen" -> "anicolson/DeepXi"
"huyanxin/phasen" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"huyanxin/phasen" -> "maggie0830/DCCRN"
"huyanxin/phasen" -> "RookieJunChen/FullSubNet-plus"
"huyanxin/phasen" -> "funcwj/conv-tasnet"
"huyanxin/phasen" -> "funcwj/setk"
"huyanxin/phasen" -> "seorim0/DCCRN-with-various-loss-functions"
"huyanxin/phasen" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"huyanxin/phasen" -> "chanil1218/DCUnet.pytorch"
"huyanxin/phasen" -> "vBaiCai/python-pesq"
"huyanxin/DeepComplexCRN" -> "maggie0830/DCCRN"
"huyanxin/DeepComplexCRN" -> "Audio-WestlakeU/FullSubNet"
"huyanxin/DeepComplexCRN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"huyanxin/DeepComplexCRN" -> "jzi040941/PercepNet"
"huyanxin/DeepComplexCRN" -> "microsoft/DNS-Challenge"
"huyanxin/DeepComplexCRN" -> "huyanxin/phasen"
"huyanxin/DeepComplexCRN" -> "breizhn/DTLN"
"huyanxin/DeepComplexCRN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"huyanxin/DeepComplexCRN" -> "RookieJunChen/FullSubNet-plus"
"huyanxin/DeepComplexCRN" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"huyanxin/DeepComplexCRN" -> "seorim0/DCCRN-with-various-loss-functions"
"huyanxin/DeepComplexCRN" -> "echocatzh/MTFAA-Net"
"huyanxin/DeepComplexCRN" -> "yluo42/TAC"
"huyanxin/DeepComplexCRN" -> "nanahou/Awesome-Speech-Enhancement"
"huyanxin/DeepComplexCRN" -> "Xiaobin-Rong/gtcrn"
"facebookresearch/denoiser" -> "microsoft/DNS-Challenge"
"facebookresearch/denoiser" -> "asteroid-team/asteroid"
"facebookresearch/denoiser" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"facebookresearch/denoiser" -> "Audio-WestlakeU/FullSubNet"
"facebookresearch/denoiser" -> "breizhn/DTLN"
"facebookresearch/denoiser" -> "nanahou/Awesome-Speech-Enhancement"
"facebookresearch/denoiser" -> "aliutkus/speechmetrics"
"facebookresearch/denoiser" -> "huyanxin/DeepComplexCRN"
"facebookresearch/denoiser" -> "schmiph2/pysepm"
"facebookresearch/denoiser" -> "facebookresearch/WavAugment" ["e"=1]
"facebookresearch/denoiser" -> "anicolson/DeepXi"
"facebookresearch/denoiser" -> "vbelz/Speech-enhancement"
"facebookresearch/denoiser" -> "microsoft/MS-SNSD"
"facebookresearch/denoiser" -> "jzi040941/PercepNet"
"facebookresearch/denoiser" -> "jik876/hifi-gan" ["e"=1]
"vivjay30/Cone-of-Silence" -> "tencent-ailab/FRA-RIR"
"vivjay30/Cone-of-Silence" -> "yuhogun0908/MISOnet"
"vivjay30/Cone-of-Silence" -> "Enny1991/beamformers"
"vivjay30/Cone-of-Silence" -> "funcwj/aps"
"vivjay30/Cone-of-Silence" -> "yluo42/TAC"
"vivjay30/Cone-of-Silence" -> "yluo42/GC3"
"gemengtju/Tutorial_Separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"gemengtju/Tutorial_Separation" -> "nanahou/Awesome-Speech-Enhancement"
"gemengtju/Tutorial_Separation" -> "xuchenglin28/speaker_extraction"
"gemengtju/Tutorial_Separation" -> "kaituoxu/Conv-TasNet"
"gemengtju/Tutorial_Separation" -> "JorisCos/LibriMix"
"gemengtju/Tutorial_Separation" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"gemengtju/Tutorial_Separation" -> "asteroid-team/asteroid"
"gemengtju/Tutorial_Separation" -> "tky823/DNN-based_source_separation"
"gemengtju/Tutorial_Separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"gemengtju/Tutorial_Separation" -> "huyanxin/DeepComplexCRN"
"gemengtju/Tutorial_Separation" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"gemengtju/Tutorial_Separation" -> "etzinis/sudo_rm_rf"
"gemengtju/Tutorial_Separation" -> "funcwj/setk"
"gemengtju/Tutorial_Separation" -> "gemengtju/SpEx_Plus"
"gemengtju/Tutorial_Separation" -> "JusperLee/Conv-TasNet"
"KyleZhang1118/Voice-Separation-and-Enhancement" -> "Tungluai/RTF-based-LCMV-GSC"
"KyleZhang1118/Voice-Separation-and-Enhancement" -> "ZitengWang/MASP"
"KyleZhang1118/Voice-Separation-and-Enhancement" -> "chenwj1989/Beamforming_Examples"
"liuxuvip/PolSF" -> "PROoshio/CRPM-Net"
"liuxuvip/PolSF" -> "Jowekk/SAR-Image-Recognition"
"liuxuvip/PolSF" -> "NEGU93/polsar_cvnn"
"liuxuvip/PolSF" -> "liuxuvip/Polarimetric-Scattering-Coding"
"liuxuvip/PolSF" -> "AICyberTeam/AIR-PolSAR-Seg"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "huyanxin/DeepComplexCRN"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "anicolson/DeepXi"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "huyanxin/phasen"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "JupiterEthan/GCRN-complex"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "Audio-WestlakeU/FullSubNet"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "maggie0830/DCCRN"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "microsoft/MS-SNSD"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "JasonSWFu/MetricGAN"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"etzinis/sudo_rm_rf" -> "yluo42/TAC"
"etzinis/sudo_rm_rf" -> "ujscjj/DPTNet"
"etzinis/sudo_rm_rf" -> "RookieJunChen/FullSubNet-plus"
"etzinis/sudo_rm_rf" -> "JorisCos/LibriMix"
"etzinis/sudo_rm_rf" -> "JusperLee/TDANet"
"etzinis/sudo_rm_rf" -> "kaituoxu/Conv-TasNet"
"etzinis/sudo_rm_rf" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"etzinis/sudo_rm_rf" -> "gemengtju/Tutorial_Separation"
"etzinis/sudo_rm_rf" -> "etzinis/two_step_mask_learning"
"etzinis/sudo_rm_rf" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"etzinis/sudo_rm_rf" -> "Audio-WestlakeU/FullSubNet"
"etzinis/sudo_rm_rf" -> "jzi040941/PercepNet"
"etzinis/sudo_rm_rf" -> "tky823/DNN-based_source_separation"
"etzinis/sudo_rm_rf" -> "Enny1991/beamformers"
"etzinis/sudo_rm_rf" -> "huyanxin/DeepComplexCRN"
"JackHCC/Audio-Digital-Processing" -> "fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI"
"JackHCC/Audio-Digital-Processing" -> "XuRulin/DSP-Example-for-MATLAB"
"JackHCC/Audio-Digital-Processing" -> "veenveenveen/SpeechSignalProcessingCourse"
"JackHCC/Audio-Digital-Processing" -> "bastamon/sound_signal_process-matlab-"
"JackHCC/Audio-Digital-Processing" -> "H874589148/Digital-Signal-Processing_Experiment"
"JackHCC/Audio-Digital-Processing" -> "GaigeY/DSP"
"JusperLee/Conv-TasNet" -> "kaituoxu/Conv-TasNet"
"JusperLee/Conv-TasNet" -> "JusperLee/Dual-Path-RNN-Pytorch"
"JusperLee/Conv-TasNet" -> "naplab/Conv-TasNet"
"JusperLee/Conv-TasNet" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JusperLee/Conv-TasNet" -> "yluo42/TAC"
"JusperLee/Conv-TasNet" -> "JorisCos/LibriMix"
"JusperLee/Conv-TasNet" -> "JusperLee/Deep-Encoder-Decoder-Conv-TasNet"
"JusperLee/Conv-TasNet" -> "funcwj/conv-tasnet"
"JusperLee/Conv-TasNet" -> "gemengtju/Tutorial_Separation"
"JusperLee/Conv-TasNet" -> "JusperLee/TDANet"
"JusperLee/Conv-TasNet" -> "Audio-WestlakeU/FullSubNet"
"JusperLee/Conv-TasNet" -> "huyanxin/DeepComplexCRN"
"JusperLee/Conv-TasNet" -> "JusperLee/Deep-Clustering-for-Speech-Separation" ["e"=1]
"JusperLee/Conv-TasNet" -> "JusperLee/AFRCNN-For-Speech-Separation" ["e"=1]
"JusperLee/Conv-TasNet" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"JorisCos/LibriMix" -> "xuchenglin28/speaker_extraction"
"JorisCos/LibriMix" -> "DavidDiazGuerra/gpuRIR"
"JorisCos/LibriMix" -> "popcornell/SparseLibriMix"
"JorisCos/LibriMix" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JorisCos/LibriMix" -> "gemengtju/Tutorial_Separation"
"JorisCos/LibriMix" -> "asteroid-team/asteroid"
"JorisCos/LibriMix" -> "chenzhuo1011/libri_css"
"JorisCos/LibriMix" -> "aliutkus/speechmetrics"
"JorisCos/LibriMix" -> "yluo42/TAC"
"JorisCos/LibriMix" -> "JusperLee/Conv-TasNet"
"JorisCos/LibriMix" -> "JusperLee/TDANet"
"JorisCos/LibriMix" -> "BUTSpeechFIT/speakerbeam"
"JorisCos/LibriMix" -> "JusperLee/Dual-Path-RNN-Pytorch"
"JorisCos/LibriMix" -> "naplab/Conv-TasNet"
"JorisCos/LibriMix" -> "huyanxin/DeepComplexCRN"
"filippogiruzzi/voice_activity_detection" -> "nicklashansen/voice-activity-detection"
"filippogiruzzi/voice_activity_detection" -> "hcmlab/vadnet"
"filippogiruzzi/voice_activity_detection" -> "jtkim-kaist/VAD"
"filippogiruzzi/voice_activity_detection" -> "marsbroshok/VAD-python"
"filippogiruzzi/voice_activity_detection" -> "voithru/voice-activity-detection"
"filippogiruzzi/voice_activity_detection" -> "eesungkim/Voice_Activity_Detector"
"filippogiruzzi/voice_activity_detection" -> "wangshub/python-vad"
"filippogiruzzi/voice_activity_detection" -> "RicherMans/GPV"
"filippogiruzzi/voice_activity_detection" -> "jymsuper/VAD_tutorial"
"filippogiruzzi/voice_activity_detection" -> "wiseman/py-webrtcvad"
"filippogiruzzi/voice_activity_detection" -> "mounalab/LSTM-RNN-VAD"
"filippogiruzzi/voice_activity_detection" -> "skgusrb12/voice_activity_detection"
"filippogiruzzi/voice_activity_detection" -> "breizhn/DTLN"
"filippogiruzzi/voice_activity_detection" -> "nanahou/Awesome-Speech-Enhancement"
"filippogiruzzi/voice_activity_detection" -> "zlzhang1124/voice_activity_detection" ["e"=1]
"vbelz/Speech-enhancement" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"vbelz/Speech-enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "nanahou/Awesome-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"vbelz/Speech-enhancement" -> "santi-pdp/segan_pytorch"
"vbelz/Speech-enhancement" -> "breizhn/DTLN"
"vbelz/Speech-enhancement" -> "drethage/speech-denoising-wavenet"
"vbelz/Speech-enhancement" -> "anicolson/DeepXi"
"vbelz/Speech-enhancement" -> "santi-pdp/segan"
"vbelz/Speech-enhancement" -> "facebookresearch/denoiser"
"vbelz/Speech-enhancement" -> "Audio-WestlakeU/FullSubNet"
"vbelz/Speech-enhancement" -> "microsoft/MS-SNSD"
"vbelz/Speech-enhancement" -> "huyanxin/DeepComplexCRN"
"vbelz/Speech-enhancement" -> "schmiph2/pysepm"
"vbelz/Speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"sharathadavanne/hungarian-net" -> "sharathadavanne/doa-net"
"ws-choi/ISMIR2020_U_Nets_SVS" -> "ws-choi/Conditioned-Source-Separation-LaSAFT"
"nanahou/Awesome-Speech-Enhancement" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"nanahou/Awesome-Speech-Enhancement" -> "gemengtju/Tutorial_Separation"
"nanahou/Awesome-Speech-Enhancement" -> "microsoft/DNS-Challenge"
"nanahou/Awesome-Speech-Enhancement" -> "huyanxin/DeepComplexCRN"
"nanahou/Awesome-Speech-Enhancement" -> "aliutkus/speechmetrics"
"nanahou/Awesome-Speech-Enhancement" -> "Audio-WestlakeU/FullSubNet"
"nanahou/Awesome-Speech-Enhancement" -> "funcwj/setk"
"nanahou/Awesome-Speech-Enhancement" -> "vbelz/Speech-enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "anicolson/DeepXi"
"nanahou/Awesome-Speech-Enhancement" -> "jzi040941/PercepNet"
"nanahou/Awesome-Speech-Enhancement" -> "asteroid-team/asteroid"
"nanahou/Awesome-Speech-Enhancement" -> "Ryuk17/SpeechAlgorithms"
"nanahou/Awesome-Speech-Enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"nanahou/Awesome-Speech-Enhancement" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"Ryuk17/SpeechAlgorithms" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"Ryuk17/SpeechAlgorithms" -> "funcwj/setk"
"Ryuk17/SpeechAlgorithms" -> "jzi040941/PercepNet"
"Ryuk17/SpeechAlgorithms" -> "athena-team/athena-signal"
"Ryuk17/SpeechAlgorithms" -> "ewan-xu/pyaec"
"Ryuk17/SpeechAlgorithms" -> "nanahou/Awesome-Speech-Enhancement"
"Ryuk17/SpeechAlgorithms" -> "Xiaobin-Rong/gtcrn"
"Ryuk17/SpeechAlgorithms" -> "huyanxin/DeepComplexCRN"
"Ryuk17/SpeechAlgorithms" -> "aliutkus/speechmetrics"
"Ryuk17/SpeechAlgorithms" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"Ryuk17/SpeechAlgorithms" -> "microsoft/AEC-Challenge"
"Ryuk17/SpeechAlgorithms" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"Ryuk17/SpeechAlgorithms" -> "Audio-WestlakeU/FullSubNet"
"Ryuk17/SpeechAlgorithms" -> "microsoft/DNS-Challenge"
"Ryuk17/SpeechAlgorithms" -> "DavidDiazGuerra/gpuRIR"
"dbklim/RNNoise_Wrapper" -> "Shb742/rnnoise_python"
"dbklim/RNNoise_Wrapper" -> "SaneBow/PiDTLN"
"NEGU93/cvnn" -> "JesperDramsch/keras-complex"
"NEGU93/cvnn" -> "NEGU93/CVNN-PolSAR"
"NEGU93/cvnn" -> "wavefrontshaping/complexPyTorch"
"NEGU93/cvnn" -> "JesperDramsch/Complex-CNN-Seismic"
"NEGU93/cvnn" -> "russellgeum/Deep-Complex-Networks"
"NEGU93/cvnn" -> "ChihebTrabelsi/deep_complex_networks"
"NEGU93/cvnn" -> "XinyuanLiao/ComplexNN"
"NEGU93/cvnn" -> "josiahwsmith10/complextorch"
"NEGU93/cvnn" -> "MRSRL/complex-networks-release"
"NEGU93/cvnn" -> "soumickmj/pytorch-complex"
"NEGU93/cvnn" -> "ericyeats/cvnn-security"
"openBliSSART/openBliSSART" -> "wslihgt/pyfasst"
"openBliSSART/openBliSSART" -> "vsubhashini/ica"
"microsoft/AEC-Challenge" -> "breizhn/DTLN-aec"
"microsoft/AEC-Challenge" -> "fjiang9/NKF-AEC"
"microsoft/AEC-Challenge" -> "jzi040941/PercepNet"
"microsoft/AEC-Challenge" -> "microsoft/DNS-Challenge"
"microsoft/AEC-Challenge" -> "microsoft/P.808"
"microsoft/AEC-Challenge" -> "echocatzh/MTFAA-Net"
"microsoft/AEC-Challenge" -> "ewan-xu/AEC3"
"microsoft/AEC-Challenge" -> "LXP-Never/AEC_DeepModel"
"microsoft/AEC-Challenge" -> "breizhn/DTLN"
"microsoft/AEC-Challenge" -> "athena-team/athena-signal"
"microsoft/AEC-Challenge" -> "DavidDiazGuerra/gpuRIR"
"microsoft/AEC-Challenge" -> "ewan-xu/pyaec"
"microsoft/AEC-Challenge" -> "huyanxin/DeepComplexCRN"
"microsoft/AEC-Challenge" -> "nay0648/unified2021"
"microsoft/AEC-Challenge" -> "wavesaudio/Speex-AEC-matlab"
"vipchengrui/traditional-speech-enhancement" -> "peak1995/Speech-enhancement-dsp"
"vipchengrui/traditional-speech-enhancement" -> "chenwj1989/python-speech-enhancement"
"vipchengrui/traditional-speech-enhancement" -> "zhr1201/OMLSA-speech-enhancement"
"vipchengrui/traditional-speech-enhancement" -> "lyapple2008/SpeechEnhancement"
"vipchengrui/traditional-speech-enhancement" -> "PandoraLS/traditional-speech-enhancement"
"tky823/DNN-based_source_separation" -> "yluo42/TAC"
"tky823/DNN-based_source_separation" -> "Audio-WestlakeU/NBSS"
"tky823/DNN-based_source_separation" -> "tky823/audio_source_separation"
"tky823/DNN-based_source_separation" -> "gemengtju/Tutorial_Separation"
"tky823/DNN-based_source_separation" -> "jzi040941/PercepNet"
"tky823/DNN-based_source_separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"tky823/DNN-based_source_separation" -> "naplab/Conv-TasNet"
"tky823/DNN-based_source_separation" -> "seorim0/DCCRN-with-various-loss-functions"
"tky823/DNN-based_source_separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"tky823/DNN-based_source_separation" -> "ujscjj/DPTNet"
"tky823/DNN-based_source_separation" -> "AppleHolic/source_separation"
"tky823/DNN-based_source_separation" -> "BUTSpeechFIT/speakerbeam"
"tky823/DNN-based_source_separation" -> "huyanxin/DeepComplexCRN"
"tky823/DNN-based_source_separation" -> "hangtingchen/Beam-Guided-TasNet"
"tky823/DNN-based_source_separation" -> "DavidDiazGuerra/gpuRIR"
"chenzhuo1011/libri_css" -> "popcornell/SparseLibriMix"
"chenzhuo1011/libri_css" -> "xuchenglin28/speaker_extraction"
"chenzhuo1011/libri_css" -> "yluo42/TAC"
"chenzhuo1011/libri_css" -> "gemengtju/SpEx_Plus"
"chenzhuo1011/libri_css" -> "Enny1991/beamformers"
"chenzhuo1011/libri_css" -> "BUTSpeechFIT/speakerbeam"
"chenzhuo1011/libri_css" -> "desh2608/gss" ["e"=1]
"chenzhuo1011/libri_css" -> "tencent-ailab/FRA-RIR"
"chenzhuo1011/libri_css" -> "fgnt/padertorch" ["e"=1]
"chenzhuo1011/libri_css" -> "speechLabBcCuny/onssen"
"chenzhuo1011/libri_css" -> "Sanyuan-Chen/CSS_with_Conformer"
"posenhuang/deeplearningsourceseparation" -> "aishoot/LSTM_PIT_Speech_Separation"
"posenhuang/deeplearningsourceseparation" -> "amaas/rnn-speech-denoising"
"posenhuang/deeplearningsourceseparation" -> "snsun/pit-speech-separation"
"posenhuang/deeplearningsourceseparation" -> "seanwood/gcc-nmf"
"posenhuang/deeplearningsourceseparation" -> "MTG/DeepConvSep"
"posenhuang/deeplearningsourceseparation" -> "posenhuang/singingvoiceseparationrpca"
"posenhuang/deeplearningsourceseparation" -> "yongxuUSTC/sednn"
"posenhuang/deeplearningsourceseparation" -> "Unisound/SpeechSeparation"
"posenhuang/deeplearningsourceseparation" -> "funcwj/CGMM-MVDR"
"posenhuang/deeplearningsourceseparation" -> "snsun/cgmm_mvdr"
"posenhuang/deeplearningsourceseparation" -> "mir-evaluation/mir_eval" ["e"=1]
"posenhuang/deeplearningsourceseparation" -> "nussl/nussl"
"posenhuang/deeplearningsourceseparation" -> "xanguera/BeamformIt"
"posenhuang/deeplearningsourceseparation" -> "andabi/music-source-separation"
"posenhuang/deeplearningsourceseparation" -> "santi-pdp/segan"
"james34602/SpleeterRT" -> "gvne/vstSpleeter"
"hadess/rtl8723bs" -> "lwfinger/rtl8723bs_bt"
"hadess/rtl8723bs" -> "onitake/gslx680-acpi"
"hadess/rtl8723bs" -> "anthonywong/rtl8723bs"
"hadess/rtl8723bs" -> "burzumishi/linux-baytrail-flexx10"
"hadess/rtl8723bs" -> "Manouchehri/vi8"
"hadess/rtl8723bs" -> "hadess/gt9xx"
"hadess/rtl8723bs" -> "jfwells/linux-asus-t100ta"
"hadess/rtl8723bs" -> "plbossart/UCM"
"hadess/rtl8723bs" -> "plbossart/sound"
"hadess/rtl8723bs" -> "AdamWill/baytrail-m"
"zhenghuatan/rVADfast" -> "zhenghuatan/rVAD"
"JeffreyCA/spleeter-web" -> "gvne/spleeterpp"
"JeffreyCA/spleeter-web" -> "kuielab/mdx-net-submission"
"JeffreyCA/spleeter-web" -> "kuielab/mdx-net"
"JeffreyCA/spleeter-web" -> "VVasanth/Spleeter_Unofficial_TF20_MobileApp"
"JeffreyCA/spleeter-web" -> "kuielab/sdx23"
"mail2chromium/Android-Audio-Processing-Using-WebRTC" -> "mail2chromium/Android-Native-Development-For-WebRTC"
"mail2chromium/Android-Audio-Processing-Using-WebRTC" -> "mail2chromium/Android_Realtime_Communication_Using_WebRTC"
"mail2chromium/Android-Audio-Processing-Using-WebRTC" -> "mail2chromium/Compile_WebRTC_Library_For_Android"
"mail2chromium/Android-Audio-Processing-Using-WebRTC" -> "dengzikun/WebRTC-APM-for-Android"
"mail2chromium/Android-Audio-Processing-Using-WebRTC" -> "theeasiestway/android-webrtc-aecm"
"GAMMA-UMD/doa-release" -> "sharathadavanne/doa-net"
"GAMMA-UMD/doa-release" -> "DavidDiazGuerra/icoDOA" ["e"=1]
"GAMMA-UMD/doa-release" -> "kjason/DnnNormTimeFreq4DoA"
"RicherMans/Datadriven-GPVAD" -> "RicherMans/GPV"
"SuperKogito/spafe" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"SuperKogito/spafe" -> "Snowdar/asv-subtools" ["e"=1]
"SuperKogito/spafe" -> "KinWaiCheuk/nnAudio" ["e"=1]
"SuperKogito/spafe" -> "jsingh811/pyAudioProcessing"
"SuperKogito/spafe" -> "detly/gammatone"
"SuperKogito/spafe" -> "ewan-xu/pyaec"
"SuperKogito/spafe" -> "cvqluu/TDNN" ["e"=1]
"SuperKogito/spafe" -> "aliutkus/speechmetrics"
"SuperKogito/spafe" -> "DavidDiazGuerra/gpuRIR"
"SuperKogito/spafe" -> "fgnt/nara_wpe"
"SuperKogito/spafe" -> "ZhihaoDU/speech_feature_extractor"
"SuperKogito/spafe" -> "Jungjee/RawNet" ["e"=1]
"SuperKogito/spafe" -> "qiuqiangkong/torchlibrosa" ["e"=1]
"SuperKogito/spafe" -> "asvspoof-challenge/2021" ["e"=1]
"SuperKogito/spafe" -> "busyyang/python_sound_open"
"microsoft/MS-SNSD" -> "microsoft/DNS-Challenge"
"microsoft/MS-SNSD" -> "huyanxin/DeepComplexCRN"
"microsoft/MS-SNSD" -> "anicolson/DeepXi"
"microsoft/MS-SNSD" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"microsoft/MS-SNSD" -> "jzi040941/PercepNet"
"microsoft/MS-SNSD" -> "microsoft/AEC-Challenge"
"microsoft/MS-SNSD" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"microsoft/MS-SNSD" -> "aliutkus/speechmetrics"
"microsoft/MS-SNSD" -> "microsoft/P.808"
"microsoft/MS-SNSD" -> "breizhn/DTLN"
"microsoft/MS-SNSD" -> "schmiph2/pysepm"
"microsoft/MS-SNSD" -> "ludlows/PESQ"
"microsoft/MS-SNSD" -> "Audio-WestlakeU/FullSubNet"
"microsoft/MS-SNSD" -> "DavidDiazGuerra/gpuRIR"
"microsoft/MS-SNSD" -> "facebookresearch/denoiser"
"m2wagner/Alternating_Projections_Gridless_DOA_Estimation" -> "ysparkwin/AlternatingProjections"
"m2wagner/Alternating_Projections_Gridless_DOA_Estimation" -> "Jimbo-Jo/GROGSBL"
"m2wagner/Alternating_Projections_Gridless_DOA_Estimation" -> "jsdaiustc/rootSBL"
"m2wagner/Alternating_Projections_Gridless_DOA_Estimation" -> "TANG16/DAE4mulDOA"
"f90/Wave-U-Net-Pytorch" -> "f90/Wave-U-Net"
"f90/Wave-U-Net-Pytorch" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"f90/Wave-U-Net-Pytorch" -> "kaituoxu/Conv-TasNet"
"f90/Wave-U-Net-Pytorch" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"f90/Wave-U-Net-Pytorch" -> "naplab/Conv-TasNet"
"f90/Wave-U-Net-Pytorch" -> "sweetcocoa/DeepComplexUNetPyTorch"
"f90/Wave-U-Net-Pytorch" -> "etzinis/sudo_rm_rf"
"f90/Wave-U-Net-Pytorch" -> "nanahou/Awesome-Speech-Enhancement"
"f90/Wave-U-Net-Pytorch" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"f90/Wave-U-Net-Pytorch" -> "AppleHolic/source_separation"
"f90/Wave-U-Net-Pytorch" -> "Audio-WestlakeU/FullSubNet"
"f90/Wave-U-Net-Pytorch" -> "JusperLee/TDANet"
"f90/Wave-U-Net-Pytorch" -> "huyanxin/DeepComplexCRN"
"f90/Wave-U-Net-Pytorch" -> "tky823/DNN-based_source_separation"
"f90/Wave-U-Net-Pytorch" -> "speechLabBcCuny/onssen"
"ap-atul/Audio-Denoising" -> "AP-Atul/wavelets-ext"
"ap-atul/Audio-Denoising" -> "will-rice/denoisers"
"ap-atul/Audio-Denoising" -> "madhavmk/Noise2Noise-audio_denoising_without_clean_training_data"
"microsoft/P.808" -> "microsoft/AEC-Challenge"
"microsoft/P.808" -> "jzi040941/PercepNet"
"microsoft/P.808" -> "microsoft/DNS-Challenge"
"microsoft/P.808" -> "microsoft/SIG-Challenge"
"microsoft/P.808" -> "microsoft/MS-SNSD"
"microsoft/P.808" -> "microsoft/PLC-Challenge"
"ewan-xu/AEC3" -> "cpuimage/WebRTC_AECM"
"ewan-xu/AEC3" -> "microsoft/AEC-Challenge"
"ewan-xu/AEC3" -> "breizhn/DTLN-aec"
"ewan-xu/AEC3" -> "YangangCao/WebRTC-3A1V"
"ewan-xu/AEC3" -> "fjiang9/NKF-AEC"
"ewan-xu/AEC3" -> "wavesaudio/Speex-AEC-matlab"
"ewan-xu/AEC3" -> "LXP-Never/AEC_DeepModel"
"ewan-xu/AEC3" -> "ewan-xu/pyaec"
"ewan-xu/AEC3" -> "athena-team/athena-signal"
"ewan-xu/AEC3" -> "xiongyihui/speexdsp-python"
"ewan-xu/AEC3" -> "jzi040941/PercepNet"
"ewan-xu/AEC3" -> "SuperAI211/Realtime_AudioDenoise_EchoCancellation"
"ewan-xu/AEC3" -> "cpuimage/WebRTC_AGC"
"ewan-xu/AEC3" -> "DoubangoTelecom/webrtc-audioproc"
"ewan-xu/AEC3" -> "shichaog/WebRTC-audio-processing"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "vbelz/Speech-enhancement"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "breizhn/DTLN"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "jonlu0602/DeepDenoisingAutoencoder"
"EncoraDigital/SAB-cnn-audio-denoiser" -> "JasonSWFu/MetricGAN"
"yluo42/TAC" -> "Enny1991/beamformers"
"yluo42/TAC" -> "yoonsanghyu/FaSNet-TAC-PyTorch"
"yluo42/TAC" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"yluo42/TAC" -> "ujscjj/DPTNet"
"yluo42/TAC" -> "tencent-ailab/FRA-RIR"
"yluo42/TAC" -> "DavidDiazGuerra/gpuRIR"
"yluo42/TAC" -> "fgnt/nn-gev"
"yluo42/TAC" -> "chenzhuo1011/libri_css"
"yluo42/TAC" -> "naplab/Conv-TasNet"
"yluo42/TAC" -> "kaituoxu/Conv-TasNet"
"yluo42/TAC" -> "JusperLee/Dual-Path-RNN-Pytorch"
"yluo42/TAC" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"yluo42/TAC" -> "huyanxin/DeepComplexCRN"
"yluo42/TAC" -> "Audio-WestlakeU/NBSS"
"yluo42/TAC" -> "Andong-Li-speech/GaGNet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "yluo42/TAC"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "ujscjj/DPTNet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "JusperLee/Dual-Path-RNN-Pytorch"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "funcwj/conv-tasnet"
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" -> "kaituoxu/Conv-TasNet"
"HinTak/seeed-voicecard" -> "respeaker/seeed-voicecard"
"HinTak/seeed-voicecard" -> "voice-engine/ec"
"HinTak/seeed-voicecard" -> "project-alice-assistant/HermesLedControl" ["e"=1]
"HinTak/seeed-voicecard" -> "koenvervloesem/awesome-rhasspy" ["e"=1]
"Wramberg/adaptfilt" -> "matousc89/Python-Adaptive-Signal-Processing-Handbook"
"Wramberg/adaptfilt" -> "rohitner/adaptive-filters"
"Wramberg/adaptfilt" -> "matousc89/padasip"
"huangzhenyu/beamforming" -> "jorgengrythe/beamforming"
"huangzhenyu/beamforming" -> "ZitengWang/MASP"
"huangzhenyu/beamforming" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"huangzhenyu/beamforming" -> "kkumatani/distant_speech_recognition"
"huangzhenyu/beamforming" -> "MiguelBlancoGalindo/MicArrayBeamforming"
"huangzhenyu/beamforming" -> "aishoot/Sound_Localization_Algorithms"
"huangzhenyu/beamforming" -> "Enny1991/beamformers"
"huangzhenyu/beamforming" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"huangzhenyu/beamforming" -> "chenwj1989/Beamforming_Examples"
"huangzhenyu/beamforming" -> "Mathilda11/Speech-processing" ["e"=1]
"huangzhenyu/beamforming" -> "chenwj1989/python_howling_suppression" ["e"=1]
"ap-atul/Video-Editing-Automation" -> "ap-atul/Torpido"
"ap-atul/Video-Editing-Automation" -> "AP-Atul/wavelets-ext"
"diracdeltas/vstSpleeter" -> "gvne/vstSpleeter"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JusperLee/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"JusperLee/Dual-Path-RNN-Pytorch" -> "kaituoxu/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "yluo42/TAC"
"JusperLee/Dual-Path-RNN-Pytorch" -> "gemengtju/Tutorial_Separation"
"JusperLee/Dual-Path-RNN-Pytorch" -> "JorisCos/LibriMix"
"JusperLee/Dual-Path-RNN-Pytorch" -> "huyanxin/DeepComplexCRN"
"JusperLee/Dual-Path-RNN-Pytorch" -> "naplab/Conv-TasNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "Audio-WestlakeU/FullSubNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "ujscjj/DPTNet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "funcwj/conv-tasnet"
"JusperLee/Dual-Path-RNN-Pytorch" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"JusperLee/Dual-Path-RNN-Pytorch" -> "tky823/DNN-based_source_separation"
"JusperLee/Dual-Path-RNN-Pytorch" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"fgnt/sms_wsj" -> "Audio-WestlakeU/RealMAN"
"fgnt/sms_wsj" -> "Enny1991/beamformers"
"IMLHF/Speech-Enhancement-Measures" -> "nglehuy/semetrics"
"stephencwelch/Perceptual-Coding-In-Python" -> "HSU-ANT/gstpeaq"
"stephencwelch/Perceptual-Coding-In-Python" -> "NikolajAndersson/PEAQ"
"stephencwelch/Perceptual-Coding-In-Python" -> "jfsantos/SRMRpy"
"dakenan1/Speech-measure-SDR-SAR-STOI-PESQ" -> "IMLHF/Speech-Enhancement-Measures"
"bingo-todd/Gammatone-filters" -> "hspark84/lgtfb-en"
"gvne/spleeterpp" -> "gvne/vstSpleeter"
"gvne/spleeterpp" -> "jinay1991/spleeter"
"Edresson/VoiceSplit" -> "xuchenglin28/speaker_extraction"
"Edresson/VoiceSplit" -> "maum-ai/voicefilter"
"Edresson/VoiceSplit" -> "BUTSpeechFIT/speakerbeam"
"Edresson/VoiceSplit" -> "JorisCos/LibriMix"
"Edresson/VoiceSplit" -> "jain-abhinav02/VoiceFilter"
"Edresson/VoiceSplit" -> "gemengtju/SpEx_Plus"
"Edresson/VoiceSplit" -> "xuchenglin28/speaker_extraction_SpEx"
"Edresson/VoiceSplit" -> "pirxus/personalVAD"
"MRSRL/complex-networks-release" -> "helrewaidy/deep-complex-convolutional-network"
"MRSRL/complex-networks-release" -> "CedricChing/DeepMRI" ["e"=1]
"MRSRL/complex-networks-release" -> "rmsouza01/MC-MRI-Rec" ["e"=1]
"MRSRL/complex-networks-release" -> "khammernik/sigmanet" ["e"=1]
"MRSRL/complex-networks-release" -> "MRSRL/dl-cs"
"MRSRL/complex-networks-release" -> "VLOGroup/mri-variationalnetwork" ["e"=1]
"MiguelBlancoGalindo/MicArrayBeamforming" -> "ZitengWang/MASP"
"MiguelBlancoGalindo/MicArrayBeamforming" -> "polarch/Spherical-Array-Processing" ["e"=1]
"russellgeum/Deep-Complex-Networks" -> "russellgeum/Phase-aware-Deep-Complex-UNet"
"russellgeum/Deep-Complex-Networks" -> "wangyifan1027/Complex-Valued_Networks"
"gvne/vstSpleeter" -> "gvne/spleeterpp"
"sharathadavanne/doa-net" -> "sharathadavanne/hungarian-net"
"mpariente/pytorch_stoi" -> "audiolabs/torch-pesq"
"schmiph2/pysepm" -> "aliutkus/speechmetrics"
"schmiph2/pysepm" -> "ludlows/PESQ"
"schmiph2/pysepm" -> "vBaiCai/python-pesq"
"schmiph2/pysepm" -> "mpariente/pystoi"
"schmiph2/pysepm" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"schmiph2/pysepm" -> "DavidDiazGuerra/gpuRIR"
"schmiph2/pysepm" -> "anicolson/DeepXi"
"schmiph2/pysepm" -> "haoxiangsnr/Wave-U-Net-for-Speech-Enhancement"
"schmiph2/pysepm" -> "Audio-WestlakeU/FullSubNet"
"schmiph2/pysepm" -> "jzi040941/PercepNet"
"schmiph2/pysepm" -> "sp-uhh/sgmse"
"schmiph2/pysepm" -> "nanahou/Awesome-Speech-Enhancement"
"schmiph2/pysepm" -> "IMLHF/Speech-Enhancement-Measures"
"schmiph2/pysepm" -> "microsoft/DNS-Challenge"
"schmiph2/pysepm" -> "huyanxin/DeepComplexCRN"
"AkojimaSLP/Neural-mask-estimation" -> "AkojimaSLP/Frame-by-frame-closed-form-update-for-mask-based-adaptive-MVDR-beamforming"
"wangtianrui/DCCRN" -> "wangtianrui/HGCN"
"wangtianrui/DCCRN" -> "maggie0830/DCCRN"
"crux82/huric" -> "crux82/ExtremITA"
"jfsantos/SRMRpy" -> "MuSAELab/SRMRToolbox"
"AkojimaSLP/Frame-by-frame-closed-form-update-for-mask-based-adaptive-MVDR-beamforming" -> "AkojimaSLP/Neural-mask-estimation"
"AkojimaSLP/Frame-by-frame-closed-form-update-for-mask-based-adaptive-MVDR-beamforming" -> "Andong-Li-speech/TaylorBeamformer"
"XianruiWang/AuxIVA" -> "d-kitamura/AuxIVA-ISS"
"zhenghuatan/rVAD" -> "zhenghuatan/rVADfast"
"zhenghuatan/rVAD" -> "RicherMans/Datadriven-GPVAD"
"pfnet-research/meta-tasnet" -> "ws-choi/Conditioned-Source-Separation-LaSAFT"
"pfnet-research/meta-tasnet" -> "sigsep/norbert"
"jinay1991/spleeter" -> "tinoucas/spleeter-tflite-convert"
"jinay1991/spleeter" -> "VVasanth/Spleeter_Unofficial_TF20_MobileApp"
"jinay1991/spleeter" -> "Turing311/Spleeter_Android_iOS"
"xuchenglin28/speaker_extraction_SpEx" -> "gemengtju/SpEx_Plus"
"xuchenglin28/speaker_extraction_SpEx" -> "haoxiangsnr/SpEx"
"xuchenglin28/speaker_extraction_SpEx" -> "xuchenglin28/speaker_extraction"
"xuchenglin28/speaker_extraction_SpEx" -> "gemengtju/L-SpEx"
"xuchenglin28/speaker_extraction_SpEx" -> "xuchenglin28/target_speaker_verification"
"xuchenglin28/speaker_extraction_SpEx" -> "mborsdorf/UniversalSpeakerExtraction"
"xuchenglin28/speaker_extraction_SpEx" -> "BUTSpeechFIT/speakerbeam"
"gemengtju/SpEx_Plus" -> "xuchenglin28/speaker_extraction_SpEx"
"gemengtju/SpEx_Plus" -> "xuchenglin28/speaker_extraction"
"gemengtju/SpEx_Plus" -> "mborsdorf/UniversalSpeakerExtraction"
"gemengtju/SpEx_Plus" -> "BUTSpeechFIT/speakerbeam"
"nglehuy/semetrics" -> "IMLHF/Speech-Enhancement-Measures"
"shichaog/RNNAec" -> "YongyuG/dnn_aec_data_process"
"ujscjj/DPTNet" -> "yoonsanghyu/Dual-Path-Transformer-Network-PyTorch"
"ujscjj/DPTNet" -> "ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation"
"ujscjj/DPTNet" -> "yluo42/TAC"
"ujscjj/DPTNet" -> "haoxiangsnr/SpEx"
"ujscjj/DPTNet" -> "etzinis/two_step_mask_learning"
"chanil1218/DCUnet.pytorch" -> "sweetcocoa/DeepComplexUNetPyTorch"
"chanil1218/DCUnet.pytorch" -> "maggie0830/DCCRN"
"MuSAELab/SRMRToolbox" -> "jfsantos/SRMRpy"
"zehuachenImperial/SkipConvNet" -> "DiegoLeon96/Neural-Speech-Dereverberation"
"newdigate/teensy-variable-playback" -> "FrankBoesing/Teensy-WavePlayer"
"jain-abhinav02/VoiceFilter" -> "HeliosX7/voice-filter"
"haoheliu/Subband-Music-Separation" -> "haoheliu/torchsubband"
"zftan0709/Feedback-ANC-Teensy-3.6" -> "masilvabustos/TMS320C6748-ANC"
"tinoucas/spleeter-tflite-convert" -> "jinay1991/spleeter"
"tinoucas/spleeter-tflite-convert" -> "VVasanth/SpleeterTF2.0_Unofficial"
"tinoucas/spleeter-tflite-convert" -> "VVasanth/Spleeter_Unofficial_TF20_MobileApp"
"mail2chromium/Compile_WebRTC_Library_For_Android" -> "mail2chromium/Android-Native-Development-For-WebRTC"
"lili-0805/MVAE" -> "d-kitamura/AuxIVA-ISS"
"ap-atul/Torpido" -> "ap-atul/Video-Editing-Automation"
"ap-atul/Torpido" -> "AP-Atul/wavelets-ext"
"xashru/robust-vad" -> "skgusrb12/voice_activity_detection"
"HeliosX7/voice-filter" -> "jain-abhinav02/VoiceFilter"
"jonashaag/RealRIRs" -> "anton-jeran/TS-RIR" ["e"=1]
"russellgeum/Phase-aware-Deep-Complex-UNet" -> "russellgeum/Deep-Complex-Networks"
"russellgeum/Phase-aware-Deep-Complex-UNet" -> "sweetcocoa/DeepComplexUNetPyTorch"
"fakufaku/auxiva-ipa" -> "d-kitamura/AuxIVA-ISS"
"fakufaku/piva" -> "d-kitamura/AuxIVA-ISS"
"WilliamYu1993/BAMSE" -> "WilliamYu1993/ICSE"
"haoxiangsnr/SpEx" -> "xuchenglin28/speaker_extraction_SpEx"
"WilliamYu1993/ICSE" -> "WilliamYu1993/BAMSE"
"bytedance/music_source_separation" -> "sigsep/open-unmix-pytorch"
"bytedance/music_source_separation" -> "asteroid-team/asteroid"
"bytedance/music_source_separation" -> "lucidrains/BS-RoFormer"
"bytedance/music_source_separation" -> "ZFTurbo/Music-Source-Separation-Training"
"bytedance/music_source_separation" -> "csteinmetz1/auraloss" ["e"=1]
"bytedance/music_source_separation" -> "moscow-technologies/blockchain-voting_2021" ["e"=1]
"bytedance/music_source_separation" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"bytedance/music_source_separation" -> "huyanxin/DeepComplexCRN"
"bytedance/music_source_separation" -> "aliutkus/speechmetrics"
"bytedance/music_source_separation" -> "microsoft/DNS-Challenge"
"bytedance/music_source_separation" -> "haoheliu/Subband-Music-Separation"
"bytedance/music_source_separation" -> "descriptinc/descript-audio-codec" ["e"=1]
"bytedance/music_source_separation" -> "haoheliu/voicefixer"
"bytedance/music_source_separation" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"bytedance/music_source_separation" -> "haoheliu/voicefixer_main"
"jzi040941/PercepNet" -> "breizhn/DTLN-aec"
"jzi040941/PercepNet" -> "microsoft/AEC-Challenge"
"jzi040941/PercepNet" -> "fjiang9/NKF-AEC"
"jzi040941/PercepNet" -> "breizhn/DTLN"
"jzi040941/PercepNet" -> "echocatzh/MTFAA-Net"
"jzi040941/PercepNet" -> "huyanxin/DeepComplexCRN"
"jzi040941/PercepNet" -> "Xiaobin-Rong/gtcrn"
"jzi040941/PercepNet" -> "ewan-xu/pyaec"
"jzi040941/PercepNet" -> "cookcodes/Percepnet-Keras"
"jzi040941/PercepNet" -> "Audio-WestlakeU/FullSubNet"
"jzi040941/PercepNet" -> "athena-team/athena-signal"
"jzi040941/PercepNet" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"jzi040941/PercepNet" -> "tencent-ailab/FRA-RIR"
"jzi040941/PercepNet" -> "RookieJunChen/FullSubNet-plus"
"jzi040941/PercepNet" -> "microsoft/DNS-Challenge"
"google/lyra" -> "facebookresearch/encodec" ["e"=1]
"google/lyra" -> "xiph/LPCNet" ["e"=1]
"google/lyra" -> "google/visqol"
"google/lyra" -> "descriptinc/descript-audio-codec" ["e"=1]
"google/lyra" -> "microsoft/DNS-Challenge"
"google/lyra" -> "xiph/rnnoise"
"google/lyra" -> "aliutkus/speechmetrics"
"google/lyra" -> "kan-bayashi/ParallelWaveGAN" ["e"=1]
"google/lyra" -> "xiph/opus" ["e"=1]
"google/lyra" -> "wesbz/SoundStream" ["e"=1]
"google/lyra" -> "yangdongchao/AcademiCodec" ["e"=1]
"google/lyra" -> "jik876/hifi-gan" ["e"=1]
"google/lyra" -> "lucidrains/audiolm-pytorch" ["e"=1]
"google/lyra" -> "drowe67/codec2-dev" ["e"=1]
"google/lyra" -> "athena-team/athena-signal"
"thooore/SpleeterGUI" -> "thooore/SpleeterCore"
"zju-isee/zju-isee" -> "Zezzid/ZJU_Course"
"zju-isee/zju-isee" -> "skyline-pro/isee"
"zju-isee/zju-isee" -> "JaceyHuang/ISEE-zju"
"zju-isee/zju-isee" -> "LeadroyaL/ZJU_ISEE_Project"
"zju-isee/zju-isee" -> "euphoniumm/isee-zju"
"zju-isee/zju-isee" -> "aerore2021/KeISEE"
"zju-isee/zju-isee" -> "l2h4/ZJU-ISEE"
"zju-isee/zju-isee" -> "ThuryW/ZJU-ISEE"
"zju-isee/zju-isee" -> "AucFang/ZJU-ISEE-byAucFang"
"zju-isee/zju-isee" -> "ZJU-Andre/ISEE-zju"
"zju-isee/zju-isee" -> "Zhang-Each/CourseNoteOfZJUSE" ["e"=1]
"zju-isee/zju-isee" -> "yjwang01/zju-isee"
"ConferencingSpeech/ConferencingSpeech2021" -> "tencent-ailab/FRA-RIR"
"JupiterEthan/GCRN-complex" -> "JupiterEthan/CRN-causal"
"ctwgL/webrtc_agc2" -> "jagger2048/WebRtc_AGC1"
"ctwgL/webrtc_agc2" -> "smail91/Speex_AEC"
"willhope/Noise-reduction" -> "zhr1201/OMLSA-speech-enhancement"
"willhope/Noise-reduction" -> "wavesaudio/Speex-AEC-matlab"
"willhope/Noise-reduction" -> "xiaochunxin/OMLSA-MCRA"
"cpuimage/WebRTC_NS_CPP" -> "ctwgL/webrtc_agc2"
"cpuimage/WebRTC_NS_CPP" -> "cpuimage/WebRTC_AECM"
"cpuimage/WebRTC_NS_CPP" -> "cpuimage/WebRTC_AGC"
"cpuimage/WebRTC_NS_CPP" -> "cpuimage/WebRTC_CNG"
"yuzhouhe2000/OMLSA-IMCRA" -> "xiaochunxin/OMLSA-MCRA"
"rishikksh20/hifigan-denoiser" -> "DiegoLeon96/Neural-Speech-Dereverberation"
"rishikksh20/hifigan-denoiser" -> "Audio-WestlakeU/FullSubNet"
"rishikksh20/hifigan-denoiser" -> "ruizhecao96/CMGAN"
"rishikksh20/hifigan-denoiser" -> "zehuachenImperial/SkipConvNet"
"seorim0/DCCRN-with-various-loss-functions" -> "seorim0/DNN-based-Speech-Enhancement-in-the-frequency-domain"
"seorim0/DCCRN-with-various-loss-functions" -> "felixfuyihui/Uformer"
"seorim0/DCCRN-with-various-loss-functions" -> "seorim0/NUNet-TLS"
"seorim0/DCCRN-with-various-loss-functions" -> "maggie0830/DCCRN"
"marsbroshok/VAD-python" -> "hcmlab/vadnet"
"marsbroshok/VAD-python" -> "jtkim-kaist/VAD"
"marsbroshok/VAD-python" -> "filippogiruzzi/voice_activity_detection"
"marsbroshok/VAD-python" -> "wiseman/py-webrtcvad"
"marsbroshok/VAD-python" -> "mwv/vad"
"marsbroshok/VAD-python" -> "wangshub/python-vad"
"marsbroshok/VAD-python" -> "nicklashansen/voice-activity-detection"
"marsbroshok/VAD-python" -> "eesungkim/Voice_Activity_Detector"
"marsbroshok/VAD-python" -> "amsehili/auditok"
"marsbroshok/VAD-python" -> "vBaiCai/python-pesq"
"marsbroshok/VAD-python" -> "mounalab/LSTM-RNN-VAD"
"marsbroshok/VAD-python" -> "xiongyihui/python-webrtc-audio-processing"
"marsbroshok/VAD-python" -> "RaviSoji/plda" ["e"=1]
"marsbroshok/VAD-python" -> "qqueing/DeepSpeaker-pytorch" ["e"=1]
"marsbroshok/VAD-python" -> "Janghyun1230/Speaker_Verification" ["e"=1]
"ewan-xu/pyaec" -> "fjiang9/NKF-AEC"
"ewan-xu/pyaec" -> "jzi040941/PercepNet"
"ewan-xu/pyaec" -> "microsoft/AEC-Challenge"
"ewan-xu/pyaec" -> "breizhn/DTLN-aec"
"ewan-xu/pyaec" -> "CharlesThaCat/acoustic-interference-cancellation"
"ewan-xu/pyaec" -> "ZitengWang/MASP"
"ewan-xu/pyaec" -> "tencent-ailab/FRA-RIR"
"ewan-xu/pyaec" -> "echocatzh/MTFAA-Net"
"ewan-xu/pyaec" -> "Ryuk17/SpeechAlgorithms"
"ewan-xu/pyaec" -> "ewan-xu/AEC3"
"ewan-xu/pyaec" -> "nay0648/unified2021"
"ewan-xu/pyaec" -> "athena-team/athena-signal"
"ewan-xu/pyaec" -> "LXP-Never/AEC_DeepModel"
"ewan-xu/pyaec" -> "adobe-research/MetaAF"
"ewan-xu/pyaec" -> "Enny1991/beamformers"
"Fafa-DL/2021-ZJU-Machine-Learning" -> "VipaiLab/machine-learning-course"
"SungFeng-Huang/SSL-pretraining-separation" -> "Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation"
"mvansegbroeck-zz/vad" -> "isrish/VAD-LTSD"
"mvansegbroeck-zz/vad" -> "rqalbuquerque/Voice-Activity-Detector-Algorithms"
"RoyJames/room-impulse-responses" -> "DavidDiazGuerra/gpuRIR"
"RoyJames/room-impulse-responses" -> "tencent-ailab/FRA-RIR"
"RoyJames/room-impulse-responses" -> "GAMMA-UMD/pygsound" ["e"=1]
"RoyJames/room-impulse-responses" -> "LCAV/pyroomacoustics"
"RoyJames/room-impulse-responses" -> "aliutkus/speechmetrics"
"RoyJames/room-impulse-responses" -> "fgnt/nara_wpe"
"RoyJames/room-impulse-responses" -> "ZitengWang/MASP"
"RoyJames/room-impulse-responses" -> "FrancoisGrondin/BIRD" ["e"=1]
"RoyJames/room-impulse-responses" -> "sp-uhh/sgmse"
"RoyJames/room-impulse-responses" -> "Audio-WestlakeU/FullSubNet"
"RoyJames/room-impulse-responses" -> "ehabets/RIR-Generator"
"RoyJames/room-impulse-responses" -> "anton-jeran/FAST-RIR" ["e"=1]
"RoyJames/room-impulse-responses" -> "jonashaag/RealRIRs"
"RoyJames/room-impulse-responses" -> "Enny1991/beamformers"
"RoyJames/room-impulse-responses" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"braton/fadapt" -> "YangangCao/AdaptiveFilter"
"Audio-WestlakeU/FullSubNet" -> "huyanxin/DeepComplexCRN"
"Audio-WestlakeU/FullSubNet" -> "RookieJunChen/FullSubNet-plus"
"Audio-WestlakeU/FullSubNet" -> "breizhn/DTLN"
"Audio-WestlakeU/FullSubNet" -> "microsoft/DNS-Challenge"
"Audio-WestlakeU/FullSubNet" -> "jzi040941/PercepNet"
"Audio-WestlakeU/FullSubNet" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"Audio-WestlakeU/FullSubNet" -> "sp-uhh/sgmse"
"Audio-WestlakeU/FullSubNet" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"Audio-WestlakeU/FullSubNet" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"Audio-WestlakeU/FullSubNet" -> "nanahou/Awesome-Speech-Enhancement"
"Audio-WestlakeU/FullSubNet" -> "yxlu-0102/MP-SENet"
"Audio-WestlakeU/FullSubNet" -> "maggie0830/DCCRN"
"Audio-WestlakeU/FullSubNet" -> "ruizhecao96/CMGAN"
"Audio-WestlakeU/FullSubNet" -> "tencent-ailab/FRA-RIR"
"Audio-WestlakeU/FullSubNet" -> "echocatzh/MTFAA-Net"
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" -> "liqingchunnnn/Only-Noisy-Training"
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" -> "NVIDIA/CleanUNet"
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" -> "pheepa/DCUnet"
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" -> "RookieJunChen/FullSubNet-plus"
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"RookieJunChen/FullSubNet-plus" -> "Audio-WestlakeU/FullSubNet"
"RookieJunChen/FullSubNet-plus" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"RookieJunChen/FullSubNet-plus" -> "felixfuyihui/Uformer"
"RookieJunChen/FullSubNet-plus" -> "echocatzh/MTFAA-Net"
"RookieJunChen/FullSubNet-plus" -> "ruizhecao96/CMGAN"
"RookieJunChen/FullSubNet-plus" -> "huyanxin/DeepComplexCRN"
"RookieJunChen/FullSubNet-plus" -> "yuguochencuc/DB-AIAT"
"RookieJunChen/FullSubNet-plus" -> "RookieJunChen/Inter-SubNet"
"RookieJunChen/FullSubNet-plus" -> "yxlu-0102/MP-SENet"
"RookieJunChen/FullSubNet-plus" -> "jzi040941/PercepNet"
"RookieJunChen/FullSubNet-plus" -> "tencent-ailab/FRA-RIR"
"RookieJunChen/FullSubNet-plus" -> "alibabasglab/FRCRN"
"RookieJunChen/FullSubNet-plus" -> "WenzheLiu-Speech/The-guidebook-of-speech-enhancement"
"RookieJunChen/FullSubNet-plus" -> "huyanxin/phasen"
"RookieJunChen/FullSubNet-plus" -> "Andong-Li-speech/GaGNet"
"facebookresearch/svoice" -> "asteroid-team/asteroid"
"facebookresearch/svoice" -> "JusperLee/Speech-Separation-Paper-Tutorial"
"facebookresearch/svoice" -> "kaituoxu/Conv-TasNet"
"facebookresearch/svoice" -> "maum-ai/voicefilter"
"facebookresearch/svoice" -> "facebookresearch/denoiser"
"facebookresearch/svoice" -> "Audio-WestlakeU/FullSubNet"
"facebookresearch/svoice" -> "JusperLee/Conv-TasNet"
"facebookresearch/svoice" -> "JorisCos/LibriMix"
"facebookresearch/svoice" -> "facebookresearch/WavAugment" ["e"=1]
"facebookresearch/svoice" -> "aliutkus/speechmetrics"
"facebookresearch/svoice" -> "gemengtju/Tutorial_Separation"
"facebookresearch/svoice" -> "yluo42/TAC"
"facebookresearch/svoice" -> "microsoft/DNS-Challenge"
"facebookresearch/svoice" -> "JusperLee/Dual-Path-RNN-Pytorch"
"facebookresearch/svoice" -> "tky823/DNN-based_source_separation"
"echocatzh/py-aec-unified2021" -> "Okrio/deepvqe"
"echocatzh/py-aec-unified2021" -> "vkothapally/Subband-Beamformer"
"seorim0/DNN-based-Speech-Enhancement-in-the-frequency-domain" -> "seorim0/DCCRN-with-various-loss-functions"
"iancraz/ANC-Implementation" -> "Aketirani/active-noise-cancellation"
"iancraz/ANC-Implementation" -> "zftan0709/Feedback-ANC-Teensy-3.6"
"iancraz/ANC-Implementation" -> "RezzaMir/Noise-Cancellation-For-Automobiles"
"iancraz/ANC-Implementation" -> "masilvabustos/TMS320C6748-ANC"
"introlab/manyears" -> "kkumatani/distant_speech_recognition"
"introlab/manyears" -> "introlab/odas"
"introlab/manyears" -> "xiaoli1368/Microphone-sound-source-localization"
"introlab/manyears" -> "LeeTaewoo/fast_sound_source_localization_using_TLSSC"
"introlab/manyears" -> "xanguera/BeamformIt"
"introlab/manyears" -> "aishoot/Sound_Localization_Algorithms"
"introlab/manyears" -> "LeeTaewoo/TL-SSC_SRP-PHAT"
"introlab/manyears" -> "seanwood/gcc-nmf"
"introlab/manyears" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"introlab/manyears" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"xshl5/KOTI_AEC" -> "DoubangoTelecom/webrtc-audioproc"
"xshl5/KOTI_AEC" -> "illuspas/libaec-android"
"hirotakaster/baytail-bootia32.efi" -> "ElXreno/archlinux-bootia32"
"wudicgi/SpleeterMsvcExe" -> "gvne/spleeterpp"
"wudicgi/SpleeterMsvcExe" -> "wudicgi/SpleeterGui"
"SaneBow/PiDTLN" -> "avcodecs/DTLNtfliteC"
"JupiterEthan/CRN-causal" -> "JupiterEthan/GCRN-complex"
"maggie0830/DCCRN" -> "huyanxin/DeepComplexCRN"
"maggie0830/DCCRN" -> "wangtianrui/DCCRN"
"maggie0830/DCCRN" -> "seorim0/DCCRN-with-various-loss-functions"
"maggie0830/DCCRN" -> "alibabasglab/FRCRN"
"maggie0830/DCCRN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"maggie0830/DCCRN" -> "JupiterEthan/GCRN-complex"
"maggie0830/DCCRN" -> "chanil1218/DCUnet.pytorch"
"maggie0830/DCCRN" -> "Audio-WestlakeU/FullSubNet"
"maggie0830/DCCRN" -> "ruizhecao96/CMGAN"
"maggie0830/DCCRN" -> "huyanxin/phasen"
"maggie0830/DCCRN" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"maggie0830/DCCRN" -> "lhwcv/DTLN_pytorch"
"maggie0830/DCCRN" -> "jzi040941/PercepNet"
"stephencwelch/Active-Noise-Cancellation" -> "stephencwelch/Acoustics-To-Deep-Learning"
"stephencwelch/Active-Noise-Cancellation" -> "stephencwelch/Neural-Networks-For-Audio-Processing"
"stephencwelch/Active-Noise-Cancellation" -> "developer-foundry/diminish"
"nussl/nussl" -> "fgnt/pb_bss"
"nussl/nussl" -> "mir-evaluation/mir_eval" ["e"=1]
"nussl/nussl" -> "source-separation/tutorial" ["e"=1]
"nussl/nussl" -> "justinsalamon/scaper" ["e"=1]
"nussl/nussl" -> "DavidDiazGuerra/gpuRIR"
"nussl/nussl" -> "MTG/DeepConvSep"
"nussl/nussl" -> "posenhuang/deeplearningsourceseparation"
"nussl/nussl" -> "sekiguchi92/SoundSourceSeparation"
"nussl/nussl" -> "mir-dataset-loaders/mirdata" ["e"=1]
"nussl/nussl" -> "tky823/DNN-based_source_separation"
"nussl/nussl" -> "csteinmetz1/auraloss" ["e"=1]
"nussl/nussl" -> "asteroid-team/asteroid"
"nussl/nussl" -> "KinWaiCheuk/nnAudio" ["e"=1]
"nussl/nussl" -> "funcwj/setk"
"nussl/nussl" -> "marl/crepe" ["e"=1]
"jangsoopark/AConvNet-pytorch" -> "fudanxu/MSTAR-AConvNet"
"jangsoopark/AConvNet-pytorch" -> "Crush0416/MS-CVNets-a-novel-complex-valued-neural-networks-for-SAR-ATR"
"wavesaudio/Speex-AEC-matlab" -> "xiongyihui/speexdsp-python"
"ws-choi/Conditioned-Source-Separation-LaSAFT" -> "ws-choi/ISMIR2020_U_Nets_SVS"
"Windstudent/Complex-MTASSNet" -> "Andong-Li-speech/GaGNet"
"Andong-Li-speech/GaGNet" -> "Andong-Li-speech/EaBNet"
"Andong-Li-speech/EaBNet" -> "Andong-Li-speech/GaGNet"
"Andong-Li-speech/EaBNet" -> "sp-uhh/deep-non-linear-filter"
"kuielab/mdx-net" -> "kuielab/mdx-net-submission"
"kuielab/mdx-net" -> "kuielab/sdx23"
"kuielab/mdx-net" -> "ws-choi/ISMIR2020_U_Nets_SVS"
"kuielab/mdx-net" -> "haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet"
"stephencwelch/Neural-Networks-For-Audio-Processing" -> "stephencwelch/Acoustics-To-Deep-Learning"
"stephencwelch/Neural-Networks-For-Audio-Processing" -> "stephencwelch/Active-Noise-Cancellation"
"LXP-Never/AEC_DeepModel" -> "rrbluke/NRES"
"LXP-Never/AEC_DeepModel" -> "fjiang9/NKF-AEC"
"LXP-Never/AEC_DeepModel" -> "microsoft/AEC-Challenge"
"LXP-Never/AEC_DeepModel" -> "Xiaobin-Rong/deepvqe"
"LXP-Never/AEC_DeepModel" -> "breizhn/DTLN-aec"
"LXP-Never/AEC_DeepModel" -> "YongyuG/dnn_aec_data_process"
"LXP-Never/AEC_DeepModel" -> "echocatzh/GFTNN"
"LXP-Never/AEC_DeepModel" -> "echocatzh/PFDKF"
"tky823/audio_source_separation" -> "d-kitamura/AuxIVA-ISS"
"tky823/audio_source_separation" -> "lili-0805/MVAE"
"tky823/audio_source_separation" -> "tky823/ssspy"
"tky823/audio_source_separation" -> "onolab-tmu/code_2020ICASSP_five"
"tky823/audio_source_separation" -> "fakufaku/auxiva-ipa"
"Audio-WestlakeU/pytorch_lightning_template_for_beginners" -> "Audio-WestlakeU/RealMAN"
"ssprl/Noise-Injection-Based-Acoustic-Feedback-Cancellation" -> "Agustin-Picard/DSP-Feedback-Suppression"
"ssprl/Noise-Injection-Based-Acoustic-Feedback-Cancellation" -> "rogaits/AFC-NR"
"yoonsanghyu/Dual-Path-Transformer-Network-PyTorch" -> "ujscjj/DPTNet"
"kuielab/mdx-net-submission" -> "kuielab/mdx-net"
"kuielab/mdx-net-submission" -> "kuielab/sdx23"
"kuielab/mdx-net-submission" -> "adefossez/mdx21_demucs"
"kuielab/mdx-net-submission" -> "yoyolicoris/music-demixing-challenge-ismir-2021-entry"
"breizhn/DTLN-aec" -> "breizhn/DTLN"
"breizhn/DTLN-aec" -> "microsoft/AEC-Challenge"
"breizhn/DTLN-aec" -> "jzi040941/PercepNet"
"breizhn/DTLN-aec" -> "fjiang9/NKF-AEC"
"breizhn/DTLN-aec" -> "SuperAI211/Realtime_AudioDenoise_EchoCancellation"
"breizhn/DTLN-aec" -> "ewan-xu/AEC3"
"breizhn/DTLN-aec" -> "LXP-Never/AEC_DeepModel"
"breizhn/DTLN-aec" -> "ewan-xu/pyaec"
"breizhn/DTLN-aec" -> "huyanxin/DeepComplexCRN"
"breizhn/DTLN-aec" -> "YongyuG/dnn_aec_data_process"
"breizhn/DTLN-aec" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"breizhn/DTLN-aec" -> "scofir/DTLN-aec"
"breizhn/DTLN-aec" -> "echocatzh/MTFAA-Net"
"breizhn/DTLN-aec" -> "ehabets/RIR-Generator"
"breizhn/DTLN-aec" -> "athena-team/athena-signal"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "breizhn/DTLN-aec"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "avcodecs/DTLNtfliteC"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "Turing311/Face_Liveness_Detection_Android_iOS"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "scofir/DTLN-aec"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "PandoraLS/traditional-speech-enhancement"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "SaneBow/PiDTLN"
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" -> "breizhn/DTLN"
"shenbengit/WebRTCExtension" -> "shenbengit/WebRTC-SRS"
"shenbengit/MVVMKit" -> "shenbengit/ArcFace4"
"shenbengit/WebRTC-SRS" -> "shenbengit/WebRTCExtension"
"shenbengit/WebRTC-SRS" -> "shenbengit/SrsRtcAndroidClient"
"shenbengit/WebRTC-SRS" -> "xiangang/WebRTCTest"
"shenbengit/WebRTC-SRS" -> "shenbengit/MVVMKit"
"adku1173/acoupipe" -> "gilleschardon/acosolo"
"DiegoLeon96/Neural-Speech-Dereverberation" -> "zehuachenImperial/SkipConvNet"
"DiegoLeon96/Neural-Speech-Dereverberation" -> "nttcslab-sp/dnn_wpe"
"Sanyuan-Chen/CSS_with_Conformer" -> "Andong-Li-speech/GaGNet"
"Sanyuan-Chen/CSS_with_Conformer" -> "yuhogun0908/MISOnet"
"voithru/voice-activity-detection" -> "voithru/wav2vec2_finetune"
"voithru/voice-activity-detection" -> "voithru/asr-text_classification-pipeline"
"voithru/voice-activity-detection" -> "skgusrb12/voice_activity_detection"
"voithru/voice-activity-detection" -> "xashru/robust-vad"
"voithru/voice-activity-detection" -> "jymsuper/VAD_tutorial"
"voithru/voice-activity-detection" -> "Yifei-ZHAO96/STAM-pytorch"
"voithru/voice-activity-detection" -> "nicklashansen/voice-activity-detection"
"voithru/voice-activity-detection" -> "NickWilkinson37/voxseg"
"acoular/spectacoular" -> "eac-ufsm/beamforming-tools"
"onitake/gslx680-acpi" -> "onitake/gsl-firmware"
"VVasanth/Spleeter_Unofficial_TF20_MobileApp" -> "VVasanth/SpleeterTF2.0_Unofficial"
"VVasanth/Spleeter_Unofficial_TF20_MobileApp" -> "farihachaiti/DoKaraokeAI_Spleeter_Android_Implementation"
"VVasanth/SpleeterTF2.0_Unofficial" -> "VVasanth/Spleeter_Unofficial_TF20_MobileApp"
"VVasanth/SpleeterTF2.0_Unofficial" -> "farihachaiti/DoKaraokeAI_Spleeter_Android_Implementation"
"yoonsanghyu/FaSNet-TAC-PyTorch" -> "yluo42/TAC"
"yoonsanghyu/FaSNet-TAC-PyTorch" -> "Enny1991/beamformers"
"yoonsanghyu/FaSNet-TAC-PyTorch" -> "RusselZHANG/Microphone-Array-Generalization-for-Multichannel-Narrowband-Deep-Speech-Enhancement"
"yoonsanghyu/FaSNet-TAC-PyTorch" -> "hangtingchen/Beam-Guided-TasNet"
"Manouchehri/vi8" -> "djvdorp/hi8"
"rrbluke/NRES" -> "YongyuG/dnn_aec_data_process"
"rrbluke/NRES" -> "Mo-yun/DSDPRNN"
"alvarouc/ica" -> "ShashShukla/ICA"
"fgnt/ci_sdr" -> "fakufaku/fast_bss_eval"
"haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet" -> "haoheliu/Subband-Music-Separation"
"Turing311/Spleeter_Android_iOS" -> "Turing311/Face_Liveness_Detection_Android_iOS"
"yoyolicoris/music-demixing-challenge-ismir-2021-entry" -> "yoyolicoris/danna-sep"
"yoyolicoris/music-demixing-challenge-ismir-2021-entry" -> "jeonchangbin49/LimitAug"
"aleXiehta/PhoneFortifiedPerceptualLoss" -> "WilliamYu1993/BAMSE"
"ap-atul/wavelets" -> "AP-Atul/wavelets-ext"
"d-kitamura/AuxIVA-ISS" -> "XianruiWang/AuxIVA"
"d-kitamura/AuxIVA-ISS" -> "fakufaku/auxiva-ipa"
"d-kitamura/AuxIVA-ISS" -> "fakufaku/piva"
"skgusrb12/voice_activity_detection" -> "xashru/robust-vad"
"haoheliu/voicefixer" -> "haoheliu/voicefixer_main"
"haoheliu/voicefixer" -> "resemble-ai/resemble-enhance"
"haoheliu/voicefixer" -> "haoheliu/versatile_audio_super_resolution"
"haoheliu/voicefixer" -> "sp-uhh/sgmse"
"haoheliu/voicefixer" -> "Rikorose/DeepFilterNet"
"haoheliu/voicefixer" -> "facebookresearch/denoiser"
"haoheliu/voicefixer" -> "aliutkus/speechmetrics"
"haoheliu/voicefixer" -> "descriptinc/descript-audio-codec" ["e"=1]
"haoheliu/voicefixer" -> "ruizhecao96/CMGAN"
"haoheliu/voicefixer" -> "yxlu-0102/MP-SENet"
"haoheliu/voicefixer" -> "RookieJunChen/FullSubNet-plus"
"haoheliu/voicefixer" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"haoheliu/voicefixer" -> "NVIDIA/BigVGAN" ["e"=1]
"haoheliu/voicefixer" -> "jik876/hifi-gan" ["e"=1]
"haoheliu/voicefixer" -> "kan-bayashi/ParallelWaveGAN" ["e"=1]
"Rikorose/DeepFilterNet" -> "microsoft/DNS-Challenge"
"Rikorose/DeepFilterNet" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"Rikorose/DeepFilterNet" -> "facebookresearch/denoiser"
"Rikorose/DeepFilterNet" -> "xiph/rnnoise"
"Rikorose/DeepFilterNet" -> "haoheliu/voicefixer"
"Rikorose/DeepFilterNet" -> "resemble-ai/resemble-enhance"
"Rikorose/DeepFilterNet" -> "asteroid-team/asteroid"
"Rikorose/DeepFilterNet" -> "jzi040941/PercepNet"
"Rikorose/DeepFilterNet" -> "sp-uhh/sgmse"
"Rikorose/DeepFilterNet" -> "Audio-WestlakeU/FullSubNet"
"Rikorose/DeepFilterNet" -> "breizhn/DTLN"
"Rikorose/DeepFilterNet" -> "Xiaobin-Rong/gtcrn"
"Rikorose/DeepFilterNet" -> "aliutkus/speechmetrics"
"Rikorose/DeepFilterNet" -> "huyanxin/DeepComplexCRN"
"Rikorose/DeepFilterNet" -> "snakers4/silero-vad" ["e"=1]
"VipaiLab/machine-learning-course" -> "Fafa-DL/2021-ZJU-Machine-Learning"
"LCAV/pyroomacoustics" -> "DavidDiazGuerra/gpuRIR"
"LCAV/pyroomacoustics" -> "ehabets/RIR-Generator"
"LCAV/pyroomacoustics" -> "microsoft/DNS-Challenge"
"LCAV/pyroomacoustics" -> "asteroid-team/asteroid"
"LCAV/pyroomacoustics" -> "fgnt/nara_wpe"
"LCAV/pyroomacoustics" -> "aliutkus/speechmetrics"
"LCAV/pyroomacoustics" -> "acoular/acoular"
"LCAV/pyroomacoustics" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"LCAV/pyroomacoustics" -> "RoyJames/room-impulse-responses"
"LCAV/pyroomacoustics" -> "xanguera/BeamformIt"
"LCAV/pyroomacoustics" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"LCAV/pyroomacoustics" -> "funcwj/setk"
"LCAV/pyroomacoustics" -> "microsoft/AEC-Challenge"
"LCAV/pyroomacoustics" -> "aishoot/Sound_Localization_Algorithms"
"LCAV/pyroomacoustics" -> "athena-team/athena-signal"
"echocatzh/MTFAA-Net" -> "felixfuyihui/Uformer"
"echocatzh/MTFAA-Net" -> "fjiang9/NKF-AEC"
"echocatzh/MTFAA-Net" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"echocatzh/MTFAA-Net" -> "Xiaobin-Rong/gtcrn"
"echocatzh/MTFAA-Net" -> "jzi040941/PercepNet"
"echocatzh/MTFAA-Net" -> "alibabasglab/FRCRN"
"echocatzh/MTFAA-Net" -> "RookieJunChen/FullSubNet-plus"
"echocatzh/MTFAA-Net" -> "tencent-ailab/FRA-RIR"
"echocatzh/MTFAA-Net" -> "Andong-Li-speech/EaBNet"
"echocatzh/MTFAA-Net" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"jorgengrythe/beamforming" -> "huangzhenyu/beamforming"
"jorgengrythe/beamforming" -> "aishoot/Sound_Localization_Algorithms"
"jorgengrythe/beamforming" -> "robin1001/beamforming"
"jorgengrythe/beamforming" -> "xanguera/BeamformIt"
"jorgengrythe/beamforming" -> "chenwj1989/Beamforming_Examples"
"jorgengrythe/beamforming" -> "ZitengWang/MASP"
"jorgengrythe/beamforming" -> "acoular/acoular"
"jorgengrythe/beamforming" -> "emilbjornson/optimal-beamforming" ["e"=1]
"jorgengrythe/beamforming" -> "TianLin0509/Hybrid-Beamforming-for-Millimeter-Wave-Systems-Using-the-MMSE-Criterion" ["e"=1]
"jorgengrythe/beamforming" -> "wangwei2009/DOA"
"jorgengrythe/beamforming" -> "TianLin0509/BF-design-with-DL" ["e"=1]
"jorgengrythe/beamforming" -> "kkumatani/distant_speech_recognition"
"jorgengrythe/beamforming" -> "MiguelBlancoGalindo/MicArrayBeamforming"
"jorgengrythe/beamforming" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"jorgengrythe/beamforming" -> "snsun/cgmm_mvdr"
"olvrhhn/audio_super_resolution" -> "chomeyama/DualCycleGAN"
"RetroCirce/Zero_Shot_Audio_Source_Separation" -> "liuxubo717/LASS" ["e"=1]
"RetroCirce/Zero_Shot_Audio_Source_Separation" -> "vb000/Waveformer"
"RetroCirce/Zero_Shot_Audio_Source_Separation" -> "RetroCirce/Choral_Music_Separation"
"yangdongchao/Tim-TSENet" -> "LiChenda/Multi-clue-TSE-data"
"ruizhecao96/CMGAN" -> "yxlu-0102/MP-SENet"
"ruizhecao96/CMGAN" -> "RoyChao19477/SEMamba"
"ruizhecao96/CMGAN" -> "sp-uhh/sgmse"
"ruizhecao96/CMGAN" -> "RookieJunChen/FullSubNet-plus"
"ruizhecao96/CMGAN" -> "alibabasglab/FRCRN"
"ruizhecao96/CMGAN" -> "yuguochencuc/DB-AIAT"
"ruizhecao96/CMGAN" -> "Audio-WestlakeU/FullSubNet"
"ruizhecao96/CMGAN" -> "sp-uhh/storm"
"ruizhecao96/CMGAN" -> "maggie0830/DCCRN"
"ruizhecao96/CMGAN" -> "huyanxin/DeepComplexCRN"
"ruizhecao96/CMGAN" -> "NVIDIA/CleanUNet"
"ruizhecao96/CMGAN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"ruizhecao96/CMGAN" -> "echocatzh/MTFAA-Net"
"ruizhecao96/CMGAN" -> "Audio-WestlakeU/McNet"
"ruizhecao96/CMGAN" -> "YunyangZeng/TAPLoss"
"Alien9427/DSN" -> "XAI4SAR/PIHA"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "Xiaobin-Rong/gtcrn"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "alibabasglab/FRCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "Qinwen-Hu/dparn"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "RookieJunChen/FullSubNet-plus"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "felixfuyihui/Uformer"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "echocatzh/MTFAA-Net"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "seorim0/DCCRN-with-various-loss-functions"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "Le-Xiaohuai-speech/SKIP-DPCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "huyanxin/DeepComplexCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "maggie0830/DCCRN"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "fjiang9/NKF-AEC"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "JupiterEthan/GCRN-complex"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "jzi040941/PercepNet"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"Le-Xiaohuai-speech/DPCRN_DNS3" -> "JupiterEthan/CRN-causal"
"Audio-WestlakeU/NBSS" -> "Audio-WestlakeU/McNet"
"Audio-WestlakeU/NBSS" -> "tencent-ailab/FRA-RIR"
"Audio-WestlakeU/NBSS" -> "Audio-WestlakeU/RealMAN"
"Audio-WestlakeU/NBSS" -> "Andong-Li-speech/EaBNet"
"Audio-WestlakeU/NBSS" -> "Audio-WestlakeU/FN-SSL"
"Audio-WestlakeU/NBSS" -> "Enny1991/beamformers"
"Audio-WestlakeU/NBSS" -> "JusperLee/SonicSim"
"Audio-WestlakeU/NBSS" -> "DavidDiazGuerra/gpuRIR"
"Audio-WestlakeU/NBSS" -> "Xiaobin-Rong/gtcrn"
"Audio-WestlakeU/NBSS" -> "hangtingchen/Beam-Guided-TasNet"
"Audio-WestlakeU/NBSS" -> "sp-uhh/deep-non-linear-filter"
"Audio-WestlakeU/NBSS" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"Audio-WestlakeU/NBSS" -> "fgnt/sms_wsj"
"haoheliu/voicefixer_main" -> "haoheliu/ssr_eval"
"haoheliu/voicefixer_main" -> "haoheliu/voicefixer"
"haoheliu/voicefixer_main" -> "rishikksh20/HiFiplusplus-pytorch" ["e"=1]
"haoheliu/voicefixer_main" -> "sp-uhh/sgmse"
"haoheliu/voicefixer_main" -> "neillu23/CDiffuSE"
"fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI" -> "JackHCC/Audio-Digital-Processing"
"fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI" -> "174563214/xinhaoshuzichuli"
"CarlGao4/Demucs-Gui" -> "adefossez/demucs"
"CarlGao4/Demucs-Gui" -> "facebookresearch/demucs"
"CarlGao4/Demucs-Gui" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"CarlGao4/Demucs-Gui" -> "Frikallo/MISST"
"CarlGao4/Demucs-Gui" -> "flipswitchingmonkey/FlexASIO_GUI" ["e"=1]
"CarlGao4/Demucs-Gui" -> "stemrollerapp/stemroller"
"CarlGao4/Demucs-Gui" -> "JeffreyCA/spleeter-web"
"CarlGao4/Demucs-Gui" -> "DamRsn/NeuralNote" ["e"=1]
"CarlGao4/Demucs-Gui" -> "sdatkinson/NeuralAmpModelerPlugin" ["e"=1]
"CarlGao4/Demucs-Gui" -> "sigsep/open-unmix-pytorch"
"CarlGao4/Demucs-Gui" -> "thooore/SpleeterGUI"
"CarlGao4/Demucs-Gui" -> "xserrat/docker-facebook-demucs"
"CarlGao4/Demucs-Gui" -> "pelennor2170/NAM_models" ["e"=1]
"CarlGao4/Demucs-Gui" -> "jarredou/MVSEP-MDX23-Colab_v2"
"CarlGao4/Demucs-Gui" -> "ZL-Audio/ZLEqualizer" ["e"=1]
"amsehili/auditok" -> "marsbroshok/VAD-python"
"amsehili/auditok" -> "ina-foss/inaSpeechSegmenter" ["e"=1]
"amsehili/auditok" -> "wiseman/py-webrtcvad"
"amsehili/auditok" -> "jtkim-kaist/VAD"
"amsehili/auditok" -> "hcmlab/vadnet"
"amsehili/auditok" -> "filippogiruzzi/voice_activity_detection"
"amsehili/auditok" -> "eesungkim/Voice_Activity_Detector"
"amsehili/auditok" -> "nicklashansen/voice-activity-detection"
"amsehili/auditok" -> "wq2012/awesome-diarization" ["e"=1]
"amsehili/auditok" -> "justinsalamon/scaper" ["e"=1]
"amsehili/auditok" -> "philipperemy/deep-speaker" ["e"=1]
"amsehili/auditok" -> "coqui-ai/open-speech-corpora" ["e"=1]
"amsehili/auditok" -> "timsainb/noisereduce"
"amsehili/auditok" -> "facebookresearch/denoiser"
"amsehili/auditok" -> "tyiannak/pyAudioAnalysis" ["e"=1]
"BUTSpeechFIT/speakerbeam" -> "xuchenglin28/speaker_extraction_SpEx"
"BUTSpeechFIT/speakerbeam" -> "gemengtju/L-SpEx"
"BUTSpeechFIT/speakerbeam" -> "xuchenglin28/speaker_extraction"
"BUTSpeechFIT/speakerbeam" -> "gemengtju/SpEx_Plus"
"BUTSpeechFIT/speakerbeam" -> "mborsdorf/UniversalSpeakerExtraction"
"BUTSpeechFIT/speakerbeam" -> "haoxiangsnr/SpEx"
"liqingchunnnn/Only-Noisy-Training" -> "madhavmk/Noise2Noise-audio_denoising_without_clean_training_data"
"HSU-ANT/gstpeaq" -> "stephencwelch/Perceptual-Coding-In-Python"
"xanguera/BeamformIt" -> "fgnt/nn-gev"
"xanguera/BeamformIt" -> "robin1001/beamforming"
"xanguera/BeamformIt" -> "funcwj/CGMM-MVDR"
"xanguera/BeamformIt" -> "kkumatani/distant_speech_recognition"
"xanguera/BeamformIt" -> "Enny1991/beamformers"
"xanguera/BeamformIt" -> "funcwj/setk"
"xanguera/BeamformIt" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"xanguera/BeamformIt" -> "acoular/acoular"
"xanguera/BeamformIt" -> "snsun/cgmm_mvdr"
"xanguera/BeamformIt" -> "fgnt/nara_wpe"
"xanguera/BeamformIt" -> "DavidDiazGuerra/gpuRIR"
"xanguera/BeamformIt" -> "ehabets/RIR-Generator"
"xanguera/BeamformIt" -> "aishoot/Sound_Localization_Algorithms"
"xanguera/BeamformIt" -> "ZitengWang/MASP"
"xanguera/BeamformIt" -> "funcwj/cgmm-mask-estimator"
"alibabasglab/FRCRN" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"alibabasglab/FRCRN" -> "echocatzh/MTFAA-Net"
"alibabasglab/FRCRN" -> "maggie0830/DCCRN"
"alibabasglab/FRCRN" -> "ruizhecao96/CMGAN"
"alibabasglab/FRCRN" -> "Xiaobin-Rong/gtcrn"
"alibabasglab/FRCRN" -> "tencent-ailab/FRA-RIR"
"alibabasglab/FRCRN" -> "alibabasglab/D2Former"
"alibabasglab/FRCRN" -> "ioyy900205/MFNet"
"Andong-Li-speech/TaylorSENet" -> "Andong-Li-speech/TaylorBeamformer"
"Andong-Li-speech/TaylorSENet" -> "wangtianrui/HGCN"
"Andong-Li-speech/TaylorSENet" -> "Andong-Li-speech/GaGNet"
"adobe-research/MetaAF" -> "fjiang9/NKF-AEC"
"adobe-research/MetaAF" -> "tencent-ailab/FRA-RIR"
"adobe-research/MetaAF" -> "vkothapally/JAECBF"
"adobe-research/MetaAF" -> "fakufaku/torchiva"
"adobe-research/MetaAF" -> "ewan-xu/pyaec"
"adobe-research/MetaAF" -> "echocatzh/MTFAA-Net"
"adobe-research/MetaAF" -> "ConferencingSpeech/ConferencingSpeech2021"
"adobe-research/MetaAF" -> "DavidDiazGuerra/gpuRIR"
"RezzaMir/Noise-Cancellation-For-Automobiles" -> "adithyasunil26/Active-Noise-Control"
"Crush0416/MS-CVNets-a-novel-complex-valued-neural-networks-for-SAR-ATR" -> "Crush0416/Fea-DA---Unknown-SAR-Target-Identification"
"audiolabs/torch-pesq" -> "tencent-ailab/FRA-RIR"
"audiolabs/torch-pesq" -> "mpariente/pytorch_stoi"
"audiolabs/torch-pesq" -> "fakufaku/torchiva"
"fgnt/nn-gev" -> "Enny1991/beamformers"
"fgnt/nn-gev" -> "funcwj/CGMM-MVDR"
"fgnt/nn-gev" -> "DistantSpeechRecognition/mcse"
"fgnt/nn-gev" -> "xanguera/BeamformIt"
"fgnt/nn-gev" -> "funcwj/setk"
"fgnt/nn-gev" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"fgnt/nn-gev" -> "snsun/cgmm_mvdr"
"fgnt/nn-gev" -> "AkojimaSLP/Neural-mask-estimation"
"fgnt/nn-gev" -> "Andong-Li-speech/EaBNet"
"fgnt/nn-gev" -> "funcwj/cgmm-mask-estimator"
"fgnt/nn-gev" -> "fgnt/pb_bss"
"fgnt/nn-gev" -> "fgnt/pb_chime5"
"fgnt/nn-gev" -> "ZitengWang/MASP"
"fgnt/nn-gev" -> "ZitengWang/nn_mask"
"fgnt/nn-gev" -> "ConferencingSpeech/ConferencingSpeech2021"
"lucmos/relreps" -> "Flegyas/latentis"
"jsdaiustc/rootSBL" -> "jsdaiustc/SBL_nested"
"jsdaiustc/rootSBL" -> "jsdaiustc/Real_SBL_linear"
"jsdaiustc/rootSBL" -> "Jimbo-Jo/GROGSBL"
"Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation" -> "SungFeng-Huang/SSL-pretraining-separation"
"BrownsugarZeer/Multi_SSL" -> "vkothapally/JAECBF"
"haoheliu/ssr_eval" -> "haoheliu/voicefixer_main"
"haoheliu/ssr_eval" -> "neoncloud/mdctGAN"
"jsdaiustc/SBL_nested" -> "jsdaiustc/rootSBL"
"jsdaiustc/Real_SBL_linear" -> "jsdaiustc/rootSBL"
"jsdaiustc/Real_SBL_linear" -> "jsdaiustc/SBL_nested"
"claritychallenge/clarity" -> "claritychallenge/clarity_CC"
"claritychallenge/clarity" -> "jfsantos/SRMRpy"
"claritychallenge/clarity" -> "dhimnsen/OpenSpeechPlatform-UCSD"
"tky823/ssspy" -> "tky823/audio_source_separation"
"tky823/ssspy" -> "fakufaku/fast_bss_eval"
"tky823/ssspy" -> "d-kitamura/AuxIVA-ISS"
"tky823/ssspy" -> "fakufaku/torchiva"
"tky823/ssspy" -> "lili-0805/MVAE"
"tky823/ssspy" -> "sekiguchi92/SoundSourceSeparation"
"neillu23/CDiffuSE" -> "sp-uhh/storm"
"neillu23/CDiffuSE" -> "sp-uhh/sgmse"
"neillu23/CDiffuSE" -> "neillu23/DiffuSE"
"neillu23/CDiffuSE" -> "tencent-ailab/FRA-RIR"
"neillu23/CDiffuSE" -> "YUCHEN005/NASE" ["e"=1]
"vkothapally/JAECBF" -> "vkothapally/Subband-Beamformer"
"felixfuyihui/Uformer" -> "wangtianrui/HGCN"
"fakufaku/fast_bss_eval" -> "fgnt/ci_sdr"
"fakufaku/fast_bss_eval" -> "fakufaku/torchiva"
"fakufaku/fast_bss_eval" -> "lili-0805/MVAE"
"fakufaku/fast_bss_eval" -> "tky823/ssspy"
"ysparkwin/AlternatingProjections" -> "Jimbo-Jo/GROGSBL"
"wangtianrui/APC-SNR" -> "Qinwen-Hu/SDCM"
"yuguochencuc/DB-AIAT" -> "felixfuyihui/Uformer"
"yuguochencuc/DB-AIAT" -> "neillu23/DiffuSE"
"yuguochencuc/DB-AIAT" -> "wangtianrui/HGCN"
"ZJU-Andre/ISEE-zju" -> "yjwang01/zju-isee"
"ZJU-Andre/ISEE-zju" -> "euphoniumm/isee-zju"
"isrish/VAD-LTSD" -> "dmngu9/Voice-Activity-Detection"
"adefossez/mdx21_demucs" -> "kuielab/mdx-net-submission"
"scofir/DTLN-aec" -> "YongyuG/dnn_aec_data_process"
"shenbengit/SrsRtcAndroidClient" -> "shenbengit/WebRTC-SRS"
"plbossart/UCM" -> "plbossart/sound"
"plbossart/UCM" -> "burzumishi/linux-baytrail-flexx10"
"BingYang-20/DP-RTF-Learning" -> "BingYang-20/SRP-DNN"
"gemengtju/L-SpEx" -> "zexupan/avse_hybrid_loss"
"FrankBoesing/Teensy-WavePlayer" -> "newdigate/teensy-variable-playback"
"DoubangoTelecom/webrtc-audioproc" -> "xshl5/KOTI_AEC"
"DoubangoTelecom/webrtc-audioproc" -> "garyyu/WebRTC_VoiceEngine"
"DoubangoTelecom/webrtc-audioproc" -> "YangangCao/WebRTC-3A1V"
"microsoft/PLC-Challenge" -> "Guanyuansheng/TFGAN-PLC"
"microsoft/PLC-Challenge" -> "microsoft/SIG-Challenge"
"voithru/asr-text_classification-pipeline" -> "voithru/wav2vec2_finetune"
"voithru/wav2vec2_finetune" -> "voithru/asr-text_classification-pipeline"
"voithru/wav2vec2_finetune" -> "voithru/voice-activity-detection"
"michelemancusi/LQVAE-separation" -> "daniele-baieri/PyGMI"
"michelemancusi/LQVAE-separation" -> "Flegyas/latentis"
"michelemancusi/LQVAE-separation" -> "gladia-research-group/latent-autoregressive-source-separation"
"farihachaiti/DoKaraokeAI_Spleeter_Android_Implementation" -> "VVasanth/Spleeter_Unofficial_TF20_MobileApp"
"Guanyuansheng/TFGAN-PLC" -> "microsoft/PLC-Challenge"
"Guanyuansheng/TFGAN-PLC" -> "breizhn/tPLCnet"
"yoyolicoris/danna-sep" -> "yoyolicoris/music-demixing-challenge-ismir-2021-entry"
"djvdorp/hi8" -> "Manouchehri/vi8"
"Asus-T100/kernel" -> "TheDrHax/t100ta-scripts"
"mt7-dev/android_kernel_huawei_mt7l09" -> "lbcgi/webrtc_aec_using_kalmanAdaption"
"stemrollerapp/stemroller" -> "facebookresearch/demucs"
"stemrollerapp/stemroller" -> "CarlGao4/Demucs-Gui"
"stemrollerapp/stemroller" -> "adefossez/demucs"
"stemrollerapp/stemroller" -> "JeffreyCA/spleeter-web"
"stemrollerapp/stemroller" -> "deezer/spleeter" ["e"=1]
"stemrollerapp/stemroller" -> "Music-and-Culture-Technology-Lab/omnizart" ["e"=1]
"stemrollerapp/stemroller" -> "Anjok07/ultimatevocalremovergui" ["e"=1]
"stemrollerapp/stemroller" -> "tsurumeso/vocal-remover"
"stemrollerapp/stemroller" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"stemrollerapp/stemroller" -> "spotify/basic-pitch" ["e"=1]
"stemrollerapp/stemroller" -> "nomadkaraoke/python-audio-separator"
"stemrollerapp/stemroller" -> "diracdeltas/spleeter4max" ["e"=1]
"stemrollerapp/stemroller" -> "pedrozath/coltrane" ["e"=1]
"stemrollerapp/stemroller" -> "intel/openvino-plugins-ai-audacity"
"stemrollerapp/stemroller" -> "runtipi/runtipi" ["e"=1]
"VipaiLab/Signals-and-Systems-course" -> "zju-isee/zju-isee"
"VipaiLab/Signals-and-Systems-course" -> "VipaiLab/machine-learning-course"
"VipaiLab/Signals-and-Systems-course" -> "Zezzid/ZJU_Course"
"VipaiLab/Signals-and-Systems-course" -> "yjwang01/zju-isee"
"VipaiLab/Signals-and-Systems-course" -> "JaceyHuang/ISEE-zju"
"VipaiLab/Signals-and-Systems-course" -> "NIT2018/NitSignal"
"VipaiLab/Signals-and-Systems-course" -> "aerore2021/KeISEE"
"VipaiLab/Signals-and-Systems-course" -> "skyline-pro/isee"
"VipaiLab/Signals-and-Systems-course" -> "SleepingMonster/SYSU_Courses" ["e"=1]
"VipaiLab/Signals-and-Systems-course" -> "LeadroyaL/ZJU_ISEE_Project"
"VipaiLab/Signals-and-Systems-course" -> "bastamon/sound_signal_process-matlab-"
"sp-uhh/sgmse" -> "sp-uhh/storm"
"sp-uhh/sgmse" -> "neillu23/CDiffuSE"
"sp-uhh/sgmse" -> "yxlu-0102/MP-SENet"
"sp-uhh/sgmse" -> "ruizhecao96/CMGAN"
"sp-uhh/sgmse" -> "Audio-WestlakeU/FullSubNet"
"sp-uhh/sgmse" -> "Xiaobin-Rong/gtcrn"
"sp-uhh/sgmse" -> "RoyChao19477/SEMamba"
"sp-uhh/sgmse" -> "tencent-ailab/FRA-RIR"
"sp-uhh/sgmse" -> "Audio-WestlakeU/NBSS"
"sp-uhh/sgmse" -> "microsoft/DNS-Challenge"
"sp-uhh/sgmse" -> "audiolabs/torch-pesq"
"sp-uhh/sgmse" -> "DavidDiazGuerra/gpuRIR"
"sp-uhh/sgmse" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"sp-uhh/sgmse" -> "schmiph2/pysepm"
"sp-uhh/sgmse" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"wiseman/py-webrtcvad" -> "jtkim-kaist/VAD"
"wiseman/py-webrtcvad" -> "snakers4/silero-vad" ["e"=1]
"wiseman/py-webrtcvad" -> "marsbroshok/VAD-python"
"wiseman/py-webrtcvad" -> "wq2012/awesome-diarization" ["e"=1]
"wiseman/py-webrtcvad" -> "microsoft/DNS-Challenge"
"wiseman/py-webrtcvad" -> "google/uis-rnn" ["e"=1]
"wiseman/py-webrtcvad" -> "pyannote/pyannote-audio" ["e"=1]
"wiseman/py-webrtcvad" -> "mravanelli/pytorch-kaldi" ["e"=1]
"wiseman/py-webrtcvad" -> "pykaldi/pykaldi" ["e"=1]
"wiseman/py-webrtcvad" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"wiseman/py-webrtcvad" -> "aliutkus/speechmetrics"
"wiseman/py-webrtcvad" -> "LCAV/pyroomacoustics"
"wiseman/py-webrtcvad" -> "jameslyons/python_speech_features" ["e"=1]
"wiseman/py-webrtcvad" -> "hcmlab/vadnet"
"wiseman/py-webrtcvad" -> "wenet-e2e/wenet" ["e"=1]
"alibabasglab/MossFormer" -> "alibabasglab/MossFormer2"
"vb000/Waveformer" -> "BUTSpeechFIT/speakerbeam"
"vb000/Waveformer" -> "RetroCirce/Zero_Shot_Audio_Source_Separation"
"vb000/Waveformer" -> "HaoFengyuan/X-TF-GridNet"
"vb000/Waveformer" -> "vb000/SemanticHearing"
"vb000/Waveformer" -> "urgent-challenge/urgent2024_challenge"
"NEGU93/CVNN-PolSAR" -> "NEGU93/polsar_cvnn"
"WenzheLiu-Speech/The-guidebook-of-speech-enhancement" -> "Andong-Li-speech/TaylorBeamformer"
"WenzheLiu-Speech/The-guidebook-of-speech-enhancement" -> "Andong-Li-speech/EaBNet"
"tencent-ailab/FRA-RIR" -> "Audio-WestlakeU/NBSS"
"tencent-ailab/FRA-RIR" -> "Audio-WestlakeU/McNet"
"tencent-ailab/FRA-RIR" -> "fakufaku/torchiva"
"shahules786/mayavoz" -> "schmiph2/pysepm"
"shahules786/mayavoz" -> "anicolson/DeepXi"
"Audio-WestlakeU/McNet" -> "Audio-WestlakeU/NBSS"
"Audio-WestlakeU/McNet" -> "Andong-Li-speech/EaBNet"
"Audio-WestlakeU/McNet" -> "Audio-WestlakeU/FN-SSL"
"onitake/gsl-firmware" -> "onitake/gslx680-acpi"
"onitake/gsl-firmware" -> "rastersoft/gsl1680"
"onitake/gsl-firmware" -> "sigboe/gslX68X"
"onitake/gsl-firmware" -> "lwfinger/rtl8723bs_bt"
"onitake/gsl-firmware" -> "edward-p/mssl1680-firmware"
"BrechtDeMan/WebAudioEvaluationTool" -> "audiolabs/webMUSHRA"
"ehabets/RIR-Generator" -> "DavidDiazGuerra/gpuRIR"
"ehabets/RIR-Generator" -> "fgnt/nara_wpe"
"ehabets/RIR-Generator" -> "fgnt/nn-gev"
"ehabets/RIR-Generator" -> "LCAV/pyroomacoustics"
"ehabets/RIR-Generator" -> "jzi040941/PercepNet"
"ehabets/RIR-Generator" -> "microsoft/DNS-Challenge"
"ehabets/RIR-Generator" -> "microsoft/AEC-Challenge"
"ehabets/RIR-Generator" -> "athena-team/athena-signal"
"ehabets/RIR-Generator" -> "huyanxin/DeepComplexCRN"
"ehabets/RIR-Generator" -> "xanguera/BeamformIt"
"ehabets/RIR-Generator" -> "fgnt/pb_bss"
"ehabets/RIR-Generator" -> "breizhn/DTLN-aec"
"ehabets/RIR-Generator" -> "funcwj/setk"
"ehabets/RIR-Generator" -> "sunits/rir_simulator_python"
"ehabets/RIR-Generator" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "yongxuUSTC/sednn"
"yongxuUSTC/DNN-for-speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"yongxuUSTC/DNN-for-speech-enhancement" -> "hyli666/DNN-SpeechEnhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"yongxuUSTC/DNN-for-speech-enhancement" -> "jtkim-kaist/Speech-enhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"yongxuUSTC/DNN-for-speech-enhancement" -> "santi-pdp/segan"
"yongxuUSTC/DNN-for-speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"matousc89/padasip" -> "matousc89/Python-Adaptive-Signal-Processing-Handbook"
"matousc89/padasip" -> "Wramberg/adaptfilt"
"matousc89/padasip" -> "ewan-xu/pyaec"
"matousc89/padasip" -> "rohitner/adaptive-filters"
"matousc89/padasip" -> "ninja3697/Kernel-Adaptive-Filtering-in-Python"
"matousc89/padasip" -> "adobe-research/MetaAF"
"matousc89/padasip" -> "YangangCao/AdaptiveFilter"
"matousc89/padasip" -> "braton/fadapt"
"matousc89/padasip" -> "fakufaku/torchiva"
"matousc89/padasip" -> "fgnt/nn-gev"
"NVIDIA/CleanUNet" -> "ruizhecao96/CMGAN"
"NVIDIA/CleanUNet" -> "sp-uhh/sgmse"
"NVIDIA/CleanUNet" -> "RookieJunChen/FullSubNet-plus"
"NVIDIA/CleanUNet" -> "madhavmk/Noise2Noise-audio_denoising_without_clean_training_data"
"NVIDIA/CleanUNet" -> "yxlu-0102/MP-SENet"
"NVIDIA/CleanUNet" -> "alibabasglab/FRCRN"
"NVIDIA/CleanUNet" -> "chomeyama/SiFiGAN" ["e"=1]
"NVIDIA/CleanUNet" -> "Audio-WestlakeU/FullSubNet"
"NVIDIA/CleanUNet" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"NVIDIA/CleanUNet" -> "YangangCao/TRUNet"
"NVIDIA/CleanUNet" -> "neillu23/CDiffuSE"
"NVIDIA/CleanUNet" -> "maum-ai/nuwave2" ["e"=1]
"NVIDIA/CleanUNet" -> "Rongjiehuang/ProDiff" ["e"=1]
"sungwon23/BSRNN" -> "microsoft/SIG-Challenge"
"LeadroyaL/ZJU_ISEE_Project" -> "Zezzid/ZJU_Course"
"LeadroyaL/ZJU_ISEE_Project" -> "JaceyHuang/ISEE-zju"
"LeadroyaL/ZJU_ISEE_Project" -> "ThuryW/ZJU-ISEE"
"LeadroyaL/ZJU_ISEE_Project" -> "zju-isee/zju-isee"
"LeadroyaL/ZJU_ISEE_Project" -> "euphoniumm/isee-zju"
"LeadroyaL/ZJU_ISEE_Project" -> "skyline-pro/isee"
"LeadroyaL/ZJU_ISEE_Project" -> "aerore2021/KeISEE"
"LeadroyaL/ZJU_ISEE_Project" -> "l2h4/ZJU-ISEE"
"LeadroyaL/ZJU_ISEE_Project" -> "yjwang01/zju-isee"
"LeadroyaL/ZJU_ISEE_Project" -> "AucFang/ZJU-ISEE-byAucFang"
"LeadroyaL/ZJU_ISEE_Project" -> "ZJU-Andre/ISEE-zju"
"microsoft/SIG-Challenge" -> "microsoft/PLC-Challenge"
"effusiveperiscope/so-vits-svc" -> "NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover"
"DistantSpeechRecognition/mcse" -> "fgnt/nn-gev"
"DistantSpeechRecognition/mcse" -> "funcwj/CGMM-MVDR"
"DistantSpeechRecognition/mcse" -> "snsun/cgmm_mvdr"
"DistantSpeechRecognition/mcse" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"DistantSpeechRecognition/mcse" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"sandprddy/Active-Noise-Cancellation-System" -> "LiXirong/AdaptiveFilterandActiveNoiseCancellation"
"JusperLee/TDANet" -> "tencent-ailab/FRA-RIR"
"JusperLee/TDANet" -> "JusperLee/SPMamba"
"JusperLee/TDANet" -> "RoyChao19477/SEMamba"
"JusperLee/TDANet" -> "JorisCos/LibriMix"
"JusperLee/TDANet" -> "Audio-WestlakeU/McNet"
"JusperLee/TDANet" -> "dmlguq456/SepReformer"
"JusperLee/TDANet" -> "RookieJunChen/FullSubNet-plus"
"JusperLee/TDANet" -> "Audio-WestlakeU/NBSS"
"JusperLee/TDANet" -> "yxlu-0102/MP-SENet"
"JusperLee/TDANet" -> "JusperLee/SonicSim"
"JusperLee/TDANet" -> "urgent-challenge/urgent2024_challenge"
"JusperLee/TDANet" -> "etzinis/sudo_rm_rf"
"JusperLee/TDANet" -> "Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation"
"JusperLee/TDANet" -> "sp-uhh/storm"
"JusperLee/TDANet" -> "JusperLee/Apollo"
"sp-uhh/storm" -> "sp-uhh/sgmse"
"sp-uhh/storm" -> "neillu23/CDiffuSE"
"sp-uhh/storm" -> "sp-uhh/sgmse-bbed"
"sp-uhh/storm" -> "yxlu-0102/MP-SENet"
"sp-uhh/storm" -> "felixfuyihui/Uformer"
"sp-uhh/storm" -> "fakufaku/diffusion-separation"
"sp-uhh/storm" -> "ICDM-UESTC/DOSE"
"fjiang9/NKF-AEC" -> "microsoft/AEC-Challenge"
"fjiang9/NKF-AEC" -> "breizhn/DTLN-aec"
"fjiang9/NKF-AEC" -> "echocatzh/MTFAA-Net"
"fjiang9/NKF-AEC" -> "jzi040941/PercepNet"
"fjiang9/NKF-AEC" -> "ewan-xu/pyaec"
"fjiang9/NKF-AEC" -> "LXP-Never/AEC_DeepModel"
"fjiang9/NKF-AEC" -> "Xiaobin-Rong/gtcrn"
"fjiang9/NKF-AEC" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"fjiang9/NKF-AEC" -> "echocatzh/PFDKF"
"fjiang9/NKF-AEC" -> "vkothapally/JAECBF"
"fjiang9/NKF-AEC" -> "adobe-research/MetaAF"
"fjiang9/NKF-AEC" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"fjiang9/NKF-AEC" -> "ewan-xu/AEC3"
"fjiang9/NKF-AEC" -> "ZitengWang/MASP"
"fjiang9/NKF-AEC" -> "tencent-ailab/FRA-RIR"
"TRvlvr/model_repo" -> "TRvlvr/application_data"
"sp-uhh/deep-non-linear-filter" -> "Andong-Li-speech/EaBNet"
"sp-uhh/deep-non-linear-filter" -> "vkothapally/JAECBF"
"sp-uhh/deep-non-linear-filter" -> "ModarHalimeh/COSPA"
"JaceyHuang/ISEE-zju" -> "euphoniumm/isee-zju"
"JaceyHuang/ISEE-zju" -> "ThuryW/ZJU-ISEE"
"JaceyHuang/ISEE-zju" -> "Zezzid/ZJU_Course"
"JaceyHuang/ISEE-zju" -> "l2h4/ZJU-ISEE"
"JaeBinCHA7/Nested-U-Net-based-Real-time-Speech-Enhancement-Mobile-App" -> "seorim0/NUNet-TLS"
"JaeBinCHA7/Nested-U-Net-based-Real-time-Speech-Enhancement-Mobile-App" -> "JaeBinCHA7/RTNR"
"JaeBinCHA7/Nested-U-Net-based-Real-time-Speech-Enhancement-Mobile-App" -> "JaeBinCHA7/DEMUCS-for-Speech-Enhancement"
"judiebig/DR-DiffuSE" -> "ICDM-UESTC/DOSE"
"XAI4SAR/SAR-HUB" -> "XAI4SAR/PIHA"
"XAI4SAR/SAR-HUB" -> "Alien9427/SAR_specific_models"
"BingYang-20/SRP-DNN" -> "BingYang-20/DP-RTF-Learning"
"BingYang-20/SRP-DNN" -> "Audio-WestlakeU/FN-SSL"
"YunyangZeng/TAPLoss" -> "muqiaoy/PAAP"
"Qinwen-Hu/SDCM" -> "wangtianrui/APC-SNR"
"chomeyama/DualCycleGAN" -> "olvrhhn/audio_super_resolution"
"chomeyama/DualCycleGAN" -> "jakeoneijk/FlashSR_Inference"
"fakufaku/torchiva" -> "fgnt/graph_pit"
"fakufaku/torchiva" -> "tencent-ailab/FRA-RIR"
"JaeBinCHA7/RTNR" -> "JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model"
"JaeBinCHA7/RTNR" -> "JaeBinCHA7/Nested-U-Net-based-Real-time-Speech-Enhancement-Mobile-App"
"gladia-research-group/multi-source-diffusion-models" -> "gladia-research-group/latent-autoregressive-source-separation"
"gladia-research-group/multi-source-diffusion-models" -> "michelemancusi/LQVAE-separation"
"gladia-research-group/multi-source-diffusion-models" -> "fakufaku/diffusion-separation"
"gladia-research-group/multi-source-diffusion-models" -> "EmilianPostolache/stable-audio-controlnet" ["e"=1]
"jeonchangbin49/MedleyVox" -> "jeonchangbin49/musdb-XL"
"eac-ufsm/beamforming-tools" -> "acoular/spectacoular"
"eac-ufsm/beamforming-tools" -> "adku1173/acoupipe"
"lhwcv/self_attention_alignment" -> "echocatzh/GFTNN"
"breizhn/tPLCnet" -> "aircarlo/bin2bin-GAN-PLC"
"lbcgi/webrtc_agc_matlab" -> "lbcgi/webrtc_aec_using_kalmanAdaption"
"Aketirani/audio-mnist" -> "Aketirani/active-noise-cancellation"
"jeonchangbin49/LimitAug" -> "jeonchangbin49/musdb-XL"
"jeonchangbin49/LimitAug" -> "yoongi43/music_source_separation"
"tata88k/webrtc-android-jni" -> "dengzikun/WebRTC-APM-for-Android"
"tata88k/webrtc-android-jni" -> "theeasiestway/android-webrtc-aecm"
"tata88k/webrtc-android-jni" -> "lhc180/webrtc-based-android-aecm"
"jeonchangbin49/musdb-XL" -> "jeonchangbin49/LimitAug"
"yoongi43/music_source_separation" -> "jeonchangbin49/LimitAug"
"nomadkaraoke/python-audio-separator" -> "seanghay/uvr"
"nomadkaraoke/python-audio-separator" -> "ZFTurbo/Music-Source-Separation-Training"
"nomadkaraoke/python-audio-separator" -> "Eddycrack864/UVR5-UI"
"nomadkaraoke/python-audio-separator" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"nomadkaraoke/python-audio-separator" -> "KimberleyJensen/Mel-Band-Roformer-Vocal-Model"
"nomadkaraoke/python-audio-separator" -> "blaisewf/rvc-cli" ["e"=1]
"nomadkaraoke/python-audio-separator" -> "nomadkaraoke/python-lyrics-transcriber"
"nomadkaraoke/python-audio-separator" -> "lucidrains/BS-RoFormer"
"nomadkaraoke/python-audio-separator" -> "haoheliu/versatile_audio_super_resolution"
"nomadkaraoke/python-audio-separator" -> "tsurumeso/vocal-remover"
"nomadkaraoke/python-audio-separator" -> "jarredou/MVSEP-MDX23-Colab_v2"
"nomadkaraoke/python-audio-separator" -> "NextAudioGen/ultimatevocalremover_api"
"nomadkaraoke/python-audio-separator" -> "nomadkaraoke/karaoke-generator"
"nomadkaraoke/python-audio-separator" -> "seanghay/uvr-mdx-infer"
"nomadkaraoke/python-audio-separator" -> "TRvlvr/model_repo"
"intel/openvino-plugins-ai-audacity" -> "intel/openvino-ai-plugins-gimp" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "DamRsn/NeuralNote" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "haoheliu/versatile_audio_super_resolution"
"intel/openvino-plugins-ai-audacity" -> "rsxdalv/tts-generation-webui" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "resemble-ai/resemble-enhance"
"intel/openvino-plugins-ai-audacity" -> "aaronaanderson/Terrain" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "plugdata-team/plugdata" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "baconpaul/airwin2rack" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "Rikorose/DeepFilterNet"
"intel/openvino-plugins-ai-audacity" -> "IAHispano/Applio" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "DISTRHO/Cardinal" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "baconpaul/six-sines" ["e"=1]
"intel/openvino-plugins-ai-audacity" -> "haoheliu/voicefixer"
"intel/openvino-plugins-ai-audacity" -> "JusperLee/Apollo"
"intel/openvino-plugins-ai-audacity" -> "audacity/audacity" ["e"=1]
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "jarredou/MVSEP-MDX23-Colab_v2"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "lucidrains/BS-RoFormer"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "ZFTurbo/Music-Source-Separation-Training"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "Captain-FLAM/KaraFan"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "KimberleyJensen/Mel-Band-Roformer-Vocal-Model"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "kuielab/mdx-net"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "amanteur/BandSplitRNN-PyTorch"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "nomadkaraoke/python-audio-separator"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "kuielab/sdx23"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "TRvlvr/model_repo"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "haoheliu/voicefixer"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "Audio-AGI/AudioSep" ["e"=1]
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "haoheliu/versatile_audio_super_resolution"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing"
"ZFTurbo/MVSEP-MDX23-music-separation-model" -> "junyuchen-cjy/DTTNet-Pytorch"
"Captain-FLAM/KaraFan" -> "jarredou/AudioSR-Colab-Fork"
"Captain-FLAM/KaraFan" -> "jarredou/MVSEP-MDX23-Colab_v2"
"LiChenda/Multi-clue-TSE-data" -> "yangdongchao/Tim-TSENet"
"stephencwelch/Imaginary-Numbers-Are-Real" -> "stephencwelch/LearningToSee"
"stephencwelch/Imaginary-Numbers-Are-Real" -> "stephencwelch/Neural-Networks-For-Audio-Processing"
"haoheliu/versatile_audio_super_resolution" -> "descriptinc/descript-audio-codec" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "haoheliu/voicefixer"
"haoheliu/versatile_audio_super_resolution" -> "NVIDIA/BigVGAN" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "kuleshov/audio-super-res"
"haoheliu/versatile_audio_super_resolution" -> "resemble-ai/resemble-enhance"
"haoheliu/versatile_audio_super_resolution" -> "JusperLee/Apollo"
"haoheliu/versatile_audio_super_resolution" -> "gemelo-ai/vocos" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "slp-rl/aero" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "shivammehta25/Matcha-TTS" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "Audio-AGI/AudioSep" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "IAHispano/Audio-Upscaler"
"haoheliu/versatile_audio_super_resolution" -> "yangdongchao/UniAudio" ["e"=1]
"haoheliu/versatile_audio_super_resolution" -> "sp-uhh/sgmse"
"haoheliu/versatile_audio_super_resolution" -> "ZFTurbo/Music-Source-Separation-Training"
"haoheliu/versatile_audio_super_resolution" -> "haoheliu/AudioLDM2" ["e"=1]
"snsun/cgmm_mvdr" -> "funcwj/cgmm-mask-estimator"
"snsun/cgmm_mvdr" -> "funcwj/CGMM-MVDR"
"snsun/cgmm_mvdr" -> "gogyzzz/beamformit_matlab"
"snsun/cgmm_mvdr" -> "fgnt/nn-gev"
"snsun/cgmm_mvdr" -> "chenwj1989/Beamforming_Examples"
"snsun/cgmm_mvdr" -> "zhr1201/Multi-channel-speech-extraction-using-DNN"
"yxlu-0102/MP-SENet" -> "RoyChao19477/SEMamba"
"yxlu-0102/MP-SENet" -> "ruizhecao96/CMGAN"
"yxlu-0102/MP-SENet" -> "Xiaobin-Rong/gtcrn"
"yxlu-0102/MP-SENet" -> "sp-uhh/sgmse"
"yxlu-0102/MP-SENet" -> "echocatzh/MTFAA-Net"
"yxlu-0102/MP-SENet" -> "sp-uhh/storm"
"yxlu-0102/MP-SENet" -> "RookieJunChen/FullSubNet-plus"
"yxlu-0102/MP-SENet" -> "Audio-WestlakeU/FullSubNet"
"yxlu-0102/MP-SENet" -> "felixfuyihui/Uformer"
"yxlu-0102/MP-SENet" -> "Audio-WestlakeU/NBSS"
"yxlu-0102/MP-SENet" -> "alibabasglab/FRCRN"
"yxlu-0102/MP-SENet" -> "huyanxin/DeepComplexCRN"
"yxlu-0102/MP-SENet" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"yxlu-0102/MP-SENet" -> "yxlu-0102/AP-BWE" ["e"=1]
"yxlu-0102/MP-SENet" -> "urgent-challenge/urgent2024_challenge"
"seanwood/gcc-nmf" -> "funcwj/setk"
"seanwood/gcc-nmf" -> "sekiguchi92/SoundSourceSeparation"
"seanwood/gcc-nmf" -> "aishoot/LSTM_PIT_Speech_Separation"
"seanwood/gcc-nmf" -> "fgnt/nn-gev"
"seanwood/gcc-nmf" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"seanwood/gcc-nmf" -> "funcwj/CGMM-MVDR"
"seanwood/gcc-nmf" -> "fgnt/pb_bss"
"seanwood/gcc-nmf" -> "speechLabBcCuny/onssen"
"seanwood/gcc-nmf" -> "snsun/cgmm_mvdr"
"seanwood/gcc-nmf" -> "d-kitamura/ILRMA"
"seanwood/gcc-nmf" -> "yongxuUSTC/sednn"
"seanwood/gcc-nmf" -> "ZitengWang/MASP"
"seanwood/gcc-nmf" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"seanwood/gcc-nmf" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"seanwood/gcc-nmf" -> "anicolson/DeepXi"
"jarredou/MVSEP-MDX23-Colab_v2" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"jarredou/MVSEP-MDX23-Colab_v2" -> "ZFTurbo/Music-Source-Separation-Training"
"jarredou/MVSEP-MDX23-Colab_v2" -> "Captain-FLAM/KaraFan"
"jarredou/MVSEP-MDX23-Colab_v2" -> "lucidrains/BS-RoFormer"
"jarredou/MVSEP-MDX23-Colab_v2" -> "KimberleyJensen/Mel-Band-Roformer-Vocal-Model"
"jarredou/MVSEP-MDX23-Colab_v2" -> "jarredou/Music-Source-Separation-Training-Colab-Inference"
"jarredou/MVSEP-MDX23-Colab_v2" -> "jarredou/AudioSR-Colab-Fork"
"jarredou/MVSEP-MDX23-Colab_v2" -> "NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover"
"jarredou/MVSEP-MDX23-Colab_v2" -> "yxlllc/ReFlow-VAE-SVC" ["e"=1]
"jarredou/MVSEP-MDX23-Colab_v2" -> "kwatcharasupat/bandit"
"Zezzid/ZJU_Course" -> "JaceyHuang/ISEE-zju"
"Zezzid/ZJU_Course" -> "skyline-pro/isee"
"Zezzid/ZJU_Course" -> "zju-isee/zju-isee"
"Zezzid/ZJU_Course" -> "euphoniumm/isee-zju"
"Zezzid/ZJU_Course" -> "aerore2021/KeISEE"
"Zezzid/ZJU_Course" -> "l2h4/ZJU-ISEE"
"Zezzid/ZJU_Course" -> "ThuryW/ZJU-ISEE"
"Zezzid/ZJU_Course" -> "LeadroyaL/ZJU_ISEE_Project"
"Zezzid/ZJU_Course" -> "yjwang01/zju-isee"
"dengzikun/WebRTC-APM-for-Android" -> "dengzikun/WebRTC-APM-for-Android-Demo"
"dengzikun/WebRTC-APM-for-Android" -> "tata88k/webrtc-android-jni"
"dengzikun/WebRTC-APM-for-Android-Demo" -> "dengzikun/WebRTC-APM-for-Android"
"dpirch/libfvad" -> "cpuimage/WebRTC_VAD"
"dpirch/libfvad" -> "unispeech/unimrcp" ["e"=1]
"dpirch/libfvad" -> "jtkim-kaist/VAD"
"dpirch/libfvad" -> "Baidu-AIP/speech-vad-demo"
"dpirch/libfvad" -> "shiweixingcn/vad"
"dpirch/libfvad" -> "voixen/voixen-vad" ["e"=1]
"dpirch/libfvad" -> "wiseman/py-webrtcvad"
"dpirch/libfvad" -> "gkonovalov/android-vad"
"dpirch/libfvad" -> "marsbroshok/VAD-python"
"dpirch/libfvad" -> "jitsi/jitsi-webrtc-vad-wrapper"
"dpirch/libfvad" -> "XiaoMi/kaldi-onnx" ["e"=1]
"dpirch/libfvad" -> "hcmlab/vadnet"
"dpirch/libfvad" -> "cotinyang/MRCP-Plugin-Demo" ["e"=1]
"dpirch/libfvad" -> "shichaog/WebRTC-audio-processing"
"dpirch/libfvad" -> "sippy/rtpproxy" ["e"=1]
"crlandsc/Music-Demixing-with-Band-Split-RNN" -> "amanteur/BandSplitRNN-PyTorch"
"crlandsc/Music-Demixing-with-Band-Split-RNN" -> "sungwon23/BSRNN"
"crlandsc/Music-Demixing-with-Band-Split-RNN" -> "junyuchen-cjy/DTTNet-Pytorch"
"crlandsc/Music-Demixing-with-Band-Split-RNN" -> "lucidrains/BS-RoFormer"
"Xiaobin-Rong/gtcrn" -> "Xiaobin-Rong/SEtrain"
"Xiaobin-Rong/gtcrn" -> "Xiaobin-Rong/TRT-SE"
"Xiaobin-Rong/gtcrn" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"Xiaobin-Rong/gtcrn" -> "Le-Xiaohuai-speech/DPCRN_DNS3"
"Xiaobin-Rong/gtcrn" -> "yxlu-0102/MP-SENet"
"Xiaobin-Rong/gtcrn" -> "echocatzh/MTFAA-Net"
"Xiaobin-Rong/gtcrn" -> "jzi040941/PercepNet"
"Xiaobin-Rong/gtcrn" -> "fjiang9/NKF-AEC"
"Xiaobin-Rong/gtcrn" -> "RoyChao19477/SEMamba"
"Xiaobin-Rong/gtcrn" -> "alibabasglab/FRCRN"
"Xiaobin-Rong/gtcrn" -> "Audio-WestlakeU/NBSS"
"Xiaobin-Rong/gtcrn" -> "Xiaobin-Rong/ul-unas"
"Xiaobin-Rong/gtcrn" -> "hyyan2k/LiSenNet"
"Xiaobin-Rong/gtcrn" -> "huyanxin/DeepComplexCRN"
"Xiaobin-Rong/gtcrn" -> "JusperLee/SonicSim"
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker_python_library"
"respeaker/get_started_with_respeaker" -> "respeaker/avs"
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker-feed"
"respeaker/get_started_with_respeaker" -> "respeaker/Alexa"
"respeaker/get_started_with_respeaker" -> "respeaker/respeaker_arduino_library"
"respeaker/get_started_with_respeaker" -> "respeaker/mic_array"
"respeaker/get_started_with_respeaker" -> "respeaker/seeed-voicecard"
"bytedance/uss" -> "gladia-research-group/multi-source-diffusion-models"
"bytedance/uss" -> "Aisaka0v0/CLAPSep"
"bytedance/uss" -> "sony/CLIPSep"
"bytedance/uss" -> "RetroCirce/Zero_Shot_Audio_Source_Separation"
"bytedance/uss" -> "JusperLee/SPMamba"
"bytedance/uss" -> "neillu23/CDiffuSE"
"bytedance/uss" -> "starrytong/SCNet"
"bytedance/uss" -> "WangHelin1997/SoloAudio"
"bytedance/uss" -> "descriptinc/audiotools" ["e"=1]
"seorim0/Multi-label-12-lead-ECG-abnormality-classification" -> "JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model"
"RSTLess-research/Fauno-Italian-LLM" -> "teelinsan/camoscio"
"RSTLess-research/Fauno-Italian-LLM" -> "michelemancusi/LQVAE-separation"
"respeaker/respeaker_python_library" -> "respeaker/get_started_with_respeaker"
"respeaker/respeaker_python_library" -> "respeaker/respeaker_arduino_library"
"respeaker/respeaker_python_library" -> "respeaker/microsoft_cognitive_services"
"lucidrains/BS-RoFormer" -> "ZFTurbo/Music-Source-Separation-Training"
"lucidrains/BS-RoFormer" -> "KimberleyJensen/Mel-Band-Roformer-Vocal-Model"
"lucidrains/BS-RoFormer" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"lucidrains/BS-RoFormer" -> "starrytong/SCNet"
"lucidrains/BS-RoFormer" -> "junyuchen-cjy/DTTNet-Pytorch"
"lucidrains/BS-RoFormer" -> "amanteur/BandSplitRNN-PyTorch"
"lucidrains/BS-RoFormer" -> "crlandsc/Music-Demixing-with-Band-Split-RNN"
"lucidrains/BS-RoFormer" -> "JusperLee/SPMamba"
"lucidrains/BS-RoFormer" -> "JusperLee/Apollo"
"lucidrains/BS-RoFormer" -> "moises-ai/moises-db"
"lucidrains/BS-RoFormer" -> "descriptinc/descript-audio-codec" ["e"=1]
"lucidrains/BS-RoFormer" -> "jarredou/MVSEP-MDX23-Colab_v2"
"lucidrains/BS-RoFormer" -> "amanteur/SCNet-PyTorch"
"lucidrains/BS-RoFormer" -> "sp-uhh/sgmse"
"lucidrains/BS-RoFormer" -> "tencent-ailab/FRA-RIR"
"robin1001/beamforming" -> "kkumatani/distant_speech_recognition"
"robin1001/beamforming" -> "xanguera/BeamformIt"
"robin1001/beamforming" -> "snsun/cgmm_mvdr"
"robin1001/beamforming" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"robin1001/beamforming" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"robin1001/beamforming" -> "athena-team/athena-signal"
"robin1001/beamforming" -> "wavesaudio/Speex-AEC-matlab"
"robin1001/beamforming" -> "jorgengrythe/beamforming"
"robin1001/beamforming" -> "wangwei2009/DOA"
"robin1001/beamforming" -> "funcwj/cgmm-mask-estimator"
"robin1001/beamforming" -> "zhr1201/OMLSA-speech-enhancement"
"robin1001/beamforming" -> "ZitengWang/MASP"
"robin1001/beamforming" -> "DistantSpeechRecognition/mcse"
"dmngu9/Voice-Activity-Detection" -> "isrish/VAD-LTSD"
"dmngu9/Voice-Activity-Detection" -> "mvansegbroeck-zz/vad"
"Flegyas/latentis" -> "daniele-baieri/PyGMI"
"Flegyas/latentis" -> "grok-ai/py-template"
"Flegyas/latentis" -> "michelemancusi/LQVAE-separation"
"Flegyas/latentis" -> "lucmos/relreps"
"Flegyas/latentis" -> "tommasomncttn/mergenetic"
"Flegyas/latentis" -> "grok-ai/nn-template-core"
"alibabasglab/MossFormer2" -> "alibabasglab/MossFormer"
"alibabasglab/MossFormer2" -> "dmlguq456/SepReformer"
"alibabasglab/MossFormer2" -> "JusperLee/SPMamba"
"alibabasglab/MossFormer2" -> "alibabasglab/FRCRN"
"alibabasglab/MossFormer2" -> "Audio-WestlakeU/FS-EEND" ["e"=1]
"nicolasobin/binauralLocalization" -> "Hardcorehobel/Binaural_Localization"
"ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing" -> "kwatcharasupat/bandit"
"kwatcharasupat/bandit" -> "kwatcharasupat/bandit-v2"
"kwatcharasupat/bandit" -> "ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing"
"kwatcharasupat/bandit" -> "kwatcharasupat/source-separation-landing"
"teelinsan/parallel-decoding" -> "daniele-baieri/PyGMI"
"Audio-WestlakeU/FN-SSL" -> "Audio-WestlakeU/RealMAN"
"Audio-WestlakeU/FN-SSL" -> "BingYang-20/SRP-DNN"
"Audio-WestlakeU/FN-SSL" -> "Audio-WestlakeU/SAR-SSL" ["e"=1]
"Audio-WestlakeU/FN-SSL" -> "Audio-WestlakeU/McNet"
"Aketirani/active-noise-cancellation" -> "Aketirani/audio-mnist"
"teelinsan/camoscio" -> "RSTLess-research/Fauno-Italian-LLM"
"teelinsan/camoscio" -> "crux82/ExtremITA"
"teelinsan/camoscio" -> "swapUniba/LLaMAntino"
"teelinsan/camoscio" -> "daniele-baieri/PyGMI"
"kuielab/sdx23" -> "aim-qmul/sdx23-aimless"
"kuielab/sdx23" -> "kuielab/mdx-net-submission"
"kuielab/sdx23" -> "davidliujiafeng/ccom_mdx2023"
"kuielab/sdx23" -> "naba89/iSeparate-SDX"
"seanghay/uvr" -> "seanghay/uvr-mdx-infer"
"seanghay/uvr" -> "nomadkaraoke/python-audio-separator"
"XAI4SAR/PIHA" -> "XAI4SAR/SAR-HUB"
"ioyy900205/MFNet" -> "wangtianrui/APC-SNR"
"skyline-pro/isee" -> "euphoniumm/isee-zju"
"skyline-pro/isee" -> "Zezzid/ZJU_Course"
"skyline-pro/isee" -> "AucFang/ZJU-ISEE-byAucFang"
"XZWY/SpatialCodec" -> "Andong-Li-speech/G2Net"
"sp-uhh/sgmse-bbed" -> "sp-uhh/sgmse_crp"
"gilleschardon/acosolo" -> "adku1173/acoupipe"
"nomadkaraoke/python-lyrics-transcriber" -> "nomadkaraoke/karaoke-prep"
"nomadkaraoke/python-lyrics-transcriber" -> "nomadkaraoke/karaoke-generator"
"jcsilva/deep-clustering" -> "zhr1201/deep-clustering"
"jcsilva/deep-clustering" -> "Unisound/SpeechSeparation"
"KimberleyJensen/kmdx-net_music-source-separation" -> "naba89/iSeparate-SDX"
"amanteur/BandSplitRNN-PyTorch" -> "crlandsc/Music-Demixing-with-Band-Split-RNN"
"amanteur/BandSplitRNN-PyTorch" -> "junyuchen-cjy/DTTNet-Pytorch"
"amanteur/BandSplitRNN-PyTorch" -> "sungwon23/BSRNN"
"amanteur/BandSplitRNN-PyTorch" -> "starrytong/SCNet"
"amanteur/BandSplitRNN-PyTorch" -> "tencent-ailab/FRA-RIR"
"amanteur/BandSplitRNN-PyTorch" -> "amanteur/SCNet-PyTorch"
"nomadkaraoke/karaoke-generator" -> "nomadkaraoke/python-lyrics-transcriber"
"respeaker/Alexa" -> "respeaker/respeaker-feed"
"aircarlo/bin2bin-GAN-PLC" -> "breizhn/tPLCnet"
"naba89/iSeparate-SDX" -> "davidliujiafeng/ccom_mdx2023"
"muqiaoy/PAAP" -> "YunyangZeng/TAPLoss"
"resemble-ai/resemble-enhance" -> "haoheliu/voicefixer"
"resemble-ai/resemble-enhance" -> "Rikorose/DeepFilterNet"
"resemble-ai/resemble-enhance" -> "haoheliu/versatile_audio_super_resolution"
"resemble-ai/resemble-enhance" -> "facebookresearch/denoiser"
"resemble-ai/resemble-enhance" -> "descriptinc/descript-audio-codec" ["e"=1]
"resemble-ai/resemble-enhance" -> "modelscope/ClearerVoice-Studio" ["e"=1]
"resemble-ai/resemble-enhance" -> "yl4579/StyleTTS2" ["e"=1]
"resemble-ai/resemble-enhance" -> "sp-uhh/sgmse"
"resemble-ai/resemble-enhance" -> "huggingface/parler-tts" ["e"=1]
"resemble-ai/resemble-enhance" -> "ZFTurbo/Music-Source-Separation-Training"
"resemble-ai/resemble-enhance" -> "Audio-AGI/AudioSep" ["e"=1]
"resemble-ai/resemble-enhance" -> "sh-lee-prml/HierSpeechpp" ["e"=1]
"resemble-ai/resemble-enhance" -> "gemelo-ai/vocos" ["e"=1]
"resemble-ai/resemble-enhance" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"resemble-ai/resemble-enhance" -> "yxlu-0102/MP-SENet"
"jgarciagimenez/GSC_beamforming" -> "XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter"
"jgarciagimenez/GSC_beamforming" -> "satyanamuduri/Speech-Enhancement-Using-GSC"
"jgarciagimenez/GSC_beamforming" -> "Akki369/Generalised-Side-Lobe-Canceller"
"jgarciagimenez/GSC_beamforming" -> "wangwei2009/Microphone-Array-postfilter"
"jgarciagimenez/GSC_beamforming" -> "chenwj1989/Beamforming_Examples"
"morriswmz/doa-tools" -> "morriswmz/doatools.py"
"morriswmz/doa-tools" -> "msamsami/doa-estimation-music"
"morriswmz/doa-tools" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"morriswmz/doa-tools" -> "wangwei2009/DOA"
"morriswmz/doa-tools" -> "chenhui07c8/DOA-AOA-algorithms"
"morriswmz/doa-tools" -> "m2wagner/Alternating_Projections_Gridless_DOA_Estimation"
"morriswmz/doa-tools" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"morriswmz/doa-tools" -> "xuchenglin28/WSCM-MUSIC"
"morriswmz/doa-tools" -> "jsdaiustc/Real_SBL_linear"
"morriswmz/doa-tools" -> "jsdaiustc/rootSBL"
"morriswmz/doa-tools" -> "xiaoli1368/Microphone-sound-source-localization"
"morriswmz/doa-tools" -> "LCAV/FRIDA"
"morriswmz/doa-tools" -> "polarch/Spherical-Array-Processing" ["e"=1]
"morriswmz/doa-tools" -> "lynnzhiyun/graduation-project"
"morriswmz/doa-tools" -> "ZitengWang/MASP"
"ZFTurbo/Music-Source-Separation-Training" -> "lucidrains/BS-RoFormer"
"ZFTurbo/Music-Source-Separation-Training" -> "SUC-DriverOld/MSST-WebUI" ["e"=1]
"ZFTurbo/Music-Source-Separation-Training" -> "KimberleyJensen/Mel-Band-Roformer-Vocal-Model"
"ZFTurbo/Music-Source-Separation-Training" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"ZFTurbo/Music-Source-Separation-Training" -> "jarredou/MVSEP-MDX23-Colab_v2"
"ZFTurbo/Music-Source-Separation-Training" -> "starrytong/SCNet"
"ZFTurbo/Music-Source-Separation-Training" -> "JusperLee/Apollo"
"ZFTurbo/Music-Source-Separation-Training" -> "nomadkaraoke/python-audio-separator"
"ZFTurbo/Music-Source-Separation-Training" -> "haoheliu/versatile_audio_super_resolution"
"ZFTurbo/Music-Source-Separation-Training" -> "crlandsc/Music-Demixing-with-Band-Split-RNN"
"ZFTurbo/Music-Source-Separation-Training" -> "amanteur/BandSplitRNN-PyTorch"
"ZFTurbo/Music-Source-Separation-Training" -> "yxlllc/ReFlow-VAE-SVC" ["e"=1]
"ZFTurbo/Music-Source-Separation-Training" -> "descriptinc/descript-audio-codec" ["e"=1]
"ZFTurbo/Music-Source-Separation-Training" -> "junyuchen-cjy/DTTNet-Pytorch"
"ZFTurbo/Music-Source-Separation-Training" -> "resemble-ai/resemble-enhance"
"adefossez/demucs" -> "CarlGao4/Demucs-Gui"
"adefossez/demucs" -> "facebookresearch/demucs"
"adefossez/demucs" -> "ZFTurbo/Music-Source-Separation-Training"
"adefossez/demucs" -> "lucidrains/BS-RoFormer"
"adefossez/demucs" -> "xserrat/docker-facebook-demucs"
"adefossez/demucs" -> "sigsep/open-unmix-pytorch"
"adefossez/demucs" -> "ZFTurbo/MVSEP-MDX23-music-separation-model"
"adefossez/demucs" -> "nomadkaraoke/python-audio-separator"
"adefossez/demucs" -> "spotify/basic-pitch" ["e"=1]
"adefossez/demucs" -> "tsurumeso/vocal-remover"
"adefossez/demucs" -> "stemrollerapp/stemroller"
"adefossez/demucs" -> "Audio-AGI/AudioSep" ["e"=1]
"adefossez/demucs" -> "bytedance/music_source_separation"
"adefossez/demucs" -> "asteroid-team/asteroid"
"adefossez/demucs" -> "DamRsn/NeuralNote" ["e"=1]
"cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement" -> "Xiaobin-Rong/gtcrn"
"cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement" -> "echocatzh/MTFAA-Net"
"vb000/LookOnceToHear" -> "wenet-e2e/wesep"
"vb000/LookOnceToHear" -> "urgent-challenge/urgent2024_challenge"
"vb000/LookOnceToHear" -> "vb000/SemanticHearing"
"vb000/LookOnceToHear" -> "vb000/Waveformer"
"vb000/LookOnceToHear" -> "DavidDiazGuerra/gpuRIR"
"vb000/LookOnceToHear" -> "Xiaobin-Rong/gtcrn"
"vb000/LookOnceToHear" -> "sp-uhh/sgmse"
"vb000/LookOnceToHear" -> "HaoFengyuan/X-TF-GridNet"
"vb000/LookOnceToHear" -> "YangangCao/TRUNet"
"vb000/LookOnceToHear" -> "facebookresearch/ears_dataset"
"vb000/LookOnceToHear" -> "chentuochao/Target-Conversation-Extraction"
"vb000/LookOnceToHear" -> "fgnt/ci_sdr"
"vb000/LookOnceToHear" -> "vivjay30/Cone-of-Silence"
"highskyno1/MIMO_DOA" -> "jsdaiustc/rootSBL"
"highskyno1/MIMO_DOA" -> "lewsilver/radar_doa"
"highskyno1/MIMO_DOA" -> "Jimbo-Jo/GROGSBL"
"chipaudette/OpenAudio_ArduinoLibrary" -> "newdigate/teensy-variable-playback"
"chipaudette/OpenAudio_ArduinoLibrary" -> "hexeguitar/hexefx_audiolib_F32"
"chipaudette/OpenAudio_ArduinoLibrary" -> "Tympan/Tympan_Library"
"chipaudette/OpenAudio_ArduinoLibrary" -> "MarkzP/AudioEffectDynamics"
"timsainb/python_spectrograms_and_inversion" -> "kastnerkyle/tools"
"timsainb/python_spectrograms_and_inversion" -> "posenhuang/singingvoiceseparationrpca"
"yuguochencuc/BAE-Net" -> "Andong-Li-speech/G2Net"
"facebookresearch/ears_dataset" -> "sp-uhh/ears_benchmark"
"facebookresearch/ears_dataset" -> "urgent-challenge/urgent2024_challenge"
"facebookresearch/ears_dataset" -> "yuguochencuc/BAE-Net"
"Eddycrack864/UVR5-NO-UI" -> "Eddycrack864/Ultimate-Vocal-Remover-5.6-for-Google-Colab"
"markostam/active-noise-cancellation" -> "xiezhq-hermann/ANC_signal-system_project"
"markostam/active-noise-cancellation" -> "RezzaMir/Noise-Cancellation-For-Automobiles"
"markostam/active-noise-cancellation" -> "LiXirong/AdaptiveFilterandActiveNoiseCancellation"
"markostam/active-noise-cancellation" -> "psykulsk/RpiANC"
"markostam/active-noise-cancellation" -> "ZitengWang/MASP"
"markostam/active-noise-cancellation" -> "sandprddy/Active-Noise-Cancellation-System"
"markostam/active-noise-cancellation" -> "masilvabustos/TMS320C6748-ANC"
"markostam/active-noise-cancellation" -> "Mathilda11/Speech-processing" ["e"=1]
"markostam/active-noise-cancellation" -> "Aketirani/active-noise-cancellation"
"markostam/active-noise-cancellation" -> "stephencwelch/Active-Noise-Cancellation"
"markostam/active-noise-cancellation" -> "ewan-xu/pyaec"
"markostam/active-noise-cancellation" -> "xiph/speexdsp"
"markostam/active-noise-cancellation" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"markostam/active-noise-cancellation" -> "Qin-Yi/Active-Noise-Control-System"
"markostam/active-noise-cancellation" -> "YosukeSugiura/ActiveNoiseControl"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "matousc89/padasip"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "rohitner/adaptive-filters"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "Wramberg/adaptfilt"
"matousc89/Python-Adaptive-Signal-Processing-Handbook" -> "ninja3697/Kernel-Adaptive-Filtering-in-Python"
"lewsilver/radar_doa" -> "highskyno1/MIMO_DOA"
"lewsilver/radar_doa" -> "liynjy/FMCW-2T4R-SIM-MUSIC" ["e"=1]
"lewsilver/radar_doa" -> "jsdaiustc/rootSBL"
"lewsilver/radar_doa" -> "Jimbo-Jo/GROGSBL"
"hamza-latif/MSTAR_tensorflow" -> "hunterlew/mstar_with_machine_learning"
"hamza-latif/MSTAR_tensorflow" -> "fudanxu/MSTAR-AConvNet"
"hamza-latif/MSTAR_tensorflow" -> "azy1988/ML-CV"
"hamza-latif/MSTAR_tensorflow" -> "huangshaoyin/MSTAR_data_deal"
"JusperLee/SPMamba" -> "wenet-e2e/wesep"
"JusperLee/SPMamba" -> "RoyChao19477/SEMamba"
"JusperLee/SPMamba" -> "JusperLee/TIGER"
"JusperLee/SPMamba" -> "xi-j/Mamba-TasNet"
"JusperLee/SPMamba" -> "urgent-challenge/urgent2024_challenge"
"JusperLee/SPMamba" -> "Andong-Li-speech/Neural-Vocoders-as-Speech-Enhancers"
"JusperLee/SPMamba" -> "HaoFengyuan/X-TF-GridNet"
"xi-j/Mamba-TasNet" -> "xi-j/Mamba-ASR"
"Audio-WestlakeU/RealMAN" -> "Audio-WestlakeU/FN-SSL"
"Audio-WestlakeU/RealMAN" -> "Audio-WestlakeU/NBSS"
"Audio-WestlakeU/RealMAN" -> "Audio-WestlakeU/SAR-SSL" ["e"=1]
"Audio-WestlakeU/RealMAN" -> "Audio-WestlakeU/pytorch_lightning_template_for_beginners"
"Audio-WestlakeU/RealMAN" -> "urgent-challenge/urgent2024_challenge"
"RoyChao19477/SEMamba" -> "yxlu-0102/MP-SENet"
"RoyChao19477/SEMamba" -> "RoyChao19477/PCS"
"RoyChao19477/SEMamba" -> "JusperLee/SPMamba"
"RoyChao19477/SEMamba" -> "ruizhecao96/CMGAN"
"RoyChao19477/SEMamba" -> "Xiaobin-Rong/gtcrn"
"RoyChao19477/SEMamba" -> "xi-j/Mamba-TasNet"
"RoyChao19477/SEMamba" -> "urgent-challenge/urgent2024_challenge"
"sindhurach94/Sound-source-localization" -> "sasi433/Sound-source-localization"
"MTG/DeepConvSep" -> "francesclluis/source-separation-wavenet"
"MTG/DeepConvSep" -> "andabi/music-source-separation"
"MTG/DeepConvSep" -> "posenhuang/deeplearningsourceseparation"
"MTG/DeepConvSep" -> "nussl/nussl"
"MTG/DeepConvSep" -> "f90/Wave-U-Net"
"MTG/DeepConvSep" -> "MTG/gaia"
"MTG/DeepConvSep" -> "mir-evaluation/mir_eval" ["e"=1]
"MTG/DeepConvSep" -> "funcwj/deep-clustering"
"MTG/DeepConvSep" -> "wslihgt/pyfasst"
"MTG/DeepConvSep" -> "madebyollin/acapellabot"
"MTG/DeepConvSep" -> "keums/melodyExtraction_JDC" ["e"=1]
"MTG/DeepConvSep" -> "zhr1201/deep-clustering"
"MTG/DeepConvSep" -> "marl/medleydb" ["e"=1]
"MTG/DeepConvSep" -> "bmcfee/muda" ["e"=1]
"MTG/DeepConvSep" -> "urinieto/msaf" ["e"=1]
"HaoFengyuan/X-TF-GridNet" -> "Beilong-Tang/TSELM"
"jarredou/AudioSR-Colab-Fork" -> "jarredou/Apollo-Colab-Inference"
"Eddycrack864/Ultimate-Vocal-Remover-5.6-for-Google-Colab" -> "Eddycrack864/UVR5-NO-UI"
"Aisaka0v0/CLAPSep" -> "LiChenda/Multi-clue-TSE-data"
"starrytong/SCNet" -> "amanteur/SCNet-PyTorch"
"starrytong/SCNet" -> "baijinglin/TS-BSmamba2"
"starrytong/SCNet" -> "junyuchen-cjy/DTTNet-Pytorch"
"BoysTownOrg/chapro" -> "rogaits/AFC-NR"
"gitwukeyi/FSPEN" -> "Okrio/FSPEN"
"sevagh/demucs.cpp" -> "sevagh/basicpitch.cpp"
"sevagh/demucs.cpp" -> "jinay1991/spleeter"
"Xiaobin-Rong/TRT-SE" -> "Xiaobin-Rong/SEtrain"
"Xiaobin-Rong/TRT-SE" -> "Xiaobin-Rong/gtcrn"
"ICDM-UESTC/DOSE" -> "judiebig/DR-DiffuSE"
"sp-uhh/sgmse_crp" -> "sp-uhh/sgmse-bbed"
"amanteur/SCNet-PyTorch" -> "starrytong/SCNet"
"haoxiangsnr/llm-tse" -> "LiChenda/Multi-clue-TSE-data"
"Xiaobin-Rong/deepvqe" -> "Okrio/deepvqe"
"Xiaobin-Rong/SEtrain" -> "Xiaobin-Rong/gtcrn"
"Xiaobin-Rong/SEtrain" -> "Xiaobin-Rong/TRT-SE"
"Xiaobin-Rong/SEtrain" -> "Xiaobin-Rong/ul-unas"
"Xiaobin-Rong/SEtrain" -> "Okrio/CRUSE"
"Xiaobin-Rong/SEtrain" -> "hyyan2k/LiSenNet"
"JaeBinCHA7/DEMUCS-for-Speech-Enhancement" -> "JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model"
"seorim0/ResUNet-LC" -> "JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model"
"JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model" -> "seorim0/ResUNet-LC"
"Okrio/FSPEN" -> "gitwukeyi/FSPEN"
"kuleshov/audio-super-res" -> "haoheliu/versatile_audio_super_resolution"
"kuleshov/audio-super-res" -> "haoheliu/voicefixer"
"kuleshov/audio-super-res" -> "maum-ai/nuwave2" ["e"=1]
"kuleshov/audio-super-res" -> "slp-rl/aero" ["e"=1]
"kuleshov/audio-super-res" -> "santi-pdp/segan"
"kuleshov/audio-super-res" -> "jhetherly/EnglishSpeechUpsampler"
"kuleshov/audio-super-res" -> "f90/Wave-U-Net"
"kuleshov/audio-super-res" -> "maum-ai/nuwave" ["e"=1]
"kuleshov/audio-super-res" -> "descriptinc/melgan-neurips" ["e"=1]
"kuleshov/audio-super-res" -> "zkx06111/WSRGlow" ["e"=1]
"kuleshov/audio-super-res" -> "kan-bayashi/ParallelWaveGAN" ["e"=1]
"kuleshov/audio-super-res" -> "xiph/LPCNet" ["e"=1]
"kuleshov/audio-super-res" -> "drethage/speech-denoising-wavenet"
"kuleshov/audio-super-res" -> "csteinmetz1/auraloss" ["e"=1]
"kuleshov/audio-super-res" -> "descriptinc/descript-audio-codec" ["e"=1]
"audiolabs/webMUSHRA" -> "nils-werner/pymushra"
"audiolabs/webMUSHRA" -> "BrechtDeMan/WebAudioEvaluationTool"
"audiolabs/webMUSHRA" -> "csteinmetz1/auraloss" ["e"=1]
"audiolabs/webMUSHRA" -> "csteinmetz1/pyloudnorm"
"audiolabs/webMUSHRA" -> "mpariente/pystoi"
"audiolabs/webMUSHRA" -> "google/visqol"
"audiolabs/webMUSHRA" -> "gabrielmittag/NISQA"
"audiolabs/webMUSHRA" -> "descriptinc/descript-audio-codec" ["e"=1]
"audiolabs/webMUSHRA" -> "aliutkus/speechmetrics"
"audiolabs/webMUSHRA" -> "pranaymanocha/PerceptualAudio" ["e"=1]
"audiolabs/webMUSHRA" -> "lochenchou/MOSNet"
"audiolabs/webMUSHRA" -> "yangdongchao/AcademiCodec" ["e"=1]
"audiolabs/webMUSHRA" -> "ludlows/PESQ"
"audiolabs/webMUSHRA" -> "DavidDiazGuerra/gpuRIR"
"dmlguq456/SepReformer" -> "merlresearch/tf-locoformer"
"dmlguq456/SepReformer" -> "JusperLee/SonicSim"
"dmlguq456/SepReformer" -> "alibabasglab/MossFormer2"
"dmlguq456/SepReformer" -> "JusperLee/TDANet"
"dmlguq456/SepReformer" -> "sp-uhh/storm"
"dmlguq456/SepReformer" -> "wenet-e2e/wesep"
"dmlguq456/SepReformer" -> "RoyChao19477/SEMamba"
"dmlguq456/SepReformer" -> "Audio-WestlakeU/RealMAN"
"Eddycrack864/UVR5-UI" -> "nomadkaraoke/python-audio-separator"
"Eddycrack864/UVR5-UI" -> "Eddycrack864/UVR5-NO-UI"
"Eddycrack864/UVR5-UI" -> "Captain-FLAM/KaraFan"
"Eddycrack864/UVR5-UI" -> "BUTSpeechFIT/DiariZen" ["e"=1]
"Eddycrack864/UVR5-UI" -> "Eddycrack864/Ultimate-Vocal-Remover-5.6-for-Google-Colab"
"JusperLee/SonicSim" -> "JusperLee/TIGER"
"JusperLee/SonicSim" -> "tencent-ailab/FRA-RIR"
"JusperLee/SonicSim" -> "Audio-WestlakeU/RealMAN"
"JusperLee/SonicSim" -> "HaoFengyuan/X-TF-GridNet"
"JusperLee/SonicSim" -> "Audio-WestlakeU/NBSS"
"JusperLee/SonicSim" -> "urgent-challenge/urgent2025_challenge"
"JusperLee/SonicSim" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"JusperLee/SonicSim" -> "starrytong/SCNet"
"JusperLee/SonicSim" -> "Xiaobin-Rong/gtcrn"
"JusperLee/SonicSim" -> "JusperLee/SPMamba"
"JusperLee/SonicSim" -> "wenet-e2e/wesep"
"JusperLee/SonicSim" -> "Audio-WestlakeU/McNet"
"yaoxunji/gen-se" -> "Beilong-Tang/TSELM"
"yaoxunji/gen-se" -> "Kevin-naticl/LLaSE-G1"
"lucidrains/minGRU-pytorch" -> "ssi-research/FQSE"
"lucidrains/minGRU-pytorch" -> "Xiaobin-Rong/TRT-SE"
"lucidrains/minGRU-pytorch" -> "cheind/mingru"
"lucidrains/minGRU-pytorch" -> "JusperLee/TIGER"
"lucidrains/minGRU-pytorch" -> "sungwon23/BSRNN"
"lucidrains/minGRU-pytorch" -> "junyuchen-cjy/DTTNet-Pytorch"
"lucidrains/minGRU-pytorch" -> "lucidrains/adam-atan2-pytorch"
"lucidrains/minGRU-pytorch" -> "hyyan2k/LiSenNet"
"jtkim-kaist/VAD" -> "hcmlab/vadnet"
"jtkim-kaist/VAD" -> "marsbroshok/VAD-python"
"jtkim-kaist/VAD" -> "jtkim-kaist/Speech-enhancement"
"jtkim-kaist/VAD" -> "wiseman/py-webrtcvad"
"jtkim-kaist/VAD" -> "filippogiruzzi/voice_activity_detection"
"jtkim-kaist/VAD" -> "mvansegbroeck-zz/vad"
"jtkim-kaist/VAD" -> "nicklashansen/voice-activity-detection"
"jtkim-kaist/VAD" -> "eesungkim/Voice_Activity_Detector"
"jtkim-kaist/VAD" -> "LCAV/pyroomacoustics"
"jtkim-kaist/VAD" -> "yongxuUSTC/sednn"
"jtkim-kaist/VAD" -> "santi-pdp/segan"
"jtkim-kaist/VAD" -> "nanahou/Awesome-Speech-Enhancement"
"jtkim-kaist/VAD" -> "Ryuk17/SpeechAlgorithms"
"jtkim-kaist/VAD" -> "anicolson/DeepXi"
"jtkim-kaist/VAD" -> "dpirch/libfvad"
"amaas/rnn-speech-denoising" -> "posenhuang/deeplearningsourceseparation"
"amaas/rnn-speech-denoising" -> "zhr1201/OMLSA-speech-enhancement"
"amaas/rnn-speech-denoising" -> "Perception-and-Neurodynamics-Laboratory/Matlab-toolbox-for-DNN-based-speech-separation"
"philipperemy/timit" -> "jtkim-kaist/Speech-enhancement"
"philipperemy/timit" -> "Faur/TIMIT"
"philipperemy/timit" -> "jzlianglu/pykaldi2" ["e"=1]
"philipperemy/timit" -> "fgnt/pb_bss"
"philipperemy/timit" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"philipperemy/timit" -> "HarryVolek/PyTorch_Speaker_Verification" ["e"=1]
"KimberleyJensen/Mel-Band-Roformer-Vocal-Model" -> "lucidrains/BS-RoFormer"
"KimberleyJensen/Mel-Band-Roformer-Vocal-Model" -> "ZFTurbo/Music-Source-Separation-Training"
"KimberleyJensen/Mel-Band-Roformer-Vocal-Model" -> "JusperLee/Apollo"
"kwatcharasupat/source-separation-landing" -> "kwatcharasupat/bandit-v2"
"axion66/minLSTM-implementation" -> "cheind/mingru"
"madebyollin/acapellabot" -> "laserb/deep-vocal-isolation"
"madebyollin/acapellabot" -> "MTG/DeepConvSep"
"stephencwelch/LearningToSee" -> "stephencwelch/Imaginary-Numbers-Are-Real"
"stephencwelch/LearningToSee" -> "stephencwelch/self_driving_cars"
"nanless/universal-speech-enhancement" -> "zelokuo/VPIDM"
"santi-pdp/segan" -> "santi-pdp/segan_pytorch"
"santi-pdp/segan" -> "yongxuUSTC/sednn"
"santi-pdp/segan" -> "drethage/speech-denoising-wavenet"
"santi-pdp/segan" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"santi-pdp/segan" -> "anicolson/DeepXi"
"santi-pdp/segan" -> "kaituoxu/Conv-TasNet"
"santi-pdp/segan" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"santi-pdp/segan" -> "leftthomas/SEGAN"
"santi-pdp/segan" -> "vbelz/Speech-enhancement"
"santi-pdp/segan" -> "seanwood/gcc-nmf"
"santi-pdp/segan" -> "yongxuUSTC/DNN-for-speech-enhancement"
"santi-pdp/segan" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"santi-pdp/segan" -> "jtkim-kaist/Speech-enhancement"
"santi-pdp/segan" -> "nanahou/Awesome-Speech-Enhancement"
"santi-pdp/segan" -> "aliutkus/speechmetrics"
"xiongyihui/tdoa" -> "wangwei2009/DOA"
"xiongyihui/tdoa" -> "xiaoli1368/Microphone-sound-source-localization"
"xiongyihui/tdoa" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"xiongyihui/tdoa" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"xiongyihui/tdoa" -> "aishoot/Sound_Localization_Algorithms"
"xiongyihui/tdoa" -> "fgnt/nn-gev"
"xiongyihui/tdoa" -> "robin1001/beamforming"
"xiongyihui/tdoa" -> "xanguera/BeamformIt"
"xiongyihui/tdoa" -> "seanwood/gcc-nmf"
"xiongyihui/tdoa" -> "jewhoguy/SRP-PHAT"
"xiongyihui/tdoa" -> "funcwj/CGMM-MVDR"
"xiongyihui/tdoa" -> "respeaker/mic_array"
"xiongyihui/tdoa" -> "snsun/cgmm_mvdr"
"xiongyihui/tdoa" -> "ZitengWang/MASP"
"linsir6/WebRTC-Voice" -> "linsir6/BaseDevelop"
"linsir6/WebRTC-Voice" -> "linsir6/MacNote"
"linsir6/WebRTC-Voice" -> "linsir6/JavaNote"
"linsir6/WebRTC-Voice" -> "linsir6/ReactNativeNote"
"linsir6/WebRTC-Voice" -> "linsir6/mCustomView"
"linsir6/WebRTC-Voice" -> "dotEngine/dotEngine-android-sdk-example"
"JusperLee/TIGER" -> "JusperLee/SonicSim"
"JusperLee/TIGER" -> "JusperLee/SPMamba"
"JusperLee/TIGER" -> "Andong-Li-speech/Neural-Vocoders-as-Speech-Enhancers"
"JusperLee/TIGER" -> "Audio-WestlakeU/RealMAN"
"JusperLee/TIGER" -> "Xiaobin-Rong/gtcrn"
"JusperLee/TIGER" -> "wenet-e2e/wesep"
"yhthu/intercom" -> "cyz7758520/Android_audio_talkback_demo_program"
"yhthu/intercom" -> "mars-ma/CallMe"
"HoerTech-gGmbH/openMHA" -> "m-r-s/hearingaid-prototype"
"HoerTech-gGmbH/openMHA" -> "Tympan/Tympan_Library"
"HoerTech-gGmbH/openMHA" -> "BoysTownOrg/chapro"
"HoerTech-gGmbH/openMHA" -> "Mathilda11/Speech-processing" ["e"=1]
"HoerTech-gGmbH/openMHA" -> "audioplastic/BioAid"
"HoerTech-gGmbH/openMHA" -> "chenwj1989/python_howling_suppression" ["e"=1]
"HoerTech-gGmbH/openMHA" -> "claritychallenge/clarity"
"HoerTech-gGmbH/openMHA" -> "cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement"
"HoerTech-gGmbH/openMHA" -> "microsoft/AEC-Challenge"
"HoerTech-gGmbH/openMHA" -> "dhimnsen/OpenSpeechPlatform-UCSD"
"HoerTech-gGmbH/openMHA" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"HoerTech-gGmbH/openMHA" -> "robin1001/beamforming"
"HoerTech-gGmbH/openMHA" -> "claritychallenge/clarity_CC"
"Tympan/Tympan_Library" -> "m-r-s/hearingaid-prototype"
"Tympan/Tympan_Library" -> "BoysTownOrg/chapro"
"Tympan/Tympan_Library" -> "HoerTech-gGmbH/openMHA"
"Tympan/Tympan_Library" -> "Tympan/Tympan_Rev_D_Hardware"
"Tympan/Tympan_Library" -> "chipaudette/OpenAudio_ArduinoLibrary"
"vsubhashini/ica" -> "openBliSSART/openBliSSART"
"vsubhashini/ica" -> "XianruiWang/FastICA"
"vsubhashini/ica" -> "robical/BlindSourceSeparation"
"vsubhashini/ica" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"vsubhashini/ica" -> "alvarouc/ica"
"SiavashShams/ssamba" -> "xi-j/Mamba-ASR"
"SiavashShams/ssamba" -> "xi-j/Mamba-TasNet"
"SiavashShams/ssamba" -> "RoyChao19477/SEMamba"
"xiongyihui/python-webrtc-audio-processing" -> "xiongyihui/speexdsp-python"
"xiongyihui/python-webrtc-audio-processing" -> "YangangCao/WebRTC-3A1V"
"xiongyihui/python-webrtc-audio-processing" -> "wavesaudio/Speex-AEC-matlab"
"xiongyihui/python-webrtc-audio-processing" -> "athena-team/athena-signal"
"xiongyihui/python-webrtc-audio-processing" -> "kkumatani/distant_speech_recognition"
"JusperLee/Apollo" -> "jarredou/Apollo-Colab-Inference"
"JusperLee/Apollo" -> "JusperLee/SPMamba"
"JusperLee/Apollo" -> "JusperLee/SonicSim"
"JusperLee/Apollo" -> "starrytong/SCNet"
"JusperLee/Apollo" -> "JusperLee/TDANet"
"JusperLee/Apollo" -> "jakeoneijk/FlashSR_Inference"
"JusperLee/Apollo" -> "eloimoliner/BABE2-music-restoration"
"JusperLee/Apollo" -> "lucidrains/BS-RoFormer"
"JusperLee/Apollo" -> "jarredou/AudioSR-Colab-Fork"
"JusperLee/Apollo" -> "urgent-challenge/urgent2024_challenge"
"JusperLee/Apollo" -> "ZFTurbo/Music-Source-Separation-Training"
"kwatcharasupat/bandit-v2" -> "kwatcharasupat/source-separation-landing"
"kwatcharasupat/bandit-v2" -> "kwatcharasupat/bandit"
"kaistmm/Audio-Mamba-AuM" -> "JiuFengSC/ElasticAST"
"kaistmm/Audio-Mamba-AuM" -> "SiavashShams/ssamba"
"kaistmm/Audio-Mamba-AuM" -> "SarthakYadav/audio-mamba-official"
"hyyan2k/LiSenNet" -> "gitwukeyi/FSPEN"
"line/open-universe" -> "zelokuo/VPIDM"
"line/open-universe" -> "urgent-challenge/urgent2024_challenge"
"xi-j/Mamba-ASR" -> "xi-j/Mamba-TasNet"
"xi-j/Mamba-ASR" -> "SiavashShams/ssamba"
"chentuochao/Target-Conversation-Extraction" -> "wyw97/DENSE"
"wenet-e2e/wesep" -> "HaoFengyuan/X-TF-GridNet"
"wenet-e2e/wesep" -> "JusperLee/SPMamba"
"wenet-e2e/wesep" -> "Beilong-Tang/TSELM"
"urgent-challenge/urgent2025_challenge" -> "Andong-Li-speech/Neural-Vocoders-as-Speech-Enhancers"
"AucFang/ZJU-ISEE-byAucFang" -> "l2h4/ZJU-ISEE"
"linksense/NNAEC-NeuralNetworkbasedAcousticEchoCancellation" -> "CharlesThaCat/acoustic-interference-cancellation"
"xiongyihui/speexdsp-python" -> "wavesaudio/Speex-AEC-matlab"
"xiongyihui/speexdsp-python" -> "xiongyihui/python-webrtc-audio-processing"
"xiongyihui/speexdsp-python" -> "ramon-astudillo/stft_up_tools"
"xiongyihui/speexdsp-python" -> "Spritea/AEC"
"jarredou/Apollo-Colab-Inference" -> "jarredou/AudioSR-Colab-Fork"
"jakeoneijk/FlashSR_Inference" -> "chomeyama/DualCycleGAN"
"xiph/rnnoise" -> "microsoft/DNS-Challenge"
"xiph/rnnoise" -> "werman/noise-suppression-for-voice" ["e"=1]
"xiph/rnnoise" -> "Rikorose/DeepFilterNet"
"xiph/rnnoise" -> "WenzheLiu-Speech/awesome-speech-enhancement"
"xiph/rnnoise" -> "breizhn/DTLN"
"xiph/rnnoise" -> "jzi040941/PercepNet"
"xiph/rnnoise" -> "facebookresearch/denoiser"
"xiph/rnnoise" -> "LCAV/pyroomacoustics"
"xiph/rnnoise" -> "athena-team/athena-signal"
"xiph/rnnoise" -> "asteroid-team/asteroid"
"xiph/rnnoise" -> "xiph/LPCNet" ["e"=1]
"xiph/rnnoise" -> "santi-pdp/segan"
"xiph/rnnoise" -> "microsoft/AEC-Challenge"
"xiph/rnnoise" -> "drethage/speech-denoising-wavenet"
"xiph/rnnoise" -> "xiph/speexdsp"
"respeaker/avs" -> "respeaker/get_started_with_respeaker"
"respeaker/avs" -> "voice-engine/voice-engine"
"respeaker/avs" -> "respeaker/4mics_hat"
"respeaker/avs" -> "alexa-pi/AlexaPi" ["e"=1]
"introlab/odas" -> "introlab/odas_web"
"introlab/odas" -> "respeaker/mic_array"
"introlab/odas" -> "introlab/manyears"
"introlab/odas" -> "aishoot/Sound_Localization_Algorithms"
"introlab/odas" -> "LCAV/pyroomacoustics"
"introlab/odas" -> "xanguera/BeamformIt"
"introlab/odas" -> "acoular/acoular"
"introlab/odas" -> "athena-team/athena-signal"
"introlab/odas" -> "wangwei2009/DOA"
"introlab/odas" -> "WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation"
"introlab/odas" -> "ZitengWang/MASP"
"introlab/odas" -> "funcwj/setk"
"introlab/odas" -> "seanwood/gcc-nmf"
"introlab/odas" -> "respeaker/usb_4_mic_array"
"introlab/odas" -> "xiongyihui/tdoa"
"ZhihaoDU/speech_feature_extractor" -> "zhr1201/Multi-channel-speech-extraction-using-DNN"
"ZhihaoDU/speech_feature_extractor" -> "bingo-todd/Gammatone-filters"
"ZhihaoDU/speech_feature_extractor" -> "aishoot/Speech_Feature_Extraction"
"zhr1201/deep-clustering" -> "funcwj/deep-clustering"
"zhr1201/deep-clustering" -> "jcsilva/deep-clustering"
"zhr1201/deep-clustering" -> "khaotik/DaNet-Tensorflow"
"zhr1201/deep-clustering" -> "snsun/pit-speech-separation"
"zhr1201/deep-clustering" -> "aishoot/LSTM_PIT_Speech_Separation"
"zhr1201/deep-clustering" -> "naplab/DANet"
"zhr1201/deep-clustering" -> "Unisound/SpeechSeparation"
"zhr1201/deep-clustering" -> "simonsuthers/Speech-Separation"
"respeaker/seeed-voicecard" -> "respeaker/mic_hat"
"respeaker/seeed-voicecard" -> "respeaker/mic_array"
"respeaker/seeed-voicecard" -> "HinTak/seeed-voicecard"
"respeaker/seeed-voicecard" -> "voice-engine/voice-engine"
"respeaker/seeed-voicecard" -> "respeaker/4mics_hat"
"respeaker/seeed-voicecard" -> "voice-engine/ec"
"respeaker/seeed-voicecard" -> "SeeedDocument/ReSpeaker-4-Mic-Array-for-Raspberry-Pi"
"respeaker/seeed-voicecard" -> "waveshareteam/WM8960-Audio-HAT"
"respeaker/seeed-voicecard" -> "respeaker/avs"
"respeaker/seeed-voicecard" -> "respeaker/respeaker_python_library"
"respeaker/seeed-voicecard" -> "respeaker/get_started_with_respeaker"
"respeaker/seeed-voicecard" -> "respeaker/pixel_ring"
"respeaker/seeed-voicecard" -> "introlab/odas"
"respeaker/seeed-voicecard" -> "voice-engine/make-a-smart-speaker"
"respeaker/seeed-voicecard" -> "introlab/odas_web"
"dotEngine/dotEngine-android-sdk-example" -> "linsir6/WebRTC-Voice"
"andabi/music-source-separation" -> "MTG/DeepConvSep"
"andabi/music-source-separation" -> "hjkwon0609/source_separation_ml_jeju"
"andabi/music-source-separation" -> "francesclluis/source-separation-wavenet"
"andabi/music-source-separation" -> "posenhuang/deeplearningsourceseparation"
"andabi/music-source-separation" -> "Js-Mim/mss_pytorch"
"andabi/music-source-separation" -> "f90/Wave-U-Net"
"andabi/music-source-separation" -> "aishoot/LSTM_PIT_Speech_Separation"
"andabi/music-source-separation" -> "sigsep/open-unmix-pytorch"
"andabi/music-source-separation" -> "drethage/speech-denoising-wavenet"
"andabi/music-source-separation" -> "sungheonpark/music_source_sepearation_SH_net"
"andabi/music-source-separation" -> "nussl/nussl"
"andabi/music-source-separation" -> "leimao/Singing-Voice-Separation-RNN"
"andabi/music-source-separation" -> "santi-pdp/segan"
"andabi/music-source-separation" -> "zhr1201/deep-clustering"
"andabi/music-source-separation" -> "madebyollin/acapellabot"
"drethage/speech-denoising-wavenet" -> "santi-pdp/segan"
"drethage/speech-denoising-wavenet" -> "francoisgermain/SpeechDenoisingWithDeepFeatureLosses"
"drethage/speech-denoising-wavenet" -> "santi-pdp/segan_pytorch"
"drethage/speech-denoising-wavenet" -> "yongxuUSTC/sednn"
"drethage/speech-denoising-wavenet" -> "vbelz/Speech-enhancement"
"drethage/speech-denoising-wavenet" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"drethage/speech-denoising-wavenet" -> "anicolson/DeepXi"
"drethage/speech-denoising-wavenet" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"drethage/speech-denoising-wavenet" -> "craigmacartney/Wave-U-Net-For-Speech-Enhancement"
"drethage/speech-denoising-wavenet" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"drethage/speech-denoising-wavenet" -> "vBaiCai/python-pesq"
"drethage/speech-denoising-wavenet" -> "auspicious3000/WaveNet-Enhancement"
"drethage/speech-denoising-wavenet" -> "nanahou/Awesome-Speech-Enhancement"
"drethage/speech-denoising-wavenet" -> "seanwood/gcc-nmf"
"drethage/speech-denoising-wavenet" -> "huyanxin/phasen"
"ChihebTrabelsi/deep_complex_networks" -> "wavefrontshaping/complexPyTorch"
"ChihebTrabelsi/deep_complex_networks" -> "litcoderr/ComplexCNN"
"ChihebTrabelsi/deep_complex_networks" -> "JesperDramsch/keras-complex"
"ChihebTrabelsi/deep_complex_networks" -> "NEGU93/cvnn"
"ChihebTrabelsi/deep_complex_networks" -> "MRSRL/complex-networks-release"
"ChihebTrabelsi/deep_complex_networks" -> "ivannz/cplxmodule"
"ChihebTrabelsi/deep_complex_networks" -> "huyanxin/DeepComplexCRN"
"ChihebTrabelsi/deep_complex_networks" -> "zhongyuanzhao/dl_ofdm" ["e"=1]
"ChihebTrabelsi/deep_complex_networks" -> "sweetcocoa/DeepComplexUNetPyTorch"
"ChihebTrabelsi/deep_complex_networks" -> "huyanxin/phasen"
"ChihebTrabelsi/deep_complex_networks" -> "maggie0830/DCCRN"
"ChihebTrabelsi/deep_complex_networks" -> "russellgeum/Deep-Complex-Networks"
"ChihebTrabelsi/deep_complex_networks" -> "js3611/Deep-MRI-Reconstruction" ["e"=1]
"ChihebTrabelsi/deep_complex_networks" -> "kaituoxu/Conv-TasNet"
"ChihebTrabelsi/deep_complex_networks" -> "CedricChing/DeepMRI" ["e"=1]
"linsir6/webRTC-android-demo-and-Server" -> "linsir6/WebRTC-Voice"
"linsir6/webRTC-android-demo-and-Server" -> "linsir6/BaseDevelop"
"fgnt/pb_bss" -> "funcwj/setk"
"fgnt/pb_bss" -> "fgnt/nn-gev"
"fgnt/pb_bss" -> "fgnt/nara_wpe"
"fgnt/pb_bss" -> "sekiguchi92/SoundSourceSeparation"
"fgnt/pb_bss" -> "fgnt/pb_chime5"
"fgnt/pb_bss" -> "fakufaku/torchiva"
"fgnt/pb_bss" -> "TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques"
"fgnt/pb_bss" -> "nttcslab-sp/dnn_wpe"
"fgnt/pb_bss" -> "ZitengWang/MASP"
"fgnt/pb_bss" -> "fakufaku/fast_bss_eval"
"fgnt/pb_bss" -> "seanwood/gcc-nmf"
"fgnt/pb_bss" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"fgnt/pb_bss" -> "fgnt/sms_wsj"
"fgnt/pb_bss" -> "ehabets/RIR-Generator"
"fgnt/pb_bss" -> "funcwj/CGMM-MVDR"
"ASLP-lab/LLaSE-G1" -> "ASLP-lab/C2SER"
"ASLP-lab/LLaSE-G1" -> "Kevin-naticl/LLaSE-G1"
"wangshub/python-vad" -> "marsbroshok/VAD-python"
"wangshub/python-vad" -> "mounalab/LSTM-RNN-VAD"
"wangshub/python-vad" -> "mwv/vad"
"wangshub/python-vad" -> "filippogiruzzi/voice_activity_detection"
"wangshub/python-vad" -> "mindorii/kws" ["e"=1]
"wangshub/python-vad" -> "Cocoxili/VAD"
"wangshub/python-vad" -> "hcmlab/vadnet"
"wangshub/python-vad" -> "YorLife/webRTC-"
"wangshub/python-vad" -> "eesungkim/Voice_Activity_Detector"
"auspicious3000/WaveNet-Enhancement" -> "auspicious3000/deepbeam"
"auspicious3000/WaveNet-Enhancement" -> "zhr1201/CNN-for-single-channel-speech-enhancement"
"auspicious3000/WaveNet-Enhancement" -> "fotisdr/aecnn-rpi"
"respeaker/mic_array" -> "introlab/odas"
"respeaker/mic_array" -> "respeaker/seeed-voicecard"
"respeaker/mic_array" -> "voice-engine/voice-engine"
"respeaker/mic_array" -> "xiongyihui/tdoa"
"respeaker/mic_array" -> "voice-engine/ec"
"respeaker/mic_array" -> "robin1001/beamforming"
"respeaker/mic_array" -> "wangwei2009/DOA"
"respeaker/mic_array" -> "respeaker/usb_4_mic_array"
"respeaker/mic_array" -> "AkojimaSLP/Beamforming-for-speech-enhancement"
"respeaker/mic_array" -> "funcwj/CGMM-MVDR"
"respeaker/mic_array" -> "xanguera/BeamformIt"
"respeaker/mic_array" -> "acoular/acoular"
"respeaker/mic_array" -> "LCAV/FRIDA"
"respeaker/mic_array" -> "respeaker/respeaker_python_library"
"respeaker/mic_array" -> "respeaker/respeaker_for_raspberrypi"
"zhr1201/OMLSA-speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"jaideeppatel/Training-Targets-for-Speech-Separation-Neural-Networks" -> "Unisound/SpeechSeparation"
"yump/doamusic" -> "amjadsaadeh/pyMUSIC"
"yump/doamusic" -> "dengjunquan/DoA-Estimation-MUSIC-ESPRIT"
"respeaker/mic_hat" -> "respeaker/seeed-voicecard"
"wangwei2009/spatial-temporal-LCMV" -> "Tungluai/RTF-based-LCMV-GSC"
"wangwei2009/spatial-temporal-LCMV" -> "wangwei2009/Microphone-Array-postfilter"
"gionanide/Cryptography" -> "gionanide/OpiRec"
"gionanide/Cryptography" -> "gionanide/Neural_Machine_Translation"
"loehnertz/rattlesnake" -> "stephencwelch/Active-Noise-Cancellation"
"Kevin-naticl/LLaSE-G1" -> "ASLP-lab/LLaSE-G1"
"Kevin-naticl/LLaSE-G1" -> "Beilong-Tang/TSELM"
"khaotik/DaNet-Tensorflow" -> "snsun/pit-speech-separation"
"khaotik/DaNet-Tensorflow" -> "zhr1201/deep-clustering"
"khaotik/DaNet-Tensorflow" -> "Unisound/SpeechSeparation"
"khaotik/DaNet-Tensorflow" -> "naplab/DANet"
"khaotik/DaNet-Tensorflow" -> "funcwj/deep-clustering"
"khaotik/DaNet-Tensorflow" -> "Totoketchup/Adaptive-MultiSpeaker-Separation"
"khaotik/DaNet-Tensorflow" -> "simonsuthers/Speech-Separation"
"khaotik/DaNet-Tensorflow" -> "jcsilva/deep-clustering"
"linsir6/BaseDevelop" -> "linsir6/WebRTC-Voice"
"linsir6/BaseDevelop" -> "linsir6/MacNote"
"linsir6/BaseDevelop" -> "linsir6/JavaNote"
"linsir6/BaseDevelop" -> "linsir6/ReactNativeNote"
"snsun/pit-speech-separation" -> "Unisound/SpeechSeparation"
"snsun/pit-speech-separation" -> "khaotik/DaNet-Tensorflow"
"snsun/pit-speech-separation" -> "funcwj/uPIT-for-speech-separation"
"snsun/pit-speech-separation" -> "aishoot/LSTM_PIT_Speech_Separation"
"snsun/pit-speech-separation" -> "funcwj/deep-clustering"
"snsun/pit-speech-separation" -> "zhr1201/deep-clustering"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "eesungkim/Speech_Enhancement_DNN_NMF"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/sednn"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "hyli666/DNN-SpeechEnhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "jtkim-kaist/Speech-enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "linan2/TensorFlow-speech-enhancement-Chinese"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "santi-pdp/segan"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "auspicious3000/WaveNet-Enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/DNN-Speech-enhancement-demo-tool"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "jonlu0602/DeepDenoisingAutoencoder"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "anicolson/DeepXi"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "yongxuUSTC/DNN-for-speech-enhancement"
"zhr1201/CNN-for-single-channel-speech-enhancement" -> "JasonSWFu/MetricGAN"
"ASLP-lab/C2SER" -> "ASLP-lab/LLaSE-G1"
"zhr1201/Multi-channel-speech-extraction-using-DNN" -> "auspicious3000/deepbeam"
"zhr1201/Multi-channel-speech-extraction-using-DNN" -> "snsun/cgmm_mvdr"
"linsir6/JavaNote" -> "linsir6/ReactNativeNote"
"linsir6/JavaNote" -> "linsir6/MacNote"
"linsir6/JavaNote" -> "linsir6/BaseDevelop"
"nihospr01/OpenSpeechPlatform-2020B" -> "dhimnsen/OpenSpeechPlatform-UCSD"
"linsir6/IOSNote" -> "linsir6/ReactNativeNote"
"Unisound/SpeechSeparation" -> "snsun/pit-speech-separation"
"Unisound/SpeechSeparation" -> "jaideeppatel/Training-Targets-for-Speech-Separation-Neural-Networks"
"yongxuUSTC/DNN-Speech-enhancement-demo-tool" -> "yongxuUSTC/DNN-for-speech-enhancement"
"linsir6/ReactNativeNote" -> "linsir6/MacNote"
"linsir6/ReactNativeNote" -> "linsir6/mCustomView"
"linsir6/ReactNativeNote" -> "linsir6/JavaNote"
"linsir6/mCustomView" -> "linsir6/ReactNativeNote"
"linsir6/mCustomView" -> "linsir6/MacNote"
"aishoot/Sound_Localization_Algorithms" ["l"="36.852,4.493"]
"WenzheLiu-Speech/sound-source-localization-algorithm_DOA_estimation" ["l"="36.879,4.514"]
"xiaoli1368/Microphone-sound-source-localization" ["l"="36.899,4.544"]
"ZitengWang/MASP" ["l"="36.843,4.466"]
"jorgengrythe/beamforming" ["l"="36.868,4.498"]
"AkojimaSLP/Beamforming-for-speech-enhancement" ["l"="36.819,4.455"]
"wangwei2009/DOA" ["l"="36.894,4.53"]
"xanguera/BeamformIt" ["l"="36.816,4.472"]
"huangzhenyu/beamforming" ["l"="36.852,4.476"]
"xiongyihui/tdoa" ["l"="36.849,4.521"]
"kkumatani/distant_speech_recognition" ["l"="36.839,4.486"]
"XiaoxiangGao/Dual_Channel_Beamformer_and_Postfilter" ["l"="36.835,4.53"]
"LCAV/pyroomacoustics" ["l"="36.815,4.416"]
"chenwj1989/Beamforming_Examples" ["l"="36.829,4.518"]
"athena-team/athena-signal" ["l"="36.848,4.445"]
"funcwj/setk" ["l"="36.764,4.443"]
"introlab/manyears" ["l"="36.836,4.546"]
"ishaaniwani/GCC-PHAT-SSL" ["l"="36.936,4.569"]
"LeeTaewoo/fast_sound_source_localization_using_TLSSC" ["l"="36.92,4.569"]
"sindhurach94/Sound-source-localization" ["l"="36.947,4.607"]
"polarch/Spherical-Array-Processing" ["l"="38.492,5.894"]
"BrownsugarZeer/Multi_SSL" ["l"="36.924,4.45"]
"morriswmz/doa-tools" ["l"="36.968,4.582"]
"marsyas/marsyas" ["l"="36.322,4.583"]
"Yaafe/Yaafe" ["l"="36.257,4.617"]
"CPJKU/madmom" ["l"="38.516,4.112"]
"MTG/gaia" ["l"="36.434,4.527"]
"WenzheLiu-Speech/awesome-speech-enhancement" ["l"="36.75,4.357"]
"seanwood/gcc-nmf" ["l"="36.751,4.483"]
"Ryuk17/SpeechAlgorithms" ["l"="36.784,4.4"]
"xuchenglin28/WSCM-MUSIC" ["l"="36.96,4.566"]
"KyleZhang1118/Voice-Separation-and-Enhancement" ["l"="36.816,4.537"]
"kaituoxu/Conv-TasNet" ["l"="36.668,4.373"]
"naplab/Conv-TasNet" ["l"="36.697,4.359"]
"JusperLee/Conv-TasNet" ["l"="36.666,4.32"]
"funcwj/conv-tasnet" ["l"="36.68,4.4"]
"JusperLee/Dual-Path-RNN-Pytorch" ["l"="36.666,4.349"]
"JusperLee/Speech-Separation-Paper-Tutorial" ["l"="36.707,4.346"]
"yluo42/TAC" ["l"="36.686,4.367"]
"asteroid-team/asteroid" ["l"="36.723,4.312"]
"kaituoxu/TasNet" ["l"="36.614,4.435"]
"huyanxin/DeepComplexCRN" ["l"="36.723,4.35"]
"gemengtju/Tutorial_Separation" ["l"="36.682,4.343"]
"aishoot/LSTM_PIT_Speech_Separation" ["l"="36.634,4.45"]
"Audio-WestlakeU/FullSubNet" ["l"="36.726,4.333"]
"maum-ai/voicefilter" ["l"="36.642,4.325"]
"ShiZiqiang/dual-path-RNNs-DPRNNs-based-speech-separation" ["l"="36.652,4.38"]
"microsoft/DNS-Challenge" ["l"="36.768,4.346"]
"YangangCao/WebRTC-3A1V" ["l"="36.967,4.472"]
"xiaochunxin/OMLSA-MCRA" ["l"="37.012,4.534"]
"cpuimage/WebRTC_AGC" ["l"="36.96,4.455"]
"ewan-xu/AEC3" ["l"="36.909,4.431"]
"cpuimage/WebRTC_AECM" ["l"="36.994,4.448"]
"DoubangoTelecom/webrtc-audioproc" ["l"="37.019,4.489"]
"lbcgi/webrtc_agc_matlab" ["l"="37.038,4.491"]
"ludlows/PESQ" ["l"="36.792,4.33"]
"mpariente/pystoi" ["l"="36.775,4.327"]
"vBaiCai/python-pesq" ["l"="36.748,4.4"]
"aliutkus/speechmetrics" ["l"="36.784,4.347"]
"schmiph2/pysepm" ["l"="36.743,4.342"]
"google/visqol" ["l"="36.824,4.303"]
"gabrielmittag/NISQA" ["l"="36.816,4.284"]
"DavidDiazGuerra/gpuRIR" ["l"="36.758,4.378"]
"microsoft/MS-SNSD" ["l"="36.768,4.364"]
"jzi040941/PercepNet" ["l"="36.788,4.363"]
"pseeth/torch-stft" ["l"="36.707,4.39"]
"huyanxin/phasen" ["l"="36.7,4.375"]
"KinWaiCheuk/nnAudio" ["l"="38.518,4.05"]
"facebookresearch/WavAugment" ["l"="38.519,3.981"]
"speechLabBcCuny/onssen" ["l"="36.659,4.421"]
"mpariente/pytorch_stoi" ["l"="36.761,4.291"]
"ConferencingSpeech/ConferencingSpeech2021" ["l"="36.767,4.409"]
"Akki369/Generalised-Side-Lobe-Canceller" ["l"="36.855,4.572"]
"satyanamuduri/Speech-Enhancement-Using-GSC" ["l"="36.839,4.576"]
"jgarciagimenez/GSC_beamforming" ["l"="36.845,4.561"]
"dengjunquan/DoA-Estimation-MUSIC-ESPRIT" ["l"="37.038,4.619"]
"morriswmz/doatools.py" ["l"="37.015,4.6"]
"yump/doamusic" ["l"="37.066,4.635"]
"msamsami/doa-estimation-music" ["l"="36.998,4.596"]
"LahiruJayasinghe/DeepDOA" ["l"="37.055,4.609"]
"GAMMA-UMD/doa-release" ["l"="37.079,4.604"]
"vslobody/MUSIC" ["l"="37.084,4.665"]
"Navigine/Direction-of-Arrival-DoA-Estimation-Algorithm" ["l"="53.633,5.039"]
"scivision/signal_subspace" ["l"="37.083,4.644"]
"lewsilver/radar_doa" ["l"="37.05,4.651"]
"shichaog/WebRTC-audio-processing" ["l"="36.868,4.429"]
"microsoft/AEC-Challenge" ["l"="36.838,4.392"]
"wavesaudio/Speex-AEC-matlab" ["l"="36.919,4.465"]
"shichaog/RNNAec" ["l"="36.941,4.387"]
"robin1001/beamforming" ["l"="36.866,4.477"]
"ewan-xu/pyaec" ["l"="36.855,4.416"]
"anicolson/DeepXi" ["l"="36.74,4.412"]
"fjiang9/NKF-AEC" ["l"="36.839,4.373"]
"santi-pdp/segan_pytorch" ["l"="36.695,4.425"]
"fgnt/nara_wpe" ["l"="36.79,4.435"]
"craigmacartney/Wave-U-Net-For-Speech-Enhancement" ["l"="36.68,4.429"]
"haoxiangsnr/A-Convolutional-Recurrent-Neural-Network-for-Real-Time-Speech-Enhancement" ["l"="36.712,4.408"]
"haoxiangsnr/IRM-based-Speech-Enhancement-using-LSTM" ["l"="36.685,4.449"]
"JasonSWFu/MetricGAN" ["l"="36.662,4.477"]
"ehabets/RIR-Generator" ["l"="36.798,4.411"]
"tsurumeso/vocal-remover" ["l"="36.736,4.056"]
"Anjok07/ultimatevocalremovergui" ["l"="38.314,1.524"]
"nomadkaraoke/python-audio-separator" ["l"="36.785,4.011"]
"ZFTurbo/MVSEP-MDX23-music-separation-model" ["l"="36.758,4.033"]
"haoheliu/voicefixer" ["l"="36.768,4.203"]
"facebookresearch/demucs" ["l"="36.658,4.094"]
"ZFTurbo/Music-Source-Separation-Training" ["l"="36.767,4.08"]
"kuielab/mdx-net" ["l"="36.713,3.94"]
"kuielab/mdx-net-submission" ["l"="36.727,3.902"]
"resemble-ai/resemble-enhance" ["l"="36.777,4.175"]
"sigsep/open-unmix-pytorch" ["l"="36.639,4.219"]
"adefossez/demucs" ["l"="36.703,4.073"]
"lucidrains/BS-RoFormer" ["l"="36.753,4.097"]
"NaJeongMo/Colaboratory-Notebook-for-Ultimate-Vocal-Remover" ["l"="36.717,3.963"]
"Rikorose/DeepFilterNet" ["l"="36.792,4.257"]
"jarredou/MVSEP-MDX23-Colab_v2" ["l"="36.754,4.014"]
"voice-engine/make-a-smart-speaker" ["l"="36.866,4.52"]
"voice-engine/ec" ["l"="36.916,4.527"]
"mindorii/kws" ["l"="35.587,2.449"]
"respeaker/mic_array" ["l"="36.882,4.562"]
"fgnt/nn-gev" ["l"="36.782,4.456"]
"voice-engine/voice-engine" ["l"="36.906,4.587"]
"colinsongf/keyword_spotting" ["l"="35.569,2.496"]
"introlab/odas" ["l"="36.858,4.541"]
"funcwj/CGMM-MVDR" ["l"="36.797,4.487"]
"xiongyihui/python-webrtc-audio-processing" ["l"="36.899,4.49"]
"f90/Wave-U-Net" ["l"="36.634,4.374"]
"sigsep/sigsep-mus-db" ["l"="36.594,4.228"]
"sigsep/sigsep-mus-eval" ["l"="36.621,4.271"]
"bytedance/music_source_separation" ["l"="36.733,4.206"]
"csteinmetz1/auraloss" ["l"="38.618,4.005"]
"nussl/nussl" ["l"="36.642,4.428"]
"sigsep/norbert" ["l"="36.583,4.04"]
"f90/Wave-U-Net-Pytorch" ["l"="36.653,4.357"]
"magenta/ddsp" ["l"="38.563,4.061"]
"marl/crepe" ["l"="38.562,4.111"]
"francesclluis/source-separation-wavenet" ["l"="36.546,4.378"]
"cyz7758520/Android_audio_talkback_demo_program" ["l"="37.267,4.513"]
"cyz7758520/Windows_audio_talkback_demo_program" ["l"="37.29,4.534"]
"yhthu/intercom" ["l"="37.369,4.559"]
"theeasiestway/android-webrtc-aecm" ["l"="37.327,4.481"]
"mail2chromium/Android-Audio-Processing-Using-WebRTC" ["l"="37.308,4.51"]
"waterfoxfox/Audio3AProcess" ["l"="37.274,4.544"]
"xia-chu/webrtc_apm" ["l"="37.14,4.474"]
"shenbengit/WebRTCExtension" ["l"="37.374,4.508"]
"bastamon/sound_signal_process-matlab-" ["l"="36.741,4.751"]
"busyyang/python_sound_open" ["l"="36.791,4.52"]
"JackHCC/Audio-Digital-Processing" ["l"="36.727,4.854"]
"veenveenveen/SpeechSignalProcessingCourse" ["l"="36.723,4.815"]
"taw19960426/-Speech-signal-processing-experiment-tutorial-_python" ["l"="36.73,4.789"]
"PandoraLS/traditional-speech-enhancement" ["l"="36.79,4.645"]
"peak1995/Speech-enhancement-dsp" ["l"="36.767,4.723"]
"ivannz/cplxmodule" ["l"="36.454,4.357"]
"MRSRL/complex-networks-release" ["l"="36.428,4.363"]
"zhaoymn/cubelearn" ["l"="36.408,4.347"]
"wavefrontshaping/complexPyTorch" ["l"="36.479,4.354"]
"JesperDramsch/keras-complex" ["l"="36.452,4.38"]
"ChihebTrabelsi/deep_complex_networks" ["l"="36.515,4.368"]
"litcoderr/ComplexCNN" ["l"="36.486,4.378"]
"NEGU93/cvnn" ["l"="36.418,4.384"]
"sweetcocoa/DeepComplexUNetPyTorch" ["l"="36.57,4.373"]
"omrijsharon/torchlex" ["l"="36.432,4.336"]
"williamFalcon/pytorch-complex-tensor" ["l"="36.401,4.327"]
"mmuckley/torchkbnufft" ["l"="-35.461,23.116"]
"computational-imaging/neural-holography" ["l"="34.125,-4.673"]
"XinyuanLiao/ComplexNN" ["l"="36.4,4.37"]
"mehdihosseinimoghadam/Complex-Neural-Networks" ["l"="36.444,4.319"]
"maggie0830/DCCRN" ["l"="36.662,4.334"]
"chanil1218/DCUnet.pytorch" ["l"="36.618,4.384"]
"AppleHolic/source_separation" ["l"="36.645,4.394"]
"russellgeum/Phase-aware-Deep-Complex-UNet" ["l"="36.503,4.395"]
"pheepa/DCUnet" ["l"="36.598,4.333"]
"Baidu-AIP/speech-vad-demo" ["l"="36.91,4.503"]
"cpuimage/WebRTC_VAD" ["l"="36.979,4.476"]
"dpirch/libfvad" ["l"="36.886,4.472"]
"cpuimage/WebRTC_NS" ["l"="36.992,4.472"]
"xiangxyq/kaldi" ["l"="35.654,2.48"]
"open-speech/speech-aligner" ["l"="37.336,2.384"]
"robin1001/nn-vad" ["l"="36.955,4.546"]
"ZhengkunTian/OpenTransformer" ["l"="35.708,2.299"]
"jtkim-kaist/VAD" ["l"="36.765,4.511"]
"marsbroshok/VAD-python" ["l"="36.774,4.545"]
"funcwj/cgmm-mask-estimator" ["l"="36.825,4.491"]
"XiaoMi/kaldi-onnx" ["l"="35.702,2.408"]
"cpuimage/rnnoise" ["l"="36.975,4.455"]
"cpuimage/WebRTC_NS_CPP" ["l"="37.008,4.449"]
"cpuimage/SimpleAudioDenoise" ["l"="37.021,4.456"]
"cpuimage/resampler" ["l"="37.002,4.46"]
"jagger2048/WebRtc_noise_suppression" ["l"="37.06,4.484"]
"cpuimage/FFTResampler" ["l"="37.016,4.472"]
"jagger2048/rnnoise-windows" ["l"="36.945,4.433"]
"garyyu/WebRTC_VoiceEngine" ["l"="37.042,4.513"]
"jagger2048/WebRtc_AGC1" ["l"="37.08,4.474"]
"TracyJichuan/webrtc_noise_suppression" ["l"="37.099,4.49"]
"XiaoxiangGao/Dual_mic_phase_based_speech_enhancement" ["l"="36.849,4.586"]
"wangwei2009/Microphone-Array-postfilter" ["l"="36.832,4.566"]
"wangwei2009/coherence" ["l"="36.841,4.599"]
"LiXirong/AdaptiveFilterandActiveNoiseCancellation" ["l"="37.049,4.438"]
"sandprddy/Active-Noise-Cancellation-System" ["l"="37.073,4.428"]
"markostam/active-noise-cancellation" ["l"="37.035,4.409"]
"YangangCao/AdaptiveFilter" ["l"="37.002,4.5"]
"mohitmewara/Noise-cancellation-LMS-adaptive-filter" ["l"="37.138,4.443"]
"SShirleyy/Adaptive-audio-filter-design" ["l"="37.106,4.443"]
"rohitner/adaptive-filters" ["l"="36.991,4.491"]
"xiezhq-hermann/ANC_signal-system_project" ["l"="37.066,4.408"]
"Spritea/AEC" ["l"="36.979,4.503"]
"Aketirani/active-noise-cancellation" ["l"="37.089,4.395"]
"psykulsk/RpiANC" ["l"="37.089,4.415"]
"fgnt/pb_bss" ["l"="36.741,4.457"]
"funcwj/aps" ["l"="36.661,4.401"]
"fgnt/pb_chime5" ["l"="36.764,4.466"]
"ujscjj/DPTNet" ["l"="36.631,4.36"]
"chenzhuo1011/libri_css" ["l"="36.641,4.343"]
"etzinis/two_step_mask_learning" ["l"="36.607,4.374"]
"Sato-Kunihiko/audio-SNR" ["l"="36.527,4.487"]
"lochenchou/MOSNet" ["l"="36.849,4.269"]
"NVIDIA/BigVGAN" ["l"="38.519,2.044"]
"sarulab-speech/UTMOS22" ["l"="38.293,2.18"]
"sp-uhh/sgmse" ["l"="36.741,4.258"]
"JasonSWFu/Quality-Net" ["l"="36.868,4.244"]
"facebookresearch/Noresqa" ["l"="36.89,4.23"]
"jik876/hifi-gan" ["l"="37.255,2.425"]
"tarepan/SpeechMOS" ["l"="38.374,2.097"]
"microsoft/P.808" ["l"="36.809,4.318"]
"detly/gammatone" ["l"="36.815,4.676"]
"bingo-todd/Gammatone-filters" ["l"="36.825,4.723"]
"ZhihaoDU/speech_feature_extractor" ["l"="36.808,4.699"]
"chenhui07c8/DOA-AOA-algorithms" ["l"="37.029,4.602"]
"Soumitro-Chakrabarty/Single-speaker-localization" ["l"="37.107,4.637"]
"petotamas/pyArgus" ["l"="53.708,5.049"]
"LCAV/FRIDA" ["l"="36.968,4.609"]
"sharathadavanne/doa-net" ["l"="37.094,4.617"]
"m2wagner/Alternating_Projections_Gridless_DOA_Estimation" ["l"="37.023,4.628"]
"ge99210/DeepNetworks-for-DoA-estimation-in-low-SNR" ["l"="37.049,4.592"]
"thesofproject/sof" ["l"="36.999,4.664"]
"thesofproject/linux" ["l"="37.074,4.767"]
"xiph/speexdsp" ["l"="36.9,4.452"]
"alsa-project/alsa-lib" ["l"="-19.22,-0.881"]
"thesofproject/sof-test" ["l"="37.019,4.695"]
"thesofproject/sof-docs" ["l"="37.012,4.709"]
"nxp-mcuxpresso/rpmsg-lite" ["l"="-17.864,-43.161"]
"foss-xtensa/nnlib-hifi4" ["l"="37.032,4.713"]
"google/liblc3" ["l"="-16.04,-43.753"]
"breizhn/DTLN-aec" ["l"="36.852,4.395"]
"respeaker/seeed-voicecard" ["l"="36.916,4.619"]
"xiongyihui/speexdsp-python" ["l"="36.943,4.48"]
"HinTak/seeed-voicecard" ["l"="36.936,4.59"]
"lschilli/wav-aec" ["l"="36.999,4.544"]
"Enny1991/beamformers" ["l"="36.726,4.383"]
"DistantSpeechRecognition/mcse" ["l"="36.811,4.489"]
"snsun/cgmm_mvdr" ["l"="36.798,4.507"]
"tencent-ailab/FRA-RIR" ["l"="36.748,4.319"]
"haoxiangsnr/SNR-Based-Progressive-Learning-of-Deep-Neural-Network-for-Speech-Enhancement" ["l"="36.622,4.531"]
"haoxiangsnr/Speech_Enhancement_Tools" ["l"="36.619,4.563"]
"TUIlmenauAMS/Comparison-of-Blind-Source-Separation-techniques" ["l"="36.683,4.589"]
"d-kitamura/ILRMA" ["l"="36.687,4.572"]
"d-kitamura/AuxIVA-ISS" ["l"="36.649,4.578"]
"XianruiWang/AuxIVA" ["l"="36.658,4.599"]
"AmitProspeed/LMS-Adaptive-Filter" ["l"="37.169,4.448"]
"runninging/TASNET" ["l"="36.577,4.459"]
"Moplast/TasNet-tensorflow" ["l"="36.568,4.452"]
"funcwj/uPIT-for-speech-separation" ["l"="36.601,4.46"]
"snsun/pit-speech-separation" ["l"="36.591,4.489"]
"jaideeppatel/Training-Targets-for-Speech-Separation-Neural-Networks" ["l"="36.564,4.481"]
"yujianyuanhaha/DoA-ML" ["l"="37.074,4.62"]
"TANG16/DAE4mulDOA" ["l"="37.049,4.631"]
"EthanLifeGreat/Mono_AEC" ["l"="36.984,4.537"]
"vaaiibhav/LMS-echo-cancellation" ["l"="37.031,4.532"]
"linksense/NNAEC-NeuralNetworkbasedAcousticEchoCancellation" ["l"="36.967,4.532"]
"haoxiangsnr/Wave-U-Net-for-Speech-Enhancement" ["l"="36.697,4.408"]
"vbelz/Speech-enhancement" ["l"="36.727,4.398"]
"nanahou/Awesome-Speech-Enhancement" ["l"="36.74,4.38"]
"eesungkim/Speech_Enhancement_DNN_NMF" ["l"="36.692,4.472"]
"yongxuUSTC/sednn" ["l"="36.716,4.46"]
"fudanxu/CV-CNN" ["l"="36,4.405"]
"liuxuvip/PolSF" ["l"="36.018,4.418"]
"PROoshio/CRPM-Net" ["l"="36.035,4.405"]
"Jowekk/SAR-Image-Recognition" ["l"="35.959,4.421"]
"NEGU93/polsar_cvnn" ["l"="36.081,4.405"]
"liuxuvip/Polarimetric-Scattering-Coding" ["l"="35.994,4.425"]
"Alien9427/XAI4SAR-PGIL" ["l"="35.939,4.395"]
"puru19962001/Automatic-Target-Classification-In-SAR-Images-Using-Convolutional-Neural-Networks" ["l"="35.911,4.429"]
"Shaunakde/deep-learning-polsar-book" ["l"="36.03,4.385"]
"Alien9427/SAR_specific_models" ["l"="35.881,4.39"]
"XAI4SAR/SAR-HUB" ["l"="35.862,4.378"]
"Alien9427/DSN" ["l"="35.885,4.364"]
"XAI4SAR/PIHA" ["l"="35.868,4.364"]
"naplab/DANet" ["l"="36.553,4.49"]
"funcwj/deep-clustering" ["l"="36.577,4.48"]
"khaotik/DaNet-Tensorflow" ["l"="36.558,4.511"]
"leftthomas/SEGAN" ["l"="36.659,4.448"]
"dansuh17/segan-pytorch" ["l"="36.611,4.479"]
"santi-pdp/segan" ["l"="36.707,4.44"]
"zhr1201/CNN-for-single-channel-speech-enhancement" ["l"="36.702,4.476"]
"Zihang97/PAGAN" ["l"="36.624,4.491"]
"plbossart/sound" ["l"="37.195,4.928"]
"MTG/DeepConvSep" ["l"="36.55,4.462"]
"andabi/music-source-separation" ["l"="36.57,4.431"]
"drethage/speech-denoising-wavenet" ["l"="36.723,4.428"]
"JesperDramsch/Complex-CNN-Seismic" ["l"="36.411,4.402"]
"russellgeum/Deep-Complex-Networks" ["l"="36.461,4.4"]
"lucianodato/speech-denoiser" ["l"="36.896,4.411"]
"lucianodato/noise-repellent" ["l"="38.675,5.409"]
"GregorR/rnnoise-nu" ["l"="36.93,4.428"]
"respeaker/pixel_ring" ["l"="36.885,4.638"]
"respeaker/usb_4_mic_array" ["l"="36.868,4.599"]
"furushchev/respeaker_ros" ["l"="36.863,4.644"]
"gionanide/Speech_Signal_Processing_and_Classification" ["l"="36.826,4.794"]
"aishoot/Speech_Feature_Extraction" ["l"="36.816,4.75"]
"gionanide/Neural_Machine_Translation" ["l"="36.839,4.843"]
"timsainb/noisereduce" ["l"="36.814,4.368"]
"facebookresearch/denoiser" ["l"="36.764,4.31"]
"xiph/rnnoise" ["l"="36.855,4.349"]
"wiseman/py-webrtcvad" ["l"="36.78,4.48"]
"breizhn/DTLN" ["l"="36.78,4.38"]
"iver56/audiomentations" ["l"="38.484,3.982"]
"snakers4/silero-vad" ["l"="40.53,3.28"]
"csteinmetz1/pyloudnorm" ["l"="36.843,4.319"]
"linan2/TensorFlow-speech-enhancement-Chinese" ["l"="36.68,4.507"]
"eesungkim/Speech_Enhancement_MMSE-STSA" ["l"="36.639,4.527"]
"yongxuUSTC/DNN-for-speech-enhancement" ["l"="36.702,4.491"]
"jtkim-kaist/Speech-enhancement" ["l"="36.734,4.481"]
"yongxuUSTC/DNN-Speech-enhancement-demo-tool" ["l"="36.714,4.522"]
"hyli666/DNN-SpeechEnhancement" ["l"="36.68,4.524"]
"jsingh811/pyAudioProcessing" ["l"="36.802,4.626"]
"SuperKogito/spafe" ["l"="36.798,4.546"]
"audiolabs/webMUSHRA" ["l"="36.852,4.293"]
"gemelo-ai/vocos" ["l"="38.493,2.01"]
"descriptinc/descript-audio-codec" ["l"="38.554,2.011"]
"pranaymanocha/PerceptualAudio" ["l"="38.535,3.947"]
"justinsalamon/scaper" ["l"="39.763,5.44"]
"asteroid-team/torch-audiomentations" ["l"="38.52,4.013"]
"hunterlew/mstar_with_machine_learning" ["l"="35.875,4.439"]
"cpuimage/AudioDenoise" ["l"="37.031,4.47"]
"YongyuG/rnnoise_16k" ["l"="36.92,4.412"]
"ouyangkk/speech_enhancement_rnnoise_mcra" ["l"="37.021,4.505"]
"introlab/odas_web" ["l"="36.875,4.621"]
"introlab/odas_ros" ["l"="36.87,4.676"]
"introlab/16SoundsUSB" ["l"="36.899,4.725"]
"respeaker/4mics_hat" ["l"="36.903,4.635"]
"JacobWang95/mWDN" ["l"="36.778,5.133"]
"yakouyang/Multilevel_Wavelet_Decomposition_Network_Pytorch" ["l"="36.777,5.107"]
"chenfei0328/mWDN-RCF" ["l"="36.795,5.131"]
"liuyox/AnomalyDetection.MWDN" ["l"="36.76,5.124"]
"5bentz/linux-asus-t100" ["l"="37.321,5.048"]
"jfwells/linux-asus-t100ta" ["l"="37.303,5.025"]
"AdamWill/baytrail-m" ["l"="37.289,5.047"]
"plbossart/UCM" ["l"="37.253,4.989"]
"hirotakaster/baytail-bootia32.efi" ["l"="37.358,5.024"]
"Asus-T100/kernel" ["l"="37.334,5.034"]
"hadess/rtl8723bs" ["l"="37.263,5.032"]
"sunits/rir_simulator_python" ["l"="36.87,4.395"]
"jonashaag/RealRIRs" ["l"="36.889,4.364"]
"RoyJames/room-impulse-responses" ["l"="36.798,4.381"]
"Audio-WestlakeU/NBSS" ["l"="36.721,4.291"]
"JorisCos/LibriMix" ["l"="36.685,4.319"]
"posenhuang/deeplearningsourceseparation" ["l"="36.645,4.491"]
"zhr1201/deep-clustering" ["l"="36.568,4.496"]
"tky823/DNN-based_source_separation" ["l"="36.675,4.361"]
"jdonley/SoundZone_Tools" ["l"="38.656,6.111"]
"auspicious3000/WaveNet-Enhancement" ["l"="36.697,4.51"]
"CharlesThaCat/acoustic-interference-cancellation" ["l"="36.934,4.511"]
"nii-yamagishilab/mos-finetune-ssl" ["l"="38.183,2.222"]
"sky1456723/Pytorch-MBNet" ["l"="38.144,2.248"]
"ZhangXInFD/SpeechTokenizer" ["l"="38.459,2.072"]
"k2kobayashi/crank" ["l"="37.322,2.649"]
"maxrmorrison/torchcrepe" ["l"="38.45,2.205"]
"r9y9/pysptk" ["l"="37.241,2.455"]
"nii-yamagishilab/multi-speaker-tacotron" ["l"="37.33,2.509"]
"mir-evaluation/mir_eval" ["l"="38.502,4.102"]
"hello-sea/DeepLearning_Wavelet-LSTM" ["l"="36.767,5.049"]
"GaigeY/DSP" ["l"="36.751,4.966"]
"ruizhecao96/CMGAN" ["l"="36.687,4.277"]
"eesungkim/Voice_Activity_Detector" ["l"="36.751,4.568"]
"mounalab/LSTM-RNN-VAD" ["l"="36.74,4.603"]
"nicklashansen/voice-activity-detection" ["l"="36.731,4.586"]
"filippogiruzzi/voice_activity_detection" ["l"="36.736,4.556"]
"hcmlab/vadnet" ["l"="36.74,4.518"]
"voithru/voice-activity-detection" ["l"="36.697,4.647"]
"jymsuper/VAD_tutorial" ["l"="36.717,4.617"]
"SIP-Lab/CNN-VAD" ["l"="36.721,4.655"]
"RicherMans/GPV" ["l"="36.72,4.686"]
"hunterlew/mstar_deeplearning_project" ["l"="35.865,4.424"]
"azy1988/ML-CV" ["l"="35.845,4.411"]
"hamza-latif/MSTAR_tensorflow" ["l"="35.85,4.435"]
"fudanxu/MSTAR-AConvNet" ["l"="35.851,4.452"]
"jangsoopark/AConvNet-pytorch" ["l"="35.83,4.452"]
"hunterlew/convolution_network_on_FPGA" ["l"="31.825,-2.769"]
"huangshaoyin/MSTAR_data_deal" ["l"="35.865,4.45"]
"ngageoint/MATLAB_SAR" ["l"="41.039,23.383"]
"joeyos/SAR-imaging" ["l"="41.084,23.387"]
"Edresson/VoiceSplit" ["l"="36.573,4.289"]
"xuchenglin28/speaker_extraction" ["l"="36.607,4.318"]
"HarryVolek/PyTorch_Speaker_Verification" ["l"="37.06,3.26"]
"funcwj/voice-filter" ["l"="36.54,4.275"]
"xmtggh/VideoCalling" ["l"="37.481,4.6"]
"LostStarTvT/PhoneCall" ["l"="37.51,4.611"]
"liuqm/Android-VideoChat-master" ["l"="37.514,4.59"]
"OboBear/AndroidPoint2PointFaceChat" ["l"="37.487,4.63"]
"ddssingsong/webrtc_android" ["l"="64.948,-14.116"]
"wbaizx/VideoLive" ["l"="37.433,4.586"]
"linsir6/webRTC-android-demo-and-Server" ["l"="37.566,4.627"]
"ddssingsong/webrtc_server_java" ["l"="64.938,-14.083"]
"LXP-Never/AEC_DeepModel" ["l"="36.907,4.38"]
"LuoZhongYao/webrtcaecm" ["l"="37.065,4.453"]
"SuperAI211/Realtime_AudioDenoise_EchoCancellation" ["l"="36.876,4.445"]
"cpuimage/WebRTC_CNG" ["l"="37.018,4.426"]
"helianvine/fdndlp" ["l"="36.814,4.518"]
"nttcslab-sp/dnn_wpe" ["l"="36.678,4.479"]
"respeaker/avs" ["l"="36.923,4.645"]
"respeaker/respeaker_for_raspberrypi" ["l"="36.894,4.609"]
"ctwgL/webrtc_agc2" ["l"="37.048,4.462"]
"jorgehatccrma/pyagc" ["l"="37.031,4.433"]
"iarray/android-webrtc-aec" ["l"="37.351,4.486"]
"zzugyl/webrtc-based-android-aecm" ["l"="37.345,4.47"]
"qiangqiang681/audioRecoder" ["l"="37.351,4.456"]
"monkey1992/HWAudioProcessSDK" ["l"="37.365,4.474"]
"jonlu0602/DeepDenoisingAutoencoder" ["l"="36.661,4.497"]
"aleXiehta/PhoneFortifiedPerceptualLoss" ["l"="36.588,4.546"]
"pquochuy/idsegan" ["l"="36.602,4.531"]
"ImperialCollegeLondon/sap-voicebox" ["l"="36.814,4.439"]
"jfsantos/SRMRpy" ["l"="36.845,4.244"]
"sofacoustics/SOFAtoolbox" ["l"="38.495,5.952"]
"orchidas/Pitch-Tracking" ["l"="36.809,4.572"]
"Tungluai/RTF-based-LCMV-GSC" ["l"="36.824,4.556"]
"ZitengWang/nn_mask" ["l"="36.811,4.503"]
"GregorR/rnnoise-models" ["l"="36.987,4.391"]
"francoisgermain/SpeechDenoisingWithDeepFeatureLosses" ["l"="36.666,4.46"]
"ododoyo/EHNet" ["l"="36.628,4.469"]
"waveshareteam/WM8960-Audio-HAT" ["l"="36.964,4.72"]
"pguyot/wm8960" ["l"="36.981,4.757"]
"richardpl/arnndn-models" ["l"="37.025,4.364"]
"CedArctic/rnnoise-ex" ["l"="36.968,4.381"]
"smallmuou/wavutils" ["l"="37.043,4.36"]
"orctom/vad4j" ["l"="37.018,4.391"]
"debmalya/JavaVAD" ["l"="37.031,4.387"]
"jitsi/jitsi-webrtc-vad-wrapper" ["l"="36.996,4.411"]
"akcarsten/Independent_Component_Analysis" ["l"="36.482,4.756"]
"alvarouc/ica" ["l"="36.485,4.729"]
"Felix-Yan/FastICA" ["l"="36.452,4.774"]
"vsubhashini/ica" ["l"="36.53,4.688"]
"pbrakel/anica" ["l"="36.466,4.792"]
"xshl5/KOTI_AEC" ["l"="37.07,4.514"]
"Andong-Li-speech/EaBNet" ["l"="36.696,4.339"]
"yoonsanghyu/FaSNet-TAC-PyTorch" ["l"="36.669,4.392"]
"hangtingchen/Beam-Guided-TasNet" ["l"="36.687,4.381"]
"AkojimaSLP/Neural-mask-estimation" ["l"="36.668,4.433"]
"Audio-WestlakeU/McNet" ["l"="36.699,4.268"]
"sp-uhh/deep-non-linear-filter" ["l"="36.731,4.361"]
"fgnt/sms_wsj" ["l"="36.714,4.363"]
"DiegoLeon96/Neural-Speech-Dereverberation" ["l"="36.597,4.435"]
"Hardcorehobel/Binaural_Localization" ["l"="36.991,4.576"]
"nicolasobin/binauralLocalization" ["l"="37.016,4.576"]
"AppleHolic/pytorch_sound" ["l"="36.541,4.414"]
"bill9800/speech_separation" ["l"="40.327,5.029"]
"dengzikun/WebRTC-APM-for-Android" ["l"="37.257,4.48"]
"MTG/essentia" ["l"="38.479,4.166"]
"MTG/pycompmusic" ["l"="38.509,3.49"]
"dominikschnitzer/musly" ["l"="36.381,4.552"]
"metabrainz/acousticbrainz-server" ["l"="15.283,-6.823"]
"xuchenglin28/speaker_extraction_SpEx" ["l"="36.571,4.306"]
"gemengtju/SpEx_Plus" ["l"="36.588,4.313"]
"BUTSpeechFIT/speakerbeam" ["l"="36.594,4.296"]
"gemengtju/L-SpEx" ["l"="36.544,4.295"]
"haoxiangsnr/SpEx" ["l"="36.575,4.325"]
"xuchenglin28/speech_separation" ["l"="36.541,4.318"]
"xuchenglin28/target_speaker_verification" ["l"="36.553,4.306"]
"PolarisShi/distillation" ["l"="35.809,4.401"]
"ruixv/DSP_CourseDesign" ["l"="36.763,4.996"]
"m-r-s/hearingaid-prototype" ["l"="37.021,4.269"]
"HoerTech-gGmbH/openMHA" ["l"="36.96,4.303"]
"Tympan/Tympan_Library" ["l"="37.042,4.248"]
"HoerTech-gGmbH/Cape4all" ["l"="37.065,4.257"]
"audioplastic/BioAid" ["l"="37.001,4.282"]
"vipchengrui/traditional-speech-enhancement" ["l"="36.78,4.7"]
"RodneyHK/Speechenhancement" ["l"="36.763,4.761"]
"MuSAELab/SRMRToolbox" ["l"="36.873,4.219"]
"SConsul/audio-source-separation" ["l"="36.502,4.342"]
"ShichengChen/Audio-Source-Separation" ["l"="36.42,4.319"]
"ninja3697/Kernel-Adaptive-Filtering-in-Python" ["l"="36.982,4.52"]
"jamiebullock/LibXtract" ["l"="36.217,4.637"]
"rajivpoddar/mmse-port" ["l"="36.602,4.565"]
"jeremyxu177/active-noise-control" ["l"="37.134,4.398"]
"YosukeSugiura/ActiveNoiseControl" ["l"="37.108,4.402"]
"adithyasunil26/Active-Noise-Control" ["l"="37.128,4.383"]
"lhc180/webrtc-based-android-aecm" ["l"="37.317,4.46"]
"tata88k/webrtc-android-jni" ["l"="37.296,4.472"]
"wangshub/python-vad" ["l"="36.75,4.589"]
"zeroQiaoba/ivector-xvector" ["l"="37.003,3.339"]
"amsehili/auditok" ["l"="36.753,4.532"]
"masilvabustos/TMS320C6748-ANC" ["l"="37.101,4.385"]
"CharlieHouse/RPi_SISO_ANC" ["l"="37.121,4.419"]
"Quantisan/nullwave" ["l"="37.14,4.415"]
"haoxiangsnr/Build-SE-Dataset" ["l"="36.594,4.592"]
"linan2/TensorFlow-speech-enhancement" ["l"="36.649,4.555"]
"boozyguo/ClearWave" ["l"="36.641,4.513"]
"gionanide/OpiRec" ["l"="36.841,4.863"]
"robical/StatisticalSignalProcessing" ["l"="37.192,4.442"]
"MiguelBlancoGalindo/MicArrayBeamforming" ["l"="36.88,4.487"]
"mosheman5/DNP" ["l"="36.611,4.51"]
"d-kitamura/multichannelNMF" ["l"="36.665,4.621"]
"sekiguchi92/SoundSourceSeparation" ["l"="36.723,4.5"]
"nay0648/unified2021" ["l"="36.829,4.44"]
"tky823/audio_source_separation" ["l"="36.653,4.532"]
"helrewaidy/deep-complex-convolutional-network" ["l"="36.387,4.356"]
"rohitner/ERP-BDAY" ["l"="13.08,-11.028"]
"Cocoxili/VAD" ["l"="36.739,4.63"]
"MRSRL/dl-cs" ["l"="36.36,4.36"]
"evanlev/cpd" ["l"="36.33,4.36"]
"pfnet-research/meta-tasnet" ["l"="36.573,3.981"]
"xashru/robust-vad" ["l"="36.71,4.64"]
"funcwj/nn-ideal-mask" ["l"="36.624,4.596"]
"braton/fadapt" ["l"="37.001,4.518"]
"eez-open/xmos-eval-board" ["l"="36.91,4.757"]
"peak1995/segan" ["l"="36.537,4.515"]
"f90/AdversarialAudioSeparation" ["l"="36.306,4.296"]
"soobinseo/wavenet" ["l"="36.353,4.305"]
"andre442/Acoustic-feedback-detection" ["l"="37.184,4.217"]
"Agustin-Picard/DSP-Feedback-Suppression" ["l"="37.178,4.231"]
"ssprl/Noise-Injection-Based-Acoustic-Feedback-Cancellation" ["l"="37.158,4.233"]
"snsun/gwpe-speech-dereverb" ["l"="36.807,4.6"]
"wangkenpu/Adaptive-Dereverberation-Algorithm" ["l"="36.819,4.585"]
"spyyes/Image4Matlab" ["l"="36.773,5.014"]
"chenwj1989/python_howling_suppression" ["l"="38.17,5.442"]
"Js-Mim/mss_pytorch" ["l"="36.478,4.455"]
"dr-costas/mad-twinnet" ["l"="36.41,4.473"]
"wangwei2009/spatial-temporal-LCMV" ["l"="36.825,4.602"]
"scpark20/universal-music-translation" ["l"="36.391,4.303"]
"IMLHF/WFb_SE" ["l"="36.598,4.628"]
"yluo42/GC3" ["l"="36.591,4.385"]
"felixfuyihui/Uformer" ["l"="36.67,4.282"]
"linsir6/git-commit-emoji" ["l"="37.634,4.635"]
"linsir6/BaseDevelop" ["l"="37.603,4.645"]
"linsir6/WebRTC-Voice" ["l"="37.615,4.635"]
"linsir6/MacNote" ["l"="37.623,4.648"]
"auspicious3000/deepbeam" ["l"="36.716,4.569"]
"zhr1201/Multi-channel-speech-extraction-using-DNN" ["l"="36.77,4.592"]
"wslihgt/pyfasst" ["l"="36.509,4.592"]
"openBliSSART/openBliSSART" ["l"="36.51,4.647"]
"PandoraLS/SpeechEnhancement" ["l"="36.498,4.535"]
"desh2608/gss" ["l"="36.958,3.121"]
"WilliamYu1993/ICSE" ["l"="36.608,4.551"]
"deezer/spleeter" ["l"="38.304,1.386"]
"spotify/basic-pitch" ["l"="38.681,4.229"]
"speechbrain/speechbrain" ["l"="35.41,2.293"]
"facebookresearch/encodec" ["l"="38.609,1.939"]
"espnet/espnet" ["l"="35.458,2.306"]
"facebookresearch/audiocraft" ["l"="38.516,1.382"]
"microsoft/muzic" ["l"="38.677,1.895"]
"pyannote/pyannote-audio" ["l"="40.503,3.253"]
"librosa/librosa" ["l"="38.441,4.098"]
"slhck/ffmpeg-normalize" ["l"="36.826,4.342"]
"lordmulder/DynamicAudioNormalizer" ["l"="36.937,4.264"]
"faroit/awesome-python-scientific-audio" ["l"="38.433,4.05"]
"amiaopensource/ffmprovisr" ["l"="-36.988,20.895"]
"bootphon/phonemizer" ["l"="37.266,2.33"]
"bavc/qctools" ["l"="-37.049,20.876"]
"gkonovalov/android-vad" ["l"="36.962,4.421"]
"nyadla-sys/whisper.tflite" ["l"="-52.571,10.319"]
"modelscope/kws-training-suite" ["l"="35.533,2.507"]
"vilassn/whisper_android" ["l"="-52.536,10.244"]
"k2-fsa/sherpa-ncnn" ["l"="35.625,2.404"]
"yangdongchao/AcademiCodec" ["l"="38.483,2.058"]
"wesbz/SoundStream" ["l"="38.547,2.069"]
"RicherMans/Datadriven-GPVAD" ["l"="36.716,4.754"]
"RicherMans/Dcase2018_pooling" ["l"="36.709,4.717"]
"SeventeenChen/Python_Speech_SZY" ["l"="36.775,4.578"]
"LXP-Never/Speech-signal-processing" ["l"="36.785,4.602"]
"echocatzh/MTFAA-Net" ["l"="36.763,4.329"]
"Le-Xiaohuai-speech/DPCRN_DNS3" ["l"="36.74,4.305"]
"Xiaobin-Rong/gtcrn" ["l"="36.76,4.271"]
"acoular/acoular" ["l"="36.842,4.504"]
"eac-ufsm/beamforming-tools" ["l"="36.938,4.626"]
"mmmgalleria/Dual-Microphone-Noise-Reduction-by-PLD-Technique" ["l"="36.839,4.645"]
"yuzhouhe2000/OMLSA-IMCRA" ["l"="37.05,4.551"]
"google-research/sound-separation" ["l"="36.702,4.326"]
"etzinis/sudo_rm_rf" ["l"="36.678,4.332"]
"xiph/speex" ["l"="-38.275,20.993"]
"RookieJunChen/FullSubNet-plus" ["l"="36.707,4.295"]
"seorim0/DCCRN-with-various-loss-functions" ["l"="36.644,4.299"]
"vivjay30/Cone-of-Silence" ["l"="36.624,4.343"]
"yuhogun0908/MISOnet" ["l"="36.543,4.343"]
"AICyberTeam/AIR-PolSAR-Seg" ["l"="36.013,4.44"]
"JupiterEthan/GCRN-complex" ["l"="36.663,4.299"]
"JusperLee/TDANet" ["l"="36.678,4.241"]
"fzzfbyx/Audio-FIR-denoising-filter-MATLAB_GUI" ["l"="36.714,4.887"]
"XuRulin/DSP-Example-for-MATLAB" ["l"="36.736,4.893"]
"H874589148/Digital-Signal-Processing_Experiment" ["l"="36.704,4.87"]
"JusperLee/Deep-Encoder-Decoder-Conv-TasNet" ["l"="36.591,4.275"]
"JusperLee/Deep-Clustering-for-Speech-Separation" ["l"="40.257,5.082"]
"JusperLee/AFRCNN-For-Speech-Separation" ["l"="52.983,3.012"]
"popcornell/SparseLibriMix" ["l"="36.631,4.288"]
"skgusrb12/voice_activity_detection" ["l"="36.704,4.621"]
"zlzhang1124/voice_activity_detection" ["l"="56.895,28.065"]
"sharathadavanne/hungarian-net" ["l"="37.124,4.627"]
"ws-choi/ISMIR2020_U_Nets_SVS" ["l"="36.627,3.912"]
"ws-choi/Conditioned-Source-Separation-LaSAFT" ["l"="36.593,3.922"]
"dbklim/RNNoise_Wrapper" ["l"="36.882,4.708"]
"Shb742/rnnoise_python" ["l"="36.889,4.761"]
"SaneBow/PiDTLN" ["l"="36.887,4.586"]
"NEGU93/CVNN-PolSAR" ["l"="36.244,4.395"]
"josiahwsmith10/complextorch" ["l"="36.381,4.408"]
"soumickmj/pytorch-complex" ["l"="36.36,4.395"]
"ericyeats/cvnn-security" ["l"="36.381,4.39"]
"chenwj1989/python-speech-enhancement" ["l"="36.781,4.763"]
"zhr1201/OMLSA-speech-enhancement" ["l"="36.791,4.583"]
"lyapple2008/SpeechEnhancement" ["l"="36.785,4.74"]
"fgnt/padertorch" ["l"="36.935,3.049"]
"Sanyuan-Chen/CSS_with_Conformer" ["l"="36.561,4.339"]
"amaas/rnn-speech-denoising" ["l"="36.665,4.575"]
"posenhuang/singingvoiceseparationrpca" ["l"="36.54,4.585"]
"Unisound/SpeechSeparation" ["l"="36.578,4.51"]
"james34602/SpleeterRT" ["l"="36.907,3.725"]
"gvne/vstSpleeter" ["l"="36.875,3.759"]
"lwfinger/rtl8723bs_bt" ["l"="37.277,5.09"]
"onitake/gslx680-acpi" ["l"="37.298,5.093"]
"anthonywong/rtl8723bs" ["l"="37.236,5.044"]
"burzumishi/linux-baytrail-flexx10" ["l"="37.245,5.011"]
"Manouchehri/vi8" ["l"="37.237,5.071"]
"hadess/gt9xx" ["l"="37.263,5.063"]
"zhenghuatan/rVADfast" ["l"="36.758,4.867"]
"zhenghuatan/rVAD" ["l"="36.746,4.835"]
"JeffreyCA/spleeter-web" ["l"="36.768,3.899"]
"gvne/spleeterpp" ["l"="36.849,3.806"]
"VVasanth/Spleeter_Unofficial_TF20_MobileApp" ["l"="36.848,3.864"]
"kuielab/sdx23" ["l"="36.747,3.908"]
"mail2chromium/Android-Native-Development-For-WebRTC" ["l"="37.318,4.534"]
"mail2chromium/Android_Realtime_Communication_Using_WebRTC" ["l"="37.34,4.514"]
"mail2chromium/Compile_WebRTC_Library_For_Android" ["l"="37.335,4.535"]
"DavidDiazGuerra/icoDOA" ["l"="39.86,5.651"]
"kjason/DnnNormTimeFreq4DoA" ["l"="37.121,4.606"]
"Snowdar/asv-subtools" ["l"="37.008,3.247"]
"cvqluu/TDNN" ["l"="37.056,3.326"]
"Jungjee/RawNet" ["l"="37.035,3.278"]
"qiuqiangkong/torchlibrosa" ["l"="38.542,4.01"]
"asvspoof-challenge/2021" ["l"="38.088,2.498"]
"ysparkwin/AlternatingProjections" ["l"="37.062,4.662"]
"Jimbo-Jo/GROGSBL" ["l"="37.045,4.665"]
"jsdaiustc/rootSBL" ["l"="37.028,4.651"]
"ap-atul/Audio-Denoising" ["l"="36.885,4.113"]
"AP-Atul/wavelets-ext" ["l"="36.96,4.05"]
"will-rice/denoisers" ["l"="36.927,4.089"]
"madhavmk/Noise2Noise-audio_denoising_without_clean_training_data" ["l"="36.709,4.234"]
"microsoft/SIG-Challenge" ["l"="36.868,4.2"]
"microsoft/PLC-Challenge" ["l"="36.9,4.207"]
"EncoraDigital/SAB-cnn-audio-denoiser" ["l"="36.695,4.457"]
"Andong-Li-speech/GaGNet" ["l"="36.618,4.326"]
"project-alice-assistant/HermesLedControl" ["l"="-14.404,-39.122"]
"koenvervloesem/awesome-rhasspy" ["l"="-14.442,-39.108"]
"Wramberg/adaptfilt" ["l"="36.961,4.498"]
"matousc89/Python-Adaptive-Signal-Processing-Handbook" ["l"="36.962,4.514"]
"matousc89/padasip" ["l"="36.926,4.483"]
"Mathilda11/Speech-processing" ["l"="38.187,5.451"]
"ap-atul/Video-Editing-Automation" ["l"="36.994,4.038"]
"ap-atul/Torpido" ["l"="36.995,4.021"]
"diracdeltas/vstSpleeter" ["l"="36.879,3.712"]
"Audio-WestlakeU/RealMAN" ["l"="36.686,4.224"]
"IMLHF/Speech-Enhancement-Measures" ["l"="36.556,4.253"]
"nglehuy/semetrics" ["l"="36.517,4.234"]
"stephencwelch/Perceptual-Coding-In-Python" ["l"="36.733,4.089"]
"HSU-ANT/gstpeaq" ["l"="36.709,4.049"]
"NikolajAndersson/PEAQ" ["l"="36.692,4.039"]
"dakenan1/Speech-measure-SDR-SAR-STOI-PESQ" ["l"="36.486,4.223"]
"hspark84/lgtfb-en" ["l"="36.839,4.754"]
"jinay1991/spleeter" ["l"="36.889,3.885"]
"jain-abhinav02/VoiceFilter" ["l"="36.485,4.268"]
"pirxus/personalVAD" ["l"="36.507,4.268"]
"CedricChing/DeepMRI" ["l"="-35.346,23.112"]
"rmsouza01/MC-MRI-Rec" ["l"="-35.364,23.135"]
"khammernik/sigmanet" ["l"="-35.354,23.101"]
"VLOGroup/mri-variationalnetwork" ["l"="-35.364,23.122"]
"wangyifan1027/Complex-Valued_Networks" ["l"="36.429,4.418"]
"audiolabs/torch-pesq" ["l"="36.785,4.296"]
"AkojimaSLP/Frame-by-frame-closed-form-update-for-mask-based-adaptive-MVDR-beamforming" ["l"="36.607,4.415"]
"wangtianrui/DCCRN" ["l"="36.612,4.298"]
"wangtianrui/HGCN" ["l"="36.605,4.277"]
"crux82/huric" ["l"="36.258,3.847"]
"crux82/ExtremITA" ["l"="36.281,3.858"]
"Andong-Li-speech/TaylorBeamformer" ["l"="36.577,4.347"]
"tinoucas/spleeter-tflite-convert" ["l"="36.88,3.861"]
"Turing311/Spleeter_Android_iOS" ["l"="36.913,4.049"]
"mborsdorf/UniversalSpeakerExtraction" ["l"="36.558,4.293"]
"YongyuG/dnn_aec_data_process" ["l"="36.926,4.373"]
"yoonsanghyu/Dual-Path-Transformer-Network-PyTorch" ["l"="36.583,4.364"]
"zehuachenImperial/SkipConvNet" ["l"="36.564,4.407"]
"newdigate/teensy-variable-playback" ["l"="37.151,4.169"]
"FrankBoesing/Teensy-WavePlayer" ["l"="37.171,4.155"]
"HeliosX7/voice-filter" ["l"="36.459,4.26"]
"haoheliu/Subband-Music-Separation" ["l"="36.656,4.039"]
"haoheliu/torchsubband" ["l"="36.618,3.991"]
"zftan0709/Feedback-ANC-Teensy-3.6" ["l"="37.144,4.366"]
"VVasanth/SpleeterTF2.0_Unofficial" ["l"="36.863,3.847"]
"lili-0805/MVAE" ["l"="36.636,4.545"]
"anton-jeran/TS-RIR" ["l"="38.097,3.657"]
"fakufaku/auxiva-ipa" ["l"="36.631,4.58"]
"fakufaku/piva" ["l"="36.634,4.609"]
"WilliamYu1993/BAMSE" ["l"="36.584,4.568"]
"moscow-technologies/blockchain-voting_2021" ["l"="44.914,30.404"]
"haoheliu/voicefixer_main" ["l"="36.801,4.18"]
"cookcodes/Percepnet-Keras" ["l"="36.87,4.316"]
"google/lyra" ["l"="36.913,4.309"]
"xiph/LPCNet" ["l"="37.232,2.476"]
"kan-bayashi/ParallelWaveGAN" ["l"="37.256,2.466"]
"xiph/opus" ["l"="-38.272,20.945"]
"lucidrains/audiolm-pytorch" ["l"="38.625,1.96"]
"drowe67/codec2-dev" ["l"="52.692,5.611"]
"thooore/SpleeterGUI" ["l"="36.652,3.909"]
"thooore/SpleeterCore" ["l"="36.638,3.875"]
"zju-isee/zju-isee" ["l"="36.621,5.042"]
"Zezzid/ZJU_Course" ["l"="36.638,5.031"]
"skyline-pro/isee" ["l"="36.653,5.031"]
"JaceyHuang/ISEE-zju" ["l"="36.652,5.045"]
"LeadroyaL/ZJU_ISEE_Project" ["l"="36.636,5.045"]
"euphoniumm/isee-zju" ["l"="36.636,5.059"]
"aerore2021/KeISEE" ["l"="36.627,5.015"]
"l2h4/ZJU-ISEE" ["l"="36.644,5.066"]
"ThuryW/ZJU-ISEE" ["l"="36.627,5.065"]
"AucFang/ZJU-ISEE-byAucFang" ["l"="36.655,5.058"]
"ZJU-Andre/ISEE-zju" ["l"="36.612,5.058"]
"Zhang-Each/CourseNoteOfZJUSE" ["l"="-7.394,20.925"]
"yjwang01/zju-isee" ["l"="36.618,5.025"]
"JupiterEthan/CRN-causal" ["l"="36.662,4.269"]
"smail91/Speex_AEC" ["l"="37.093,4.465"]
"willhope/Noise-reduction" ["l"="36.926,4.549"]
"rishikksh20/hifigan-denoiser" ["l"="36.6,4.359"]
"seorim0/DNN-based-Speech-Enhancement-in-the-frequency-domain" ["l"="36.601,4.261"]
"seorim0/NUNet-TLS" ["l"="36.5,4.247"]
"mwv/vad" ["l"="36.758,4.619"]
"RaviSoji/plda" ["l"="37.077,3.341"]
"qqueing/DeepSpeaker-pytorch" ["l"="37.093,3.277"]
"Janghyun1230/Speaker_Verification" ["l"="37.081,3.253"]
"adobe-research/MetaAF" ["l"="36.822,4.392"]
"Fafa-DL/2021-ZJU-Machine-Learning" ["l"="36.553,5.079"]
"VipaiLab/machine-learning-course" ["l"="36.575,5.051"]
"SungFeng-Huang/SSL-pretraining-separation" ["l"="36.513,4.187"]
"Zhongyang-debug/Attention-Is-All-You-Need-In-Speech-Separation" ["l"="36.554,4.202"]
"mvansegbroeck-zz/vad" ["l"="36.656,4.664"]
"isrish/VAD-LTSD" ["l"="36.634,4.708"]
"rqalbuquerque/Voice-Activity-Detector-Algorithms" ["l"="36.629,4.688"]
"GAMMA-UMD/pygsound" ["l"="38.111,3.648"]
"FrancoisGrondin/BIRD" ["l"="38.494,3.903"]
"anton-jeran/FAST-RIR" ["l"="38.119,3.671"]
"yxlu-0102/MP-SENet" ["l"="36.716,4.251"]
"liqingchunnnn/Only-Noisy-Training" ["l"="36.702,4.182"]
"NVIDIA/CleanUNet" ["l"="36.695,4.248"]
"yuguochencuc/DB-AIAT" ["l"="36.649,4.253"]
"RookieJunChen/Inter-SubNet" ["l"="36.632,4.255"]
"alibabasglab/FRCRN" ["l"="36.71,4.269"]
"WenzheLiu-Speech/The-guidebook-of-speech-enhancement" ["l"="36.625,4.303"]
"facebookresearch/svoice" ["l"="36.687,4.301"]
"echocatzh/py-aec-unified2021" ["l"="37.006,4.315"]
"Okrio/deepvqe" ["l"="37.023,4.327"]
"vkothapally/Subband-Beamformer" ["l"="36.957,4.337"]
"iancraz/ANC-Implementation" ["l"="37.123,4.364"]
"RezzaMir/Noise-Cancellation-For-Automobiles" ["l"="37.097,4.373"]
"LeeTaewoo/TL-SSC_SRP-PHAT" ["l"="36.842,4.613"]
"illuspas/libaec-android" ["l"="37.107,4.532"]
"ElXreno/archlinux-bootia32" ["l"="37.385,5.03"]
"wudicgi/SpleeterMsvcExe" ["l"="36.842,3.748"]
"wudicgi/SpleeterGui" ["l"="36.838,3.721"]
"avcodecs/DTLNtfliteC" ["l"="36.886,4.539"]
"lhwcv/DTLN_pytorch" ["l"="36.573,4.269"]
"stephencwelch/Active-Noise-Cancellation" ["l"="37.219,4.347"]
"stephencwelch/Acoustics-To-Deep-Learning" ["l"="37.253,4.333"]
"stephencwelch/Neural-Networks-For-Audio-Processing" ["l"="37.276,4.323"]
"developer-foundry/diminish" ["l"="37.236,4.326"]
"source-separation/tutorial" ["l"="38.511,4.195"]
"mir-dataset-loaders/mirdata" ["l"="38.573,4.128"]
"Crush0416/MS-CVNets-a-novel-complex-valued-neural-networks-for-SAR-ATR" ["l"="35.802,4.465"]
"Windstudent/Complex-MTASSNet" ["l"="36.519,4.306"]
"haoheliu/2021-ISMIR-MSS-Challenge-CWS-PResUNet" ["l"="36.67,3.96"]
"rrbluke/NRES" ["l"="36.962,4.357"]
"Xiaobin-Rong/deepvqe" ["l"="36.991,4.349"]
"echocatzh/GFTNN" ["l"="36.985,4.333"]
"echocatzh/PFDKF" ["l"="36.91,4.354"]
"tky823/ssspy" ["l"="36.665,4.518"]
"onolab-tmu/code_2020ICASSP_five" ["l"="36.612,4.579"]
"Audio-WestlakeU/pytorch_lightning_template_for_beginners" ["l"="36.678,4.182"]
"rogaits/AFC-NR" ["l"="37.11,4.25"]
"adefossez/mdx21_demucs" ["l"="36.72,3.859"]
"yoyolicoris/music-demixing-challenge-ismir-2021-entry" ["l"="36.712,3.81"]
"scofir/DTLN-aec" ["l"="36.902,4.395"]
"Turing311/Face_Liveness_Detection_Android_iOS" ["l"="36.907,4.237"]
"shenbengit/WebRTC-SRS" ["l"="37.42,4.503"]
"shenbengit/MVVMKit" ["l"="37.463,4.496"]
"shenbengit/ArcFace4" ["l"="37.488,4.491"]
"shenbengit/SrsRtcAndroidClient" ["l"="37.443,4.511"]
"xiangang/WebRTCTest" ["l"="37.442,4.483"]
"adku1173/acoupipe" ["l"="36.971,4.685"]
"gilleschardon/acosolo" ["l"="36.984,4.708"]
"voithru/wav2vec2_finetune" ["l"="36.682,4.672"]
"voithru/asr-text_classification-pipeline" ["l"="36.678,4.686"]
"Yifei-ZHAO96/STAM-pytorch" ["l"="36.693,4.682"]
"NickWilkinson37/voxseg" ["l"="36.672,4.713"]
"acoular/spectacoular" ["l"="36.961,4.65"]
"onitake/gsl-firmware" ["l"="37.307,5.126"]
"farihachaiti/DoKaraokeAI_Spleeter_Android_Implementation" ["l"="36.848,3.844"]
"RusselZHANG/Microphone-Array-Generalization-for-Multichannel-Narrowband-Deep-Speech-Enhancement" ["l"="36.591,4.408"]
"djvdorp/hi8" ["l"="37.229,5.089"]
"Mo-yun/DSDPRNN" ["l"="37.008,4.34"]
"ShashShukla/ICA" ["l"="36.455,4.743"]
"fgnt/ci_sdr" ["l"="36.608,4.397"]
"fakufaku/fast_bss_eval" ["l"="36.649,4.47"]
"yoyolicoris/danna-sep" ["l"="36.707,3.789"]
"jeonchangbin49/LimitAug" ["l"="36.703,3.751"]
"ap-atul/wavelets" ["l"="36.974,4.023"]
"haoheliu/versatile_audio_super_resolution" ["l"="36.778,4.135"]
"cszheng-ioa/Sixty-years-of-frequency-domain-monaural-speech-enhancement" ["l"="36.782,4.281"]
"emilbjornson/optimal-beamforming" ["l"="55.456,4.6"]
"TianLin0509/Hybrid-Beamforming-for-Millimeter-Wave-Systems-Using-the-MMSE-Criterion" ["l"="55.439,4.592"]
"TianLin0509/BF-design-with-DL" ["l"="-51.628,-14.922"]
"olvrhhn/audio_super_resolution" ["l"="36.892,4.001"]
"chomeyama/DualCycleGAN" ["l"="36.869,4.019"]
"RetroCirce/Zero_Shot_Audio_Source_Separation" ["l"="36.543,4.11"]
"liuxubo717/LASS" ["l"="39.69,5.72"]
"vb000/Waveformer" ["l"="36.58,4.172"]
"RetroCirce/Choral_Music_Separation" ["l"="36.503,4.083"]
"yangdongchao/Tim-TSENet" ["l"="36.464,3.957"]
"LiChenda/Multi-clue-TSE-data" ["l"="36.479,3.968"]
"RoyChao19477/SEMamba" ["l"="36.68,4.202"]
"sp-uhh/storm" ["l"="36.663,4.207"]
"YunyangZeng/TAPLoss" ["l"="36.573,4.23"]
"Qinwen-Hu/dparn" ["l"="36.794,4.227"]
"Le-Xiaohuai-speech/SKIP-DPCRN" ["l"="36.773,4.241"]
"Audio-WestlakeU/FN-SSL" ["l"="36.661,4.234"]
"JusperLee/SonicSim" ["l"="36.713,4.209"]
"haoheliu/ssr_eval" ["l"="36.865,4.145"]
"rishikksh20/HiFiplusplus-pytorch" ["l"="38.426,2.402"]
"neillu23/CDiffuSE" ["l"="36.697,4.2"]
"174563214/xinhaoshuzichuli" ["l"="36.706,4.912"]
"CarlGao4/Demucs-Gui" ["l"="36.686,4.008"]
"Frikallo/MISST" ["l"="36.642,3.953"]
"flipswitchingmonkey/FlexASIO_GUI" ["l"="38.552,5.451"]
"stemrollerapp/stemroller" ["l"="36.724,3.997"]
"DamRsn/NeuralNote" ["l"="38.523,5.548"]
"sdatkinson/NeuralAmpModelerPlugin" ["l"="38.515,5.674"]
"xserrat/docker-facebook-demucs" ["l"="36.655,4.004"]
"pelennor2170/NAM_models" ["l"="38.577,6.782"]
"ZL-Audio/ZLEqualizer" ["l"="38.747,5.534"]
"ina-foss/inaSpeechSegmenter" ["l"="37.052,3.171"]
"wq2012/awesome-diarization" ["l"="37.021,3.203"]
"philipperemy/deep-speaker" ["l"="37.091,3.236"]
"coqui-ai/open-speech-corpora" ["l"="37.272,2.355"]
"tyiannak/pyAudioAnalysis" ["l"="38.365,4.176"]
"alibabasglab/D2Former" ["l"="36.717,4.19"]
"ioyy900205/MFNet" ["l"="36.605,4.187"]
"Andong-Li-speech/TaylorSENet" ["l"="36.561,4.316"]
"vkothapally/JAECBF" ["l"="36.873,4.378"]
"fakufaku/torchiva" ["l"="36.761,4.424"]
"Crush0416/Fea-DA---Unknown-SAR-Target-Identification" ["l"="35.78,4.473"]
"lucmos/relreps" ["l"="36.381,3.852"]
"Flegyas/latentis" ["l"="36.376,3.876"]
"jsdaiustc/SBL_nested" ["l"="37.031,4.672"]
"jsdaiustc/Real_SBL_linear" ["l"="37.011,4.641"]
"neoncloud/mdctGAN" ["l"="36.914,4.115"]
"claritychallenge/clarity" ["l"="36.96,4.241"]
"claritychallenge/clarity_CC" ["l"="36.985,4.26"]
"dhimnsen/OpenSpeechPlatform-UCSD" ["l"="36.995,4.243"]
"neillu23/DiffuSE" ["l"="36.648,4.196"]
"YUCHEN005/NASE" ["l"="47.841,30.452"]
"wangtianrui/APC-SNR" ["l"="36.54,4.148"]
"Qinwen-Hu/SDCM" ["l"="36.512,4.137"]
"dmngu9/Voice-Activity-Detection" ["l"="36.621,4.722"]
"BingYang-20/DP-RTF-Learning" ["l"="36.577,4.196"]
"BingYang-20/SRP-DNN" ["l"="36.605,4.207"]
"zexupan/avse_hybrid_loss" ["l"="36.498,4.289"]
"Guanyuansheng/TFGAN-PLC" ["l"="36.941,4.178"]
"michelemancusi/LQVAE-separation" ["l"="36.391,3.915"]
"daniele-baieri/PyGMI" ["l"="36.35,3.874"]
"gladia-research-group/latent-autoregressive-source-separation" ["l"="36.429,3.954"]
"breizhn/tPLCnet" ["l"="36.984,4.148"]
"TheDrHax/t100ta-scripts" ["l"="37.351,5.052"]
"mt7-dev/android_kernel_huawei_mt7l09" ["l"="37.133,4.521"]
"lbcgi/webrtc_aec_using_kalmanAdaption" ["l"="37.099,4.51"]
"Music-and-Culture-Technology-Lab/omnizart" ["l"="38.652,4.205"]
"diracdeltas/spleeter4max" ["l"="36.314,5.778"]
"pedrozath/coltrane" ["l"="4.239,-37.561"]
"intel/openvino-plugins-ai-audacity" ["l"="36.807,4.121"]
"runtipi/runtipi" ["l"="12.404,-8.986"]
"VipaiLab/Signals-and-Systems-course" ["l"="36.645,4.993"]
"NIT2018/NitSignal" ["l"="36.676,5.004"]
"SleepingMonster/SYSU_Courses" ["l"="-5.066,19.99"]
"google/uis-rnn" ["l"="37.055,3.21"]
"mravanelli/pytorch-kaldi" ["l"="35.563,2.316"]
"pykaldi/pykaldi" ["l"="35.62,2.358"]
"jameslyons/python_speech_features" ["l"="35.493,2.279"]
"wenet-e2e/wenet" ["l"="35.55,2.34"]
"alibabasglab/MossFormer" ["l"="36.602,4.128"]
"alibabasglab/MossFormer2" ["l"="36.638,4.161"]
"HaoFengyuan/X-TF-GridNet" ["l"="36.661,4.159"]
"vb000/SemanticHearing" ["l"="36.558,4.185"]
"urgent-challenge/urgent2024_challenge" ["l"="36.634,4.18"]
"shahules786/mayavoz" ["l"="36.628,4.409"]
"rastersoft/gsl1680" ["l"="37.334,5.14"]
"sigboe/gslX68X" ["l"="37.318,5.155"]
"edward-p/mssl1680-firmware" ["l"="37.298,5.152"]
"BrechtDeMan/WebAudioEvaluationTool" ["l"="36.894,4.262"]
"chomeyama/SiFiGAN" ["l"="38.459,2.224"]
"YangangCao/TRUNet" ["l"="36.619,4.2"]
"maum-ai/nuwave2" ["l"="38.433,2.42"]
"Rongjiehuang/ProDiff" ["l"="38.47,2.232"]
"sungwon23/BSRNN" ["l"="36.839,4.125"]
"effusiveperiscope/so-vits-svc" ["l"="36.685,3.885"]
"JusperLee/SPMamba" ["l"="36.676,4.148"]
"dmlguq456/SepReformer" ["l"="36.659,4.182"]
"JusperLee/Apollo" ["l"="36.739,4.122"]
"sp-uhh/sgmse-bbed" ["l"="36.601,4.154"]
"fakufaku/diffusion-separation" ["l"="36.547,4.083"]
"ICDM-UESTC/DOSE" ["l"="36.583,4.148"]
"TRvlvr/model_repo" ["l"="36.781,3.964"]
"TRvlvr/application_data" ["l"="36.787,3.929"]
"ModarHalimeh/COSPA" ["l"="36.675,4.411"]
"JaeBinCHA7/Nested-U-Net-based-Real-time-Speech-Enhancement-Mobile-App" ["l"="36.397,4.212"]
"JaeBinCHA7/RTNR" ["l"="36.366,4.2"]
"JaeBinCHA7/DEMUCS-for-Speech-Enhancement" ["l"="36.352,4.196"]
"judiebig/DR-DiffuSE" ["l"="36.557,4.131"]
"muqiaoy/PAAP" ["l"="36.543,4.221"]
"jakeoneijk/FlashSR_Inference" ["l"="36.831,4.049"]
"fgnt/graph_pit" ["l"="36.74,4.496"]
"JaeBinCHA7/ECG-Multi-Label-Classification-Using-Multi-Model" ["l"="36.329,4.187"]
"gladia-research-group/multi-source-diffusion-models" ["l"="36.478,3.999"]
"EmilianPostolache/stable-audio-controlnet" ["l"="38.778,4.128"]
"jeonchangbin49/MedleyVox" ["l"="36.697,3.688"]
"jeonchangbin49/musdb-XL" ["l"="36.702,3.722"]
"lhwcv/self_attention_alignment" ["l"="37.035,4.31"]
"aircarlo/bin2bin-GAN-PLC" ["l"="37.004,4.134"]
"Aketirani/audio-mnist" ["l"="37.114,4.388"]
"yoongi43/music_source_separation" ["l"="36.692,3.736"]
"seanghay/uvr" ["l"="36.816,3.981"]
"Eddycrack864/UVR5-UI" ["l"="36.824,3.94"]
"KimberleyJensen/Mel-Band-Roformer-Vocal-Model" ["l"="36.768,4.056"]
"blaisewf/rvc-cli" ["l"="38.813,1.63"]
"nomadkaraoke/python-lyrics-transcriber" ["l"="36.799,3.944"]
"NextAudioGen/ultimatevocalremover_api" ["l"="36.848,3.958"]
"nomadkaraoke/karaoke-generator" ["l"="36.804,3.963"]
"seanghay/uvr-mdx-infer" ["l"="36.836,3.978"]
"intel/openvino-ai-plugins-gimp" ["l"="63.985,-2.399"]
"rsxdalv/tts-generation-webui" ["l"="38.731,1.714"]
"aaronaanderson/Terrain" ["l"="38.767,5.479"]
"plugdata-team/plugdata" ["l"="38.549,5.636"]
"baconpaul/airwin2rack" ["l"="38.719,5.496"]
"IAHispano/Applio" ["l"="38.721,1.668"]
"DISTRHO/Cardinal" ["l"="38.594,5.61"]
"baconpaul/six-sines" ["l"="38.737,5.493"]
"audacity/audacity" ["l"="-32.8,-29.207"]
"Captain-FLAM/KaraFan" ["l"="36.781,3.987"]
"amanteur/BandSplitRNN-PyTorch" ["l"="36.775,4.111"]
"Audio-AGI/AudioSep" ["l"="38.679,2.044"]
"ZFTurbo/MVSEP-CDX23-Cinematic-Sound-Demixing" ["l"="36.747,3.954"]
"junyuchen-cjy/DTTNet-Pytorch" ["l"="36.788,4.076"]
"jarredou/AudioSR-Colab-Fork" ["l"="36.781,4.04"]
"stephencwelch/Imaginary-Numbers-Are-Real" ["l"="37.362,4.293"]
"stephencwelch/LearningToSee" ["l"="37.4,4.279"]
"kuleshov/audio-super-res" ["l"="36.751,4.234"]
"slp-rl/aero" ["l"="38.433,2.505"]
"shivammehta25/Matcha-TTS" ["l"="38.492,1.986"]
"IAHispano/Audio-Upscaler" ["l"="36.836,4.074"]
"yangdongchao/UniAudio" ["l"="38.492,2.071"]
"haoheliu/AudioLDM2" ["l"="38.669,1.957"]
"gogyzzz/beamformit_matlab" ["l"="36.788,4.568"]
"yxlu-0102/AP-BWE" ["l"="38.375,2.555"]
"jarredou/Music-Source-Separation-Training-Colab-Inference" ["l"="36.758,3.971"]
"yxlllc/ReFlow-VAE-SVC" ["l"="38.368,1.973"]
"kwatcharasupat/bandit" ["l"="36.734,3.929"]
"dengzikun/WebRTC-APM-for-Android-Demo" ["l"="37.273,4.465"]
"unispeech/unimrcp" ["l"="63.584,-14.748"]
"shiweixingcn/vad" ["l"="36.941,4.46"]
"voixen/voixen-vad" ["l"="35.86,23.646"]
"cotinyang/MRCP-Plugin-Demo" ["l"="63.631,-14.703"]
"sippy/rtpproxy" ["l"="63.515,-14.836"]
"crlandsc/Music-Demixing-with-Band-Split-RNN" ["l"="36.799,4.089"]
"Xiaobin-Rong/SEtrain" ["l"="36.826,4.21"]
"Xiaobin-Rong/TRT-SE" ["l"="36.811,4.202"]
"Xiaobin-Rong/ul-unas" ["l"="36.814,4.224"]
"hyyan2k/LiSenNet" ["l"="36.848,4.173"]
"respeaker/get_started_with_respeaker" ["l"="36.923,4.674"]
"respeaker/respeaker_python_library" ["l"="36.902,4.665"]
"respeaker/respeaker-feed" ["l"="36.936,4.717"]
"respeaker/Alexa" ["l"="36.938,4.736"]
"respeaker/respeaker_arduino_library" ["l"="36.921,4.699"]
"bytedance/uss" ["l"="36.583,4.07"]
"Aisaka0v0/CLAPSep" ["l"="36.52,4.016"]
"sony/CLIPSep" ["l"="36.541,4.047"]
"starrytong/SCNet" ["l"="36.716,4.1"]
"WangHelin1997/SoloAudio" ["l"="36.547,4.025"]
"descriptinc/audiotools" ["l"="38.48,2.178"]
"seorim0/Multi-label-12-lead-ECG-abnormality-classification" ["l"="36.298,4.182"]
"RSTLess-research/Fauno-Italian-LLM" ["l"="36.336,3.889"]
"teelinsan/camoscio" ["l"="36.312,3.868"]
"respeaker/microsoft_cognitive_services" ["l"="36.906,4.699"]
"moises-ai/moises-db" ["l"="36.716,4.028"]
"amanteur/SCNet-PyTorch" ["l"="36.734,4.105"]
"grok-ai/py-template" ["l"="36.366,3.848"]
"tommasomncttn/mergenetic" ["l"="36.357,3.859"]
"grok-ai/nn-template-core" ["l"="36.394,3.865"]
"Audio-WestlakeU/FS-EEND" ["l"="36.916,3.138"]
"kwatcharasupat/bandit-v2" ["l"="36.713,3.905"]
"kwatcharasupat/source-separation-landing" ["l"="36.717,3.886"]
"teelinsan/parallel-decoding" ["l"="36.332,3.835"]
"Audio-WestlakeU/SAR-SSL" ["l"="36.9,3.042"]
"swapUniba/LLaMAntino" ["l"="36.292,3.842"]
"aim-qmul/sdx23-aimless" ["l"="36.765,3.862"]
"davidliujiafeng/ccom_mdx2023" ["l"="36.747,3.874"]
"naba89/iSeparate-SDX" ["l"="36.748,3.854"]
"XZWY/SpatialCodec" ["l"="36.366,4.086"]
"Andong-Li-speech/G2Net" ["l"="36.4,4.103"]
"sp-uhh/sgmse_crp" ["l"="36.578,4.131"]
"nomadkaraoke/karaoke-prep" ["l"="36.809,3.912"]
"jcsilva/deep-clustering" ["l"="36.549,4.531"]
"KimberleyJensen/kmdx-net_music-source-separation" ["l"="36.751,3.817"]
"modelscope/ClearerVoice-Studio" ["l"="38.521,1.83"]
"yl4579/StyleTTS2" ["l"="38.574,1.711"]
"huggingface/parler-tts" ["l"="38.561,1.742"]
"sh-lee-prml/HierSpeechpp" ["l"="38.497,1.963"]
"lynnzhiyun/graduation-project" ["l"="36.992,4.621"]
"SUC-DriverOld/MSST-WebUI" ["l"="38.299,1.976"]
"vb000/LookOnceToHear" ["l"="36.621,4.234"]
"wenet-e2e/wesep" ["l"="36.687,4.159"]
"facebookresearch/ears_dataset" ["l"="36.529,4.163"]
"chentuochao/Target-Conversation-Extraction" ["l"="36.53,4.2"]
"highskyno1/MIMO_DOA" ["l"="37.059,4.679"]
"chipaudette/OpenAudio_ArduinoLibrary" ["l"="37.103,4.206"]
"hexeguitar/hexefx_audiolib_F32" ["l"="37.118,4.18"]
"MarkzP/AudioEffectDynamics" ["l"="37.137,4.192"]
"timsainb/python_spectrograms_and_inversion" ["l"="36.465,4.638"]
"kastnerkyle/tools" ["l"="36.431,4.662"]
"yuguochencuc/BAE-Net" ["l"="36.446,4.125"]
"sp-uhh/ears_benchmark" ["l"="36.486,4.145"]
"Eddycrack864/UVR5-NO-UI" ["l"="36.841,3.896"]
"Eddycrack864/Ultimate-Vocal-Remover-5.6-for-Google-Colab" ["l"="36.855,3.908"]
"Qin-Yi/Active-Noise-Control-System" ["l"="37.067,4.383"]
"liynjy/FMCW-2T4R-SIM-MUSIC" ["l"="64.075,35.24"]
"JusperLee/TIGER" ["l"="36.721,4.166"]
"xi-j/Mamba-TasNet" ["l"="36.625,4.118"]
"Andong-Li-speech/Neural-Vocoders-as-Speech-Enhancers" ["l"="36.697,4.134"]
"xi-j/Mamba-ASR" ["l"="36.607,4.084"]
"RoyChao19477/PCS" ["l"="36.644,4.144"]
"sasi433/Sound-source-localization" ["l"="36.97,4.634"]
"madebyollin/acapellabot" ["l"="36.495,4.481"]
"keums/melodyExtraction_JDC" ["l"="38.562,4.447"]
"marl/medleydb" ["l"="38.535,4.195"]
"bmcfee/muda" ["l"="38.407,4.057"]
"urinieto/msaf" ["l"="38.549,4.081"]
"Beilong-Tang/TSELM" ["l"="36.746,4.079"]
"jarredou/Apollo-Colab-Inference" ["l"="36.785,4.062"]
"baijinglin/TS-BSmamba2" ["l"="36.676,4.052"]
"BoysTownOrg/chapro" ["l"="37.048,4.271"]
"gitwukeyi/FSPEN" ["l"="36.91,4.144"]
"Okrio/FSPEN" ["l"="36.934,4.132"]
"sevagh/demucs.cpp" ["l"="36.928,3.841"]
"sevagh/basicpitch.cpp" ["l"="36.947,3.818"]
"haoxiangsnr/llm-tse" ["l"="36.458,3.937"]
"Okrio/CRUSE" ["l"="36.879,4.173"]
"seorim0/ResUNet-LC" ["l"="36.313,4.176"]
"jhetherly/EnglishSpeechUpsampler" ["l"="36.747,4.152"]
"maum-ai/nuwave" ["l"="38.428,2.377"]
"descriptinc/melgan-neurips" ["l"="37.251,2.513"]
"zkx06111/WSRGlow" ["l"="38.425,2.486"]
"nils-werner/pymushra" ["l"="36.911,4.253"]
"merlresearch/tf-locoformer" ["l"="36.619,4.141"]
"BUTSpeechFIT/DiariZen" ["l"="36.894,3.141"]
"urgent-challenge/urgent2025_challenge" ["l"="36.707,4.151"]
"yaoxunji/gen-se" ["l"="36.812,4.031"]
"Kevin-naticl/LLaSE-G1" ["l"="36.831,4.014"]
"lucidrains/minGRU-pytorch" ["l"="36.848,4.105"]
"ssi-research/FQSE" ["l"="36.88,4.07"]
"cheind/mingru" ["l"="36.887,4.055"]
"lucidrains/adam-atan2-pytorch" ["l"="36.906,4.07"]
"Perception-and-Neurodynamics-Laboratory/Matlab-toolbox-for-DNN-based-speech-separation" ["l"="36.631,4.631"]
"philipperemy/timit" ["l"="36.695,4.544"]
"Faur/TIMIT" ["l"="36.676,4.603"]
"jzlianglu/pykaldi2" ["l"="35.719,2.361"]
"axion66/minLSTM-implementation" ["l"="36.917,4.026"]
"laserb/deep-vocal-isolation" ["l"="36.441,4.497"]
"stephencwelch/self_driving_cars" ["l"="37.439,4.267"]
"nanless/universal-speech-enhancement" ["l"="36.425,4.055"]
"zelokuo/VPIDM" ["l"="36.461,4.077"]
"jewhoguy/SRP-PHAT" ["l"="36.868,4.578"]
"linsir6/JavaNote" ["l"="37.61,4.66"]
"linsir6/ReactNativeNote" ["l"="37.626,4.661"]
"linsir6/mCustomView" ["l"="37.64,4.652"]
"dotEngine/dotEngine-android-sdk-example" ["l"="37.626,4.616"]
"mars-ma/CallMe" ["l"="37.391,4.579"]
"Tympan/Tympan_Rev_D_Hardware" ["l"="37.07,4.228"]
"XianruiWang/FastICA" ["l"="36.505,4.71"]
"robical/BlindSourceSeparation" ["l"="36.524,4.719"]
"SiavashShams/ssamba" ["l"="36.591,4.094"]
"eloimoliner/BABE2-music-restoration" ["l"="36.704,4.111"]
"kaistmm/Audio-Mamba-AuM" ["l"="36.53,3.998"]
"JiuFengSC/ElasticAST" ["l"="36.519,3.96"]
"SarthakYadav/audio-mamba-official" ["l"="36.503,3.97"]
"line/open-universe" ["l"="36.519,4.113"]
"wyw97/DENSE" ["l"="36.482,4.183"]
"ramon-astudillo/stft_up_tools" ["l"="36.979,4.436"]
"werman/noise-suppression-for-voice" ["l"="-14.307,-0.8"]
"alexa-pi/AlexaPi" ["l"="35.533,1.424"]
"simonsuthers/Speech-Separation" ["l"="36.527,4.528"]
"respeaker/mic_hat" ["l"="36.944,4.657"]
"SeeedDocument/ReSpeaker-4-Mic-Array-for-Raspberry-Pi" ["l"="36.948,4.682"]
"hjkwon0609/source_separation_ml_jeju" ["l"="36.51,4.456"]
"sungheonpark/music_source_sepearation_SH_net" ["l"="36.516,4.436"]
"leimao/Singing-Voice-Separation-RNN" ["l"="36.498,4.435"]
"zhongyuanzhao/dl_ofdm" ["l"="55.603,4.511"]
"js3611/Deep-MRI-Reconstruction" ["l"="-35.376,23.111"]
"ASLP-lab/LLaSE-G1" ["l"="36.862,3.988"]
"ASLP-lab/C2SER" ["l"="36.88,3.973"]
"YorLife/webRTC-" ["l"="36.748,4.655"]
"fotisdr/aecnn-rpi" ["l"="36.67,4.554"]
"amjadsaadeh/pyMUSIC" ["l"="37.104,4.661"]
"gionanide/Cryptography" ["l"="36.849,4.876"]
"loehnertz/rattlesnake" ["l"="37.271,4.353"]
"Totoketchup/Adaptive-MultiSpeaker-Separation" ["l"="36.51,4.554"]
"nihospr01/OpenSpeechPlatform-2020B" ["l"="37.028,4.212"]
"linsir6/IOSNote" ["l"="37.643,4.678"]
}