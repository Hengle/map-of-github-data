digraph G {
"facebookresearch/LAMA" -> "facebookresearch/KILT" ["e"=1]
"facebookresearch/LAMA" -> "facebookresearch/DPR" ["e"=1]
"facebookresearch/LAMA" -> "jzbjyb/LPAQA"
"facebookresearch/LAMA" -> "facebookresearch/XLM" ["e"=1]
"facebookresearch/LAMA" -> "facebookresearch/BLINK" ["e"=1]
"facebookresearch/LAMA" -> "ucinlp/autoprompt"
"facebookresearch/LAMA" -> "thunlp/ERNIE" ["e"=1]
"facebookresearch/LAMA" -> "atcbosselut/comet-commonsense" ["e"=1]
"facebookresearch/LAMA" -> "THUDM/P-tuning"
"facebookresearch/LAMA" -> "google-research/electra" ["e"=1]
"facebookresearch/LAMA" -> "facebookresearch/GENRE" ["e"=1]
"facebookresearch/LAMA" -> "princeton-nlp/LM-BFF"
"facebookresearch/LAMA" -> "nyu-mll/jiant" ["e"=1]
"facebookresearch/LAMA" -> "namisan/mt-dnn" ["e"=1]
"facebookresearch/LAMA" -> "danqi/acl2020-openqa-tutorial" ["e"=1]
"strawberrypie/bert_adapter" -> "cs-mshah/Adapter-Bert"
"google-research/adapter-bert" -> "AsaCooperStickland/Bert-n-Pals"
"google-research/adapter-bert" -> "adapter-hub/adapters"
"google-research/adapter-bert" -> "strawberrypie/bert_adapter"
"google-research/adapter-bert" -> "jxhe/unify-parameter-efficient-tuning"
"google-research/adapter-bert" -> "XiangLi1999/PrefixTuning"
"google-research/adapter-bert" -> "clarkkev/attention-analysis" ["e"=1]
"google-research/adapter-bert" -> "facebookresearch/LAMA"
"google-research/adapter-bert" -> "microsoft/K-Adapter" ["e"=1]
"google-research/adapter-bert" -> "THUDM/P-tuning"
"google-research/adapter-bert" -> "princeton-nlp/LM-BFF"
"adapter-hub/adapters" -> "jxhe/unify-parameter-efficient-tuning"
"adapter-hub/adapters" -> "thunlp/OpenDelta"
"adapter-hub/adapters" -> "XiangLi1999/PrefixTuning"
"adapter-hub/adapters" -> "thunlp/OpenPrompt"
"adapter-hub/adapters" -> "bigscience-workshop/promptsource" ["e"=1]
"adapter-hub/adapters" -> "huggingface/peft" ["e"=1]
"adapter-hub/adapters" -> "AGI-Edgerunners/LLM-Adapters"
"adapter-hub/adapters" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"adapter-hub/adapters" -> "thunlp/PromptPapers"
"adapter-hub/adapters" -> "makcedward/nlpaug" ["e"=1]
"adapter-hub/adapters" -> "THUDM/P-tuning-v2" ["e"=1]
"adapter-hub/adapters" -> "allenai/RL4LMs" ["e"=1]
"adapter-hub/adapters" -> "CarperAI/trlx" ["e"=1]
"adapter-hub/adapters" -> "timoschick/pet"
"adapter-hub/adapters" -> "princeton-nlp/SimCSE" ["e"=1]
"timoschick/pet" -> "princeton-nlp/LM-BFF"
"timoschick/pet" -> "THUDM/P-tuning"
"timoschick/pet" -> "timoschick/fewglue"
"timoschick/pet" -> "rrmenon10/ADAPET"
"timoschick/pet" -> "XiangLi1999/PrefixTuning"
"timoschick/pet" -> "thunlp/OpenPrompt"
"timoschick/pet" -> "thunlp/PromptPapers"
"timoschick/pet" -> "princeton-nlp/SimCSE" ["e"=1]
"timoschick/pet" -> "ucinlp/autoprompt"
"timoschick/pet" -> "marcotcr/checklist" ["e"=1]
"timoschick/pet" -> "THUDM/P-tuning-v2" ["e"=1]
"timoschick/pet" -> "makcedward/nlpaug" ["e"=1]
"timoschick/pet" -> "google-research/multilingual-t5" ["e"=1]
"timoschick/pet" -> "bigscience-workshop/promptsource" ["e"=1]
"timoschick/pet" -> "tonyzhaozh/few-shot-learning"
"ucinlp/autoprompt" -> "princeton-nlp/LM-BFF"
"ucinlp/autoprompt" -> "THUDM/P-tuning"
"ucinlp/autoprompt" -> "XiangLi1999/PrefixTuning"
"ucinlp/autoprompt" -> "jzbjyb/LPAQA"
"ucinlp/autoprompt" -> "timoschick/pet"
"ucinlp/autoprompt" -> "Eric-Wallace/universal-triggers" ["e"=1]
"ucinlp/autoprompt" -> "princeton-nlp/OptiPrompt"
"ucinlp/autoprompt" -> "facebookresearch/LAMA"
"ucinlp/autoprompt" -> "thunlp/OpenPrompt"
"ucinlp/autoprompt" -> "tonyzhaozh/few-shot-learning"
"ucinlp/autoprompt" -> "kipgparker/soft-prompt-tuning"
"ucinlp/autoprompt" -> "thunlp/PromptPapers"
"ucinlp/autoprompt" -> "keirp/automatic_prompt_engineer" ["e"=1]
"ucinlp/autoprompt" -> "thunlp/OpenDelta"
"ucinlp/autoprompt" -> "google-research-datasets/KELM-corpus"
"google-research/task_adaptation" -> "dongzelian/SSF"
"google-research/task_adaptation" -> "ZhangYuanhan-AI/NOAH"
"google-research/task_adaptation" -> "hjbahng/visual_prompting"
"google-research/task_adaptation" -> "KMnP/vpt"
"google-research/task_adaptation" -> "JieShibo/PETL-ViT"
"google-research/task_adaptation" -> "google-research/head2toe"
"yyhhenry/tank" -> "pufanyi/syphus"
"jzbjyb/LPAQA" -> "princeton-nlp/OptiPrompt"
"timoschick/fewglue" -> "timoschick/pet"
"thunlp/PromptPapers" -> "thunlp/OpenPrompt"
"thunlp/PromptPapers" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"thunlp/PromptPapers" -> "princeton-nlp/SimCSE" ["e"=1]
"thunlp/PromptPapers" -> "thunlp/PLMpapers" ["e"=1]
"thunlp/PromptPapers" -> "XiangLi1999/PrefixTuning"
"thunlp/PromptPapers" -> "THUDM/P-tuning-v2" ["e"=1]
"thunlp/PromptPapers" -> "km1994/nlp_paper_study" ["e"=1]
"thunlp/PromptPapers" -> "THUDM/P-tuning"
"thunlp/PromptPapers" -> "bigscience-workshop/promptsource" ["e"=1]
"thunlp/PromptPapers" -> "thunlp/OpenDelta"
"thunlp/PromptPapers" -> "MLNLP-World/Paper-Writing-Tips" ["e"=1]
"thunlp/PromptPapers" -> "timoschick/pet"
"thunlp/PromptPapers" -> "yizhongw/self-instruct" ["e"=1]
"thunlp/PromptPapers" -> "princeton-nlp/LM-BFF"
"thunlp/PromptPapers" -> "CLUEbenchmark/CLUE" ["e"=1]
"sagizty/Insight" -> "sagizty/MAE"
"sagizty/Insight" -> "sagizty/Multi-Stage-Hybrid-Transformer"
"sagizty/Insight" -> "sagizty/NTUS_application"
"sagizty/Insight" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/Insight" -> "sagizty/sagizty"
"sagizty/Insight" -> "sagizty/VPT"
"sagizty/Insight" -> "lsqqqq/notifyemail"
"lsqqqq/notifyemail" -> "sagizty/MAE"
"lsqqqq/notifyemail" -> "sagizty/Multi-Stage-Hybrid-Transformer"
"XiangLi1999/PrefixTuning" -> "THUDM/P-tuning"
"XiangLi1999/PrefixTuning" -> "kipgparker/soft-prompt-tuning"
"XiangLi1999/PrefixTuning" -> "THUDM/P-tuning-v2" ["e"=1]
"XiangLi1999/PrefixTuning" -> "google-research/prompt-tuning"
"XiangLi1999/PrefixTuning" -> "princeton-nlp/LM-BFF"
"XiangLi1999/PrefixTuning" -> "thunlp/PromptPapers"
"XiangLi1999/PrefixTuning" -> "thunlp/OpenPrompt"
"XiangLi1999/PrefixTuning" -> "xlang-ai/UnifiedSKG" ["e"=1]
"XiangLi1999/PrefixTuning" -> "timoschick/pet"
"XiangLi1999/PrefixTuning" -> "jxhe/unify-parameter-efficient-tuning"
"XiangLi1999/PrefixTuning" -> "ucinlp/autoprompt"
"XiangLi1999/PrefixTuning" -> "mkshing/Prompt-Tuning"
"XiangLi1999/PrefixTuning" -> "jordiclive/ControlPrefixes"
"XiangLi1999/PrefixTuning" -> "adapter-hub/adapters"
"XiangLi1999/PrefixTuning" -> "allenai/natural-instructions" ["e"=1]
"TsinghuaAI/CPM-2-Pretrain" -> "TsinghuaAI/CPM-2-Finetune"
"TsinghuaAI/CPM-2-Pretrain" -> "TsinghuaAI/CPM-1-Finetune"
"TsinghuaAI/CPM-2-Pretrain" -> "TsinghuaAI/CPM"
"TsinghuaAI/CPM-2-Pretrain" -> "BAAI-WuDao/P-tuning"
"OpenBMB/BMInf" -> "OpenBMB/BMCook"
"OpenBMB/BMInf" -> "OpenBMB/CPM-Live"
"OpenBMB/BMInf" -> "OpenBMB/BMTrain"
"OpenBMB/BMInf" -> "OpenBMB/BMList"
"OpenBMB/BMInf" -> "OpenBMB/ModelCenter"
"OpenBMB/BMInf" -> "TsinghuaAI/CPM"
"OpenBMB/BMInf" -> "TsinghuaAI/CPM-1-Generate" ["e"=1]
"OpenBMB/BMInf" -> "TsinghuaAI/CPM-2-Pretrain"
"OpenBMB/BMInf" -> "TsinghuaAI/CPM-2-Finetune"
"OpenBMB/BMInf" -> "deepdialog/CPM-LM-TF2" ["e"=1]
"OpenBMB/BMInf" -> "thunlp/OpenDelta"
"OpenBMB/BMInf" -> "thu-coai/EVA" ["e"=1]
"OpenBMB/BMInf" -> "CLUEbenchmark/pCLUE" ["e"=1]
"OpenBMB/BMInf" -> "yangjianxin1/CPM" ["e"=1]
"OpenBMB/BMInf" -> "hpcaitech/EnergonAI" ["e"=1]
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/MAE"
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/NTUS_application"
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/sagizty"
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/Insight"
"sagizty/Multi-Stage-Hybrid-Transformer" -> "sagizty/VPT"
"google-research-datasets/KELM-corpus" -> "wenhuchen/KGPT" ["e"=1]
"jxhe/unify-parameter-efficient-tuning" -> "ylsung/Ladder-Side-Tuning"
"jxhe/unify-parameter-efficient-tuning" -> "ylsung/VL_adapter"
"jxhe/unify-parameter-efficient-tuning" -> "ShoufaChen/AdaptFormer"
"jxhe/unify-parameter-efficient-tuning" -> "adapter-hub/adapters"
"jxhe/unify-parameter-efficient-tuning" -> "JieShibo/PETL-ViT"
"jxhe/unify-parameter-efficient-tuning" -> "XiangLi1999/PrefixTuning"
"jxhe/unify-parameter-efficient-tuning" -> "thunlp/OpenDelta"
"jxhe/unify-parameter-efficient-tuning" -> "dongzelian/SSF"
"jxhe/unify-parameter-efficient-tuning" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"jxhe/unify-parameter-efficient-tuning" -> "KMnP/vpt"
"jxhe/unify-parameter-efficient-tuning" -> "AkariAsai/ATTEMPT"
"jxhe/unify-parameter-efficient-tuning" -> "r-three/t-few"
"jxhe/unify-parameter-efficient-tuning" -> "AGI-Edgerunners/LLM-Adapters"
"jxhe/unify-parameter-efficient-tuning" -> "ZhangYuanhan-AI/NOAH"
"jxhe/unify-parameter-efficient-tuning" -> "fuzihaofzh/AnalyzeParameterEfficientFinetune"
"grandchicken/1708SEM_ISIM" -> "sagizty/MAE"
"grandchicken/1708SEM_ISIM" -> "sagizty/NTUS_application"
"grandchicken/1708SEM_ISIM" -> "sagizty/Parallel-Hybrid-Transformer"
"grandchicken/1708SEM_ISIM" -> "sagizty/Multi-Stage-Hybrid-Transformer"
"kipgparker/soft-prompt-tuning" -> "mkshing/Prompt-Tuning"
"kipgparker/soft-prompt-tuning" -> "corolla-johnson/mkultra"
"kipgparker/soft-prompt-tuning" -> "XiangLi1999/PrefixTuning"
"kipgparker/soft-prompt-tuning" -> "google-research/prompt-tuning"
"kipgparker/soft-prompt-tuning" -> "Zeng-WH/Prompt-Tuning"
"kipgparker/soft-prompt-tuning" -> "qhduan/mt5-soft-prompt-tuning"
"kipgparker/soft-prompt-tuning" -> "exelents/soft-prompt-tuning"
"kipgparker/soft-prompt-tuning" -> "THUDM/P-tuning"
"kipgparker/soft-prompt-tuning" -> "txsun1997/Black-Box-Tuning" ["e"=1]
"kipgparker/soft-prompt-tuning" -> "hiaoxui/soft-prompts"
"kipgparker/soft-prompt-tuning" -> "thu-coai/PPT"
"kipgparker/soft-prompt-tuning" -> "thunlp/PTR"
"kipgparker/soft-prompt-tuning" -> "jordiclive/ControlPrefixes"
"kipgparker/soft-prompt-tuning" -> "AkariAsai/ATTEMPT"
"kipgparker/soft-prompt-tuning" -> "ucinlp/autoprompt"
"IntelLabs/academic-budget-bert" -> "princeton-nlp/DinkyTrain"
"princeton-nlp/LM-BFF" -> "ucinlp/autoprompt"
"princeton-nlp/LM-BFF" -> "timoschick/pet"
"princeton-nlp/LM-BFF" -> "XiangLi1999/PrefixTuning"
"princeton-nlp/LM-BFF" -> "THUDM/P-tuning"
"princeton-nlp/LM-BFF" -> "princeton-nlp/OptiPrompt"
"princeton-nlp/LM-BFF" -> "rrmenon10/ADAPET"
"princeton-nlp/LM-BFF" -> "tonyzhaozh/few-shot-learning"
"princeton-nlp/LM-BFF" -> "princeton-nlp/DensePhrases" ["e"=1]
"princeton-nlp/LM-BFF" -> "thunlp/PromptPapers"
"princeton-nlp/LM-BFF" -> "yym6472/ConSERT" ["e"=1]
"princeton-nlp/LM-BFF" -> "princeton-nlp/SimCSE" ["e"=1]
"princeton-nlp/LM-BFF" -> "zjunlp/DART" ["e"=1]
"princeton-nlp/LM-BFF" -> "thunlp/OpenPrompt"
"princeton-nlp/LM-BFF" -> "facebookresearch/DPR" ["e"=1]
"princeton-nlp/LM-BFF" -> "microsoft/ANCE" ["e"=1]
"THUDM/P-tuning" -> "THUDM/P-tuning-v2" ["e"=1]
"THUDM/P-tuning" -> "XiangLi1999/PrefixTuning"
"THUDM/P-tuning" -> "bojone/P-tuning" ["e"=1]
"THUDM/P-tuning" -> "timoschick/pet"
"THUDM/P-tuning" -> "princeton-nlp/LM-BFF"
"THUDM/P-tuning" -> "kipgparker/soft-prompt-tuning"
"THUDM/P-tuning" -> "ucinlp/autoprompt"
"THUDM/P-tuning" -> "thunlp/PromptPapers"
"THUDM/P-tuning" -> "google-research/prompt-tuning"
"THUDM/P-tuning" -> "THUDM/GLM" ["e"=1]
"THUDM/P-tuning" -> "thunlp/OpenPrompt"
"THUDM/P-tuning" -> "princeton-nlp/SimCSE" ["e"=1]
"THUDM/P-tuning" -> "bojone/Pattern-Exploiting-Training" ["e"=1]
"THUDM/P-tuning" -> "facebookresearch/LAMA"
"THUDM/P-tuning" -> "thunlp/OpenDelta"
"tonyzhaozh/few-shot-learning" -> "peterwestuw/surface-form-competition"
"tonyzhaozh/few-shot-learning" -> "princeton-nlp/LM-BFF"
"tonyzhaozh/few-shot-learning" -> "ethanjperez/true_few_shot"
"tonyzhaozh/few-shot-learning" -> "Alrope123/rethinking-demonstrations" ["e"=1]
"tonyzhaozh/few-shot-learning" -> "ucinlp/autoprompt"
"tonyzhaozh/few-shot-learning" -> "timoschick/pet"
"tonyzhaozh/few-shot-learning" -> "urvashik/knnlm" ["e"=1]
"TsinghuaAI/CPM-KG" -> "TsinghuaAI/CPM-1-Finetune"
"thunlp/PTR" -> "zjunlp/KnowPrompt"
"thunlp/PTR" -> "wzhouad/RE_improved_baseline" ["e"=1]
"thunlp/PTR" -> "thunlp/KnowledgeablePromptTuning"
"BAAI-WuDao/Model" -> "BAAI-WuDao/CogView"
"BAAI-WuDao/CogView" -> "BAAI-WuDao/P-tuning"
"BAAI-WuDao/CogView" -> "BAAI-WuDao/CPM"
"TsinghuaAI/CPM" -> "TsinghuaAI/CPM-2-Finetune"
"TsinghuaAI/CPM" -> "TsinghuaAI/CPM-2-Pretrain"
"TsinghuaAI/CPM" -> "TsinghuaAI/CPM-1-Pretrain"
"TsinghuaAI/CPM" -> "OpenBMB/BMInf"
"TsinghuaAI/CPM" -> "thu-coai/EVA" ["e"=1]
"sagizty/Parallel-Hybrid-Transformer" -> "sagizty/NTUS_application"
"sagizty/Parallel-Hybrid-Transformer" -> "sagizty/MAE"
"sagizty/Parallel-Hybrid-Transformer" -> "sagizty/sagizty"
"corolla-johnson/mkultra" -> "mkshing/Prompt-Tuning"
"corolla-johnson/mkultra" -> "kipgparker/soft-prompt-tuning"
"corolla-johnson/mkultra" -> "exelents/soft-prompt-tuning"
"rabeehk/hyperformer" -> "AkariAsai/ATTEMPT"
"rabeehk/hyperformer" -> "rabeehk/compacter"
"rabeehk/hyperformer" -> "McGill-NLP/polytropon"
"rabeehk/hyperformer" -> "ylsung/VL_adapter"
"rrmenon10/ADAPET" -> "ethanjperez/true_few_shot"
"TsinghuaAI/CPM-2-Finetune" -> "TsinghuaAI/CPM-2-Pretrain"
"TsinghuaAI/CPM-2-Finetune" -> "TsinghuaAI/CPM"
"thunlp/Prompt-Transferability" -> "RUCAIBox/Transfer-Prompts-for-Text-Generation"
"ethanjperez/true_few_shot" -> "rrmenon10/ADAPET"
"TsinghuaAI/CPM-1-Finetune" -> "jm12138/CPM-Generate-Pytorch"
"TsinghuaAI/CPM-1-Finetune" -> "BAAI-WuDao/EVA"
"TsinghuaAI/CPM-1-Finetune" -> "TsinghuaAI/CPM-KG"
"TsinghuaAI/CPM-1-Finetune" -> "TsinghuaAI/TDS"
"princeton-nlp/OptiPrompt" -> "princeton-nlp/EntityQuestions" ["e"=1]
"princeton-nlp/OptiPrompt" -> "princeton-nlp/DinkyTrain"
"princeton-nlp/OptiPrompt" -> "princeton-nlp/rationale-robustness"
"TsinghuaAI/CPM-1-Pretrain" -> "TsinghuaAI/TDS"
"TsinghuaAI/CPM-1-Pretrain" -> "TsinghuaAI/CPM-1-Distill"
"jm12138/CPM-Generate-Pytorch" -> "TsinghuaAI/CPM-1-Finetune"
"BAAI-WuDao/Chinese-Transformer-XL" -> "BAAI-WuDao/GLM"
"BAAI-WuDao/Chinese-Transformer-XL" -> "BAAI-WuDao/CPM"
"BAAI-WuDao/GLM" -> "BAAI-WuDao/Chinese-Transformer-XL"
"BAAI-WuDao/CPM" -> "BAAI-WuDao/Chinese-Transformer-XL"
"TsinghuaAI/TDS" -> "TsinghuaAI/CPM-1-Pretrain"
"thunlp/OpenPrompt" -> "thunlp/PromptPapers"
"thunlp/OpenPrompt" -> "thunlp/OpenDelta"
"thunlp/OpenPrompt" -> "bigscience-workshop/promptsource" ["e"=1]
"thunlp/OpenPrompt" -> "princeton-nlp/SimCSE" ["e"=1]
"thunlp/OpenPrompt" -> "THUDM/P-tuning-v2" ["e"=1]
"thunlp/OpenPrompt" -> "XiangLi1999/PrefixTuning"
"thunlp/OpenPrompt" -> "timoschick/pet"
"thunlp/OpenPrompt" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"thunlp/OpenPrompt" -> "CLUEbenchmark/CLUE" ["e"=1]
"thunlp/OpenPrompt" -> "LianjiaTech/BELLE" ["e"=1]
"thunlp/OpenPrompt" -> "THUDM/P-tuning"
"thunlp/OpenPrompt" -> "km1994/NLP-Interview-Notes" ["e"=1]
"thunlp/OpenPrompt" -> "km1994/nlp_paper_study" ["e"=1]
"thunlp/OpenPrompt" -> "dbiir/UER-py" ["e"=1]
"thunlp/OpenPrompt" -> "adapter-hub/adapters"
"KaiyangZhou/CoOp" -> "muzairkhattak/multimodal-prompt-learning"
"KaiyangZhou/CoOp" -> "KMnP/vpt"
"KaiyangZhou/CoOp" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"KaiyangZhou/CoOp" -> "gaopengcuhk/Tip-Adapter"
"KaiyangZhou/CoOp" -> "gaopengcuhk/CLIP-Adapter"
"KaiyangZhou/CoOp" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"KaiyangZhou/CoOp" -> "raoyongming/DenseCLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "microsoft/GLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "salesforce/ALBEF" ["e"=1]
"KaiyangZhou/CoOp" -> "muzairkhattak/PromptSRC"
"KaiyangZhou/CoOp" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs"
"KaiyangZhou/CoOp" -> "mlfoundations/open_clip" ["e"=1]
"KaiyangZhou/CoOp" -> "yzhuoning/Awesome-CLIP"
"KaiyangZhou/CoOp" -> "salesforce/BLIP" ["e"=1]
"KaiyangZhou/CoOp" -> "salesforce/LAVIS" ["e"=1]
"sagizty/VPT" -> "sagizty/MAE"
"sagizty/VPT" -> "sagizty/Multi-Stage-Hybrid-Transformer"
"sagizty/VPT" -> "sagizty/NTUS_application"
"sagizty/VPT" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/VPT" -> "sagizty/sagizty"
"sagizty/VPT" -> "sagizty/Insight"
"sagizty/VPT" -> "ZhangYuanhan-AI/NOAH"
"Yutong-Zhou-cv/Awesome-Multimodality" -> "Yutong-Zhou-cv/Awesome-Transformer-in-CV"
"Yutong-Zhou-cv/Awesome-Multimodality" -> "wangxiao5791509/MultiModal_BigModels_Survey"
"thunlp/OpenDelta" -> "thunlp/OpenPrompt"
"thunlp/OpenDelta" -> "thunlp/DeltaPapers"
"thunlp/OpenDelta" -> "OpenBMB/BMTrain"
"thunlp/OpenDelta" -> "jxhe/unify-parameter-efficient-tuning"
"thunlp/OpenDelta" -> "thunlp/PromptPapers"
"thunlp/OpenDelta" -> "OpenBMB/CPM-Live"
"thunlp/OpenDelta" -> "adapter-hub/adapters"
"thunlp/OpenDelta" -> "txsun1997/LMaaS-Papers" ["e"=1]
"thunlp/OpenDelta" -> "txsun1997/Black-Box-Tuning" ["e"=1]
"thunlp/OpenDelta" -> "XiangLi1999/PrefixTuning"
"thunlp/OpenDelta" -> "OpenBMB/BMInf"
"thunlp/OpenDelta" -> "OpenBMB/ModelCenter"
"thunlp/OpenDelta" -> "THUDM/P-tuning"
"thunlp/OpenDelta" -> "princeton-nlp/LM-BFF"
"thunlp/OpenDelta" -> "thunlp/UltraChat" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"yzhuoning/Awesome-CLIP" -> "KaiyangZhou/CoOp"
"yzhuoning/Awesome-CLIP" -> "raoyongming/DenseCLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "gaopengcuhk/CLIP-Adapter"
"yzhuoning/Awesome-CLIP" -> "Sense-GVT/DeCLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "microsoft/GLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "dk-liang/Awesome-Visual-Transformer" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "jingyi0000/VLM_survey" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "ShoufaChen/DiffusionDet" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "mlfoundations/open_clip" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "yuewang-cuhk/awesome-vision-language-pretraining-papers" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "facebookresearch/SLIP" ["e"=1]
"yzhuoning/Awesome-CLIP" -> "gaopengcuhk/Tip-Adapter"
"yzhuoning/Awesome-CLIP" -> "TheShadow29/awesome-grounding" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "KMnP/vpt"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "muzairkhattak/multimodal-prompt-learning"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "KaiyangZhou/CoOp"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "yzhuoning/Awesome-CLIP"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "YuejiangLIU/awesome-source-free-test-time-adaptation" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "hjbahng/visual_prompting"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "gaopengcuhk/Tip-Adapter"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "DirtyHarryLYL/LLM-in-Vision" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "google-research/l2p" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "amirbar/visual_prompting" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "ZhangYuanhan-AI/NOAH"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "JindongGu/Awesome-Prompting-on-Vision-Language-Model"
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" -> "yuewang-cuhk/awesome-vision-language-pretraining-papers" ["e"=1]
"gaopengcuhk/Tip-Adapter" -> "gaopengcuhk/CLIP-Adapter"
"gaopengcuhk/Tip-Adapter" -> "OpenGVLab/CaFo"
"gaopengcuhk/Tip-Adapter" -> "KaiyangZhou/CoOp"
"gaopengcuhk/Tip-Adapter" -> "yangyangyang127/APE"
"gaopengcuhk/Tip-Adapter" -> "muzairkhattak/multimodal-prompt-learning"
"gaopengcuhk/Tip-Adapter" -> "linzhiqiu/cross_modal_adaptation"
"gaopengcuhk/Tip-Adapter" -> "raoyongming/DenseCLIP" ["e"=1]
"gaopengcuhk/Tip-Adapter" -> "sarahpratt/CuPL"
"gaopengcuhk/Tip-Adapter" -> "KMnP/vpt"
"gaopengcuhk/Tip-Adapter" -> "muzairkhattak/PromptSRC"
"gaopengcuhk/Tip-Adapter" -> "vishaal27/SuS-X"
"gaopengcuhk/Tip-Adapter" -> "CHENGY12/PLOT"
"gaopengcuhk/Tip-Adapter" -> "mrflogs/ICLR24" ["e"=1]
"gaopengcuhk/Tip-Adapter" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"gaopengcuhk/Tip-Adapter" -> "ZiyuGuo99/CALIP"
"ShoufaChen/AdaptFormer" -> "dongzelian/SSF"
"ShoufaChen/AdaptFormer" -> "JieShibo/PETL-ViT"
"ShoufaChen/AdaptFormer" -> "KMnP/vpt"
"ShoufaChen/AdaptFormer" -> "ZhangYuanhan-AI/NOAH"
"ShoufaChen/AdaptFormer" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"ShoufaChen/AdaptFormer" -> "jxhe/unify-parameter-efficient-tuning"
"ShoufaChen/AdaptFormer" -> "hustvl/MIMDet" ["e"=1]
"ShoufaChen/AdaptFormer" -> "hjbahng/visual_prompting"
"ShoufaChen/AdaptFormer" -> "czczup/ViT-Adapter" ["e"=1]
"ShoufaChen/AdaptFormer" -> "Leiyi-Hu/mona"
"ShoufaChen/AdaptFormer" -> "luogen1996/RepAdapter"
"ShoufaChen/AdaptFormer" -> "synbol/Awesome-Parameter-Efficient-Transfer-Learning" ["e"=1]
"ShoufaChen/AdaptFormer" -> "gaopengcuhk/Tip-Adapter"
"ylsung/VL_adapter" -> "ylsung/Ladder-Side-Tuning"
"ylsung/VL_adapter" -> "j-min/VL-T5" ["e"=1]
"ylsung/VL_adapter" -> "LeapLabTHU/Cross-Modal-Adapter" ["e"=1]
"ylsung/VL_adapter" -> "dongzelian/SSF"
"r-three/t-few" -> "bigscience-workshop/t-zero" ["e"=1]
"r-three/t-few" -> "AkariAsai/ATTEMPT"
"r-three/t-few" -> "microsoft/AdaMix"
"r-three/t-few" -> "ylsung/Ladder-Side-Tuning"
"r-three/t-few" -> "craffel/llm-seminar"
"r-three/t-few" -> "google-research/prompt-tuning"
"r-three/t-few" -> "jxhe/unify-parameter-efficient-tuning"
"r-three/t-few" -> "allenai/acl2022-zerofewshot-tutorial" ["e"=1]
"r-three/t-few" -> "txsun1997/Black-Box-Tuning" ["e"=1]
"r-three/t-few" -> "clinicalml/TabLLM" ["e"=1]
"r-three/t-few" -> "Shark-NLP/OpenICL" ["e"=1]
"r-three/t-few" -> "ylsung/VL_adapter"
"r-three/t-few" -> "tonyzhaozh/few-shot-learning"
"r-three/t-few" -> "facebookresearch/tart" ["e"=1]
"r-three/t-few" -> "thunlp/Prompt-Transferability"
"ylsung/Ladder-Side-Tuning" -> "ylsung/VL_adapter"
"ylsung/Ladder-Side-Tuning" -> "jxhe/unify-parameter-efficient-tuning"
"ylsung/Ladder-Side-Tuning" -> "dongzelian/SSF"
"ylsung/Ladder-Side-Tuning" -> "Paranioar/UniPT" ["e"=1]
"McGill-NLP/polytropon" -> "microsoft/mttl"
"thunlp/KnowledgeablePromptTuning" -> "wjn1996/TransPrompt" ["e"=1]
"thunlp/KnowledgeablePromptTuning" -> "zjunlp/KnowPrompt"
"thunlp/KnowledgeablePromptTuning" -> "thunlp/PTR"
"thunlp/KnowledgeablePromptTuning" -> "thu-coai/PPT"
"thunlp/KnowledgeablePromptTuning" -> "kongds/Prompt-BERT" ["e"=1]
"declare-lab/RelationPrompt" -> "dinobby/ZS-BERT"
"declare-lab/RelationPrompt" -> "ssnvxia/OneRel" ["e"=1]
"wangxiao5791509/MultiModal_BigModels_Survey" -> "muzairkhattak/multimodal-prompt-learning"
"wangxiao5791509/MultiModal_BigModels_Survey" -> "Yutong-Zhou-cv/Awesome-Multimodality"
"gaopengcuhk/CLIP-Adapter" -> "gaopengcuhk/Tip-Adapter"
"gaopengcuhk/CLIP-Adapter" -> "KaiyangZhou/CoOp"
"gaopengcuhk/CLIP-Adapter" -> "OpenGVLab/CaFo"
"gaopengcuhk/CLIP-Adapter" -> "muzairkhattak/multimodal-prompt-learning"
"gaopengcuhk/CLIP-Adapter" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"gaopengcuhk/CLIP-Adapter" -> "raoyongming/DenseCLIP" ["e"=1]
"gaopengcuhk/CLIP-Adapter" -> "linzhiqiu/cross_modal_adaptation"
"gaopengcuhk/CLIP-Adapter" -> "KMnP/vpt"
"gaopengcuhk/CLIP-Adapter" -> "yangyangyang127/APE"
"gaopengcuhk/CLIP-Adapter" -> "ylsung/VL_adapter"
"gaopengcuhk/CLIP-Adapter" -> "sarahpratt/CuPL"
"gaopengcuhk/CLIP-Adapter" -> "mlfoundations/wise-ft" ["e"=1]
"gaopengcuhk/CLIP-Adapter" -> "BeierZhu/Prompt-align"
"gaopengcuhk/CLIP-Adapter" -> "muzairkhattak/PromptSRC"
"gaopengcuhk/CLIP-Adapter" -> "CHENGY12/PLOT"
"tonyhuang2022/UPL" -> "BatsResearch/menghini-neurips23-code" ["e"=1]
"tonyhuang2022/UPL" -> "yuhangzang/UPT"
"tonyhuang2022/UPL" -> "korawat-tanwisuth/POUF"
"tonyhuang2022/UPL" -> "CEWu/PTNL"
"hongfz16/Garment4D" -> "hongfz16/HCMoCo"
"OpenBMB/CPM-Live" -> "OpenBMB/BMTrain"
"OpenBMB/CPM-Live" -> "OpenBMB/ModelCenter"
"OpenBMB/CPM-Live" -> "OpenBMB/BMCook"
"OpenBMB/CPM-Live" -> "OpenBMB/BMList"
"OpenBMB/CPM-Live" -> "OpenBMB/BMInf"
"OpenBMB/CPM-Live" -> "thunlp/OpenDelta"
"OpenBMB/CPM-Live" -> "thu-coai/EVA" ["e"=1]
"OpenBMB/CPM-Live" -> "thunlp/WebCPM" ["e"=1]
"OpenBMB/CPM-Live" -> "OpenBMB/CPM-Bee" ["e"=1]
"OpenBMB/CPM-Live" -> "Langboat/Mengzi" ["e"=1]
"google-research/prompt-tuning" -> "XiangLi1999/PrefixTuning"
"google-research/prompt-tuning" -> "kipgparker/soft-prompt-tuning"
"google-research/prompt-tuning" -> "mkshing/Prompt-Tuning"
"google-research/prompt-tuning" -> "THUDM/P-tuning"
"google-research/prompt-tuning" -> "THUDM/P-tuning-v2" ["e"=1]
"google-research/prompt-tuning" -> "thu-coai/PPT"
"google-research/prompt-tuning" -> "r-three/t-few"
"google-research/prompt-tuning" -> "AkariAsai/ATTEMPT"
"google-research/prompt-tuning" -> "jxhe/unify-parameter-efficient-tuning"
"google-research/prompt-tuning" -> "bigscience-workshop/t-zero" ["e"=1]
"google-research/prompt-tuning" -> "thunlp/Prompt-Transferability"
"google-research/prompt-tuning" -> "princeton-nlp/LM-BFF"
"google-research/prompt-tuning" -> "corolla-johnson/mkultra"
"google-research/prompt-tuning" -> "thunlp/OpenPrompt"
"google-research/prompt-tuning" -> "google-research/t5x" ["e"=1]
"OpenBMB/BMTrain" -> "OpenBMB/ModelCenter"
"OpenBMB/BMTrain" -> "OpenBMB/BMCook"
"OpenBMB/BMTrain" -> "OpenBMB/CPM-Live"
"OpenBMB/BMTrain" -> "OpenBMB/BMInf"
"OpenBMB/BMTrain" -> "OpenBMB/BMList"
"OpenBMB/BMTrain" -> "thunlp/OpenDelta"
"OpenBMB/ModelCenter" -> "OpenBMB/BMTrain"
"OpenBMB/ModelCenter" -> "OpenBMB/BMCook"
"OpenBMB/ModelCenter" -> "OpenBMB/CPM-Live"
"OpenBMB/ModelCenter" -> "OpenBMB/BMList"
"OpenBMB/ModelCenter" -> "OpenBMB/BMInf"
"princeton-nlp/DinkyTrain" -> "princeton-nlp/OptiPrompt"
"hjbahng/visual_prompting" -> "KMnP/vpt"
"hjbahng/visual_prompting" -> "changdaeoh/BlackVIP"
"hjbahng/visual_prompting" -> "shikiw/DAM-VP" ["e"=1]
"hjbahng/visual_prompting" -> "amirbar/visual_prompting" ["e"=1]
"hjbahng/visual_prompting" -> "UCSC-VLAA/EVP"
"hjbahng/visual_prompting" -> "OPTML-Group/ILM-VP"
"hjbahng/visual_prompting" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"hjbahng/visual_prompting" -> "muzairkhattak/multimodal-prompt-learning"
"hjbahng/visual_prompting" -> "dongzelian/SSF"
"hjbahng/visual_prompting" -> "ZhangYuanhan-AI/NOAH"
"hjbahng/visual_prompting" -> "gaopengcuhk/Tip-Adapter"
"hjbahng/visual_prompting" -> "ShoufaChen/AdaptFormer"
"hjbahng/visual_prompting" -> "sagizty/VPT"
"hjbahng/visual_prompting" -> "yuhangzang/UPT"
"hjbahng/visual_prompting" -> "azshue/TPT"
"ZhangYuanhan-AI/Bamboo" -> "ZhangYuanhan-AI/OmniBenchmark"
"ZhangYuanhan-AI/Bamboo" -> "KaiyangZhou/on-device-dg"
"ZhangYuanhan-AI/Bamboo" -> "hongfz16/HCMoCo"
"ZhangYuanhan-AI/Bamboo" -> "hongfz16/Garment4D"
"AkariAsai/ATTEMPT" -> "ShiZhengyan/DePT"
"sagizty/NTUS_application" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/NTUS_application" -> "sagizty/MAE"
"sagizty/NTUS_application" -> "sagizty/sagizty"
"sagizty/MAE" -> "sagizty/NTUS_application"
"sagizty/MAE" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/MAE" -> "sagizty/sagizty"
"sagizty/MAE" -> "sagizty/Multi-Stage-Hybrid-Transformer"
"thunlp/DeltaPapers" -> "thunlp/OpenDelta"
"thunlp/DeltaPapers" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"thunlp/DeltaPapers" -> "txsun1997/Black-Box-Tuning" ["e"=1]
"thunlp/DeltaPapers" -> "cambridgeltl/autopeft"
"thunlp/DeltaPapers" -> "calpt/awesome-adapter-resources"
"jordiclive/ControlPrefixes" -> "EagleW/Stage-wise-Fine-tuning"
"jordiclive/ControlPrefixes" -> "RUCAIBox/Transfer-Prompts-for-Text-Generation"
"zjunlp/KnowPrompt" -> "zjunlp/PromptKG" ["e"=1]
"zjunlp/KnowPrompt" -> "rtmaww/EntLM" ["e"=1]
"zjunlp/KnowPrompt" -> "thunlp/KnowledgeablePromptTuning"
"zjunlp/KnowPrompt" -> "thunlp/PTR"
"zjunlp/KnowPrompt" -> "declare-lab/RelationPrompt"
"zjunlp/KnowPrompt" -> "thu-coai/PPT"
"hongfz16/HCMoCo" -> "hongfz16/Garment4D"
"Arnav0400/ViT-Slim" -> "VITA-Group/UVC" ["e"=1]
"Arnav0400/ViT-Slim" -> "ZhangYuanhan-AI/NOAH"
"Arnav0400/ViT-Slim" -> "ziplab/SPT"
"Arnav0400/ViT-Slim" -> "dongzelian/SSF"
"Arnav0400/ViT-Slim" -> "luogen1996/RepAdapter"
"Arnav0400/ViT-Slim" -> "VITA-Group/SViTE" ["e"=1]
"mkshing/Prompt-Tuning" -> "kipgparker/soft-prompt-tuning"
"mkshing/Prompt-Tuning" -> "corolla-johnson/mkultra"
"mkshing/Prompt-Tuning" -> "Zeng-WH/Prompt-Tuning"
"mkshing/Prompt-Tuning" -> "google-research/prompt-tuning"
"OpenBMB/BMCook" -> "OpenBMB/ModelCenter"
"OpenBMB/BMCook" -> "OpenBMB/BMTrain"
"OpenBMB/BMCook" -> "OpenBMB/BMInf"
"OpenBMB/BMCook" -> "OpenBMB/BMList"
"OpenBMB/BMCook" -> "OpenBMB/CPM-Live"
"Zeng-WH/Prompt-Tuning" -> "mkshing/Prompt-Tuning"
"Jiahao000/ORL" -> "Jingkang50/EgoLife"
"BeierZhu/Prompt-align" -> "CHENGY12/PLOT"
"BeierZhu/Prompt-align" -> "BeierZhu/xERM"
"BeierZhu/Prompt-align" -> "muzairkhattak/PromptSRC"
"BeierZhu/Prompt-align" -> "yxymessi/H2E-Framework"
"ShiZhengyan/StepGame" -> "ZhengxiangShi/LearnToAsk"
"ShiZhengyan/StepGame" -> "amzn/pretraining-or-self-training"
"ShiZhengyan/StepGame" -> "ShiZhengyan/PowerfulPromptFT"
"ShiZhengyan/StepGame" -> "Fangjun-Li/SpatialLM-StepGame"
"ShiZhengyan/StepGame" -> "ZhengxiangShi/SelfContrastiveLearningRecSys"
"muzairkhattak/multimodal-prompt-learning" -> "muzairkhattak/PromptSRC"
"muzairkhattak/multimodal-prompt-learning" -> "KaiyangZhou/CoOp"
"muzairkhattak/multimodal-prompt-learning" -> "KMnP/vpt"
"muzairkhattak/multimodal-prompt-learning" -> "gaopengcuhk/Tip-Adapter"
"muzairkhattak/multimodal-prompt-learning" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"muzairkhattak/multimodal-prompt-learning" -> "zhengli97/PromptKD"
"muzairkhattak/multimodal-prompt-learning" -> "gaopengcuhk/CLIP-Adapter"
"muzairkhattak/multimodal-prompt-learning" -> "muzairkhattak/ViFi-CLIP"
"muzairkhattak/multimodal-prompt-learning" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs"
"muzairkhattak/multimodal-prompt-learning" -> "CHENGY12/PLOT"
"muzairkhattak/multimodal-prompt-learning" -> "muzairkhattak/ProText"
"muzairkhattak/multimodal-prompt-learning" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"muzairkhattak/multimodal-prompt-learning" -> "jameelhassan/PromptAlign"
"muzairkhattak/multimodal-prompt-learning" -> "YiLunLee/missing_aware_prompts" ["e"=1]
"muzairkhattak/multimodal-prompt-learning" -> "azshue/TPT"
"muzairkhattak/ViFi-CLIP" -> "TalalWasim/Vita-CLIP" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "mbzuai-oryx/CVRR-Evaluation-Suite"
"muzairkhattak/ViFi-CLIP" -> "muzairkhattak/multimodal-prompt-learning"
"muzairkhattak/ViFi-CLIP" -> "ju-chen/Efficient-Prompt" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "sallymmx/ActionCLIP" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "whwu95/BIKE" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "jameelhassan/PromptAlign"
"muzairkhattak/ViFi-CLIP" -> "hanoonaR/object-centric-ovd" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "muzairkhattak/PromptSRC"
"muzairkhattak/ViFi-CLIP" -> "asif-hanif/vafa"
"muzairkhattak/ViFi-CLIP" -> "OpenGVLab/efficient-video-recognition" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "wengzejia1/Open-VCLIP" ["e"=1]
"muzairkhattak/ViFi-CLIP" -> "muzairkhattak/ProText"
"muzairkhattak/ViFi-CLIP" -> "mbzuai-oryx/VideoGLaMM"
"muzairkhattak/ViFi-CLIP" -> "TalalWasim/Video-FocalNets"
"linzhiqiu/cross_modal_adaptation" -> "OpenGVLab/CaFo"
"linzhiqiu/cross_modal_adaptation" -> "gaopengcuhk/Tip-Adapter"
"linzhiqiu/cross_modal_adaptation" -> "yangyangyang127/APE"
"linzhiqiu/cross_modal_adaptation" -> "gaopengcuhk/CLIP-Adapter"
"linzhiqiu/cross_modal_adaptation" -> "skingorz/FD-Align"
"linzhiqiu/cross_modal_adaptation" -> "muzairkhattak/multimodal-prompt-learning"
"linzhiqiu/cross_modal_adaptation" -> "sarahpratt/CuPL"
"linzhiqiu/cross_modal_adaptation" -> "mrflogs/SHIP" ["e"=1]
"linzhiqiu/cross_modal_adaptation" -> "KaiyangZhou/CoOp"
"linzhiqiu/cross_modal_adaptation" -> "vishaal27/SuS-X"
"linzhiqiu/cross_modal_adaptation" -> "YiLunLee/missing_aware_prompts" ["e"=1]
"linzhiqiu/cross_modal_adaptation" -> "ArmanAfrasiyabi/SetFeat-fs" ["e"=1]
"linzhiqiu/cross_modal_adaptation" -> "muzairkhattak/PromptSRC"
"linzhiqiu/cross_modal_adaptation" -> "sachit-menon/classify_by_description_release"
"linzhiqiu/cross_modal_adaptation" -> "LightDXY/FT-CLIP"
"KMnP/vpt" -> "KaiyangZhou/CoOp"
"KMnP/vpt" -> "muzairkhattak/multimodal-prompt-learning"
"KMnP/vpt" -> "hjbahng/visual_prompting"
"KMnP/vpt" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"KMnP/vpt" -> "ShoufaChen/AdaptFormer"
"KMnP/vpt" -> "dongzelian/SSF"
"KMnP/vpt" -> "gaopengcuhk/Tip-Adapter"
"KMnP/vpt" -> "sagizty/VPT"
"KMnP/vpt" -> "ZhangYuanhan-AI/NOAH"
"KMnP/vpt" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"KMnP/vpt" -> "JieShibo/PETL-ViT"
"KMnP/vpt" -> "gaopengcuhk/CLIP-Adapter"
"KMnP/vpt" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"KMnP/vpt" -> "microsoft/GLIP" ["e"=1]
"KMnP/vpt" -> "tim-learn/awesome-test-time-adaptation" ["e"=1]
"azshue/TPT" -> "jameelhassan/PromptAlign"
"azshue/TPT" -> "mr-eggplant/SAR" ["e"=1]
"azshue/TPT" -> "kdiAAA/TDA"
"azshue/TPT" -> "chunmeifeng/DiffTPT"
"azshue/TPT" -> "mzhaoshuai/RLCF"
"azshue/TPT" -> "zhangce01/DPE-CLIP"
"azshue/TPT" -> "muzairkhattak/PromptSRC"
"azshue/TPT" -> "CHENGY12/PLOT"
"azshue/TPT" -> "mrflogs/SHIP" ["e"=1]
"azshue/TPT" -> "ShuvenduRoy/CoPrompt"
"azshue/TPT" -> "DequanWang/tent" ["e"=1]
"azshue/TPT" -> "qinenergy/cotta" ["e"=1]
"azshue/TPT" -> "BeierZhu/Prompt-align"
"azshue/TPT" -> "FarinaMatteo/zero"
"azshue/TPT" -> "Bala93/CLIPCalib"
"sachit-menon/classify_by_description_release" -> "ExplainableML/WaffleCLIP"
"sachit-menon/classify_by_description_release" -> "sarahpratt/CuPL"
"sachit-menon/classify_by_description_release" -> "mertyg/vision-language-models-are-bows" ["e"=1]
"dongzelian/SSF" -> "JieShibo/PETL-ViT"
"dongzelian/SSF" -> "ShoufaChen/AdaptFormer"
"dongzelian/SSF" -> "ZhangYuanhan-AI/NOAH"
"dongzelian/SSF" -> "ziplab/SPT"
"dongzelian/SSF" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"dongzelian/SSF" -> "DavidYanAnDe/ARC"
"dongzelian/SSF" -> "KMnP/vpt"
"dongzelian/SSF" -> "ylsung/VL_adapter"
"dongzelian/SSF" -> "luogen1996/RepAdapter"
"JieShibo/PETL-ViT" -> "ZhangYuanhan-AI/NOAH"
"JieShibo/PETL-ViT" -> "dongzelian/SSF"
"JieShibo/PETL-ViT" -> "ShoufaChen/AdaptFormer"
"JieShibo/PETL-ViT" -> "ylsung/VL_adapter"
"JieShibo/PETL-ViT" -> "ChengHan111/E2VPT"
"JieShibo/PETL-ViT" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"JieShibo/PETL-ViT" -> "linziyi96/st-adapter" ["e"=1]
"JieShibo/PETL-ViT" -> "KMnP/vpt"
"sarahpratt/CuPL" -> "vishaal27/SuS-X"
"sarahpratt/CuPL" -> "ExplainableML/WaffleCLIP"
"sarahpratt/CuPL" -> "yangyangyang127/APE"
"sarahpratt/CuPL" -> "sachit-menon/classify_by_description_release"
"sarahpratt/CuPL" -> "OpenGVLab/CaFo"
"sarahpratt/CuPL" -> "ZiyuGuo99/CALIP"
"sarahpratt/CuPL" -> "zhangce01/DualAdapter"
"sarahpratt/CuPL" -> "gaopengcuhk/Tip-Adapter"
"vishaal27/SuS-X" -> "ZiyuGuo99/CALIP"
"vishaal27/SuS-X" -> "yangyangyang127/APE"
"vishaal27/SuS-X" -> "sarahpratt/CuPL"
"vishaal27/SuS-X" -> "OpenGVLab/CaFo"
"htyao89/KgCoOp" -> "bbbdylan/proda"
"ZhangYuanhan-AI/NOAH" -> "JieShibo/PETL-ViT"
"ZhangYuanhan-AI/NOAH" -> "dongzelian/SSF"
"ZhangYuanhan-AI/NOAH" -> "ZhangYuanhan-AI/OmniBenchmark"
"ZhangYuanhan-AI/NOAH" -> "sagizty/VPT"
"ZhangYuanhan-AI/NOAH" -> "ziplab/SPT"
"ZhangYuanhan-AI/NOAH" -> "luogen1996/RepAdapter"
"ZhangYuanhan-AI/NOAH" -> "KaiyangZhou/on-device-dg"
"ZhangYuanhan-AI/NOAH" -> "ShoufaChen/AdaptFormer"
"ZhangYuanhan-AI/NOAH" -> "Arnav0400/ViT-Slim"
"ZhangYuanhan-AI/NOAH" -> "KMnP/vpt"
"ZhangYuanhan-AI/NOAH" -> "Jiahao000/ORL"
"thunlp/BMCourse" -> "OpenBMB/ModelCenter"
"thunlp/BMCourse" -> "OpenBMB/BMInf"
"ZiyuGuo99/CALIP" -> "vishaal27/SuS-X"
"ZiyuGuo99/CALIP" -> "yangyangyang127/APE"
"ZiyuGuo99/CALIP" -> "Ivan-Tang-3D/ViewRefer3D" ["e"=1]
"ZiyuGuo99/CALIP" -> "OpenGVLab/CaFo"
"OpenBMB/BMList" -> "OpenBMB/BMCook"
"OpenBMB/BMList" -> "OpenBMB/CPM-Live"
"OpenBMB/BMList" -> "OpenBMB/ModelCenter"
"OpenBMB/BMList" -> "OpenBMB/BMInf"
"OpenBMB/BMList" -> "OpenBMB/BMTrain"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "dongzelian/SSF"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "synbol/Awesome-Parameter-Efficient-Transfer-Learning" ["e"=1]
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "ShoufaChen/AdaptFormer"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "JieShibo/PETL-ViT"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "thunlp/DeltaPapers"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "KMnP/vpt"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "ylsung/VL_adapter"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "calpt/awesome-adapter-resources"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "WillDreamer/Aurora"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "jxhe/unify-parameter-efficient-tuning"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "YuejiangLIU/awesome-source-free-test-time-adaptation" ["e"=1]
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "luogen1996/RepAdapter"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "muzairkhattak/multimodal-prompt-learning"
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" -> "ZhangYuanhan-AI/NOAH"
"Computer-Vision-in-the-Wild/DataDownload" -> "Computer-Vision-in-the-Wild/Elevater_Toolkit_IC"
"CHENGY12/PLOT" -> "BeierZhu/Prompt-align"
"CHENGY12/PLOT" -> "htyao89/KgCoOp"
"CHENGY12/PLOT" -> "azshue/TPT"
"CHENGY12/PLOT" -> "BatsResearch/csp" ["e"=1]
"CHENGY12/PLOT" -> "ShuvenduRoy/CoPrompt"
"CHENGY12/PLOT" -> "muzairkhattak/multimodal-prompt-learning"
"eric-ai-lab/PEViT" -> "Computer-Vision-in-the-Wild/Elevater_Toolkit_IC"
"sagizty/sagizty" -> "sagizty/NTUS_application"
"sagizty/sagizty" -> "sagizty/Parallel-Hybrid-Transformer"
"sagizty/sagizty" -> "sagizty/MAE"
"luogen1996/RepAdapter" -> "ZhangYuanhan-AI/NOAH"
"luogen1996/RepAdapter" -> "DavidYanAnDe/ARC"
"craffel/llm-seminar" -> "r-three/t-few"
"craffel/llm-seminar" -> "r-three/git-theta"
"LightDXY/FT-CLIP" -> "sarahpratt/CuPL"
"microsoft/mttl" -> "McGill-NLP/polytropon"
"Computer-Vision-in-the-Wild/Elevater_Toolkit_IC" -> "Computer-Vision-in-the-Wild/DataDownload"
"Computer-Vision-in-the-Wild/Elevater_Toolkit_IC" -> "ZhangYuanhan-AI/OmniBenchmark"
"ZhangYuanhan-AI/OmniBenchmark" -> "Jiahao000/ORL"
"ZhangYuanhan-AI/OmniBenchmark" -> "KaiyangZhou/on-device-dg"
"ZhangYuanhan-AI/OmniBenchmark" -> "ZhangYuanhan-AI/Bamboo"
"ZhangYuanhan-AI/OmniBenchmark" -> "Jingkang50/EgoLife"
"muzairkhattak/PromptSRC" -> "muzairkhattak/multimodal-prompt-learning"
"muzairkhattak/PromptSRC" -> "muzairkhattak/ProText"
"muzairkhattak/PromptSRC" -> "ShuvenduRoy/CoPrompt"
"muzairkhattak/PromptSRC" -> "zhengli97/PromptKD"
"muzairkhattak/PromptSRC" -> "jameelhassan/PromptAlign"
"muzairkhattak/PromptSRC" -> "TalalWasim/Video-FocalNets"
"muzairkhattak/PromptSRC" -> "BeierZhu/Prompt-align"
"muzairkhattak/PromptSRC" -> "Koorye/DePT"
"muzairkhattak/PromptSRC" -> "azshue/TPT"
"muzairkhattak/PromptSRC" -> "mrflogs/SHIP" ["e"=1]
"muzairkhattak/PromptSRC" -> "ZjjConan/VLM-MultiModalAdapter"
"muzairkhattak/PromptSRC" -> "tonyhuang2022/UPL"
"muzairkhattak/PromptSRC" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs"
"muzairkhattak/PromptSRC" -> "ThomasWangY/2024-AAAI-HPT"
"muzairkhattak/PromptSRC" -> "CHENGY12/PLOT"
"awaisrauf/Awesome-CV-Foundational-Models" -> "uncbiag/Awesome-Foundation-Models"
"awaisrauf/Awesome-CV-Foundational-Models" -> "mbzuai-oryx/groundingLMM" ["e"=1]
"awaisrauf/Awesome-CV-Foundational-Models" -> "DirtyHarryLYL/LLM-in-Vision" ["e"=1]
"awaisrauf/Awesome-CV-Foundational-Models" -> "asif-hanif/vafa"
"awaisrauf/Awesome-CV-Foundational-Models" -> "muzairkhattak/PromptSRC"
"awaisrauf/Awesome-CV-Foundational-Models" -> "muzairkhattak/ViFi-CLIP"
"awaisrauf/Awesome-CV-Foundational-Models" -> "mbzuai-oryx/Video-LLaVA" ["e"=1]
"awaisrauf/Awesome-CV-Foundational-Models" -> "xmindflow/Awesome-Foundation-Models-in-Medical-Imaging" ["e"=1]
"awaisrauf/Awesome-CV-Foundational-Models" -> "yzhuoning/Awesome-CLIP"
"awaisrauf/Awesome-CV-Foundational-Models" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"awaisrauf/Awesome-CV-Foundational-Models" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs"
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "DirtyHarryLYL/LLM-in-Vision" ["e"=1]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "KaiyangZhou/CoOp"
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "jingyi0000/VLM_survey" ["e"=1]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "uncbiag/Awesome-Foundation-Models"
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "xmed-lab/CLIP_Surgery" ["e"=1]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" -> "muzairkhattak/multimodal-prompt-learning"
"cs-mshah/Adapter-Bert" -> "strawberrypie/bert_adapter"
"EvolvingLMMs-Lab/RelateAnything" -> "Jingkang50/OpenPSG" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "Nicous20/FunQA"
"EvolvingLMMs-Lab/RelateAnything" -> "hongfz16/HCMoCo"
"EvolvingLMMs-Lab/RelateAnything" -> "hongfz16/Garment4D"
"EvolvingLMMs-Lab/RelateAnything" -> "kaleido-lab/dolphin"
"EvolvingLMMs-Lab/RelateAnything" -> "ZhangYuanhan-AI/Bamboo"
"EvolvingLMMs-Lab/RelateAnything" -> "Jun-CEN/SegmentAnyRGBD" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "Kenneth-Wong/MMSceneGraph" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "JialianW/GRiT" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "ZhangYuanhan-AI/OmniBenchmark"
"EvolvingLMMs-Lab/RelateAnything" -> "omniobject3d/OmniObject3D" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "jiawei-ren/diffmimic" ["e"=1]
"EvolvingLMMs-Lab/RelateAnything" -> "Jiahao000/ORL"
"cliangyu/Cola" -> "pufanyi/syphus"
"Nicous20/FunQA" -> "pufanyi/syphus"
"Nicous20/FunQA" -> "Jingkang50/EgoLife"
"OpenGVLab/CaFo" -> "gaopengcuhk/Tip-Adapter"
"OpenGVLab/CaFo" -> "yangyangyang127/APE"
"OpenGVLab/CaFo" -> "gaopengcuhk/CLIP-Adapter"
"OpenGVLab/CaFo" -> "vishaal27/SuS-X"
"OpenGVLab/CaFo" -> "ZiyuGuo99/CALIP"
"OpenGVLab/CaFo" -> "linzhiqiu/cross_modal_adaptation"
"OpenGVLab/CaFo" -> "sarahpratt/CuPL"
"OpenGVLab/CaFo" -> "mrflogs/ICLR24" ["e"=1]
"OpenGVLab/CaFo" -> "ZrrSkywalker/CaFo"
"OpenGVLab/CaFo" -> "CHENGY12/PLOT"
"OpenGVLab/CaFo" -> "geekyutao/TaskRes"
"OpenGVLab/CaFo" -> "skingorz/FD-Align"
"OpenGVLab/CaFo" -> "Tsingularity/FRN" ["e"=1]
"OpenGVLab/CaFo" -> "ShuvenduRoy/CoPrompt"
"OpenGVLab/CaFo" -> "jusiro/CLAP" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "adapter-hub/adapters"
"AGI-Edgerunners/LLM-Adapters" -> "jxhe/unify-parameter-efficient-tuning"
"AGI-Edgerunners/LLM-Adapters" -> "NVlabs/DoRA" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "AetherCortex/Llama-X" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "HillZhang1999/llm-hallucination-survey" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "SinclairCoder/Instruction-Tuning-Papers" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "GanjinZero/RRHF" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "thunlp/OpenDelta"
"AGI-Edgerunners/LLM-Adapters" -> "PhoebusSi/Alpaca-CoT" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "FranxYao/chain-of-thought-hub" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "zjunlp/EasyEdit" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "Instruction-Tuning-with-GPT-4/GPT-4-LLM" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"AGI-Edgerunners/LLM-Adapters" -> "allenai/open-instruct" ["e"=1]
"altndrr/vic" -> "altndrr/lmms-owc"
"altndrr/vic" -> "tdemin16/multi-lane"
"altndrr/vic" -> "FarinaMatteo/zero"
"kaleido-lab/dolphin" -> "Nicous20/FunQA"
"kaleido-lab/dolphin" -> "Jiahao000/ORL"
"kaleido-lab/dolphin" -> "EvolvingLMMs-Lab/RelateAnything"
"uncbiag/Awesome-Foundation-Models" -> "awaisrauf/Awesome-CV-Foundational-Models"
"uncbiag/Awesome-Foundation-Models" -> "JindongGu/Awesome-Prompting-on-Vision-Language-Model"
"uncbiag/Awesome-Foundation-Models" -> "Jianing-Qiu/Awesome-Healthcare-Foundation-Models" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "EdisonLeeeee/Awesome-Masked-Autoencoders" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "jingyi0000/VLM_survey" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "liliu-avril/Awesome-Segment-Anything" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "Hedlen/awesome-segment-anything" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "Computer-Vision-in-the-Wild/CVinW_Readings" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "richard-peng-xia/awesome-multimodal-in-medical-imaging" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"uncbiag/Awesome-Foundation-Models" -> "NVlabs/RADIO" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "robotics-survey/Awesome-Robotics-Foundation-Models" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "xmindflow/Awesome-Foundation-Models-in-Medical-Imaging" ["e"=1]
"uncbiag/Awesome-Foundation-Models" -> "yzhuoning/Awesome-CLIP"
"ryongithub/GatedPromptTuning" -> "WangYZ1608/Self-Prompt-Tuning"
"ChengHan111/E2VPT" -> "ryongithub/GatedPromptTuning"
"yangyangyang127/APE" -> "ZiyuGuo99/CALIP"
"yangyangyang127/APE" -> "vishaal27/SuS-X"
"yangyangyang127/APE" -> "OpenGVLab/CaFo"
"yangyangyang127/APE" -> "gaopengcuhk/Tip-Adapter"
"yangyangyang127/APE" -> "sarahpratt/CuPL"
"yangyangyang127/APE" -> "mlvlab/RPO"
"yangyangyang127/APE" -> "mrflogs/ICLR24" ["e"=1]
"ExplainableML/WaffleCLIP" -> "Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification"
"FarinaMatteo/qmmf" -> "tdemin16/Continual-LayerNorm-Tuning"
"ShiZhengyan/DePT" -> "ShiZhengyan/PowerfulPromptFT"
"ShiZhengyan/DePT" -> "ZhengxiangShi/LearnToAsk"
"ShiZhengyan/DePT" -> "amzn/pretraining-or-self-training"
"ShiZhengyan/DePT" -> "ShiZhengyan/StepGame"
"ShiZhengyan/DePT" -> "ZhengxiangShi/SelfContrastiveLearningRecSys"
"ShiZhengyan/DePT" -> "ZhengxiangShi/InstructionModelling"
"calpt/awesome-adapter-resources" -> "UKPLab/adaptable-adapters"
"calpt/awesome-adapter-resources" -> "cambridgeltl/autopeft"
"calpt/awesome-adapter-resources" -> "jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning"
"Koorye/DePT" -> "Koorye/SkipTuning"
"Koorye/DePT" -> "muzairkhattak/PromptSRC"
"chunmeifeng/DiffTPT" -> "kdiAAA/TDA"
"chunmeifeng/DiffTPT" -> "chunmeifeng/FedIns"
"ShiZhengyan/PowerfulPromptFT" -> "ZhengxiangShi/LearnToAsk"
"ShiZhengyan/PowerfulPromptFT" -> "amzn/pretraining-or-self-training"
"ShiZhengyan/PowerfulPromptFT" -> "ShiZhengyan/StepGame"
"ShiZhengyan/PowerfulPromptFT" -> "ShiZhengyan/DePT"
"ziplab/SPT" -> "DavidYanAnDe/ARC"
"ziplab/SPT" -> "WangYZ1608/Self-Prompt-Tuning"
"WillDreamer/Aurora" -> "RERV/UniAdapter"
"WillDreamer/Aurora" -> "UniAdapter/UniAdapter"
"TalalWasim/Video-FocalNets" -> "muzairkhattak/PromptSRC"
"TalalWasim/Video-FocalNets" -> "asif-hanif/vafa"
"ZhengxiangShi/SelfContrastiveLearningRecSys" -> "ZhengxiangShi/LearnToAsk"
"amzn/pretraining-or-self-training" -> "ZhengxiangShi/LearnToAsk"
"amzn/pretraining-or-self-training" -> "ShiZhengyan/PowerfulPromptFT"
"asif-hanif/vafa" -> "asif-hanif/baple"
"asif-hanif/vafa" -> "Muhammad-Huzaifaa/ObjectCompose"
"Luodian/GenBench" -> "pufanyi/syphus"
"tdemin16/Continual-LayerNorm-Tuning" -> "FarinaMatteo/qmmf"
"pufanyi/syphus" -> "Jingkang50/EgoLife"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "zhengli97/PromptKD"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "muzairkhattak/multimodal-prompt-learning"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "muzairkhattak/PromptSRC"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "JindongGu/Awesome-Prompting-on-Vision-Language-Model"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "ZjjConan/VLM-MultiModalAdapter"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "KaiyangZhou/CoOp"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "gaopengcuhk/Tip-Adapter"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "ShuvenduRoy/CoPrompt"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "CHENGY12/PLOT"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "YBZh/DMN"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "tim-learn/awesome-test-time-adaptation" ["e"=1]
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "ThomasWangY/2024-AAAI-HPT"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "OpenGVLab/CaFo"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision"
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" -> "sarahpratt/CuPL"
"Razaimam45/TTL-Test-Time-Low-Rank-Adaptation" -> "umer-sheikh/bird-whisperer"
"muzairkhattak/ProText" -> "muzairkhattak/PromptSRC"
"muzairkhattak/ProText" -> "mbzuai-oryx/CVRR-Evaluation-Suite"
"muzairkhattak/ProText" -> "jameelhassan/PromptAlign"
"muzairkhattak/ProText" -> "asif-hanif/baple"
"WangYZ1608/Self-Prompt-Tuning" -> "tommy-xq/SA2VP"
"zhengli97/PromptKD" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs"
"zhengli97/PromptKD" -> "muzairkhattak/PromptSRC"
"zhengli97/PromptKD" -> "muzairkhattak/multimodal-prompt-learning"
"zhengli97/PromptKD" -> "ShuvenduRoy/CoPrompt"
"zhengli97/PromptKD" -> "muzairkhattak/ProText"
"zhengli97/PromptKD" -> "CHENGY12/PLOT"
"zhengli97/PromptKD" -> "Koorye/DePT"
"zhengli97/PromptKD" -> "zhengli97/ATPrompt" ["e"=1]
"zhengli97/PromptKD" -> "ZjjConan/VLM-MultiModalAdapter"
"zhengli97/PromptKD" -> "OpenGVLab/CaFo"
"zhengli97/PromptKD" -> "tonyhuang2022/UPL"
"zhengli97/PromptKD" -> "KaiyangZhou/Dassl.pytorch" ["e"=1]
"zhengli97/PromptKD" -> "BeierZhu/Prompt-align"
"ShuvenduRoy/CoPrompt" -> "muzairkhattak/PromptSRC"
"ShuvenduRoy/CoPrompt" -> "zhaohengz/LLaMP"
"ShuvenduRoy/CoPrompt" -> "schowdhury671/APoLLo"
"Picsart-AI-Research/OpenBias" -> "FarinaMatteo/qmmf"
"Leiyi-Hu/mona" -> "ShoufaChen/AdaptFormer"
"kdiAAA/TDA" -> "zhangce01/DPE-CLIP"
"kdiAAA/TDA" -> "YBZh/DMN"
"kdiAAA/TDA" -> "elaine-sui/TPS"
"kdiAAA/TDA" -> "FarinaMatteo/zero"
"kdiAAA/TDA" -> "chunmeifeng/DiffTPT"
"ZjjConan/VLM-MultiModalAdapter" -> "ShuvenduRoy/CoPrompt"
"tsunghan-wu/SLD" -> "hananshafi/llmblueprint"
"hananshafi/llmblueprint" -> "rohit901/VANE-Bench" ["e"=1]
"hananshafi/llmblueprint" -> "HashmatShadab/MambaRobustness"
"hananshafi/llmblueprint" -> "mbzuai-oryx/VideoGLaMM"
"hananshafi/llmblueprint" -> "Razaimam45/TTL-Test-Time-Low-Rank-Adaptation"
"hananshafi/llmblueprint" -> "Muhammad-Huzaifaa/ObjectCompose"
"DavidYanAnDe/ARC" -> "zstarN70/RLRR"
"elaine-sui/TPS" -> "zhangce01/DPE-CLIP"
"Muhammad-Huzaifaa/ObjectCompose" -> "HashmatShadab/MambaRobustness"
"benedettaliberatori/T3AL" -> "marco-garosi/ComCa"
"benedettaliberatori/T3AL" -> "tdemin16/multi-lane"
"benedettaliberatori/T3AL" -> "altndrr/lmms-owc"
"benedettaliberatori/T3AL" -> "francescotonini/al-gtd"
"YBZh/DMN" -> "YBZh/LAPT" ["e"=1]
"YBZh/DMN" -> "kdiAAA/TDA"
"YBZh/DMN" -> "zhangce01/DPE-CLIP"
"YBZh/DMN" -> "strongwolf/OpenSD" ["e"=1]
"mbzuai-oryx/CVRR-Evaluation-Suite" -> "HashmatShadab/MambaRobustness"
"BioMedIA-MBZUAI/MedPromptX" -> "BioMedIA-MBZUAI/XReal"
"BioMedIA-MBZUAI/MedPromptX" -> "asif-hanif/baple"
"BioMedIA-MBZUAI/MedPromptX" -> "umer-sheikh/bird-whisperer"
"BioMedIA-MBZUAI/MedPromptX" -> "Muhammad-Huzaifaa/ObjectCompose"
"jameelhassan/PromptAlign" -> "azshue/TPT"
"jameelhassan/PromptAlign" -> "muzairkhattak/ProText"
"jameelhassan/PromptAlign" -> "asif-hanif/baple"
"jameelhassan/PromptAlign" -> "mbzuai-oryx/CVRR-Evaluation-Suite"
"jameelhassan/PromptAlign" -> "akhtarvision/cal-detr" ["e"=1]
"zstarN70/RLRR" -> "DavidYanAnDe/ARC"
"FarinaMatteo/multiflow" -> "FarinaMatteo/qmmf"
"FarinaMatteo/multiflow" -> "altndrr/lmms-owc"
"Jingkang50/EgoLife" -> "pufanyi/syphus"
"tommy-xq/SA2VP" -> "WangYZ1608/Self-Prompt-Tuning"
"hee-suk-yoon/C-TPT" -> "Bala93/CLIPCalib"
"umer-sheikh/bird-whisperer" -> "Muhammad-Ibraheem-Siddiqui/PerSense"
"umer-sheikh/bird-whisperer" -> "asif-hanif/baple"
"umer-sheikh/bird-whisperer" -> "Razaimam45/TTL-Test-Time-Low-Rank-Adaptation"
"asif-hanif/baple" -> "umer-sheikh/bird-whisperer"
"asif-hanif/baple" -> "asif-hanif/vafa"
"asif-hanif/baple" -> "Razaimam45/TTL-Test-Time-Low-Rank-Adaptation"
"asif-hanif/baple" -> "asif-hanif/palm"
"zhangce01/DPE-CLIP" -> "elaine-sui/TPS"
"zhangce01/DPE-CLIP" -> "kdiAAA/TDA"
"FarinaMatteo/zero" -> "tdemin16/multi-lane"
"FarinaMatteo/zero" -> "altndrr/lmms-owc"
"FarinaMatteo/zero" -> "elaine-sui/TPS"
"Muhammad-Ibraheem-Siddiqui/PerSense" -> "umer-sheikh/bird-whisperer"
"mbzuai-oryx/VideoGLaMM" -> "mbzuai-oryx/CVRR-Evaluation-Suite"
"ayesha-ishaq/Open3DTrack" -> "umer-sheikh/bird-whisperer"
"francescotonini/al-gtd" -> "marco-garosi/ComCa"
"francescotonini/al-gtd" -> "tdemin16/multi-lane"
"francescotonini/al-gtd" -> "FarinaMatteo/qmmf"
"ZhengxiangShi/InstructionModelling" -> "ZhengxiangShi/LearnToAsk"
"tdemin16/multi-lane" -> "marco-garosi/ComCa"
"tdemin16/multi-lane" -> "francescotonini/al-gtd"
"HashmatShadab/MambaRobustness" -> "HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models"
"HashmatShadab/MambaRobustness" -> "fahadshamshad/deep-facial-privacy-prior"
"mbzuai-oryx/UniMed-CLIP" -> "Muhammad-Huzaifaa/ObjectCompose"
"mbzuai-oryx/UniMed-CLIP" -> "umer-sheikh/bird-whisperer"
"mbzuai-oryx/UniMed-CLIP" -> "ayesha-ishaq/Open3DTrack"
"EvolvingLMMs-Lab/VideoMMMU" -> "pufanyi/syphus"
"altndrr/lmms-owc" -> "FarinaMatteo/qmmf"
"altndrr/lmms-owc" -> "marco-garosi/ComCa"
"altndrr/lmms-owc" -> "FarinaMatteo/multiflow"
"altndrr/lmms-owc" -> "tdemin16/multi-lane"
"EvolvingLMMs-Lab/Aero-1" -> "EvolvingLMMs-Lab/VideoMMMU"
"EvolvingLMMs-Lab/Aero-1" -> "pufanyi/syphus"
"marco-garosi/ComCa" -> "francescotonini/al-gtd"
"facebookresearch/LAMA" ["l"="49.998,38.071"]
"facebookresearch/KILT" ["l"="54.501,25.555"]
"facebookresearch/DPR" ["l"="54.497,25.597"]
"jzbjyb/LPAQA" ["l"="49.98,38.045"]
"facebookresearch/XLM" ["l"="53.036,25.657"]
"facebookresearch/BLINK" ["l"="-0.394,-42.155"]
"ucinlp/autoprompt" ["l"="50.032,38.065"]
"thunlp/ERNIE" ["l"="53.397,27.266"]
"atcbosselut/comet-commonsense" ["l"="55.763,25.925"]
"THUDM/P-tuning" ["l"="50.066,38.077"]
"google-research/electra" ["l"="53.282,27.163"]
"facebookresearch/GENRE" ["l"="-0.406,-42.173"]
"princeton-nlp/LM-BFF" ["l"="50.039,38.082"]
"nyu-mll/jiant" ["l"="52.948,25.537"]
"namisan/mt-dnn" ["l"="53.308,27.184"]
"danqi/acl2020-openqa-tutorial" ["l"="54.495,25.53"]
"strawberrypie/bert_adapter" ["l"="50.017,38.152"]
"cs-mshah/Adapter-Bert" ["l"="49.998,38.162"]
"google-research/adapter-bert" ["l"="50.064,38.125"]
"AsaCooperStickland/Bert-n-Pals" ["l"="50.039,38.157"]
"adapter-hub/adapters" ["l"="50.123,38.113"]
"jxhe/unify-parameter-efficient-tuning" ["l"="50.167,38.161"]
"XiangLi1999/PrefixTuning" ["l"="50.086,38.092"]
"clarkkev/attention-analysis" ["l"="23.564,14.904"]
"microsoft/K-Adapter" ["l"="-0.392,-42.235"]
"thunlp/OpenDelta" ["l"="50.146,38.073"]
"thunlp/OpenPrompt" ["l"="50.099,38.067"]
"bigscience-workshop/promptsource" ["l"="37.178,-0.097"]
"huggingface/peft" ["l"="40.04,0.52"]
"AGI-Edgerunners/LLM-Adapters" ["l"="50.173,38.121"]
"OpenGVLab/LLaMA-Adapter" ["l"="39.851,0.706"]
"thunlp/PromptPapers" ["l"="50.059,38.052"]
"makcedward/nlpaug" ["l"="52.729,25.717"]
"THUDM/P-tuning-v2" ["l"="39.159,-2.107"]
"allenai/RL4LMs" ["l"="37.17,-0.197"]
"CarperAI/trlx" ["l"="37.133,-0.204"]
"timoschick/pet" ["l"="50.044,38.101"]
"princeton-nlp/SimCSE" ["l"="53.339,27.107"]
"timoschick/fewglue" ["l"="50.005,38.126"]
"rrmenon10/ADAPET" ["l"="49.983,38.101"]
"marcotcr/checklist" ["l"="52.788,25.588"]
"google-research/multilingual-t5" ["l"="53.272,27.002"]
"tonyzhaozh/few-shot-learning" ["l"="50.014,38.105"]
"Eric-Wallace/universal-triggers" ["l"="52.797,25.345"]
"princeton-nlp/OptiPrompt" ["l"="49.956,38.053"]
"kipgparker/soft-prompt-tuning" ["l"="50.086,38.043"]
"keirp/automatic_prompt_engineer" ["l"="36.859,-2.471"]
"google-research-datasets/KELM-corpus" ["l"="49.986,38.017"]
"google-research/task_adaptation" ["l"="50.242,38.257"]
"dongzelian/SSF" ["l"="50.217,38.222"]
"ZhangYuanhan-AI/NOAH" ["l"="50.218,38.256"]
"hjbahng/visual_prompting" ["l"="50.289,38.254"]
"KMnP/vpt" ["l"="50.273,38.24"]
"JieShibo/PETL-ViT" ["l"="50.222,38.231"]
"google-research/head2toe" ["l"="50.207,38.288"]
"yyhhenry/tank" ["l"="50.051,38.404"]
"pufanyi/syphus" ["l"="50.066,38.396"]
"Timothyxxx/Chain-of-ThoughtsPapers" ["l"="36.759,-2.46"]
"thunlp/PLMpapers" ["l"="53.319,27.158"]
"km1994/nlp_paper_study" ["l"="53.515,27.092"]
"MLNLP-World/Paper-Writing-Tips" ["l"="-3.951,23.526"]
"yizhongw/self-instruct" ["l"="39.042,-2.296"]
"CLUEbenchmark/CLUE" ["l"="53.381,27.209"]
"sagizty/Insight" ["l"="50.215,38.326"]
"sagizty/MAE" ["l"="50.229,38.338"]
"sagizty/Multi-Stage-Hybrid-Transformer" ["l"="50.231,38.327"]
"sagizty/NTUS_application" ["l"="50.246,38.329"]
"sagizty/Parallel-Hybrid-Transformer" ["l"="50.242,38.336"]
"sagizty/sagizty" ["l"="50.238,38.321"]
"sagizty/VPT" ["l"="50.238,38.301"]
"lsqqqq/notifyemail" ["l"="50.214,38.347"]
"google-research/prompt-tuning" ["l"="50.11,38.089"]
"xlang-ai/UnifiedSKG" ["l"="37.899,-2.309"]
"mkshing/Prompt-Tuning" ["l"="50.112,38.046"]
"jordiclive/ControlPrefixes" ["l"="50.136,38.047"]
"allenai/natural-instructions" ["l"="37.211,-0.1"]
"TsinghuaAI/CPM-2-Pretrain" ["l"="50.265,37.945"]
"TsinghuaAI/CPM-2-Finetune" ["l"="50.258,37.967"]
"TsinghuaAI/CPM-1-Finetune" ["l"="50.276,37.898"]
"TsinghuaAI/CPM" ["l"="50.239,37.959"]
"BAAI-WuDao/P-tuning" ["l"="50.309,37.91"]
"OpenBMB/BMInf" ["l"="50.215,38"]
"OpenBMB/BMCook" ["l"="50.218,38.018"]
"OpenBMB/CPM-Live" ["l"="50.203,38.035"]
"OpenBMB/BMTrain" ["l"="50.181,38.025"]
"OpenBMB/BMList" ["l"="50.191,38.002"]
"OpenBMB/ModelCenter" ["l"="50.198,38.015"]
"TsinghuaAI/CPM-1-Generate" ["l"="53.313,27.122"]
"deepdialog/CPM-LM-TF2" ["l"="53.276,27.034"]
"thu-coai/EVA" ["l"="56.774,29.037"]
"CLUEbenchmark/pCLUE" ["l"="39.171,-2.255"]
"yangjianxin1/CPM" ["l"="53.292,27.119"]
"hpcaitech/EnergonAI" ["l"="38.988,-0.837"]
"wenhuchen/KGPT" ["l"="37.812,-2.183"]
"ylsung/Ladder-Side-Tuning" ["l"="50.174,38.184"]
"ylsung/VL_adapter" ["l"="50.197,38.201"]
"ShoufaChen/AdaptFormer" ["l"="50.241,38.231"]
"jianghaojun/Awesome-Parameter-Efficient-Transfer-Learning" ["l"="50.242,38.206"]
"AkariAsai/ATTEMPT" ["l"="50.086,38.143"]
"r-three/t-few" ["l"="50.119,38.15"]
"fuzihaofzh/AnalyzeParameterEfficientFinetune" ["l"="50.146,38.177"]
"grandchicken/1708SEM_ISIM" ["l"="50.239,38.351"]
"corolla-johnson/mkultra" ["l"="50.113,38.032"]
"Zeng-WH/Prompt-Tuning" ["l"="50.099,38.022"]
"qhduan/mt5-soft-prompt-tuning" ["l"="50.079,38.008"]
"exelents/soft-prompt-tuning" ["l"="50.108,38.007"]
"txsun1997/Black-Box-Tuning" ["l"="36.817,-2.603"]
"hiaoxui/soft-prompts" ["l"="50.089,37.991"]
"thu-coai/PPT" ["l"="50.059,38.005"]
"thunlp/PTR" ["l"="50.042,37.98"]
"IntelLabs/academic-budget-bert" ["l"="49.861,38.028"]
"princeton-nlp/DinkyTrain" ["l"="49.909,38.042"]
"princeton-nlp/DensePhrases" ["l"="54.506,25.572"]
"yym6472/ConSERT" ["l"="53.336,27.054"]
"zjunlp/DART" ["l"="38.284,-7.837"]
"microsoft/ANCE" ["l"="54.475,25.7"]
"bojone/P-tuning" ["l"="53.315,26.951"]
"THUDM/GLM" ["l"="39.147,-2.076"]
"bojone/Pattern-Exploiting-Training" ["l"="53.322,26.986"]
"peterwestuw/surface-form-competition" ["l"="49.973,38.124"]
"ethanjperez/true_few_shot" ["l"="49.957,38.108"]
"Alrope123/rethinking-demonstrations" ["l"="36.98,-2.517"]
"urvashik/knnlm" ["l"="36.965,-2.651"]
"TsinghuaAI/CPM-KG" ["l"="50.265,37.88"]
"zjunlp/KnowPrompt" ["l"="50.025,37.958"]
"wzhouad/RE_improved_baseline" ["l"="55.538,26.866"]
"thunlp/KnowledgeablePromptTuning" ["l"="50.048,37.961"]
"BAAI-WuDao/Model" ["l"="50.346,37.851"]
"BAAI-WuDao/CogView" ["l"="50.343,37.875"]
"BAAI-WuDao/CPM" ["l"="50.373,37.858"]
"TsinghuaAI/CPM-1-Pretrain" ["l"="50.242,37.921"]
"rabeehk/hyperformer" ["l"="50.1,38.209"]
"rabeehk/compacter" ["l"="50.076,38.235"]
"McGill-NLP/polytropon" ["l"="50.051,38.242"]
"thunlp/Prompt-Transferability" ["l"="50.153,38.101"]
"RUCAIBox/Transfer-Prompts-for-Text-Generation" ["l"="50.17,38.07"]
"jm12138/CPM-Generate-Pytorch" ["l"="50.285,37.88"]
"BAAI-WuDao/EVA" ["l"="50.302,37.887"]
"TsinghuaAI/TDS" ["l"="50.255,37.906"]
"princeton-nlp/EntityQuestions" ["l"="54.477,25.647"]
"princeton-nlp/rationale-robustness" ["l"="49.932,38.035"]
"TsinghuaAI/CPM-1-Distill" ["l"="50.231,37.904"]
"BAAI-WuDao/Chinese-Transformer-XL" ["l"="50.39,37.846"]
"BAAI-WuDao/GLM" ["l"="50.404,37.835"]
"LianjiaTech/BELLE" ["l"="39.054,-2.075"]
"km1994/NLP-Interview-Notes" ["l"="53.498,27.11"]
"dbiir/UER-py" ["l"="53.376,27.187"]
"KaiyangZhou/CoOp" ["l"="50.344,38.24"]
"muzairkhattak/multimodal-prompt-learning" ["l"="50.364,38.261"]
"KaiyangZhou/Dassl.pytorch" ["l"="50.818,37.918"]
"gaopengcuhk/Tip-Adapter" ["l"="50.332,38.271"]
"gaopengcuhk/CLIP-Adapter" ["l"="50.337,38.258"]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" ["l"="50.313,38.23"]
"raoyongming/DenseCLIP" ["l"="48.818,30.315"]
"microsoft/GLIP" ["l"="48.866,30.251"]
"salesforce/ALBEF" ["l"="48.761,31.992"]
"muzairkhattak/PromptSRC" ["l"="50.408,38.267"]
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" ["l"="50.383,38.257"]
"mlfoundations/open_clip" ["l"="48.974,30.216"]
"yzhuoning/Awesome-CLIP" ["l"="50.366,38.215"]
"salesforce/BLIP" ["l"="48.991,30.249"]
"salesforce/LAVIS" ["l"="49.008,30.194"]
"Yutong-Zhou-cv/Awesome-Multimodality" ["l"="50.439,38.403"]
"Yutong-Zhou-cv/Awesome-Transformer-in-CV" ["l"="50.458,38.436"]
"wangxiao5791509/MultiModal_BigModels_Survey" ["l"="50.419,38.365"]
"thunlp/DeltaPapers" ["l"="50.215,38.139"]
"txsun1997/LMaaS-Papers" ["l"="36.778,-2.536"]
"thunlp/UltraChat" ["l"="50.786,2.873"]
"Sense-GVT/DeCLIP" ["l"="48.883,30.342"]
"ArrowLuo/CLIP4Clip" ["l"="47.909,32.98"]
"dk-liang/Awesome-Visual-Transformer" ["l"="50.812,29.72"]
"jingyi0000/VLM_survey" ["l"="50.954,2.79"]
"ShoufaChen/DiffusionDet" ["l"="48.83,30.299"]
"yuewang-cuhk/awesome-vision-language-pretraining-papers" ["l"="48.733,31.999"]
"facebookresearch/SLIP" ["l"="48.929,30.344"]
"TheShadow29/awesome-grounding" ["l"="48.847,31.967"]
"YuejiangLIU/awesome-source-free-test-time-adaptation" ["l"="50.903,37.922"]
"DirtyHarryLYL/LLM-in-Vision" ["l"="47.427,30.163"]
"google-research/l2p" ["l"="34.085,31.922"]
"amirbar/visual_prompting" ["l"="33.104,31.549"]
"MarkMoHR/Awesome-Referring-Image-Segmentation" ["l"="48.925,31.903"]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" ["l"="50.339,38.212"]
"OpenGVLab/CaFo" ["l"="50.366,38.284"]
"yangyangyang127/APE" ["l"="50.33,38.295"]
"linzhiqiu/cross_modal_adaptation" ["l"="50.35,38.288"]
"sarahpratt/CuPL" ["l"="50.354,38.309"]
"vishaal27/SuS-X" ["l"="50.344,38.3"]
"CHENGY12/PLOT" ["l"="50.398,38.252"]
"mrflogs/ICLR24" ["l"="38.326,0.076"]
"ZiyuGuo99/CALIP" ["l"="50.334,38.308"]
"hustvl/MIMDet" ["l"="52.886,29.378"]
"czczup/ViT-Adapter" ["l"="48.832,30.241"]
"Leiyi-Hu/mona" ["l"="50.232,38.274"]
"luogen1996/RepAdapter" ["l"="50.203,38.237"]
"synbol/Awesome-Parameter-Efficient-Transfer-Learning" ["l"="-54.32,-11.476"]
"j-min/VL-T5" ["l"="47.84,32.913"]
"LeapLabTHU/Cross-Modal-Adapter" ["l"="49.273,32.974"]
"bigscience-workshop/t-zero" ["l"="37.173,-0.038"]
"microsoft/AdaMix" ["l"="50.108,38.179"]
"craffel/llm-seminar" ["l"="50.075,38.18"]
"allenai/acl2022-zerofewshot-tutorial" ["l"="36.947,-2.563"]
"clinicalml/TabLLM" ["l"="46.149,24.759"]
"Shark-NLP/OpenICL" ["l"="36.863,-2.508"]
"facebookresearch/tart" ["l"="54.429,25.575"]
"Paranioar/UniPT" ["l"="32.793,31.114"]
"microsoft/mttl" ["l"="50.028,38.257"]
"wjn1996/TransPrompt" ["l"="38.256,-7.85"]
"kongds/Prompt-BERT" ["l"="53.301,26.899"]
"declare-lab/RelationPrompt" ["l"="50,37.921"]
"dinobby/ZS-BERT" ["l"="49.984,37.898"]
"ssnvxia/OneRel" ["l"="55.477,26.588"]
"mlfoundations/wise-ft" ["l"="48.956,30.334"]
"BeierZhu/Prompt-align" ["l"="50.417,38.242"]
"tonyhuang2022/UPL" ["l"="50.391,38.312"]
"BatsResearch/menghini-neurips23-code" ["l"="52.827,27.778"]
"yuhangzang/UPT" ["l"="50.313,38.299"]
"korawat-tanwisuth/POUF" ["l"="50.4,38.341"]
"CEWu/PTNL" ["l"="50.415,38.335"]
"hongfz16/Garment4D" ["l"="50.139,38.389"]
"hongfz16/HCMoCo" ["l"="50.119,38.391"]
"thunlp/WebCPM" ["l"="50.705,2.93"]
"OpenBMB/CPM-Bee" ["l"="51.127,2.846"]
"Langboat/Mengzi" ["l"="53.407,27.011"]
"google-research/t5x" ["l"="37.139,-0.072"]
"changdaeoh/BlackVIP" ["l"="50.29,38.205"]
"shikiw/DAM-VP" ["l"="38.305,-0.105"]
"UCSC-VLAA/EVP" ["l"="50.282,38.22"]
"OPTML-Group/ILM-VP" ["l"="50.276,38.284"]
"azshue/TPT" ["l"="50.443,38.248"]
"ZhangYuanhan-AI/Bamboo" ["l"="50.147,38.365"]
"ZhangYuanhan-AI/OmniBenchmark" ["l"="50.154,38.346"]
"KaiyangZhou/on-device-dg" ["l"="50.171,38.321"]
"ShiZhengyan/DePT" ["l"="49.973,38.187"]
"cambridgeltl/autopeft" ["l"="50.246,38.141"]
"calpt/awesome-adapter-resources" ["l"="50.248,38.166"]
"EagleW/Stage-wise-Fine-tuning" ["l"="50.143,38.019"]
"zjunlp/PromptKG" ["l"="53.865,15.187"]
"rtmaww/EntLM" ["l"="53.805,27.643"]
"Arnav0400/ViT-Slim" ["l"="50.191,38.256"]
"VITA-Group/UVC" ["l"="49.09,33.256"]
"ziplab/SPT" ["l"="50.174,38.25"]
"VITA-Group/SViTE" ["l"="49.083,33.218"]
"Jiahao000/ORL" ["l"="50.134,38.333"]
"Jingkang50/EgoLife" ["l"="50.1,38.37"]
"BeierZhu/xERM" ["l"="50.455,38.225"]
"yxymessi/H2E-Framework" ["l"="50.455,38.205"]
"ShiZhengyan/StepGame" ["l"="49.935,38.198"]
"ZhengxiangShi/LearnToAsk" ["l"="49.952,38.199"]
"amzn/pretraining-or-self-training" ["l"="49.953,38.19"]
"ShiZhengyan/PowerfulPromptFT" ["l"="49.94,38.184"]
"Fangjun-Li/SpatialLM-StepGame" ["l"="49.909,38.205"]
"ZhengxiangShi/SelfContrastiveLearningRecSys" ["l"="49.946,38.209"]
"zhengli97/PromptKD" ["l"="50.397,38.279"]
"muzairkhattak/ViFi-CLIP" ["l"="50.438,38.277"]
"muzairkhattak/ProText" ["l"="50.435,38.289"]
"jameelhassan/PromptAlign" ["l"="50.455,38.275"]
"YiLunLee/missing_aware_prompts" ["l"="56.454,27.984"]
"TalalWasim/Vita-CLIP" ["l"="48.146,33.888"]
"mbzuai-oryx/CVRR-Evaluation-Suite" ["l"="50.472,38.302"]
"ju-chen/Efficient-Prompt" ["l"="48.086,33.92"]
"sallymmx/ActionCLIP" ["l"="48.051,33.881"]
"whwu95/BIKE" ["l"="48.139,33.845"]
"hanoonaR/object-centric-ovd" ["l"="48.546,30.31"]
"asif-hanif/vafa" ["l"="50.483,38.279"]
"OpenGVLab/efficient-video-recognition" ["l"="48.127,33.857"]
"wengzejia1/Open-VCLIP" ["l"="48.215,33.853"]
"mbzuai-oryx/VideoGLaMM" ["l"="50.492,38.311"]
"TalalWasim/Video-FocalNets" ["l"="50.455,38.29"]
"skingorz/FD-Align" ["l"="50.375,38.306"]
"mrflogs/SHIP" ["l"="38.308,0.073"]
"ArmanAfrasiyabi/SetFeat-fs" ["l"="57.839,19.142"]
"sachit-menon/classify_by_description_release" ["l"="50.364,38.331"]
"LightDXY/FT-CLIP" ["l"="50.333,38.337"]
"tim-learn/awesome-test-time-adaptation" ["l"="50.888,37.933"]
"mr-eggplant/SAR" ["l"="50.937,37.942"]
"kdiAAA/TDA" ["l"="50.499,38.238"]
"chunmeifeng/DiffTPT" ["l"="50.502,38.223"]
"mzhaoshuai/RLCF" ["l"="50.479,38.212"]
"zhangce01/DPE-CLIP" ["l"="50.495,38.25"]
"ShuvenduRoy/CoPrompt" ["l"="50.412,38.287"]
"DequanWang/tent" ["l"="50.925,37.923"]
"qinenergy/cotta" ["l"="50.922,37.938"]
"FarinaMatteo/zero" ["l"="50.538,38.23"]
"Bala93/CLIPCalib" ["l"="50.479,38.226"]
"ExplainableML/WaffleCLIP" ["l"="50.363,38.355"]
"mertyg/vision-language-models-are-bows" ["l"="38.248,-0.115"]
"DavidYanAnDe/ARC" ["l"="50.177,38.235"]
"ChengHan111/E2VPT" ["l"="50.168,38.27"]
"linziyi96/st-adapter" ["l"="48.167,33.858"]
"zhangce01/DualAdapter" ["l"="50.351,38.343"]
"htyao89/KgCoOp" ["l"="50.434,38.193"]
"bbbdylan/proda" ["l"="50.453,38.17"]
"thunlp/BMCourse" ["l"="50.204,37.969"]
"Ivan-Tang-3D/ViewRefer3D" ["l"="65.077,11.793"]
"WillDreamer/Aurora" ["l"="50.171,38.216"]
"Computer-Vision-in-the-Wild/DataDownload" ["l"="50.177,38.418"]
"Computer-Vision-in-the-Wild/Elevater_Toolkit_IC" ["l"="50.166,38.403"]
"BatsResearch/csp" ["l"="52.82,27.754"]
"eric-ai-lab/PEViT" ["l"="50.163,38.437"]
"r-three/git-theta" ["l"="50.032,38.205"]
"Koorye/DePT" ["l"="50.442,38.264"]
"ZjjConan/VLM-MultiModalAdapter" ["l"="50.419,38.278"]
"ThomasWangY/2024-AAAI-HPT" ["l"="50.424,38.255"]
"awaisrauf/Awesome-CV-Foundational-Models" ["l"="50.424,38.221"]
"uncbiag/Awesome-Foundation-Models" ["l"="50.381,38.189"]
"mbzuai-oryx/groundingLMM" ["l"="47.465,30.182"]
"mbzuai-oryx/Video-LLaVA" ["l"="47.543,30.119"]
"xmindflow/Awesome-Foundation-Models-in-Medical-Imaging" ["l"="62.419,37.616"]
"jianzongwu/Awesome-Open-Vocabulary" ["l"="48.681,30.233"]
"mbzuai-oryx/ClimateGPT" ["l"="48.882,33.03"]
"xmed-lab/CLIP_Surgery" ["l"="48.678,30.279"]
"EvolvingLMMs-Lab/RelateAnything" ["l"="50.117,38.365"]
"Jingkang50/OpenPSG" ["l"="47.641,32.075"]
"Nicous20/FunQA" ["l"="50.081,38.377"]
"kaleido-lab/dolphin" ["l"="50.092,38.354"]
"Jun-CEN/SegmentAnyRGBD" ["l"="65.108,11.631"]
"Kenneth-Wong/MMSceneGraph" ["l"="47.634,32.052"]
"JialianW/GRiT" ["l"="47.45,30.28"]
"omniobject3d/OmniObject3D" ["l"="64.225,3.534"]
"jiawei-ren/diffmimic" ["l"="30.446,28.686"]
"cliangyu/Cola" ["l"="50.028,38.415"]
"ZrrSkywalker/CaFo" ["l"="50.378,38.242"]
"geekyutao/TaskRes" ["l"="50.394,38.235"]
"Tsingularity/FRN" ["l"="57.863,19.25"]
"jusiro/CLAP" ["l"="62.287,37.074"]
"NVlabs/DoRA" ["l"="38.605,-0.136"]
"AetherCortex/Llama-X" ["l"="39.103,-2.269"]
"HillZhang1999/llm-hallucination-survey" ["l"="37.656,-6.917"]
"SinclairCoder/Instruction-Tuning-Papers" ["l"="36.756,-2.518"]
"GanjinZero/RRHF" ["l"="37.215,-0.204"]
"PhoebusSi/Alpaca-CoT" ["l"="39.078,-2.202"]
"FranxYao/chain-of-thought-hub" ["l"="37.241,-0.207"]
"zjunlp/EasyEdit" ["l"="37.704,-6.998"]
"Instruction-Tuning-with-GPT-4/GPT-4-LLM" ["l"="39.064,-2.245"]
"allenai/open-instruct" ["l"="37.202,-0.321"]
"altndrr/vic" ["l"="50.571,38.216"]
"altndrr/lmms-owc" ["l"="50.594,38.215"]
"tdemin16/multi-lane" ["l"="50.587,38.226"]
"Jianing-Qiu/Awesome-Healthcare-Foundation-Models" ["l"="62.379,37.633"]
"EdisonLeeeee/Awesome-Masked-Autoencoders" ["l"="52.811,29.38"]
"liliu-avril/Awesome-Segment-Anything" ["l"="48.774,30.116"]
"Hedlen/awesome-segment-anything" ["l"="48.803,30.077"]
"Computer-Vision-in-the-Wild/CVinW_Readings" ["l"="47.472,30.142"]
"richard-peng-xia/awesome-multimodal-in-medical-imaging" ["l"="62.381,37.596"]
"NVlabs/RADIO" ["l"="64.088,2.918"]
"robotics-survey/Awesome-Robotics-Foundation-Models" ["l"="59.391,16.667"]
"ryongithub/GatedPromptTuning" ["l"="50.142,38.286"]
"WangYZ1608/Self-Prompt-Tuning" ["l"="50.136,38.27"]
"mlvlab/RPO" ["l"="50.306,38.328"]
"Zhiyuan-R/ChatGPT-Powered-Hierarchical-Comparisons-for-Image-Classification" ["l"="50.363,38.38"]
"FarinaMatteo/qmmf" ["l"="50.625,38.206"]
"tdemin16/Continual-LayerNorm-Tuning" ["l"="50.645,38.208"]
"ZhengxiangShi/InstructionModelling" ["l"="49.963,38.209"]
"UKPLab/adaptable-adapters" ["l"="50.272,38.15"]
"Koorye/SkipTuning" ["l"="50.478,38.264"]
"chunmeifeng/FedIns" ["l"="50.524,38.21"]
"RERV/UniAdapter" ["l"="50.133,38.231"]
"UniAdapter/UniAdapter" ["l"="50.144,38.216"]
"asif-hanif/baple" ["l"="50.51,38.291"]
"Muhammad-Huzaifaa/ObjectCompose" ["l"="50.527,38.312"]
"Luodian/GenBench" ["l"="50.039,38.393"]
"YBZh/DMN" ["l"="50.47,38.245"]
"Razaimam45/TTL-Test-Time-Low-Rank-Adaptation" ["l"="50.536,38.304"]
"umer-sheikh/bird-whisperer" ["l"="50.551,38.296"]
"tommy-xq/SA2VP" ["l"="50.116,38.277"]
"zhengli97/ATPrompt" ["l"="47.747,35.556"]
"zhaohengz/LLaMP" ["l"="50.442,38.318"]
"schowdhury671/APoLLo" ["l"="50.425,38.315"]
"Picsart-AI-Research/OpenBias" ["l"="50.649,38.193"]
"elaine-sui/TPS" ["l"="50.519,38.243"]
"tsunghan-wu/SLD" ["l"="50.57,38.358"]
"hananshafi/llmblueprint" ["l"="50.534,38.33"]
"rohit901/VANE-Bench" ["l"="48.509,30.383"]
"HashmatShadab/MambaRobustness" ["l"="50.51,38.329"]
"zstarN70/RLRR" ["l"="50.156,38.24"]
"benedettaliberatori/T3AL" ["l"="50.618,38.227"]
"marco-garosi/ComCa" ["l"="50.604,38.229"]
"francescotonini/al-gtd" ["l"="50.608,38.217"]
"YBZh/LAPT" ["l"="-35.407,21.173"]
"strongwolf/OpenSD" ["l"="-35.392,21.183"]
"BioMedIA-MBZUAI/MedPromptX" ["l"="50.55,38.312"]
"BioMedIA-MBZUAI/XReal" ["l"="50.577,38.328"]
"akhtarvision/cal-detr" ["l"="39.493,-7.48"]
"FarinaMatteo/multiflow" ["l"="50.608,38.201"]
"hee-suk-yoon/C-TPT" ["l"="50.503,38.205"]
"Muhammad-Ibraheem-Siddiqui/PerSense" ["l"="50.571,38.287"]
"asif-hanif/palm" ["l"="50.534,38.281"]
"ayesha-ishaq/Open3DTrack" ["l"="50.584,38.299"]
"HashmatShadab/Robustness-of-Volumetric-Medical-Segmentation-Models" ["l"="50.512,38.349"]
"fahadshamshad/deep-facial-privacy-prior" ["l"="50.526,38.348"]
"mbzuai-oryx/UniMed-CLIP" ["l"="50.571,38.311"]
"EvolvingLMMs-Lab/VideoMMMU" ["l"="50.054,38.419"]
"EvolvingLMMs-Lab/Aero-1" ["l"="50.071,38.423"]
}