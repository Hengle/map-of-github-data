digraph G {
"idealo/image-quality-assessment" -> "titu1994/neural-image-assessment"
"idealo/image-quality-assessment" -> "yunxiaoshi/Neural-IMage-Assessment"
"idealo/image-quality-assessment" -> "xialeiliu/RankIQA"
"idealo/image-quality-assessment" -> "ocampor/image-quality"
"idealo/image-quality-assessment" -> "aimerykong/deepImageAestheticsAnalysis"
"idealo/image-quality-assessment" -> "truskovskiyk/nima.pytorch"
"idealo/image-quality-assessment" -> "chaofengc/Awesome-Image-Quality-Assessment"
"idealo/image-quality-assessment" -> "ylogx/aesthetics"
"idealo/image-quality-assessment" -> "imfing/ava_downloader"
"idealo/image-quality-assessment" -> "chaofengc/IQA-PyTorch"
"idealo/image-quality-assessment" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"idealo/image-quality-assessment" -> "SSL92/hyperIQA"
"idealo/image-quality-assessment" -> "pterhoer/FaceImageQuality" ["e"=1]
"idealo/image-quality-assessment" -> "idealo/imagededup" ["e"=1]
"idealo/image-quality-assessment" -> "dmaniry/deepIQA"
"jacob6/ENIQA" -> "imfing/CEIQ"
"open-webrtc-toolkit/QoSTestFramework" -> "lidq92/MDTVSFA"
"open-webrtc-toolkit/QoSTestFramework" -> "vztu/VIDEVAL"
"open-webrtc-toolkit/QoSTestFramework" -> "Tencent/DVQA"
"dsoellinger/blind_image_quality_toolbox" -> "bukalapak/pybrisque"
"dsoellinger/blind_image_quality_toolbox" -> "HuiZeng/BIQA_Toolbox"
"dsoellinger/blind_image_quality_toolbox" -> "ysyscool/SGDNet"
"dsoellinger/blind_image_quality_toolbox" -> "lidq92/CNNIQAplusplus"
"dsoellinger/blind_image_quality_toolbox" -> "zwx8981/DBCNN"
"dsoellinger/blind_image_quality_toolbox" -> "lidq92/WaDIQaM"
"dsoellinger/blind_image_quality_toolbox" -> "gregfreeman/image_quality_toolbox"
"lidq92/SFA" -> "lidq92/CNNIQAplusplus"
"lidq92/SFA" -> "lidq92/WaDIQaM"
"lidq92/SFA" -> "lidq92/LinearityIQA"
"lidq92/SFA" -> "HuiZeng/BIQA_Toolbox"
"lidq92/SFA" -> "ysyscool/SGDNet"
"lidq92/SFA" -> "imfing/CEIQ"
"lidq92/SFA" -> "zwx8981/DBCNN"
"lidq92/SFA" -> "lidq92/CNNIQA"
"lidq92/SFA" -> "lidq92/MDTVSFA"
"lidq92/SFA" -> "lidq92/VSFA"
"lidq92/SFA" -> "zhuhancheng/MetaIQA"
"lidq92/SFA" -> "qingsenyangit/Two-stream_IQA"
"lidq92/SFA" -> "subpic/koniq"
"lidq92/SFA" -> "zwx8981/DBCNN-PyTorch"
"xungeer29/No-reference-Image-Quality-Assessment" -> "jongyookim/IQA_BIECON_release"
"xungeer29/No-reference-Image-Quality-Assessment" -> "lidq92/CNNIQAplusplus"
"zwx8981/DBCNN-PyTorch" -> "zwx8981/DBCNN"
"zwx8981/DBCNN-PyTorch" -> "zwx8981/UNIQUE"
"zwx8981/DBCNN-PyTorch" -> "SSL92/hyperIQA"
"zwx8981/DBCNN-PyTorch" -> "zhuhancheng/MetaIQA"
"zwx8981/DBCNN-PyTorch" -> "lidq92/CNNIQAplusplus"
"zwx8981/DBCNN-PyTorch" -> "dmaniry/deepIQA"
"zwx8981/DBCNN-PyTorch" -> "ysyscool/SGDNet"
"zwx8981/DBCNN-PyTorch" -> "lidq92/WaDIQaM"
"zwx8981/DBCNN-PyTorch" -> "lidq92/CNNIQA"
"zwx8981/DBCNN-PyTorch" -> "subpic/koniq"
"zwx8981/DBCNN-PyTorch" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"zwx8981/DBCNN-PyTorch" -> "lidq92/SFA"
"zwx8981/DBCNN-PyTorch" -> "lidq92/VSFA"
"zwx8981/DBCNN-PyTorch" -> "pavancm/CONTRIQUE"
"zwx8981/DBCNN-PyTorch" -> "xialeiliu/RankIQA"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "yiling-chen/flickr-cropping-dataset"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "zijunwei/ViewProposalNet"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "yiling-chen/view-finding-network"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "zijunwei/ViewEvaluationNet"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "wuhuikai/TF-A2RL"
"HuiZeng/Grid-Anchor-based-Image-Cropping" -> "CVBase-Bupt/EndtoEndCroppingSystem"
"subpic/ava-mlsp" -> "Openning07/MPADA"
"subpic/ava-mlsp" -> "miyamotty/awesome_ImageAesthetics"
"subpic/ava-mlsp" -> "zhuhancheng/BLG-PIAA"
"subpic/ava-mlsp" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"subpic/ava-mlsp" -> "alanspike/personalizedImageAesthetics"
"subpic/ava-mlsp" -> "fei-aiart/ReLIC"
"subpic/ava-mlsp" -> "huangeddie/ML-Aesthetics-NIMA"
"subpic/ava-mlsp" -> "HuiZeng/Unified_IAA"
"subpic/ava-mlsp" -> "cgtuebingen/will-people-like-your-image"
"ocampor/image-quality" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"ocampor/image-quality" -> "jongyookim/IQA_BIECON_release"
"ocampor/image-quality" -> "idealo/image-quality-assessment"
"ocampor/image-quality" -> "ryanxingql/image-quality-assessment-toolbox"
"ocampor/image-quality" -> "krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model"
"ocampor/image-quality" -> "francois-rozet/piqa" ["e"=1]
"ocampor/image-quality" -> "bukalapak/pybrisque"
"ocampor/image-quality" -> "lidq92/CNNIQA"
"ocampor/image-quality" -> "chaofengc/Awesome-Image-Quality-Assessment"
"ocampor/image-quality" -> "SSL92/hyperIQA"
"ocampor/image-quality" -> "buyizhiyou/NRVQA"
"ocampor/image-quality" -> "subpic/koniq"
"ocampor/image-quality" -> "zwx8981/DBCNN-PyTorch"
"ocampor/image-quality" -> "zwx8981/DBCNN"
"ocampor/image-quality" -> "guptapraful/niqe"
"titu1994/neural-image-assessment" -> "truskovskiyk/nima.pytorch"
"titu1994/neural-image-assessment" -> "yunxiaoshi/Neural-IMage-Assessment"
"titu1994/neural-image-assessment" -> "idealo/image-quality-assessment"
"titu1994/neural-image-assessment" -> "imfing/ava_downloader"
"titu1994/neural-image-assessment" -> "aimerykong/deepImageAestheticsAnalysis"
"titu1994/neural-image-assessment" -> "xialeiliu/RankIQA"
"titu1994/neural-image-assessment" -> "ylogx/aesthetics"
"titu1994/neural-image-assessment" -> "BestiVictory/ILGnet"
"titu1994/neural-image-assessment" -> "master/nima"
"titu1994/neural-image-assessment" -> "Adnan1011/NR-IQA-CNN"
"titu1994/neural-image-assessment" -> "cgtuebingen/will-people-like-your-image"
"titu1994/neural-image-assessment" -> "dmaniry/deepIQA"
"titu1994/neural-image-assessment" -> "wuhuikai/TF-A2RL"
"titu1994/neural-image-assessment" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"titu1994/neural-image-assessment" -> "zwx8981/DBCNN-PyTorch"
"mahdihosseini/FoucsPath" -> "mahdihosseini/HVS-MaxPol"
"sergeyk/vislab" -> "aimerykong/deepImageAestheticsAnalysis"
"zwx8981/DBCNN" -> "zwx8981/DBCNN-PyTorch"
"zwx8981/DBCNN" -> "jongyookim/IQA_BIECON_release"
"zwx8981/DBCNN" -> "zwx8981/UNIQUE"
"zwx8981/DBCNN" -> "lidq92/SFA"
"zwx8981/DBCNN" -> "lidq92/WaDIQaM"
"zwx8981/DBCNN" -> "ysyscool/SGDNet"
"zwx8981/DBCNN" -> "SenJia/Saliency-CNN-Image-Quality-Assessment"
"zwx8981/DBCNN" -> "HuiZeng/BIQA_Toolbox"
"zwx8981/DBCNN" -> "lidq92/CNNIQA"
"zwx8981/DBCNN" -> "lidq92/CNNIQAplusplus"
"zwx8981/DBCNN" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"zwx8981/DBCNN" -> "dmaniry/deepIQA"
"zwx8981/DBCNN" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"zwx8981/DBCNN" -> "junyongyou/triq"
"zwx8981/DBCNN" -> "zhuhancheng/MetaIQA"
"jongyookim/IQA_DeepQA_FR_release" -> "jongyookim/IQA_BIECON_release"
"jongyookim/IQA_DeepQA_FR_release" -> "lidq92/CNNIQAplusplus"
"jongyookim/IQA_DeepQA_FR_release" -> "LeonLIU08/DeepQA-with-Pytorch"
"jongyookim/IQA_DeepQA_FR_release" -> "dmaniry/deepIQA"
"jongyookim/IQA_DeepQA_FR_release" -> "Bobholamovic/CNN-FRIQA"
"jongyookim/IQA_DeepQA_FR_release" -> "lidq92/CNNIQA"
"truskovskiyk/nima.pytorch" -> "yunxiaoshi/Neural-IMage-Assessment"
"truskovskiyk/nima.pytorch" -> "titu1994/neural-image-assessment"
"truskovskiyk/nima.pytorch" -> "imfing/ava_downloader"
"truskovskiyk/nima.pytorch" -> "aimerykong/deepImageAestheticsAnalysis"
"truskovskiyk/nima.pytorch" -> "Openning07/MPADA"
"truskovskiyk/nima.pytorch" -> "subpic/ava-mlsp"
"truskovskiyk/nima.pytorch" -> "ylogx/aesthetics"
"truskovskiyk/nima.pytorch" -> "idealo/image-quality-assessment"
"truskovskiyk/nima.pytorch" -> "zwx8981/DBCNN-PyTorch"
"truskovskiyk/nima.pytorch" -> "BestiVictory/ILGnet"
"truskovskiyk/nima.pytorch" -> "master/nima"
"truskovskiyk/nima.pytorch" -> "anse3832/MUSIQ"
"truskovskiyk/nima.pytorch" -> "alanspike/personalizedImageAesthetics"
"truskovskiyk/nima.pytorch" -> "cgtuebingen/will-people-like-your-image"
"truskovskiyk/nima.pytorch" -> "hejingwenhejingwen/CSRNet" ["e"=1]
"yunxiaoshi/Neural-IMage-Assessment" -> "truskovskiyk/nima.pytorch"
"yunxiaoshi/Neural-IMage-Assessment" -> "titu1994/neural-image-assessment"
"yunxiaoshi/Neural-IMage-Assessment" -> "imfing/ava_downloader"
"yunxiaoshi/Neural-IMage-Assessment" -> "idealo/image-quality-assessment"
"yunxiaoshi/Neural-IMage-Assessment" -> "aimerykong/deepImageAestheticsAnalysis"
"yunxiaoshi/Neural-IMage-Assessment" -> "Openning07/MPADA"
"yunxiaoshi/Neural-IMage-Assessment" -> "zwx8981/DBCNN-PyTorch"
"yunxiaoshi/Neural-IMage-Assessment" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"yunxiaoshi/Neural-IMage-Assessment" -> "subpic/ava-mlsp"
"yunxiaoshi/Neural-IMage-Assessment" -> "ylogx/aesthetics"
"yunxiaoshi/Neural-IMage-Assessment" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"yunxiaoshi/Neural-IMage-Assessment" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"yunxiaoshi/Neural-IMage-Assessment" -> "SSL92/hyperIQA"
"yunxiaoshi/Neural-IMage-Assessment" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"yunxiaoshi/Neural-IMage-Assessment" -> "IceClear/CLIP-IQA"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "bukalapak/pybrisque"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "xungeer29/No-reference-Image-Quality-Assessment"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "jongyookim/IQA_BIECON_release"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "ocampor/image-quality"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "lidq92/CNNIQAplusplus"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "xialeiliu/RankIQA"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "guptapraful/niqe"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "zhenglab/IQA"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "lidq92/CNNIQA"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "dmaniry/deepIQA"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "zwx8981/DBCNN-PyTorch"
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" -> "zhuhancheng/MetaIQA"
"lidq92/CNNIQA" -> "lidq92/CNNIQAplusplus"
"lidq92/CNNIQA" -> "jongyookim/IQA_BIECON_release"
"lidq92/CNNIQA" -> "lidq92/WaDIQaM"
"lidq92/CNNIQA" -> "zwx8981/DBCNN-PyTorch"
"lidq92/CNNIQA" -> "lidq92/SFA"
"lidq92/CNNIQA" -> "dmaniry/deepIQA"
"lidq92/CNNIQA" -> "zwx8981/DBCNN"
"lidq92/CNNIQA" -> "jongyookim/IQA_DeepQA_FR_release"
"lidq92/CNNIQA" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"lidq92/CNNIQA" -> "HuiZeng/BIQA_Toolbox"
"lidq92/CNNIQA" -> "zhuhancheng/MetaIQA"
"lidq92/CNNIQA" -> "xialeiliu/RankIQA"
"lidq92/CNNIQA" -> "ysyscool/SGDNet"
"lidq92/CNNIQA" -> "kwanyeelin/HIQA"
"lidq92/CNNIQA" -> "LeonLIU08/DeepQA-with-Pytorch"
"imfing/CEIQ" -> "steffensbola/blind_iqa_contrast"
"imfing/CEIQ" -> "lidq92/SFA"
"imfing/CEIQ" -> "jacob6/ENIQA"
"wuhuikai/TF-A2RL" -> "yiling-chen/view-finding-network"
"wuhuikai/TF-A2RL" -> "yiling-chen/flickr-cropping-dataset"
"wuhuikai/TF-A2RL" -> "zijunwei/ViewProposalNet"
"wuhuikai/TF-A2RL" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"wuhuikai/TF-A2RL" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"wuhuikai/TF-A2RL" -> "zijunwei/ViewEvaluationNet"
"wuhuikai/TF-A2RL" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"wuhuikai/TF-A2RL" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"wuhuikai/TF-A2RL" -> "bcmi/Human-Centric-Image-Cropping"
"wuhuikai/TF-A2RL" -> "bo-zhang-cs/CACNet-Pytorch"
"ysyscool/SGDNet" -> "lidq92/CNNIQAplusplus"
"ysyscool/SGDNet" -> "SenJia/Saliency-CNN-Image-Quality-Assessment"
"ysyscool/SGDNet" -> "HuiZeng/BIQA_Toolbox"
"ysyscool/SGDNet" -> "qingsenyangit/Two-stream_IQA"
"ysyscool/SGDNet" -> "lidq92/SFA"
"ysyscool/SGDNet" -> "zwx8981/DBCNN-PyTorch"
"ysyscool/SGDNet" -> "zwx8981/DBCNN"
"ysyscool/SGDNet" -> "junyongyou/triq"
"ysyscool/SGDNet" -> "zwx8981/UNIQUE"
"ysyscool/SGDNet" -> "subpic/koniq"
"lidq92/VSFA" -> "lidq92/MDTVSFA"
"lidq92/VSFA" -> "vztu/BVQA_Benchmark"
"lidq92/VSFA" -> "vztu/VIDEVAL"
"lidq92/VSFA" -> "baidut/PatchVQ"
"lidq92/VSFA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"lidq92/VSFA" -> "lidq92/WaDIQaM"
"lidq92/VSFA" -> "jarikorhonen/nr-vqa-consumervideo"
"lidq92/VSFA" -> "lidq92/SFA"
"lidq92/VSFA" -> "zwx8981/DBCNN-PyTorch"
"lidq92/VSFA" -> "zwx8981/TCSVT-2022-BVQA"
"lidq92/VSFA" -> "Tencent/DVQA"
"lidq92/VSFA" -> "woojaekim/DeepVQA_Release"
"lidq92/VSFA" -> "ysyscool/SGDNet"
"lidq92/VSFA" -> "vztu/RAPIQUE"
"lidq92/VSFA" -> "sunwei925/SimpleVQA"
"vinthony/s2am" -> "Dominoer/bmvc2020_image_harmonization"
"vinthony/s2am" -> "wasidennis/DeepHarmonization"
"vinthony/s2am" -> "stefanLeong/S2CRNet"
"vinthony/s2am" -> "jflalonde/colorRealism"
"prashnani/PerceptualImageError" -> "lidq92/WaDIQaM"
"prashnani/PerceptualImageError" -> "dingkeyan93/DISTS"
"prashnani/PerceptualImageError" -> "dingkeyan93/IQA-optimization"
"prashnani/PerceptualImageError" -> "dmaniry/deepIQA"
"prashnani/PerceptualImageError" -> "zwx8981/DBCNN-PyTorch"
"prashnani/PerceptualImageError" -> "HuiZeng/BIQA_Toolbox"
"prashnani/PerceptualImageError" -> "IIGROUP/AHIQ"
"prashnani/PerceptualImageError" -> "zwx8981/DBCNN"
"prashnani/PerceptualImageError" -> "lidq92/CNNIQAplusplus"
"prashnani/PerceptualImageError" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"prashnani/PerceptualImageError" -> "zhuhancheng/MetaIQA"
"prashnani/PerceptualImageError" -> "HaomingCai/PIPAL-dataset"
"prashnani/PerceptualImageError" -> "kwanyeelin/HIQA"
"prashnani/PerceptualImageError" -> "lidq92/CNNIQA"
"prashnani/PerceptualImageError" -> "SSL92/hyperIQA"
"bukalapak/pybrisque" -> "dsoellinger/blind_image_quality_toolbox"
"bukalapak/pybrisque" -> "buyizhiyou/NRVQA"
"bukalapak/pybrisque" -> "guptapraful/niqe"
"bukalapak/pybrisque" -> "krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model"
"bukalapak/pybrisque" -> "HuiZeng/BIQA_Toolbox"
"bukalapak/pybrisque" -> "rehanguha/brisque"
"bukalapak/pybrisque" -> "rendezhous/image-quality-assessment-python"
"bukalapak/pybrisque" -> "SSL92/hyperIQA"
"bukalapak/pybrisque" -> "zhuhancheng/MetaIQA"
"bukalapak/pybrisque" -> "subpic/koniq"
"bukalapak/pybrisque" -> "ocampor/notebooks"
"bukalapak/pybrisque" -> "zwx8981/DBCNN-PyTorch"
"bukalapak/pybrisque" -> "lidq92/WaDIQaM"
"bukalapak/pybrisque" -> "ocampor/image-quality"
"alanspike/personalizedImageAesthetics" -> "zhuhancheng/BLG-PIAA"
"alanspike/personalizedImageAesthetics" -> "subpic/ava-mlsp"
"jarikorhonen/nr-vqa-consumervideo" -> "baidut/PatchVQ"
"jarikorhonen/nr-vqa-consumervideo" -> "pavancm/vbliinds"
"jarikorhonen/nr-vqa-consumervideo" -> "vztu/RAPIQUE"
"jarikorhonen/nr-vqa-consumervideo" -> "lfovia/NRVQA-NSTSS"
"jarikorhonen/nr-vqa-consumervideo" -> "vztu/VIDEVAL"
"jarikorhonen/nr-vqa-consumervideo" -> "jarikorhonen/cnn-tlvqm"
"jarikorhonen/nr-vqa-consumervideo" -> "zwx8981/TCSVT-2022-BVQA"
"zijunwei/ViewEvaluationNet" -> "zijunwei/ViewProposalNet"
"zijunwei/ViewEvaluationNet" -> "yiling-chen/view-finding-network"
"zijunwei/ViewEvaluationNet" -> "remorsecs/pytorch-view-finding-network"
"HuiZeng/BIQA_Toolbox" -> "lidq92/SFA"
"HuiZeng/BIQA_Toolbox" -> "lidq92/WaDIQaM"
"HuiZeng/BIQA_Toolbox" -> "jongyookim/IQA_BIECON_release"
"HuiZeng/BIQA_Toolbox" -> "ysyscool/SGDNet"
"HuiZeng/BIQA_Toolbox" -> "xialeiliu/RankIQA"
"HuiZeng/BIQA_Toolbox" -> "dmaniry/deepIQA"
"HuiZeng/BIQA_Toolbox" -> "lidq92/CNNIQAplusplus"
"HuiZeng/BIQA_Toolbox" -> "zwx8981/DBCNN"
"HuiZeng/BIQA_Toolbox" -> "Adnan1011/NR-IQA-CNN"
"HuiZeng/BIQA_Toolbox" -> "zhuhancheng/MetaIQA"
"HuiZeng/BIQA_Toolbox" -> "zwx8981/DBCNN-PyTorch"
"HuiZeng/BIQA_Toolbox" -> "lidq92/CNNIQA"
"HuiZeng/BIQA_Toolbox" -> "qingsenyangit/Two-stream_IQA"
"HuiZeng/BIQA_Toolbox" -> "Archer-Tatsu/V-CNN" ["e"=1]
"HuiZeng/BIQA_Toolbox" -> "baidut/paq2piq"
"pcpmartins/video-quality-assessment" -> "vztu/BVQA_Benchmark"
"lidq92/WaDIQaM" -> "dmaniry/deepIQA"
"lidq92/WaDIQaM" -> "lidq92/SFA"
"lidq92/WaDIQaM" -> "lidq92/CNNIQAplusplus"
"lidq92/WaDIQaM" -> "jongyookim/IQA_BIECON_release"
"lidq92/WaDIQaM" -> "HuiZeng/BIQA_Toolbox"
"lidq92/WaDIQaM" -> "lidq92/CNNIQA"
"lidq92/WaDIQaM" -> "zhuhancheng/MetaIQA"
"lidq92/WaDIQaM" -> "zwx8981/DBCNN-PyTorch"
"lidq92/WaDIQaM" -> "lidq92/VSFA"
"lidq92/WaDIQaM" -> "subpic/koniq"
"lidq92/WaDIQaM" -> "zwx8981/DBCNN"
"lidq92/WaDIQaM" -> "SSL92/hyperIQA"
"lidq92/WaDIQaM" -> "prashnani/PerceptualImageError"
"lidq92/WaDIQaM" -> "baidut/PaQ-2-PiQ"
"lidq92/WaDIQaM" -> "junyongyou/triq"
"cgtuebingen/will-people-like-your-image" -> "BestiVictory/DPC-Captions"
"cgtuebingen/will-people-like-your-image" -> "ylogx/aesthetics"
"cgtuebingen/will-people-like-your-image" -> "aimerykong/deepImageAestheticsAnalysis"
"cgtuebingen/will-people-like-your-image" -> "subpic/ava-mlsp"
"cgtuebingen/will-people-like-your-image" -> "kunghunglu/DeepPhotoCritic-ICCV17"
"SINRG-Lab/VQA-Deep-Learning" -> "woojaekim/DeepVQA_Release"
"lidq92/CNNIQAplusplus" -> "lidq92/CNNIQA"
"lidq92/CNNIQAplusplus" -> "jongyookim/IQA_BIECON_release"
"lidq92/CNNIQAplusplus" -> "lidq92/SFA"
"lidq92/CNNIQAplusplus" -> "ysyscool/SGDNet"
"lidq92/CNNIQAplusplus" -> "lidq92/WaDIQaM"
"lidq92/CNNIQAplusplus" -> "dmaniry/deepIQA"
"lidq92/CNNIQAplusplus" -> "zwx8981/DBCNN-PyTorch"
"lidq92/CNNIQAplusplus" -> "HuiZeng/BIQA_Toolbox"
"lidq92/CNNIQAplusplus" -> "jongyookim/IQA_DeepQA_FR_release"
"lidq92/CNNIQAplusplus" -> "zwx8981/DBCNN"
"zijunwei/ViewProposalNet" -> "zijunwei/ViewEvaluationNet"
"zijunwei/ViewProposalNet" -> "yiling-chen/view-finding-network"
"zijunwei/ViewProposalNet" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"zijunwei/ViewProposalNet" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"zijunwei/ViewProposalNet" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"zijunwei/ViewProposalNet" -> "yiling-chen/flickr-cropping-dataset"
"CVBase-Bupt/EndtoEndCroppingSystem" -> "bo-zhang-cs/CGS-Pytorch"
"mahdihosseini/MaxPol" -> "mahdihosseini/HVS-MaxPol"
"mahdihosseini/MaxPol" -> "mahdihosseini/1Shot-MaxPol"
"mahdihosseini/FQPath" -> "mahdihosseini/HVS-MaxPol"
"mahdihosseini/FQPath" -> "mahdihosseini/FoucsPath"
"mahdihosseini/HVS-MaxPol" -> "mahdihosseini/FoucsPath"
"mahdihosseini/HVS-MaxPol" -> "mahdihosseini/MaxPol"
"steffensbola/blind_iqa_contrast" -> "imfing/CEIQ"
"mahdihosseini/1Shot-MaxPol" -> "mahdihosseini/MaxPol"
"huangeddie/ML-Aesthetics-NIMA" -> "isaaccorley/deep-aesthetics-pytorch"
"huangeddie/ML-Aesthetics-NIMA" -> "fei-aiart/ReLIC"
"huangeddie/ML-Aesthetics-NIMA" -> "janpf/self-supervised-multi-task-aesthetic-pretraining"
"SenJia/Saliency-CNN-Image-Quality-Assessment" -> "qingsenyangit/Two-stream_IQA"
"qingsenyangit/Two-stream_IQA" -> "SenJia/Saliency-CNN-Image-Quality-Assessment"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "zijunwei/ViewProposalNet"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "zijunwei/ViewEvaluationNet"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "suyukun666/S2CNet"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bo-zhang-cs/CGS-Pytorch"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "yiling-chen/view-finding-network"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "yiling-chen/flickr-cropping-dataset"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "luwr1022/listwise-view-ranking"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "liuxiaoyu1104/UNIC"
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bo-zhang-cs/CACNet-Pytorch"
"miyamotty/awesome_ImageAesthetics" -> "subpic/ava-mlsp"
"miyamotty/awesome_ImageAesthetics" -> "Openning07/MPADA"
"miyamotty/awesome_ImageAesthetics" -> "alanspike/personalizedImageAesthetics"
"Tencent/DVQA" -> "lidq92/VSFA"
"Tencent/DVQA" -> "vztu/VIDEVAL"
"Tencent/DVQA" -> "vztu/BVQA_Benchmark"
"Tencent/DVQA" -> "Tencent/CenseoQoE"
"Tencent/DVQA" -> "lidq92/MDTVSFA"
"Tencent/DVQA" -> "SINRG-Lab/VQA-Deep-Learning"
"Tencent/DVQA" -> "woojaekim/DeepVQA_Release"
"Tencent/DVQA" -> "open-webrtc-toolkit/QoSTestFramework"
"Tencent/DVQA" -> "zhuhancheng/MetaIQA"
"Tencent/DVQA" -> "SSL92/hyperIQA"
"Tencent/DVQA" -> "zwx8981/DBCNN-PyTorch"
"Tencent/DVQA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"Tencent/DVQA" -> "xialeiliu/RankIQA"
"Tencent/DVQA" -> "jarikorhonen/nr-vqa-consumervideo"
"Tencent/DVQA" -> "baidut/PatchVQ"
"SSL92/hyperIQA" -> "zwx8981/DBCNN-PyTorch"
"SSL92/hyperIQA" -> "zhuhancheng/MetaIQA"
"SSL92/hyperIQA" -> "h4nwei/SPAQ"
"SSL92/hyperIQA" -> "zwx8981/UNIQUE"
"SSL92/hyperIQA" -> "junyongyou/triq"
"SSL92/hyperIQA" -> "xialeiliu/RankIQA"
"SSL92/hyperIQA" -> "lidq92/WaDIQaM"
"SSL92/hyperIQA" -> "pavancm/CONTRIQUE"
"SSL92/hyperIQA" -> "isalirezag/TReS"
"SSL92/hyperIQA" -> "anse3832/MUSIQ"
"SSL92/hyperIQA" -> "dmaniry/deepIQA"
"SSL92/hyperIQA" -> "subpic/koniq"
"SSL92/hyperIQA" -> "zwx8981/DBCNN"
"SSL92/hyperIQA" -> "lidq92/LinearityIQA"
"SSL92/hyperIQA" -> "IIGROUP/MANIQA"
"zwx8981/UNIQUE" -> "zwx8981/DBCNN-PyTorch"
"zwx8981/UNIQUE" -> "zwx8981/BIQA_CL"
"zwx8981/UNIQUE" -> "zwx8981/DBCNN"
"zwx8981/UNIQUE" -> "h4nwei/SPAQ"
"zwx8981/UNIQUE" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"zwx8981/UNIQUE" -> "SSL92/hyperIQA"
"zwx8981/UNIQUE" -> "zhuhancheng/MetaIQA"
"zwx8981/UNIQUE" -> "guanghaoyin/CVRKD-IQA"
"zwx8981/UNIQUE" -> "ysyscool/SGDNet"
"zwx8981/UNIQUE" -> "subpic/koniq"
"zwx8981/UNIQUE" -> "anse3832/MUSIQ"
"zwx8981/UNIQUE" -> "researchmm/CKDN"
"zwx8981/UNIQUE" -> "geekyutao/GraphIQA"
"zwx8981/UNIQUE" -> "pavancm/CONTRIQUE"
"zwx8981/UNIQUE" -> "lidq92/WaDIQaM"
"fei-aiart/ReLIC" -> "huangeddie/ML-Aesthetics-NIMA"
"cientgu/GIQA" -> "junyongyou/triq"
"cientgu/GIQA" -> "SSL92/hyperIQA"
"cientgu/GIQA" -> "zhuhancheng/MetaIQA"
"cientgu/GIQA" -> "zwx8981/DBCNN-PyTorch"
"cientgu/GIQA" -> "h4nwei/SPAQ"
"cientgu/GIQA" -> "lidq92/SFA"
"cientgu/GIQA" -> "subpic/koniq"
"cientgu/GIQA" -> "LeonLIU08/DeepQA-with-Pytorch"
"cientgu/GIQA" -> "zwx8981/UNIQUE"
"cientgu/GIQA" -> "researchmm/CKDN"
"cientgu/GIQA" -> "prashnani/PerceptualImageError"
"cientgu/GIQA" -> "lidq92/WaDIQaM"
"cientgu/GIQA" -> "pavancm/CONTRIQUE"
"cientgu/GIQA" -> "anse3832/IQT"
"cientgu/GIQA" -> "guanghaoyin/CVRKD-IQA"
"zheng-yuwei/RankIQA.PyTorch" -> "YunanZhu/Pytorch-TestRankIQA"
"zheng-yuwei/RankIQA.PyTorch" -> "xialeiliu/RankIQA"
"zheng-yuwei/RankIQA.PyTorch" -> "lidq92/LinearityIQA"
"zheng-yuwei/RankIQA.PyTorch" -> "lidq92/MDTVSFA"
"zheng-yuwei/RankIQA.PyTorch" -> "SSL92/hyperIQA"
"zheng-yuwei/RankIQA.PyTorch" -> "pavancm/CONTRIQUE"
"zheng-yuwei/RankIQA.PyTorch" -> "zwx8981/BIQA_CL"
"zheng-yuwei/RankIQA.PyTorch" -> "zwx8981/LIQE"
"zheng-yuwei/RankIQA.PyTorch" -> "guanghaoyin/CVRKD-IQA"
"zheng-yuwei/RankIQA.PyTorch" -> "HaomingCai/PIPAL-dataset"
"zheng-yuwei/RankIQA.PyTorch" -> "xungeer29/No-reference-Image-Quality-Assessment"
"zheng-yuwei/RankIQA.PyTorch" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "bo-zhang-cs/CACNet-Pytorch"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "suyukun666/S2CNet"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "mediatechnologycenter/Aestheval"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "Dreemurr-T/BAID"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "woshidandan/Image-Aesthetics-and-Quality-Assessment"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "bcmi/Human-Centric-Image-Cropping"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "aimerykong/deepImageAestheticsAnalysis"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "subpic/ava-mlsp"
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" -> "liuxiaoyu1104/UNIC"
"icbcbicc/FocusLiteNN" -> "mahdihosseini/HVS-MaxPol"
"icbcbicc/FocusLiteNN" -> "mahdihosseini/FoucsPath"
"icbcbicc/FocusLiteNN" -> "icbcbicc/PyTorch_EPLL"
"lidq92/LinearityIQA" -> "lidq92/MDTVSFA"
"lidq92/LinearityIQA" -> "lidq92/SFA"
"lidq92/LinearityIQA" -> "zhuhancheng/MetaIQA"
"lidq92/LinearityIQA" -> "ysyscool/SGDNet"
"lidq92/LinearityIQA" -> "SSL92/hyperIQA"
"h4nwei/SPAQ" -> "zwx8981/UNIQUE"
"h4nwei/SPAQ" -> "SSL92/hyperIQA"
"h4nwei/SPAQ" -> "zhuhancheng/MetaIQA"
"h4nwei/SPAQ" -> "zwx8981/DBCNN-PyTorch"
"h4nwei/SPAQ" -> "guanghaoyin/CVRKD-IQA"
"h4nwei/SPAQ" -> "DXOMARK-Research/PIQ2023"
"h4nwei/SPAQ" -> "baidut/PaQ-2-PiQ"
"h4nwei/SPAQ" -> "baidut/paq2piq"
"h4nwei/SPAQ" -> "subpic/koniq"
"h4nwei/SPAQ" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"h4nwei/SPAQ" -> "zwx8981/BIQA_CL"
"h4nwei/SPAQ" -> "isalirezag/TReS"
"h4nwei/SPAQ" -> "cientgu/GIQA"
"h4nwei/SPAQ" -> "anse3832/MUSIQ"
"h4nwei/SPAQ" -> "HuiZeng/BIQA_Toolbox"
"ZhengyuZhao/koniq-PyTorch" -> "subpic/koniq"
"buyizhiyou/NRVQA" -> "guptapraful/niqe"
"buyizhiyou/NRVQA" -> "bukalapak/pybrisque"
"buyizhiyou/NRVQA" -> "lidq92/VSFA"
"buyizhiyou/NRVQA" -> "zhuhancheng/MetaIQA"
"buyizhiyou/NRVQA" -> "chaoma99/sr-metric"
"buyizhiyou/NRVQA" -> "EadCat/NIQA"
"buyizhiyou/NRVQA" -> "buyizhiyou/papers"
"buyizhiyou/NRVQA" -> "vztu/VIDEVAL"
"buyizhiyou/NRVQA" -> "lidq92/MDTVSFA"
"buyizhiyou/NRVQA" -> "guanghaoyin/CVRKD-IQA"
"buyizhiyou/NRVQA" -> "Tencent/DVQA"
"buyizhiyou/NRVQA" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"buyizhiyou/NRVQA" -> "IIGROUP/MANIQA"
"buyizhiyou/NRVQA" -> "subpic/koniq"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Awesome-Image-Composition" ["e"=1]
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Image-Harmonization-Dataset-iHarmony4"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/Awesome-Image-Harmonization" -> "SamsungLabs/image_harmonization"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/libcom"
"bcmi/Awesome-Image-Harmonization" -> "junleen/RainNet"
"bcmi/Awesome-Image-Harmonization" -> "chenhaoxing/HDNet"
"bcmi/Awesome-Image-Harmonization" -> "ZHKKKe/Harmonizer"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Awesome-Object-Placement"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/ControlCom-Image-Composition"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Awesome-Image-Harmonization" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/F2GAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "WisconsinAIVision/few-shot-gan-adaptation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/CaGNet-Zero-Shot-Semantic-Segmentation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "edward3862/LoFGAN-pytorch"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/MatchingGAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/ControlCom-Image-Composition"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "kobeshegu/awesome-few-shot-generation"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "georgosgeorgos/few-shot-diffusion-models"
"bcmi/Awesome-Few-Shot-Image-Generation" -> "bcmi/BargainNet-Image-Harmonization"
"subpic/koniq" -> "ZhengyuZhao/koniq-PyTorch"
"subpic/koniq" -> "zhuhancheng/MetaIQA"
"subpic/koniq" -> "baidut/PaQ-2-PiQ"
"subpic/koniq" -> "zwx8981/DBCNN-PyTorch"
"subpic/koniq" -> "lidq92/WaDIQaM"
"subpic/koniq" -> "lidq92/SFA"
"subpic/koniq" -> "ysyscool/SGDNet"
"subpic/koniq" -> "isalirezag/TReS"
"subpic/koniq" -> "zwx8981/UNIQUE"
"subpic/koniq" -> "anse3832/MUSIQ"
"subpic/koniq" -> "SSL92/hyperIQA"
"subpic/koniq" -> "lidq92/CNNIQAplusplus"
"subpic/koniq" -> "junyongyou/triq"
"subpic/koniq" -> "h4nwei/SPAQ"
"subpic/koniq" -> "zwx8981/DBCNN"
"dingkeyan93/DISTS" -> "dingkeyan93/IQA-optimization"
"dingkeyan93/DISTS" -> "prashnani/PerceptualImageError"
"dingkeyan93/DISTS" -> "zwx8981/DBCNN-PyTorch"
"dingkeyan93/DISTS" -> "junyongyou/triq"
"dingkeyan93/DISTS" -> "zwx8981/UNIQUE"
"dingkeyan93/DISTS" -> "IIGROUP/AHIQ"
"dingkeyan93/DISTS" -> "subpic/koniq"
"dingkeyan93/DISTS" -> "SSL92/hyperIQA"
"dingkeyan93/DISTS" -> "lidq92/WaDIQaM"
"dingkeyan93/DISTS" -> "zhuhancheng/MetaIQA"
"dingkeyan93/DISTS" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"dingkeyan93/DISTS" -> "zwx8981/DBCNN"
"dingkeyan93/DISTS" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"dingkeyan93/DISTS" -> "IIGROUP/MANIQA"
"dingkeyan93/DISTS" -> "xialeiliu/RankIQA"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "zwx8981/DBCNN-PyTorch"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "lidq92/CNNIQA"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "zwx8981/DBCNN"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "lidq92/WaDIQaM"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "dingkeyan93/IQA-optimization"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "ryanxingql/image-quality-assessment-toolbox"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "ysyscool/SGDNet"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "zwx8981/UNIQUE"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "zhuhancheng/MetaIQA"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "SSL92/hyperIQA"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "ocampor/image-quality"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "icbcbicc/IQA-Dataset"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "xungeer29/No-reference-Image-Quality-Assessment"
"weizhou-geek/Image-Quality-Assessment-Benchmark" -> "pavancm/CONTRIQUE"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/CaGNet-Zero-Shot-Semantic-Segmentation"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Awesome-Image-Harmonization"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Awesome-Image-Composition" ["e"=1]
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "SamsungLabs/image_harmonization"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "junleen/RainNet"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "wasidennis/DeepHarmonization"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Awesome-Few-Shot-Image-Generation"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/libcom"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Image-Harmonization-Dataset-iHarmony4" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"SamsungLabs/image_harmonization" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"SamsungLabs/image_harmonization" -> "zhenglab/HarmonyTransformer"
"SamsungLabs/image_harmonization" -> "wasidennis/DeepHarmonization"
"SamsungLabs/image_harmonization" -> "vinthony/s2am"
"SamsungLabs/image_harmonization" -> "junleen/RainNet"
"SamsungLabs/image_harmonization" -> "bcmi/BargainNet-Image-Harmonization"
"SamsungLabs/image_harmonization" -> "bcmi/Awesome-Image-Harmonization"
"SamsungLabs/image_harmonization" -> "chenhaoxing/HDNet"
"SamsungLabs/image_harmonization" -> "rockeyben/DCCF"
"SamsungLabs/image_harmonization" -> "bcmi/Image-Harmonization-Dataset-iHarmony4"
"SamsungLabs/image_harmonization" -> "Dominoer/bmvc2020_image_harmonization"
"SamsungLabs/image_harmonization" -> "zhenglab/IntrinsicHarmony"
"SamsungLabs/image_harmonization" -> "rakutentech/PCT-Net-Image-Harmonization"
"SamsungLabs/image_harmonization" -> "stefanLeong/S2CRNet"
"SamsungLabs/image_harmonization" -> "VITA-Group/SSHarmonization"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Image-Harmonization-Dataset-iHarmony4"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/F2GAN-Few-Shot-Image-Generation"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "valeoai/ZS3"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/MatchingGAN-Few-Shot-Image-Generation"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Few-Shot-Image-Generation"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "subhc/SPNet"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/GracoNet-Object-Placement"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Object-Placement"
"dingkeyan93/IQA-optimization" -> "dingkeyan93/DISTS"
"dingkeyan93/IQA-optimization" -> "icbcbicc/IQA-Dataset"
"dingkeyan93/IQA-optimization" -> "lidq92/WaDIQaM"
"dingkeyan93/IQA-optimization" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"dingkeyan93/IQA-optimization" -> "prashnani/PerceptualImageError"
"dingkeyan93/IQA-optimization" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"dingkeyan93/IQA-optimization" -> "zwx8981/UNIQUE"
"dingkeyan93/IQA-optimization" -> "subpic/koniq"
"dingkeyan93/IQA-optimization" -> "SSL92/hyperIQA"
"dingkeyan93/IQA-optimization" -> "zwx8981/DBCNN-PyTorch"
"dingkeyan93/IQA-optimization" -> "isalirezag/TReS"
"dingkeyan93/IQA-optimization" -> "IIGROUP/AHIQ"
"dingkeyan93/IQA-optimization" -> "lidq92/LinearityIQA"
"dingkeyan93/IQA-optimization" -> "photosynthesis-team/piq" ["e"=1]
"dingkeyan93/IQA-optimization" -> "junyongyou/triq"
"guptapraful/niqe" -> "buyizhiyou/NRVQA"
"guptapraful/niqe" -> "chaoma99/sr-metric"
"guptapraful/niqe" -> "bukalapak/pybrisque"
"guptapraful/niqe" -> "roimehrez/PIRM2018" ["e"=1]
"guptapraful/niqe" -> "dingkeyan93/IQA-optimization"
"guptapraful/niqe" -> "weichen582/RetinexNet" ["e"=1]
"guptapraful/niqe" -> "zwx8981/UNIQUE"
"guptapraful/niqe" -> "yuanjunchai/IKC" ["e"=1]
"guptapraful/niqe" -> "xialeiliu/RankIQA"
"guptapraful/niqe" -> "hitzhangyu/Self-supervised-Image-Enhancement-Network-Training-With-Low-Light-Images-Only" ["e"=1]
"guptapraful/niqe" -> "sefibk/KernelGAN" ["e"=1]
"guptapraful/niqe" -> "flyywh/CVPR-2020-Semi-Low-Light" ["e"=1]
"guptapraful/niqe" -> "zwx8981/DBCNN-PyTorch"
"owenzlz/DeepImageBlending" -> "wuhuikai/GP-GAN"
"owenzlz/DeepImageBlending" -> "bcmi/Awesome-Image-Composition" ["e"=1]
"owenzlz/DeepImageBlending" -> "Erkaman/poisson_blend" ["e"=1]
"owenzlz/DeepImageBlending" -> "bcmi/Awesome-Image-Harmonization"
"owenzlz/DeepImageBlending" -> "bcmi/Image-Harmonization-Dataset-iHarmony4"
"owenzlz/DeepImageBlending" -> "SamsungLabs/image_harmonization"
"owenzlz/DeepImageBlending" -> "wasidennis/DeepHarmonization"
"owenzlz/DeepImageBlending" -> "RenYurui/StructureFlow" ["e"=1]
"owenzlz/DeepImageBlending" -> "msinghal34/Image-Blending-using-GP-GANs"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "zwx8981/UNIQUE"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "zwx8981/DBCNN"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "pavancm/CONTRIQUE"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "weizhou-geek/VGCN-PyTorch"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "xiangjieSui/img2video"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "junyongyou/triq"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "zhuhancheng/MetaIQA"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "anse3832/IQT"
"weizhou-geek/Recent-Image-Quality-Related-Papers" -> "zwx8981/BIQA_CL"
"pavancm/vbliinds" -> "jarikorhonen/nr-vqa-consumervideo"
"kang-gnak/eva-dataset" -> "BestiVictory/DPC-Captions"
"vztu/VIDEVAL" -> "vztu/BVQA_Benchmark"
"vztu/VIDEVAL" -> "vztu/RAPIQUE"
"vztu/VIDEVAL" -> "jarikorhonen/nr-vqa-consumervideo"
"vztu/VIDEVAL" -> "baidut/PatchVQ"
"vztu/VIDEVAL" -> "lidq92/VSFA"
"vztu/VIDEVAL" -> "lidq92/MDTVSFA"
"vztu/VIDEVAL" -> "zwx8981/TCSVT-2022-BVQA"
"vztu/VIDEVAL" -> "pavancm/vbliinds"
"vztu/VIDEVAL" -> "junyongyou/triq"
"vztu/VIDEVAL" -> "woojaekim/DeepVQA_Release"
"vztu/VIDEVAL" -> "sunwei925/CompressedVQA"
"vztu/VIDEVAL" -> "Tencent/DVQA"
"vztu/BVQA_Benchmark" -> "vztu/VIDEVAL"
"vztu/BVQA_Benchmark" -> "lidq92/VSFA"
"vztu/BVQA_Benchmark" -> "lidq92/MDTVSFA"
"vztu/BVQA_Benchmark" -> "vztu/RAPIQUE"
"vztu/BVQA_Benchmark" -> "baidut/PatchVQ"
"vztu/BVQA_Benchmark" -> "jarikorhonen/nr-vqa-consumervideo"
"vztu/BVQA_Benchmark" -> "zwx8981/TCSVT-2022-BVQA"
"vztu/BVQA_Benchmark" -> "atelili/2BiVQA"
"vztu/BVQA_Benchmark" -> "junyongyou/triq"
"vztu/BVQA_Benchmark" -> "woojaekim/DeepVQA_Release"
"vztu/BVQA_Benchmark" -> "pavancm/vbliinds"
"baidut/PaQ-2-PiQ" -> "baidut/paq2piq"
"baidut/PaQ-2-PiQ" -> "subpic/koniq"
"baidut/PaQ-2-PiQ" -> "ysyscool/SGDNet"
"baidut/PaQ-2-PiQ" -> "niu-haoran/FLIVE_Database"
"baidut/PaQ-2-PiQ" -> "baidut/PatchVQ"
"baidut/PaQ-2-PiQ" -> "lidq92/WaDIQaM"
"valeoai/ZS3" -> "bcmi/CaGNet-Zero-Shot-Semantic-Segmentation"
"valeoai/ZS3" -> "subhc/SPNet"
"valeoai/ZS3" -> "RohanDoshi2018/ZeroshotSemanticSegmentation"
"valeoai/ZS3" -> "Yang-Bob/PMMs" ["e"=1]
"valeoai/ZS3" -> "MendelXu/zsseg.baseline" ["e"=1]
"valeoai/ZS3" -> "valeoai/BUDA"
"zhuhancheng/MetaIQA" -> "zwx8981/DBCNN-PyTorch"
"zhuhancheng/MetaIQA" -> "SSL92/hyperIQA"
"zhuhancheng/MetaIQA" -> "lidq92/WaDIQaM"
"zhuhancheng/MetaIQA" -> "subpic/koniq"
"zhuhancheng/MetaIQA" -> "junyongyou/triq"
"zhuhancheng/MetaIQA" -> "lidq92/SFA"
"zhuhancheng/MetaIQA" -> "niu-haoran/FLIVE_Database"
"zhuhancheng/MetaIQA" -> "zwx8981/UNIQUE"
"zhuhancheng/MetaIQA" -> "ysyscool/SGDNet"
"zhuhancheng/MetaIQA" -> "baidut/paq2piq"
"zhuhancheng/MetaIQA" -> "HuiZeng/BIQA_Toolbox"
"zhuhancheng/MetaIQA" -> "h4nwei/SPAQ"
"zhuhancheng/MetaIQA" -> "dmaniry/deepIQA"
"zhuhancheng/MetaIQA" -> "lidq92/LinearityIQA"
"zhuhancheng/MetaIQA" -> "zwx8981/DBCNN"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bo-zhang-cs/CACNet-Pytorch"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "zijunwei/ViewProposalNet"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "suyukun666/S2CNet"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "zijunwei/ViewEvaluationNet"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bcmi/Human-Centric-Image-Cropping"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "CVBase-Bupt/EndtoEndCroppingSystem"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bo-zhang-cs/CGS-Pytorch"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" -> "yiling-chen/view-finding-network"
"Openning07/MPADA" -> "subpic/ava-mlsp"
"Openning07/MPADA" -> "miyamotty/awesome_ImageAesthetics"
"Openning07/MPADA" -> "GuillaumeBalezo/A-Lamp"
"Openning07/MPADA" -> "huangeddie/ML-Aesthetics-NIMA"
"Openning07/MPADA" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"Openning07/MPADA" -> "DreamvLee/Image-Aesthetic-Assessment-Assisted-by-Attributes-through-Adversarial-Learning"
"Openning07/MPADA" -> "fei-aiart/ReLIC"
"woojaekim/DeepVQA_Release" -> "pavancm/vbliinds"
"woojaekim/DeepVQA_Release" -> "lfovia/NRVQA-NSTSS"
"mahdihosseini/RMSGD" -> "mahdihosseini/ADP"
"mahdihosseini/RMSGD" -> "icbcbicc/FocusLiteNN"
"pavancm/GREED" -> "uniqzheng/HFR-BVQA"
"baidut/paq2piq" -> "baidut/PaQ-2-PiQ"
"ldq9526/ARShadowGAN" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"V-Sense/Aesthetic-Image-Captioning-ICCVW-2019" -> "PengZai/ARIC"
"V-Sense/Aesthetic-Image-Captioning-ICCVW-2019" -> "mediatechnologycenter/Aestheval"
"sunwei925/CVIQDatabase" -> "sunwei925/MC360IQA"
"jarikorhonen/cnn-tlvqm" -> "Baoliang93/GSTVQA"
"twitter-research/image-crop-analysis" -> "bcmi/Human-Centric-Image-Cropping"
"twitter-research/image-crop-analysis" -> "bo-zhang-cs/CGS-Pytorch"
"twitter-research/image-crop-analysis" -> "twitter-research/visual-sentiment-analysis"
"junyongyou/triq" -> "zhuhancheng/MetaIQA"
"junyongyou/triq" -> "guanghaoyin/CVRKD-IQA"
"junyongyou/triq" -> "vztu/VIDEVAL"
"junyongyou/triq" -> "SSL92/hyperIQA"
"junyongyou/triq" -> "ysyscool/SGDNet"
"junyongyou/triq" -> "vztu/BVQA_Benchmark"
"junyongyou/triq" -> "lidq92/WaDIQaM"
"junyongyou/triq" -> "researchmm/CKDN"
"junyongyou/triq" -> "cientgu/GIQA"
"junyongyou/triq" -> "zwx8981/DBCNN"
"junyongyou/triq" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"junyongyou/triq" -> "lidq92/MDTVSFA"
"junyongyou/triq" -> "zwx8981/UNIQUE"
"junyongyou/triq" -> "anse3832/IQT"
"junyongyou/triq" -> "zwx8981/DBCNN-PyTorch"
"YunanZhu/Pytorch-TestRankIQA" -> "YunanZhu/RecycleD"
"lidq92/MDTVSFA" -> "lidq92/VSFA"
"lidq92/MDTVSFA" -> "vztu/BVQA_Benchmark"
"lidq92/MDTVSFA" -> "vztu/VIDEVAL"
"lidq92/MDTVSFA" -> "lidq92/LinearityIQA"
"lidq92/MDTVSFA" -> "baidut/PatchVQ"
"lidq92/MDTVSFA" -> "woojaekim/DeepVQA_Release"
"lidq92/MDTVSFA" -> "jarikorhonen/nr-vqa-consumervideo"
"lidq92/MDTVSFA" -> "zwx8981/TCSVT-2022-BVQA"
"lidq92/MDTVSFA" -> "lidq92/SFA"
"lidq92/MDTVSFA" -> "vztu/RAPIQUE"
"lidq92/MDTVSFA" -> "sunwei925/CompressedVQA"
"lidq92/MDTVSFA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"isalirezag/TReS" -> "IIGROUP/MANIQA"
"isalirezag/TReS" -> "anse3832/MUSIQ"
"isalirezag/TReS" -> "pavancm/CONTRIQUE"
"isalirezag/TReS" -> "subpic/koniq"
"isalirezag/TReS" -> "anse3832/IQT"
"isalirezag/TReS" -> "geekyutao/GraphIQA"
"isalirezag/TReS" -> "SSL92/hyperIQA"
"isalirezag/TReS" -> "narthchin/DEIQT"
"isalirezag/TReS" -> "zwx8981/DBCNN-PyTorch"
"isalirezag/TReS" -> "zwx8981/UNIQUE"
"isalirezag/TReS" -> "zwx8981/LIQE"
"isalirezag/TReS" -> "IIGROUP/AHIQ"
"isalirezag/TReS" -> "h4nwei/SPAQ"
"isalirezag/TReS" -> "guanghaoyin/CVRKD-IQA"
"isalirezag/TReS" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"WisconsinAIVision/few-shot-gan-adaptation" -> "StevenShaw1999/RSSA"
"WisconsinAIVision/few-shot-gan-adaptation" -> "edward3862/LoFGAN-pytorch"
"WisconsinAIVision/few-shot-gan-adaptation" -> "bcmi/Awesome-Few-Shot-Image-Generation"
"WisconsinAIVision/few-shot-gan-adaptation" -> "YBYBZhang/DiFa" ["e"=1]
"WisconsinAIVision/few-shot-gan-adaptation" -> "e-271/few-shot-gan"
"woshidandan/IAA_Tutorial" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/IAA_Tutorial" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/IAA_Tutorial" -> "woshidandan/Image-Aesthetics-and-Quality-Assessment"
"woshidandan/IAA_Tutorial" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"woshidandan/IAA_Tutorial" -> "woshidandan/AK4Prompts"
"woshidandan/IAA_Tutorial" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"junleen/RainNet" -> "chenhaoxing/HDNet"
"junleen/RainNet" -> "SamsungLabs/image_harmonization"
"junleen/RainNet" -> "rakutentech/PCT-Net-Image-Harmonization"
"junleen/RainNet" -> "zhenglab/HarmonyTransformer"
"junleen/RainNet" -> "zhenglab/IntrinsicHarmony"
"junleen/RainNet" -> "stefanLeong/S2CRNet"
"junleen/RainNet" -> "bcmi/Awesome-Image-Harmonization"
"junleen/RainNet" -> "ZHKKKe/Harmonizer"
"junleen/RainNet" -> "bcmi/BargainNet-Image-Harmonization"
"junleen/RainNet" -> "YCHang686/SCS-Co-CVPR2022"
"junleen/RainNet" -> "VITA-Group/SSHarmonization"
"finint/RL-Solutions" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"finint/RL-Solutions" -> "bcmi/BargainNet-Image-Harmonization"
"finint/RL-Solutions" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"finint/RL-Solutions" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"HaomingCai/PIPAL-dataset" -> "anse3832/IQT"
"HaomingCai/PIPAL-dataset" -> "IIGROUP/AHIQ"
"HaomingCai/PIPAL-dataset" -> "zwx8981/BIQA_CL"
"HaomingCai/PIPAL-dataset" -> "guanghaoyin/CVRKD-IQA"
"HaomingCai/PIPAL-dataset" -> "smehdia/NTIRE2021-IQA-MACS"
"zwx8981/BIQA_CL" -> "HaomingCai/PIPAL-dataset"
"zwx8981/BIQA_CL" -> "maruiperfect/R-R-Net"
"zwx8981/BIQA_CL" -> "guanghaoyin/CVRKD-IQA"
"zwx8981/BIQA_CL" -> "zwx8981/UNIQUE"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/MatchingGAN-Few-Shot-Image-Generation"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/CaGNet-Zero-Shot-Semantic-Segmentation"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/F2GAN-Few-Shot-Image-Generation" -> "bcmi/SimTrans-Weak-Shot-Classification"
"icbcbicc/IQA-Dataset" -> "avinabsaha/ReIQA"
"icbcbicc/IQA-Dataset" -> "zwx8981/DBCNN-PyTorch"
"icbcbicc/IQA-Dataset" -> "zwx8981/LIQE"
"icbcbicc/IQA-Dataset" -> "pavancm/CONTRIQUE"
"icbcbicc/IQA-Dataset" -> "IIGROUP/RADN"
"icbcbicc/IQA-Dataset" -> "dingkeyan93/IQA-optimization"
"icbcbicc/IQA-Dataset" -> "researchmm/CKDN"
"icbcbicc/IQA-Dataset" -> "zwx8981/BIQA_CL"
"icbcbicc/IQA-Dataset" -> "IIGROUP/AHIQ"
"icbcbicc/IQA-Dataset" -> "icbcbicc/FocusLiteNN"
"icbcbicc/IQA-Dataset" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"icbcbicc/IQA-Dataset" -> "miccunifi/ARNIQA"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bo-zhang-cs/CACNet-Pytorch"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "mediatechnologycenter/Aestheval"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "subpic/ava-mlsp"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "Openning07/MPADA"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "days1011/HLAGCN"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "shedy-pub/hlagcn-jittor"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Image-Composition-Assessment-Dataset-CADB" -> "liuxiaoyu1104/UNIC"
"ryanxingql/image-quality-assessment-toolbox" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"ryanxingql/image-quality-assessment-toolbox" -> "ryanxingql/blog" ["e"=1]
"shedy-pub/hlagcn-jittor" -> "days1011/HLAGCN"
"days1011/HLAGCN" -> "shedy-pub/hlagcn-jittor"
"sunwei925/MC360IQA" -> "sunwei925/CVIQDatabase"
"vztu/RAPIQUE" -> "vztu/VIDEVAL"
"vztu/RAPIQUE" -> "jarikorhonen/nr-vqa-consumervideo"
"vztu/RAPIQUE" -> "baidut/PatchVQ"
"vztu/RAPIQUE" -> "vztu/BVQA_Benchmark"
"vztu/RAPIQUE" -> "zwx8981/TCSVT-2022-BVQA"
"vztu/RAPIQUE" -> "pavancm/vbliinds"
"IIGROUP/RADN" -> "guanghaoyin/CVRKD-IQA"
"IIGROUP/RADN" -> "IIGROUP/AHIQ"
"IIGROUP/RADN" -> "IIGROUP/AttentionProbe" ["e"=1]
"IIGROUP/RADN" -> "researchmm/CKDN"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/Awesome-Object-Placement"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" -> "bcmi/SimTrans-Weak-Shot-Classification"
"baidut/PatchVQ" -> "jarikorhonen/nr-vqa-consumervideo"
"baidut/PatchVQ" -> "vztu/RAPIQUE"
"baidut/PatchVQ" -> "vztu/VIDEVAL"
"baidut/PatchVQ" -> "zwx8981/TCSVT-2022-BVQA"
"baidut/PatchVQ" -> "vztu/BVQA_Benchmark"
"baidut/PatchVQ" -> "sunwei925/SimpleVQA"
"baidut/PatchVQ" -> "lidq92/MDTVSFA"
"baidut/PatchVQ" -> "lidq92/VSFA"
"baidut/PatchVQ" -> "baidut/paq2piq"
"baidut/PatchVQ" -> "woojaekim/DeepVQA_Release"
"zhenglab/IntrinsicHarmony" -> "zhenglab/HarmonyTransformer"
"researchmm/CKDN" -> "guanghaoyin/CVRKD-IQA"
"researchmm/CKDN" -> "anse3832/IQT"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/BargainNet-Image-Harmonization" -> "bcmi/GracoNet-Object-Placement"
"VITA-Group/SSHarmonization" -> "zhenglab/HarmonyTransformer"
"zhenglab/HarmonyTransformer" -> "zhenglab/IntrinsicHarmony"
"zhenglab/HarmonyTransformer" -> "stefanLeong/S2CRNet"
"zhenglab/HarmonyTransformer" -> "YCHang686/SCS-Co-CVPR2022"
"zhenglab/HarmonyTransformer" -> "VITA-Group/SSHarmonization"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/Awesome-Object-Placement"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/SimTrans-Weak-Shot-Classification"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/Object-Placement-Assessment-Dataset-OPA" -> "bcmi/MatchingGAN-Few-Shot-Image-Generation"
"janpf/self-supervised-multi-task-aesthetic-pretraining" -> "huangeddie/ML-Aesthetics-NIMA"
"edward3862/LoFGAN-pytorch" -> "UniBester/AGE"
"edward3862/LoFGAN-pytorch" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"edward3862/LoFGAN-pytorch" -> "reyllama/mixdl"
"geekyutao/GraphIQA" -> "guanghaoyin/CVRKD-IQA"
"sunwei925/CompressedVQA" -> "zwx8981/TCSVT-2022-BVQA"
"bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony" -> "bcmi/BargainNet-Image-Harmonization"
"Baoliang93/GSTVQA" -> "h4nwei/STI-VQA"
"Baoliang93/GSTVQA" -> "jarikorhonen/cnn-tlvqm"
"bcmi/MatchingGAN-Few-Shot-Image-Generation" -> "bcmi/F2GAN-Few-Shot-Image-Generation"
"bcmi/DIRL-Inharmonious-Region-Localization" -> "bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony"
"bcmi/DIRL-Inharmonious-Region-Localization" -> "bcmi/MadisNet-Inharmonious-Region-Localization"
"bcmi/DIRL-Inharmonious-Region-Localization" -> "bcmi/BargainNet-Image-Harmonization"
"isaaccorley/deep-aesthetics-pytorch" -> "huangeddie/ML-Aesthetics-NIMA"
"atelili/2BiVQA" -> "atelili/raindrop-detection-on-a-windshield"
"jflalonde/colorRealism" -> "junyanz/RealismCNN"
"uniqzheng/HFR-BVQA" -> "pavancm/GREED"
"smehdia/NTIRE2021-IQA-MACS" -> "AliRoyat/NTIRE2021-IQA-MACS-Pytorch"
"AliRoyat/NTIRE2021-IQA-MACS-Pytorch" -> "smehdia/NTIRE2021-IQA-MACS"
"chaofengc/IQA-PyTorch" -> "chaofengc/Awesome-Image-Quality-Assessment"
"chaofengc/IQA-PyTorch" -> "IceClear/CLIP-IQA"
"chaofengc/IQA-PyTorch" -> "photosynthesis-team/piq" ["e"=1]
"chaofengc/IQA-PyTorch" -> "Q-Future/Q-Align"
"chaofengc/IQA-PyTorch" -> "IceClear/StableSR" ["e"=1]
"chaofengc/IQA-PyTorch" -> "richzhang/PerceptualSimilarity" ["e"=1]
"chaofengc/IQA-PyTorch" -> "IIGROUP/MANIQA"
"chaofengc/IQA-PyTorch" -> "swz30/Restormer" ["e"=1]
"chaofengc/IQA-PyTorch" -> "DarrenPan/Awesome-CVPR2024-Low-Level-Vision" ["e"=1]
"chaofengc/IQA-PyTorch" -> "XPixelGroup/BasicSR" ["e"=1]
"chaofengc/IQA-PyTorch" -> "Kobaayyy/Awesome-CVPR2025-CVPR2024-CVPR2021-CVPR2020-Low-Level-Vision" ["e"=1]
"chaofengc/IQA-PyTorch" -> "cszn/KAIR" ["e"=1]
"chaofengc/IQA-PyTorch" -> "SSL92/hyperIQA"
"chaofengc/IQA-PyTorch" -> "Algolzw/daclip-uir" ["e"=1]
"chaofengc/IQA-PyTorch" -> "ChaofWang/Awesome-Super-Resolution" ["e"=1]
"mediatechnologycenter/Aestheval" -> "Dreemurr-T/BAID"
"mediatechnologycenter/Aestheval" -> "V-Sense/Aesthetic-Image-Captioning-ICCVW-2019"
"mediatechnologycenter/Aestheval" -> "PengZai/ARIC"
"mediatechnologycenter/Aestheval" -> "yipoh/AesExpert"
"mediatechnologycenter/Aestheval" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"mediatechnologycenter/Aestheval" -> "BestiVictory/DPC-Captions"
"zwx8981/TCSVT-2022-BVQA" -> "sunwei925/CompressedVQA"
"zwx8981/TCSVT-2022-BVQA" -> "cpf0079/UCDA"
"zwx8981/TCSVT-2022-BVQA" -> "baidut/PatchVQ"
"zwx8981/TCSVT-2022-BVQA" -> "vztu/RAPIQUE"
"zwx8981/TCSVT-2022-BVQA" -> "vztu/VIDEVAL"
"zwx8981/TCSVT-2022-BVQA" -> "jarikorhonen/nr-vqa-consumervideo"
"pavancm/CONTRIQUE" -> "avinabsaha/ReIQA"
"pavancm/CONTRIQUE" -> "isalirezag/TReS"
"pavancm/CONTRIQUE" -> "anse3832/MUSIQ"
"pavancm/CONTRIQUE" -> "zwx8981/LIQE"
"pavancm/CONTRIQUE" -> "zwx8981/DBCNN-PyTorch"
"pavancm/CONTRIQUE" -> "miccunifi/ARNIQA"
"pavancm/CONTRIQUE" -> "cpf0079/UCDA"
"pavancm/CONTRIQUE" -> "SSL92/hyperIQA"
"pavancm/CONTRIQUE" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"pavancm/CONTRIQUE" -> "zwx8981/UNIQUE"
"pavancm/CONTRIQUE" -> "researchmm/CKDN"
"pavancm/CONTRIQUE" -> "icbcbicc/IQA-Dataset"
"pavancm/CONTRIQUE" -> "geekyutao/GraphIQA"
"pavancm/CONTRIQUE" -> "zhuhancheng/MetaIQA"
"pavancm/CONTRIQUE" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"IIGROUP/MANIQA" -> "isalirezag/TReS"
"IIGROUP/MANIQA" -> "IIGROUP/AHIQ"
"IIGROUP/MANIQA" -> "anse3832/MUSIQ"
"IIGROUP/MANIQA" -> "IceClear/CLIP-IQA"
"IIGROUP/MANIQA" -> "chaofengc/Awesome-Image-Quality-Assessment"
"IIGROUP/MANIQA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"IIGROUP/MANIQA" -> "SSL92/hyperIQA"
"IIGROUP/MANIQA" -> "HaomingCai/PIPAL-dataset"
"IIGROUP/MANIQA" -> "zwx8981/LIQE"
"IIGROUP/MANIQA" -> "guanghaoyin/CVRKD-IQA"
"IIGROUP/MANIQA" -> "zhuhancheng/MetaIQA"
"IIGROUP/MANIQA" -> "h4nwei/SPAQ"
"IIGROUP/MANIQA" -> "zwx8981/UNIQUE"
"IIGROUP/MANIQA" -> "VQAssessment/DOVER"
"IIGROUP/MANIQA" -> "icbcbicc/IQA-Dataset"
"yiling-chen/flickr-cropping-dataset" -> "yiling-chen/view-finding-network"
"yiling-chen/flickr-cropping-dataset" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"yiling-chen/flickr-cropping-dataset" -> "zijunwei/ViewProposalNet"
"yiling-chen/flickr-cropping-dataset" -> "bcmi/Human-Centric-Image-Cropping"
"yiling-chen/flickr-cropping-dataset" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"yiling-chen/flickr-cropping-dataset" -> "wuhuikai/TF-A2RL"
"yiling-chen/flickr-cropping-dataset" -> "CVBase-Bupt/EndtoEndCroppingSystem"
"yiling-chen/flickr-cropping-dataset" -> "liuxiaoyu1104/UNIC"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Image-Aesthetics-and-Quality-Assessment"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Prompt-DeT"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "Dreemurr-T/BAID"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/IAA_Tutorial"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "mediatechnologycenter/Aestheval"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "subpic/ava-mlsp"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "zwx8981/LIQE"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "bo-zhang-cs/CACNet-Pytorch"
"woshidandan/TANet-image-aesthetics-and-quality-assessment" -> "Openning07/MPADA"
"Tencent/CenseoQoE" -> "vztu/BVQA_Benchmark"
"Tencent/CenseoQoE" -> "zwx8981/TCSVT-2022-BVQA"
"Tencent/CenseoQoE" -> "lidq92/VSFA"
"Tencent/CenseoQoE" -> "junyongyou/triq"
"Tencent/CenseoQoE" -> "vztu/VIDEVAL"
"Tencent/CenseoQoE" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"Tencent/CenseoQoE" -> "Tencent/DVQA"
"Tencent/CenseoQoE" -> "lidq92/MDTVSFA"
"Tencent/CenseoQoE" -> "baidut/PatchVQ"
"Tencent/CenseoQoE" -> "SSL92/hyperIQA"
"Tencent/CenseoQoE" -> "lixinustc/KVQ-Challenge-CVPR-NTIRE2024"
"Tencent/CenseoQoE" -> "VQAssessment/DOVER"
"Tencent/CenseoQoE" -> "lidq92/LinearityIQA"
"Tencent/CenseoQoE" -> "Baoliang93/GSTVQA"
"Tencent/CenseoQoE" -> "sunwei925/CompressedVQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "chaofengc/IQA-PyTorch"
"chaofengc/Awesome-Image-Quality-Assessment" -> "IceClear/CLIP-IQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "zwx8981/LIQE"
"chaofengc/Awesome-Image-Quality-Assessment" -> "IIGROUP/MANIQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "SSL92/hyperIQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "Q-Future/Q-Align"
"chaofengc/Awesome-Image-Quality-Assessment" -> "photosynthesis-team/piq" ["e"=1]
"chaofengc/Awesome-Image-Quality-Assessment" -> "isalirezag/TReS"
"chaofengc/Awesome-Image-Quality-Assessment" -> "avinabsaha/ReIQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "weizhou-geek/Image-Quality-Assessment-Benchmark"
"chaofengc/Awesome-Image-Quality-Assessment" -> "icbcbicc/IQA-Dataset"
"chaofengc/Awesome-Image-Quality-Assessment" -> "Q-Future/Q-Bench"
"chaofengc/Awesome-Image-Quality-Assessment" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"chaofengc/Awesome-Image-Quality-Assessment" -> "anse3832/MUSIQ"
"chaofengc/Awesome-Image-Quality-Assessment" -> "VQAssessment/DOVER"
"georgosgeorgos/few-shot-diffusion-models" -> "sjtuplayer/few-shot-diffusion"
"georgosgeorgos/few-shot-diffusion-models" -> "jiamings/d2c"
"georgosgeorgos/few-shot-diffusion-models" -> "kobeshegu/awesome-few-shot-generation"
"StevenShaw1999/RSSA" -> "WisconsinAIVision/few-shot-gan-adaptation"
"anse3832/MUSIQ" -> "isalirezag/TReS"
"anse3832/MUSIQ" -> "IIGROUP/MANIQA"
"anse3832/MUSIQ" -> "pavancm/CONTRIQUE"
"anse3832/MUSIQ" -> "IIGROUP/AHIQ"
"anse3832/MUSIQ" -> "zwx8981/UNIQUE"
"anse3832/MUSIQ" -> "zwx8981/BIQA_CL"
"anse3832/MUSIQ" -> "subpic/koniq"
"anse3832/MUSIQ" -> "SSL92/hyperIQA"
"anse3832/MUSIQ" -> "guanghaoyin/CVRKD-IQA"
"anse3832/MUSIQ" -> "avinabsaha/ReIQA"
"anse3832/MUSIQ" -> "researchmm/CKDN"
"anse3832/MUSIQ" -> "zhuhancheng/MetaIQA"
"anse3832/MUSIQ" -> "zwx8981/LIQE"
"anse3832/MUSIQ" -> "weizhou-geek/Recent-Image-Quality-Related-Papers"
"anse3832/MUSIQ" -> "mediatechnologycenter/Aestheval"
"UniBester/AGE" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"UniBester/AGE" -> "edward3862/LoFGAN-pytorch"
"UniBester/AGE" -> "lingxiao-li/HAE"
"IIGROUP/AHIQ" -> "anse3832/IQT"
"IIGROUP/AHIQ" -> "HaomingCai/PIPAL-dataset"
"IIGROUP/AHIQ" -> "IIGROUP/RADN"
"IIGROUP/AHIQ" -> "mv-lab/IQA-Conformer-BNS"
"IIGROUP/AHIQ" -> "researchmm/CKDN"
"IIGROUP/AHIQ" -> "IIGROUP/MANIQA"
"IIGROUP/AHIQ" -> "guanghaoyin/CVRKD-IQA"
"IIGROUP/AHIQ" -> "zwx8981/BIQA_CL"
"IIGROUP/AHIQ" -> "anse3832/MUSIQ"
"IIGROUP/AHIQ" -> "DXOMARK-Research/PIQ2023"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "VQAssessment/DOVER"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "sunwei925/SimpleVQA"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "VQAssessment/ExplainableVQA"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "Q-Future/Q-Bench"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "lidq92/VSFA"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "Q-Future/Q-Align"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "baidut/PatchVQ"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "lidq92/MDTVSFA"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "zwx8981/LIQE"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "VQAssessment/BVQI"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "Q-Future/Q-Instruct"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "zwx8981/TCSVT-2022-BVQA"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "lixinustc/KVQ-Challenge-CVPR-NTIRE2024"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "vztu/BVQA_Benchmark"
"VQAssessment/FAST-VQA-and-FasterVQA" -> "sunwei925/RQ-VQA"
"scikit-video/scikit-video" -> "lidq92/VSFA"
"scikit-video/scikit-video" -> "vztu/BVQA_Benchmark"
"scikit-video/scikit-video" -> "rohitgirdhar/ActionVLAD" ["e"=1]
"scikit-video/scikit-video" -> "yoosan/video-understanding-dataset" ["e"=1]
"scikit-video/scikit-video" -> "vadimkantorov/mpegflow" ["e"=1]
"scikit-video/scikit-video" -> "jarikorhonen/nr-vqa-consumervideo"
"bo-zhang-cs/CACNet-Pytorch" -> "bcmi/Human-Centric-Image-Cropping"
"bo-zhang-cs/CACNet-Pytorch" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"bo-zhang-cs/CACNet-Pytorch" -> "bo-zhang-cs/CGS-Pytorch"
"bo-zhang-cs/CACNet-Pytorch" -> "bo-zhang-cs/GAIC-Pytorch"
"bo-zhang-cs/CACNet-Pytorch" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"bo-zhang-cs/CACNet-Pytorch" -> "bcmi/Image-Composition-Assessment-Dataset-CADB"
"bo-zhang-cs/CACNet-Pytorch" -> "suyukun666/S2CNet"
"bo-zhang-cs/CACNet-Pytorch" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"bo-zhang-cs/CACNet-Pytorch" -> "sunyasheng/a2rl_pytorch"
"bo-zhang-cs/CACNet-Pytorch" -> "zijunwei/ViewProposalNet"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/GracoNet-Object-Placement"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/Awesome-Object-Placement"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/BargainNet-Image-Harmonization"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/SimTrans-Weak-Shot-Classification"
"bcmi/CDTNet-High-Resolution-Image-Harmonization" -> "bcmi/MatchingGAN-Few-Shot-Image-Generation"
"jiamings/d2c" -> "georgosgeorgos/few-shot-diffusion-models"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/SimTrans-Weak-Shot-Classification"
"bcmi/Video-Harmonization-Dataset-HYouTube" -> "bcmi/Awesome-Object-Placement"
"anse3832/IQT" -> "HaomingCai/PIPAL-dataset"
"anse3832/IQT" -> "IIGROUP/AHIQ"
"anse3832/IQT" -> "guanghaoyin/CVRKD-IQA"
"anse3832/IQT" -> "researchmm/CKDN"
"anse3832/IQT" -> "zwx8981/BIQA_CL"
"guanghaoyin/CVRKD-IQA" -> "researchmm/CKDN"
"guanghaoyin/CVRKD-IQA" -> "IIGROUP/RADN"
"guanghaoyin/CVRKD-IQA" -> "anse3832/IQT"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Awesome-Object-Placement"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/Awesome-Image-Blending"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/Awesome-Object-Shadow-Generation" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"junyanz/RealismCNN" -> "jflalonde/colorRealism"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/SimTrans-Weak-Shot-Classification"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/Awesome-Object-Placement"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Awesome-Weak-Shot-Learning" -> "bcmi/F2GAN-Few-Shot-Image-Generation"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/TraMaS-Weak-Shot-Object-Detection"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/Awesome-Weak-Shot-Learning"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/SimTrans-Weak-Shot-Classification" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bo-zhang-cs/CGS-Pytorch" -> "sunyasheng/a2rl_pytorch"
"bcmi/TraMaS-Weak-Shot-Object-Detection" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/TraMaS-Weak-Shot-Object-Detection" -> "bcmi/SimTrans-Weak-Shot-Classification"
"bcmi/TraMaS-Weak-Shot-Object-Detection" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/TraMaS-Weak-Shot-Object-Detection" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/MadisNet-Inharmonious-Region-Localization" -> "bcmi/DIRL-Inharmonious-Region-Localization"
"WindVChen/Solution-For-AISafety-CVPR2022" -> "WindVChen/VCO-AP"
"IceClear/CLIP-IQA" -> "zwx8981/LIQE"
"IceClear/CLIP-IQA" -> "chaofengc/Awesome-Image-Quality-Assessment"
"IceClear/CLIP-IQA" -> "IIGROUP/MANIQA"
"IceClear/CLIP-IQA" -> "Q-Future/Q-Align"
"IceClear/CLIP-IQA" -> "Q-Future/Q-Bench"
"IceClear/CLIP-IQA" -> "chaofengc/IQA-PyTorch"
"IceClear/CLIP-IQA" -> "Q-Future/Q-Instruct"
"IceClear/CLIP-IQA" -> "VQAssessment/DOVER"
"IceClear/CLIP-IQA" -> "anse3832/MUSIQ"
"IceClear/CLIP-IQA" -> "SSL92/hyperIQA"
"IceClear/CLIP-IQA" -> "icbcbicc/IQA-Dataset"
"IceClear/CLIP-IQA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"IceClear/CLIP-IQA" -> "isalirezag/TReS"
"IceClear/CLIP-IQA" -> "zwx8981/BIQA_CL"
"IceClear/CLIP-IQA" -> "pavancm/CONTRIQUE"
"chaoma99/sr-metric" -> "roimehrez/PIRM2018" ["e"=1]
"chaoma99/sr-metric" -> "guptapraful/niqe"
"avinabsaha/ReIQA" -> "pavancm/CONTRIQUE"
"avinabsaha/ReIQA" -> "miccunifi/ARNIQA"
"avinabsaha/ReIQA" -> "icbcbicc/IQA-Dataset"
"avinabsaha/ReIQA" -> "suhas-srinath/GRepQ"
"avinabsaha/ReIQA" -> "zwx8981/LIQE"
"avinabsaha/ReIQA" -> "anse3832/MUSIQ"
"avinabsaha/ReIQA" -> "avinabsaha/HIDRO-VQA"
"avinabsaha/ReIQA" -> "narthchin/DEIQT"
"VQAssessment/ExplainableVQA" -> "VQAssessment/BVQI"
"VQAssessment/ExplainableVQA" -> "Q-Future/Co-Instruct"
"VQAssessment/ExplainableVQA" -> "Q-Future/Q-Bench"
"VQAssessment/ExplainableVQA" -> "Q-Future/Q-Instruct"
"VQAssessment/ExplainableVQA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"VQAssessment/ExplainableVQA" -> "VQAssessment/DOVER"
"VQAssessment/ExplainableVQA" -> "SaMMyCHoo/Light-VQA-plus"
"VQAssessment/ExplainableVQA" -> "Q-Future/Q-Align"
"VQAssessment/ExplainableVQA" -> "Q-Future/Visual-Question-Answering-for-Video-Quality-Assessment"
"VQAssessment/ExplainableVQA" -> "zwx8981/LIQE"
"bcmi/Human-Centric-Image-Cropping" -> "bo-zhang-cs/CGS-Pytorch"
"bcmi/Human-Centric-Image-Cropping" -> "liuxiaoyu1104/UNIC"
"bcmi/Human-Centric-Image-Cropping" -> "bo-zhang-cs/CACNet-Pytorch"
"rakutentech/PCT-Net-Image-Harmonization" -> "chenhaoxing/HDNet"
"rakutentech/PCT-Net-Image-Harmonization" -> "bcmi/DucoNet-Image-Harmonization"
"rakutentech/PCT-Net-Image-Harmonization" -> "rockeyben/DCCF"
"rakutentech/PCT-Net-Image-Harmonization" -> "adobe/PIH"
"chenhaoxing/HDNet" -> "rakutentech/PCT-Net-Image-Harmonization"
"chenhaoxing/HDNet" -> "WindVChen/Diff-Harmonization"
"chenhaoxing/HDNet" -> "bcmi/DucoNet-Image-Harmonization"
"chenhaoxing/HDNet" -> "adobe/PIH"
"chenhaoxing/HDNet" -> "rockeyben/DCCF"
"chenhaoxing/HDNet" -> "junleen/RainNet"
"bcmi/GracoNet-Object-Placement" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/GracoNet-Object-Placement" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/GracoNet-Object-Placement" -> "bcmi/Awesome-Object-Placement"
"bcmi/GracoNet-Object-Placement" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/GracoNet-Object-Placement" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/GracoNet-Object-Placement" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/GracoNet-Object-Placement" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/GracoNet-Object-Placement" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/GracoNet-Object-Placement" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/GracoNet-Object-Placement" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/GracoNet-Object-Placement" -> "bcmi/Awesome-Image-Blending"
"bcmi/GracoNet-Object-Placement" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"VQAssessment/DOVER" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"VQAssessment/DOVER" -> "VQAssessment/ExplainableVQA"
"VQAssessment/DOVER" -> "Q-Future/Q-Align"
"VQAssessment/DOVER" -> "Q-Future/Q-Bench"
"VQAssessment/DOVER" -> "zwx8981/LIQE"
"VQAssessment/DOVER" -> "Q-Future/Q-Instruct"
"VQAssessment/DOVER" -> "sunwei925/SimpleVQA"
"VQAssessment/DOVER" -> "lixinustc/KVQ-Challenge-CVPR-NTIRE2024"
"VQAssessment/DOVER" -> "sunwei925/RQ-VQA"
"VQAssessment/DOVER" -> "IceClear/CLIP-IQA"
"VQAssessment/DOVER" -> "VQAssessment/BVQI"
"VQAssessment/DOVER" -> "zwx8981/TCSVT-2022-BVQA"
"VQAssessment/DOVER" -> "Q-Future/Co-Instruct"
"VQAssessment/DOVER" -> "taco-group/COVER"
"VQAssessment/DOVER" -> "IIGROUP/MANIQA"
"bcmi/RETAB-Weak-Shot-Semantic-Segmentation" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/RETAB-Weak-Shot-Semantic-Segmentation" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/RETAB-Weak-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Image-Blending"
"kobeshegu/ECCV2022_WaveGAN" -> "kobeshegu/FreGAN_NeurIPS2022"
"kobeshegu/ECCV2022_WaveGAN" -> "edward3862/LoFGAN-pytorch"
"VQAssessment/BVQI" -> "VQAssessment/ExplainableVQA"
"ZHKKKe/Harmonizer" -> "junleen/RainNet"
"ZHKKKe/Harmonizer" -> "adobe/PIH"
"ZHKKKe/Harmonizer" -> "bcmi/Awesome-Image-Harmonization"
"ZHKKKe/Harmonizer" -> "chenhaoxing/HDNet"
"ZHKKKe/Harmonizer" -> "rockeyben/DCCF"
"ZHKKKe/Harmonizer" -> "ZHKKKe/NeuralPreset" ["e"=1]
"ZHKKKe/Harmonizer" -> "rakutentech/PCT-Net-Image-Harmonization"
"ZHKKKe/Harmonizer" -> "stefanLeong/S2CRNet"
"ZHKKKe/Harmonizer" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"ZHKKKe/Harmonizer" -> "WindVChen/INR-Harmonization"
"ZHKKKe/Harmonizer" -> "WindVChen/Diff-Harmonization"
"ZHKKKe/Harmonizer" -> "csjliang/PPR10K" ["e"=1]
"PengZai/ARIC" -> "V-Sense/Aesthetic-Image-Captioning-ICCVW-2019"
"sunwei925/SimpleVQA" -> "sunwei925/RQ-VQA"
"sunwei925/SimpleVQA" -> "k-zha14/Zoom-VQA"
"sunwei925/SimpleVQA" -> "baidut/PatchVQ"
"sunwei925/SimpleVQA" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"sunwei925/SimpleVQA" -> "winwinwenwen77/ModularBVQA"
"sunwei925/SimpleVQA" -> "sunwei925/CompressedVQA"
"sunwei925/SimpleVQA" -> "Sissuire/SAMA"
"sunwei925/SimpleVQA" -> "lixinustc/KVQ-Challenge-CVPR-NTIRE2024"
"bcmi/Awesome-Object-Placement" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Awesome-Object-Placement" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Object-Placement" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Awesome-Object-Placement" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Awesome-Object-Placement" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/Awesome-Object-Placement" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/Awesome-Object-Placement" -> "bcmi/Awesome-Image-Blending"
"bcmi/Awesome-Object-Placement" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Object-Placement" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/Awesome-Object-Placement" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Awesome-Object-Placement" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/Awesome-Object-Placement" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/GracoNet-Object-Placement"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/Awesome-Object-Placement"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/DeltaGAN-Few-Shot-Image-Generation" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/GracoNet-Object-Placement"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Object-Placement"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" -> "bcmi/Awesome-Image-Blending"
"kobeshegu/FreGAN_NeurIPS2022" -> "kobeshegu/ECCV2022_WaveGAN"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/Awesome-Object-Placement"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/Awesome-Image-Blending"
"bcmi/FOPA-Fast-Object-Placement-Assessment" -> "bcmi/GracoNet-Object-Placement"
"rockeyben/DCCF" -> "stefanLeong/S2CRNet"
"rockeyben/DCCF" -> "rakutentech/PCT-Net-Image-Harmonization"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Prompt-DeT"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/IAA_Tutorial"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/AK4Prompts"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/ITU-Standard-for-IAA"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"woshidandan/Image-Aesthetics-and-Quality-Assessment" -> "mRobotit/M2Beats"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Image-Aesthetics-and-Quality-Assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Prompt-DeT"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/IAA_Tutorial"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/AK4Prompts"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" -> "Dreemurr-T/BAID"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/ControlCom-Image-Composition"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Awesome-Image-Blending"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/GracoNet-Object-Placement"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Awesome-Object-Placement"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Video-Harmonization-Dataset-HYouTube"
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/GracoNet-Object-Placement"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/Awesome-Image-Blending"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/Awesome-Object-Placement"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/PHDiffusion-Painterly-Image-Harmonization" -> "bcmi/ControlCom-Image-Composition"
"sjtuplayer/few-shot-diffusion" -> "sjtuplayer/Compositional_Neural_Painter"
"sjtuplayer/few-shot-diffusion" -> "georgosgeorgos/few-shot-diffusion-models"
"sjtuplayer/few-shot-diffusion" -> "YuCao16/CRDI"
"kobeshegu/awesome-few-shot-generation" -> "UniBester/AGE"
"KyanChen/FunSR" -> "WindVChen/VCO-AP"
"sjtuplayer/Compositional_Neural_Painter" -> "sjtuplayer/few-shot-diffusion"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/ObjectStitch-Image-Composition"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/ControlCom-Image-Composition"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/Awesome-Image-Blending"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/DreamCom-Image-Composition"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/Composite-Image-Evaluation"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/SycoNet-Adaptive-Image-Harmonization"
"bcmi/Awesome-Generative-Image-Composition" -> "bcmi/Awesome-Object-Placement"
"aimerykong/deepImageAestheticsAnalysis" -> "ylogx/aesthetics"
"aimerykong/deepImageAestheticsAnalysis" -> "BestiVictory/ILGnet"
"aimerykong/deepImageAestheticsAnalysis" -> "cgtuebingen/will-people-like-your-image"
"aimerykong/deepImageAestheticsAnalysis" -> "imfing/ava_downloader"
"aimerykong/deepImageAestheticsAnalysis" -> "Openning07/MPADA"
"aimerykong/deepImageAestheticsAnalysis" -> "subpic/ava-mlsp"
"aimerykong/deepImageAestheticsAnalysis" -> "HiiYL/PiQual"
"aimerykong/deepImageAestheticsAnalysis" -> "titu1994/neural-image-assessment"
"aimerykong/deepImageAestheticsAnalysis" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"aimerykong/deepImageAestheticsAnalysis" -> "alanspike/personalizedImageAesthetics"
"aimerykong/deepImageAestheticsAnalysis" -> "yunxiaoshi/Neural-IMage-Assessment"
"aimerykong/deepImageAestheticsAnalysis" -> "truskovskiyk/nima.pytorch"
"aimerykong/deepImageAestheticsAnalysis" -> "rawmarshmellows/deep-photo-aesthetics"
"aimerykong/deepImageAestheticsAnalysis" -> "sergeyk/vislab"
"aimerykong/deepImageAestheticsAnalysis" -> "h4nwei/SPAQ"
"bcmi/DucoNet-Image-Harmonization" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/DucoNet-Image-Harmonization" -> "chenhaoxing/HDNet"
"bcmi/DucoNet-Image-Harmonization" -> "rakutentech/PCT-Net-Image-Harmonization"
"bcmi/DucoNet-Image-Harmonization" -> "bcmi/SycoNet-Adaptive-Image-Harmonization"
"GYZHikari/Semantic-Cosegmentation" -> "GYZHikari/UAV-Saliency"
"bcmi/ControlCom-Image-Composition" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"bcmi/ControlCom-Image-Composition" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/ControlCom-Image-Composition" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/ControlCom-Image-Composition" -> "bcmi/ObjectStitch-Image-Composition"
"bcmi/ControlCom-Image-Composition" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/ControlCom-Image-Composition" -> "bcmi/GracoNet-Object-Placement"
"bcmi/ControlCom-Image-Composition" -> "bcmi/Awesome-Object-Placement"
"bcmi/ControlCom-Image-Composition" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/ControlCom-Image-Composition" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/ControlCom-Image-Composition" -> "bcmi/Awesome-Image-Blending"
"bcmi/ControlCom-Image-Composition" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/ControlCom-Image-Composition" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/ControlCom-Image-Composition" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/ControlCom-Image-Composition" -> "bcmi/Awesome-Generative-Image-Composition"
"bcmi/ControlCom-Image-Composition" -> "bcmi/libcom"
"bcmi/Composite-Image-Evaluation" -> "bcmi/SycoNet-Adaptive-Image-Harmonization"
"zwx8981/LIQE" -> "IceClear/CLIP-IQA"
"zwx8981/LIQE" -> "TianheWu/MLLMs-for-IQA"
"zwx8981/LIQE" -> "XPixelGroup/DepictQA"
"zwx8981/LIQE" -> "Q-Future/Q-Align"
"zwx8981/LIQE" -> "VQAssessment/ExplainableVQA"
"zwx8981/LIQE" -> "Q-Future/Q-Instruct"
"zwx8981/LIQE" -> "VQAssessment/DOVER"
"zwx8981/LIQE" -> "pavancm/CONTRIQUE"
"zwx8981/LIQE" -> "Q-Future/Co-Instruct"
"zwx8981/LIQE" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"zwx8981/LIQE" -> "Q-Future/Q-Bench"
"zwx8981/LIQE" -> "miccunifi/ARNIQA"
"zwx8981/LIQE" -> "DXOMARK-Research/PIQ2023"
"zwx8981/LIQE" -> "taco-group/COVER"
"zwx8981/LIQE" -> "avinabsaha/ReIQA"
"Q-Future/Q-Bench" -> "Q-Future/Q-Instruct"
"Q-Future/Q-Bench" -> "VQAssessment/ExplainableVQA"
"Q-Future/Q-Bench" -> "Q-Future/Q-Align"
"Q-Future/Q-Bench" -> "Q-Future/Co-Instruct"
"Q-Future/Q-Bench" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"Q-Future/Q-Bench" -> "TianheWu/MLLMs-for-IQA"
"Q-Future/Q-Bench" -> "VQAssessment/DOVER"
"Q-Future/Q-Bench" -> "zwx8981/LIQE"
"Q-Future/Q-Bench" -> "lcysyzxdxc/AGIQA-3k-Database"
"Q-Future/Q-Bench" -> "XPixelGroup/DepictQA"
"Q-Future/Q-Bench" -> "Q-Future/Compare2Score"
"Q-Future/Q-Bench" -> "zhiyuanyou/DeQA-Score"
"Q-Future/Q-Bench" -> "VQAssessment/BVQI"
"Q-Future/Q-Bench" -> "IceClear/CLIP-IQA"
"Q-Future/Q-Bench" -> "Q-Future/Q-Ground"
"zhenglab/IQA" -> "ranjiewwen/IQA-paper"
"zhenglab/IQA" -> "jongyookim/IQA_BIECON_release"
"Dreemurr-T/BAID" -> "mediatechnologycenter/Aestheval"
"Dreemurr-T/BAID" -> "woshidandan/TANet-image-aesthetics-and-quality-assessment"
"Dreemurr-T/BAID" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"lcysyzxdxc/AGIQA-1k-Database" -> "lcysyzxdxc/AGIQA-3k-Database"
"lcysyzxdxc/AGIQA-3k-Database" -> "lcysyzxdxc/AGIQA-1k-Database"
"lcysyzxdxc/AGIQA-3k-Database" -> "wangjiarui153/AIGCIQA2023"
"lcysyzxdxc/AGIQA-3k-Database" -> "Q-Future/CMC-Bench"
"lcysyzxdxc/AGIQA-3k-Database" -> "Q-Future/Q-Refine"
"zzc-1998/SJTU-H3D" -> "zzc-1998/MLLM-QA-Papers-with-Code"
"yipoh/TAVAR" -> "yipoh/AesNet"
"bcmi/Awesome-Image-Blending" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/Awesome-Image-Blending" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/Awesome-Image-Blending" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"WindVChen/Diff-Harmonization" -> "WindVChen/INR-Harmonization"
"WindVChen/Diff-Harmonization" -> "chenhaoxing/HDNet"
"WindVChen/Diff-Harmonization" -> "adobe/PIH"
"WindVChen/Diff-Harmonization" -> "rakutentech/PCT-Net-Image-Harmonization"
"WindVChen/Diff-Harmonization" -> "bcmi/SycoNet-Adaptive-Image-Harmonization"
"WindVChen/Diff-Harmonization" -> "bcmi/DucoNet-Image-Harmonization"
"WindVChen/INR-Harmonization" -> "WindVChen/Diff-Harmonization"
"WindVChen/INR-Harmonization" -> "WindVChen/VCO-AP"
"DreamEditBenchTeam/DreamEdit" -> "bcmi/DreamCom-Image-Composition"
"DXOMARK-Research/PIQ2023" -> "zwx8981/BIQA_CL"
"DXOMARK-Research/PIQ2023" -> "zwx8981/LIQE"
"DXOMARK-Research/PIQ2023" -> "IIGROUP/AHIQ"
"DXOMARK-Research/PIQ2023" -> "YangiD/DefenseIQA-NT"
"DXOMARK-Research/PIQ2023" -> "h4nwei/SPAQ"
"wangjiarui153/AIGCIQA2023" -> "lcysyzxdxc/AGIQA-3k-Database"
"bcmi/SycoNet-Adaptive-Image-Harmonization" -> "bcmi/Composite-Image-Evaluation"
"TianheWu/Assessor360" -> "sunwei925/CVIQDatabase"
"TianheWu/Assessor360" -> "xiangjieSui/img2video"
"adobe/PIH" -> "chenhaoxing/HDNet"
"adobe/PIH" -> "rakutentech/PCT-Net-Image-Harmonization"
"liuxiaoyu1104/UNIC" -> "liuxiaoyu1104/AnimateAnywhere" ["e"=1]
"liuxiaoyu1104/UNIC" -> "mrluin/UniRestorer" ["e"=1]
"liuxiaoyu1104/UNIC" -> "bcmi/Human-Centric-Image-Cropping"
"liuxiaoyu1104/UNIC" -> "ZcsrenlongZ/ZoomGS" ["e"=1]
"Adnan1011/NR-IQA-CNN" -> "jongyookim/IQA_BIECON_release"
"Adnan1011/NR-IQA-CNN" -> "HuiZeng/BIQA_Toolbox"
"Adnan1011/NR-IQA-CNN" -> "xialeiliu/RankIQA"
"Adnan1011/NR-IQA-CNN" -> "dmaniry/deepIQA"
"Adnan1011/NR-IQA-CNN" -> "lidq92/CNNIQAplusplus"
"Adnan1011/NR-IQA-CNN" -> "zhenglab/IQA"
"Adnan1011/NR-IQA-CNN" -> "jongyookim/IQA_DeepQA_FR_release"
"Adnan1011/NR-IQA-CNN" -> "HC-2016/weighted_DCNN_IQA"
"GZHU-DVL/AttackVQA" -> "zwx8981/PerceptualAttack_BIQA"
"k-zha14/Zoom-VQA" -> "sunwei925/SimpleVQA"
"ShengCN/PixHtLab-Src" -> "ShengCN/SSN_SoftShadowNet"
"ShengCN/PixHtLab-Src" -> "bcmi/Awesome-Object-Shadow-Generation"
"zzc-1998/MD-VQA" -> "Coobiw/TriVQA"
"imfing/ava_downloader" -> "truskovskiyk/nima.pytorch"
"imfing/ava_downloader" -> "yunxiaoshi/Neural-IMage-Assessment"
"imfing/ava_downloader" -> "aimerykong/deepImageAestheticsAnalysis"
"imfing/ava_downloader" -> "titu1994/neural-image-assessment"
"imfing/ava_downloader" -> "ylogx/aesthetics"
"imfing/ava_downloader" -> "BestiVictory/ILGnet"
"imfing/ava_downloader" -> "xialeiliu/RankIQA"
"imfing/ava_downloader" -> "miyamotty/awesome_ImageAesthetics"
"imfing/ava_downloader" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"imfing/ava_downloader" -> "h4nwei/SPAQ"
"imfing/ava_downloader" -> "cgtuebingen/will-people-like-your-image"
"imfing/ava_downloader" -> "fei-aiart/ReLIC"
"imfing/ava_downloader" -> "Dreemurr-T/BAID"
"imfing/ava_downloader" -> "junyongyou/triq"
"imfing/ava_downloader" -> "HuiZeng/BIQA_Toolbox"
"dmaniry/deepIQA" -> "jongyookim/IQA_BIECON_release"
"dmaniry/deepIQA" -> "lidq92/WaDIQaM"
"dmaniry/deepIQA" -> "lidq92/CNNIQAplusplus"
"dmaniry/deepIQA" -> "xialeiliu/RankIQA"
"dmaniry/deepIQA" -> "zwx8981/DBCNN-PyTorch"
"dmaniry/deepIQA" -> "HuiZeng/BIQA_Toolbox"
"dmaniry/deepIQA" -> "lidq92/CNNIQA"
"dmaniry/deepIQA" -> "jongyookim/IQA_DeepQA_FR_release"
"dmaniry/deepIQA" -> "zwx8981/DBCNN"
"dmaniry/deepIQA" -> "zhuhancheng/MetaIQA"
"dmaniry/deepIQA" -> "SSL92/hyperIQA"
"dmaniry/deepIQA" -> "lidq92/SFA"
"dmaniry/deepIQA" -> "Adnan1011/NR-IQA-CNN"
"dmaniry/deepIQA" -> "prashnani/PerceptualImageError"
"dmaniry/deepIQA" -> "HC-2016/weighted_DCNN_IQA"
"woshidandan/Prompt-DeT" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/Prompt-DeT" -> "woshidandan/Image-Color-Aesthetics-and-Quality-Assessment"
"woshidandan/Prompt-DeT" -> "woshidandan/AK4Prompts"
"woshidandan/Prompt-DeT" -> "woshidandan/Image-Aesthetics-and-Quality-Assessment"
"woshidandan/Prompt-DeT" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Prompt-DeT" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/Prompt-DeT" -> "mRobotit/M2Beats"
"woshidandan/Prompt-DeT" -> "woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"
"woshidandan/Prompt-DeT" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"bcmi/ObjectStitch-Image-Composition" -> "bcmi/Awesome-Generative-Image-Composition"
"bcmi/ObjectStitch-Image-Composition" -> "bcmi/ControlCom-Image-Composition"
"bcmi/ObjectStitch-Image-Composition" -> "Xuan-World/UniCombine"
"bcmi/ObjectStitch-Image-Composition" -> "bcmi/DreamCom-Image-Composition"
"bcmi/ObjectStitch-Image-Composition" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"Q-Future/Q-Align" -> "Q-Future/Q-Instruct"
"Q-Future/Q-Align" -> "Q-Future/Co-Instruct"
"Q-Future/Q-Align" -> "Q-Future/Q-Bench"
"Q-Future/Q-Align" -> "VQAssessment/ExplainableVQA"
"Q-Future/Q-Align" -> "zwx8981/LIQE"
"Q-Future/Q-Align" -> "VQAssessment/DOVER"
"Q-Future/Q-Align" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"Q-Future/Q-Align" -> "XPixelGroup/DepictQA"
"Q-Future/Q-Align" -> "IceClear/CLIP-IQA"
"Q-Future/Q-Align" -> "TianheWu/MLLMs-for-IQA"
"Q-Future/Q-Align" -> "sunwei925/RQ-VQA"
"Q-Future/Q-Align" -> "zhiyuanyou/DeQA-Score"
"Q-Future/Q-Align" -> "chaofengc/Awesome-Image-Quality-Assessment"
"Q-Future/Q-Align" -> "VQAssessment/BVQI"
"Q-Future/Q-Align" -> "Q-Future/Compare2Score"
"bcmi/libcom" -> "bcmi/ControlCom-Image-Composition"
"bcmi/libcom" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBAv2"
"bcmi/libcom" -> "bcmi/Awesome-Object-Placement"
"bcmi/libcom" -> "bcmi/Awesome-Image-Composition" ["e"=1]
"bcmi/libcom" -> "bcmi/Awesome-Object-Shadow-Generation"
"bcmi/libcom" -> "bcmi/Object-Shadow-Generation-Dataset-DESOBA"
"bcmi/libcom" -> "bcmi/Awesome-Image-Harmonization"
"bcmi/libcom" -> "bcmi/Awesome-Generative-Image-Composition"
"bcmi/libcom" -> "bcmi/GracoNet-Object-Placement"
"bcmi/libcom" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/libcom" -> "bcmi/CDTNet-High-Resolution-Image-Harmonization"
"bcmi/libcom" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/libcom" -> "bcmi/Object-Placement-Assessment-Dataset-OPA"
"bcmi/libcom" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/libcom" -> "bcmi/ObjectStitch-Image-Composition"
"miccunifi/ARNIQA" -> "miccunifi/QualiCLIP" ["e"=1]
"miccunifi/ARNIQA" -> "avinabsaha/ReIQA"
"miccunifi/ARNIQA" -> "miccunifi/TAPE" ["e"=1]
"miccunifi/ARNIQA" -> "pavancm/CONTRIQUE"
"miccunifi/ARNIQA" -> "zwx8981/LIQE"
"miccunifi/ARNIQA" -> "taco-group/COVER"
"miccunifi/ARNIQA" -> "sunwei925/UIQA"
"miccunifi/ARNIQA" -> "suhas-srinath/GRepQ"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "woshidandan/AK4Prompts"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" -> "mRobotit/M2Beats"
"mRobotit/M2Beats" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"mRobotit/M2Beats" -> "woshidandan/AK4Prompts"
"mRobotit/M2Beats" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"yipoh/AesBench" -> "yipoh/AesExpert"
"yipoh/AesBench" -> "Q-Future/Q-Instruct"
"yipoh/AesBench" -> "mediatechnologycenter/Aestheval"
"yipoh/AesBench" -> "sxfly99/CG-IAA"
"yipoh/AesBench" -> "Q-Future/Co-Instruct"
"yipoh/AesBench" -> "zwx8981/LIQE"
"yipoh/AesBench" -> "yipoh/AesNet"
"yipoh/AesBench" -> "Q-Future/Q-Bench"
"yipoh/AesBench" -> "Q-Future/Q-Align"
"yipoh/AesBench" -> "yipoh/TAVAR"
"yipoh/AesBench" -> "KwaiVGI/Uniaa" ["e"=1]
"yipoh/AesBench" -> "Dreemurr-T/BAID"
"yipoh/AesBench" -> "bcmi/Awesome-Aesthetic-Evaluation-and-Cropping"
"yipoh/AesBench" -> "IceClear/CLIP-IQA"
"Q-Future/Q-Instruct" -> "Q-Future/Q-Bench"
"Q-Future/Q-Instruct" -> "Q-Future/Co-Instruct"
"Q-Future/Q-Instruct" -> "Q-Future/Q-Align"
"Q-Future/Q-Instruct" -> "VQAssessment/ExplainableVQA"
"Q-Future/Q-Instruct" -> "TianheWu/MLLMs-for-IQA"
"Q-Future/Q-Instruct" -> "yipoh/AesExpert"
"Q-Future/Q-Instruct" -> "VQAssessment/BVQI"
"Q-Future/Q-Instruct" -> "Q-Future/Q-Ground"
"Q-Future/Q-Instruct" -> "zwx8981/LIQE"
"Q-Future/Q-Instruct" -> "XPixelGroup/DepictQA"
"Q-Future/Q-Instruct" -> "VQAssessment/DOVER"
"Q-Future/Q-Instruct" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"Q-Future/Q-Instruct" -> "yipoh/AesBench"
"Q-Future/Q-Instruct" -> "Q-Future/Compare2Score"
"Q-Future/Q-Instruct" -> "lcysyzxdxc/AGIQA-3k-Database"
"yipoh/AesExpert" -> "sxfly99/CG-IAA"
"yipoh/AesExpert" -> "yipoh/AesBench"
"yipoh/AesExpert" -> "yipoh/AesNet"
"yipoh/AesExpert" -> "yipoh/TAVAR"
"yipoh/AesExpert" -> "Q-Future/Q-Instruct"
"yipoh/AesExpert" -> "Q-Future/Q-Ground"
"yipoh/AesExpert" -> "mediatechnologycenter/Aestheval"
"yipoh/AesExpert" -> "KwaiVGI/Uniaa" ["e"=1]
"yipoh/AesExpert" -> "Q-Future/Co-Instruct"
"Q-Future/Q-Refine" -> "zzc-1998/MLLM-QA-Papers-with-Code"
"Q-Future/Q-Refine" -> "zzc-1998/SJTU-H3D"
"zijianchen98/AGIN" -> "zzc-1998/SJTU-H3D"
"zijianchen98/AGIN" -> "zijianchen98/Awesome-AI-Generated-Image-Tasks"
"zijianchen98/AGIN" -> "zzc-1998/MLLM-QA-Papers-with-Code"
"suyukun666/S2CNet" -> "bo-zhang-cs/GAIC-Pytorch"
"suyukun666/S2CNet" -> "jhong93/gencrop"
"suyukun666/S2CNet" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"suyukun666/S2CNet" -> "liuxiaoyu1104/UNIC"
"suyukun666/S2CNet" -> "HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch"
"suyukun666/S2CNet" -> "bo-zhang-cs/CACNet-Pytorch"
"woshidandan/ITU-Standard-for-IAA" -> "woshidandan/AK4Prompts"
"hridayK/Detection-of-AI-generated-images" -> "bcmi/SSP-AI-Generated-Image-Detection"
"bcmi/ProPIH-Painterly-Image-Harmonization" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/ProPIH-Painterly-Image-Harmonization" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/ProPIH-Painterly-Image-Harmonization" -> "bcmi/Awesome-Image-Blending"
"bcmi/ArtoPIH-Painterly-Image-Harmonization" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/ArtoPIH-Painterly-Image-Harmonization" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/ArtoPIH-Painterly-Image-Harmonization" -> "bcmi/Awesome-Image-Blending"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/RETAB-Weak-Shot-Semantic-Segmentation"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/ArtoPIH-Painterly-Image-Harmonization"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/ProPIH-Painterly-Image-Harmonization"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/Awesome-Image-Blending"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/SimFormer-Weak-Shot-Semantic-Segmentation"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/FOPA-Fast-Object-Placement-Assessment"
"bcmi/SSP-AI-Generated-Image-Detection" -> "hridayK/Detection-of-AI-generated-images"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/PHDiffusion-Painterly-Image-Harmonization"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/DeltaGAN-Few-Shot-Image-Generation"
"bcmi/SSP-AI-Generated-Image-Detection" -> "bcmi/Awesome-Object-Placement"
"showlab/T2VScore" -> "Coobiw/TriVQA"
"showlab/T2VScore" -> "showlab/Efficient-CLS" ["e"=1]
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "taco-group/COVER"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "sunwei925/RQ-VQA"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "winwinwenwen77/ModularBVQA"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "sunwei925/SimpleVQA"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "VQAssessment/BVQI"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "VQAssessment/ExplainableVQA"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "VQAssessment/FAST-VQA-and-FasterVQA"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "SaMMyCHoo/Light-VQA-plus"
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" -> "Sissuire/SAMA"
"chencn2020/PromptIQA" -> "chencn2020/SEAGULL"
"taco-group/COVER" -> "lixinustc/KVQ-Challenge-CVPR-NTIRE2024"
"taco-group/COVER" -> "sunwei925/RQ-VQA"
"taco-group/COVER" -> "taco-group/Video-Quality-Assessment-A-Comprehensive-Survey"
"taco-group/COVER" -> "lcysyzxdxc/MPD"
"taco-group/COVER" -> "uniqzheng/HFR-BVQA"
"taco-group/COVER" -> "Sissuire/SAMA"
"BestiVictory/ILGnet" -> "aimerykong/deepImageAestheticsAnalysis"
"BestiVictory/ILGnet" -> "cgtuebingen/will-people-like-your-image"
"BestiVictory/ILGnet" -> "HiiYL/PiQual"
"BestiVictory/ILGnet" -> "alanspike/personalizedImageAesthetics"
"BestiVictory/ILGnet" -> "Openning07/MPADA"
"BestiVictory/ILGnet" -> "BestiVictory/CJS-CNN"
"BestiVictory/ILGnet" -> "ylogx/aesthetics"
"BestiVictory/ILGnet" -> "mediatechnologycenter/Aestheval"
"winwinwenwen77/ModularBVQA" -> "sunwei925/RQ-VQA"
"Q-Future/Co-Instruct" -> "Q-Future/Q-Instruct"
"Q-Future/Co-Instruct" -> "Q-Future/Q-Ground"
"Q-Future/Co-Instruct" -> "VQAssessment/BVQI"
"Q-Future/Co-Instruct" -> "TianheWu/MLLMs-for-IQA"
"Q-Future/Co-Instruct" -> "VQAssessment/ExplainableVQA"
"Q-Future/Co-Instruct" -> "Q-Future/Q-Align"
"Q-Future/Co-Instruct" -> "Q-Future/Q-Bench"
"sunwei925/RQ-VQA" -> "sunwei925/SimpleVQA"
"sunwei925/RQ-VQA" -> "winwinwenwen77/ModularBVQA"
"sunwei925/RQ-VQA" -> "taco-group/COVER"
"sunwei925/RQ-VQA" -> "QMME/StableVQA"
"sunwei925/RQ-VQA" -> "Sissuire/SAMA"
"TianheWu/MLLMs-for-IQA" -> "Q-Future/Co-Instruct"
"TianheWu/MLLMs-for-IQA" -> "Q-Future/Q-Ground"
"TianheWu/MLLMs-for-IQA" -> "XPixelGroup/DepictQA"
"TianheWu/MLLMs-for-IQA" -> "zwx8981/LIQE"
"TianheWu/MLLMs-for-IQA" -> "TianheWu/Assessor360"
"TianheWu/MLLMs-for-IQA" -> "Q-Future/Compare2Score"
"TianheWu/MLLMs-for-IQA" -> "Q-Future/Q-Instruct"
"TianheWu/MLLMs-for-IQA" -> "zhiyuanyou/DeQA-Score"
"TianheWu/MLLMs-for-IQA" -> "Q-Future/Q-Bench"
"YangiD/DefenseIQA-NT" -> "zwx8981/PerceptualAttack_BIQA"
"YangiD/DefenseIQA-NT" -> "h4nwei/2AFC-LMMs"
"Sissuire/SAMA" -> "zzc-1998/MD-VQA"
"Sissuire/SAMA" -> "Coobiw/TriVQA"
"lcysyzxdxc/MISC" -> "Q-Future/CMC-Bench"
"Q-Future/Chinese-Q-Bench" -> "zzc-1998/MLLM-QA-Papers-with-Code"
"ylogx/aesthetics" -> "aimerykong/deepImageAestheticsAnalysis"
"ylogx/aesthetics" -> "cgtuebingen/will-people-like-your-image"
"ylogx/aesthetics" -> "imfing/ava_downloader"
"ylogx/aesthetics" -> "mediatechnologycenter/Aestheval"
"ylogx/aesthetics" -> "subpic/ava-mlsp"
"ylogx/aesthetics" -> "BestiVictory/ILGnet"
"ylogx/aesthetics" -> "Openning07/MPADA"
"ylogx/aesthetics" -> "alanspike/personalizedImageAesthetics"
"ylogx/aesthetics" -> "miyamotty/awesome_ImageAesthetics"
"ylogx/aesthetics" -> "titu1994/neural-image-assessment"
"ylogx/aesthetics" -> "truskovskiyk/nima.pytorch"
"ylogx/aesthetics" -> "yunxiaoshi/Neural-IMage-Assessment"
"ylogx/aesthetics" -> "kang-gnak/eva-dataset"
"ylogx/aesthetics" -> "kunghunglu/DeepPhotoCritic-ICCV17"
"ylogx/aesthetics" -> "sergeyk/vislab"
"wuhuikai/GP-GAN" -> "owenzlz/DeepImageBlending"
"wuhuikai/GP-GAN" -> "wasidennis/DeepHarmonization"
"wuhuikai/GP-GAN" -> "wuhuikai/TF-A2RL"
"wuhuikai/GP-GAN" -> "msinghal34/Image-Blending-using-GP-GANs"
"XPixelGroup/DepictQA" -> "zhiyuanyou/DeQA-Score"
"XPixelGroup/DepictQA" -> "TianheWu/MLLMs-for-IQA"
"XPixelGroup/DepictQA" -> "Q-Future/Q-Ground"
"XPixelGroup/DepictQA" -> "zwx8981/LIQE"
"XPixelGroup/DepictQA" -> "Q-Future/Co-Instruct"
"XPixelGroup/DepictQA" -> "Q-Future/Q-Instruct"
"XPixelGroup/DepictQA" -> "Q-Future/Compare2Score"
"XPixelGroup/DepictQA" -> "lwq20020127/Q-Insight" ["e"=1]
"XPixelGroup/DepictQA" -> "Q-Future/Q-Align"
"XPixelGroup/DepictQA" -> "Q-Future/Q-Bench"
"XPixelGroup/DepictQA" -> "DXOMARK-Research/PIQ2023"
"yiling-chen/view-finding-network" -> "zijunwei/ViewEvaluationNet"
"yiling-chen/view-finding-network" -> "yiling-chen/flickr-cropping-dataset"
"yiling-chen/view-finding-network" -> "zijunwei/ViewProposalNet"
"yiling-chen/view-finding-network" -> "remorsecs/pytorch-view-finding-network"
"yiling-chen/view-finding-network" -> "lld533/Grid-Anchor-based-Image-Cropping-Pytorch"
"yiling-chen/view-finding-network" -> "wuhuikai/TF-A2RL"
"yiling-chen/view-finding-network" -> "HuiZeng/Grid-Anchor-based-Image-Cropping"
"yiling-chen/view-finding-network" -> "bcmi/Human-Centric-Image-Cropping"
"yiling-chen/view-finding-network" -> "bo-zhang-cs/CGS-Pytorch"
"woshidandan/AK4Prompts" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Long-Tail-image-aesthetics-and-quality-assessment" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Long-Tail-image-aesthetics-and-quality-assessment" -> "woshidandan/AK4Prompts"
"woshidandan/Long-Tail-image-aesthetics-and-quality-assessment" -> "woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment"
"woshidandan/Long-Tail-image-aesthetics-and-quality-assessment" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"woshidandan/SR-IAA-image-aesthetics-and-quality-assessment" -> "woshidandan/AK4Prompts"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/SR-IAA-image-aesthetics-and-quality-assessment"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/AK4Prompts"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/Long-Tail-image-aesthetics-and-quality-assessment"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/Rethinking-Personalized-Aesthetics-Assessment"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "mRobotit/M2Beats"
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" -> "woshidandan/Prompt-DeT"
"wasidennis/DeepHarmonization" -> "vinthony/s2am"
"wasidennis/DeepHarmonization" -> "SamsungLabs/image_harmonization"
"wasidennis/DeepHarmonization" -> "jflalonde/colorRealism"
"wasidennis/DeepHarmonization" -> "junyanz/RealismCNN"
"wasidennis/DeepHarmonization" -> "GYZHikari/Semantic-Cosegmentation"
"wasidennis/DeepHarmonization" -> "Dominoer/bmvc2020_image_harmonization"
"wasidennis/DeepHarmonization" -> "zhenglab/HarmonyTransformer"
"Q-Future/Compare2Score" -> "Q-Future/Q-Ground"
"Q-Future/Visual-Question-Answering-for-Video-Quality-Assessment" -> "lcysyzxdxc/MPD"
"chencn2020/SEAGULL" -> "chencn2020/PromptIQA"
"Q-Future/CMC-Bench" -> "lcysyzxdxc/MISC"
"Q-Future/Q-Ground" -> "Q-Future/Co-Instruct"
"Q-Future/Q-Ground" -> "zhengchen1999/Grounding-IQA"
"Q-Future/Q-Ground" -> "zzc-1998/MLLM-QA-Papers-with-Code"
"zhengchen1999/Grounding-IQA" -> "Kai-Liu001/Dog-IQA"
"zhengchen1999/Grounding-IQA" -> "Q-Future/Q-Ground"
"lcysyzxdxc/MPD" -> "Coobiw/TriVQA"
"lcysyzxdxc/MPD" -> "zzc-1998/SJTU-H3D"
"Xuan-World/UniCombine" -> "bcmi/ObjectStitch-Image-Composition"
"Xuan-World/UniCombine" -> "chfyfr/PixelPonder"
"xialeiliu/RankIQA" -> "dmaniry/deepIQA"
"xialeiliu/RankIQA" -> "HuiZeng/BIQA_Toolbox"
"xialeiliu/RankIQA" -> "SSL92/hyperIQA"
"xialeiliu/RankIQA" -> "zwx8981/DBCNN-PyTorch"
"xialeiliu/RankIQA" -> "lidq92/SFA"
"xialeiliu/RankIQA" -> "jongyookim/IQA_BIECON_release"
"xialeiliu/RankIQA" -> "zhuhancheng/MetaIQA"
"xialeiliu/RankIQA" -> "Adnan1011/NR-IQA-CNN"
"xialeiliu/RankIQA" -> "lidq92/WaDIQaM"
"xialeiliu/RankIQA" -> "zheng-yuwei/RankIQA.PyTorch"
"xialeiliu/RankIQA" -> "zwx8981/DBCNN"
"xialeiliu/RankIQA" -> "lidq92/CNNIQA"
"xialeiliu/RankIQA" -> "h4nwei/SPAQ"
"xialeiliu/RankIQA" -> "lidq92/CNNIQAplusplus"
"xialeiliu/RankIQA" -> "ysyscool/SGDNet"
"woshidandan/Rethinking-Personalized-Aesthetics-Assessment" -> "woshidandan/AK4Prompts"
"zhiyuanyou/DeQA-Score" -> "XPixelGroup/DepictQA"
"zhiyuanyou/DeQA-Score" -> "lwq20020127/Q-Insight" ["e"=1]
"zhiyuanyou/DeQA-Score" -> "TianheWu/MLLMs-for-IQA"
"zhiyuanyou/DeQA-Score" -> "chencn2020/PromptIQA"
"zhiyuanyou/DeQA-Score" -> "Q-Future/Co-Instruct"
"zhiyuanyou/DeQA-Score" -> "Q-Future/Q-Ground"
"taco-group/Video-Quality-Assessment-A-Comprehensive-Survey" -> "taco-group/COVER"
"taco-group/Video-Quality-Assessment-A-Comprehensive-Survey" -> "sunwei925/RQ-VQA"
"taco-group/Video-Quality-Assessment-A-Comprehensive-Survey" -> "winwinwenwen77/ModularBVQA"
"jongyookim/IQA_BIECON_release" -> "lidq92/CNNIQAplusplus"
"jongyookim/IQA_BIECON_release" -> "lidq92/CNNIQA"
"jongyookim/IQA_BIECON_release" -> "dmaniry/deepIQA"
"jongyookim/IQA_BIECON_release" -> "jongyookim/IQA_DeepQA_FR_release"
"jongyookim/IQA_BIECON_release" -> "zwx8981/DBCNN"
"jongyookim/IQA_BIECON_release" -> "lidq92/WaDIQaM"
"jongyookim/IQA_BIECON_release" -> "HuiZeng/BIQA_Toolbox"
"jongyookim/IQA_BIECON_release" -> "Adnan1011/NR-IQA-CNN"
"jongyookim/IQA_BIECON_release" -> "HC-2016/weighted_DCNN_IQA"
"jongyookim/IQA_BIECON_release" -> "xungeer29/No-reference-Image-Quality-Assessment"
"jongyookim/IQA_BIECON_release" -> "zwx8981/DBCNN-PyTorch"
"jongyookim/IQA_BIECON_release" -> "xialeiliu/RankIQA"
"jongyookim/IQA_BIECON_release" -> "zhenglab/IQA"
"idealo/image-quality-assessment" ["l"="46.924,31.348"]
"titu1994/neural-image-assessment" ["l"="46.897,31.33"]
"yunxiaoshi/Neural-IMage-Assessment" ["l"="46.876,31.327"]
"xialeiliu/RankIQA" ["l"="47.016,31.342"]
"ocampor/image-quality" ["l"="47.028,31.364"]
"aimerykong/deepImageAestheticsAnalysis" ["l"="46.859,31.309"]
"truskovskiyk/nima.pytorch" ["l"="46.873,31.341"]
"chaofengc/Awesome-Image-Quality-Assessment" ["l"="46.979,31.386"]
"ylogx/aesthetics" ["l"="46.855,31.326"]
"imfing/ava_downloader" ["l"="46.89,31.313"]
"chaofengc/IQA-PyTorch" ["l"="46.995,31.419"]
"weizhou-geek/Image-Quality-Assessment-Benchmark" ["l"="47.012,31.355"]
"SSL92/hyperIQA" ["l"="46.998,31.34"]
"pterhoer/FaceImageQuality" ["l"="33.351,29.404"]
"idealo/imagededup" ["l"="51.052,29.696"]
"dmaniry/deepIQA" ["l"="47.032,31.348"]
"jacob6/ENIQA" ["l"="47.115,31.241"]
"imfing/CEIQ" ["l"="47.084,31.257"]
"open-webrtc-toolkit/QoSTestFramework" ["l"="46.998,31.243"]
"lidq92/MDTVSFA" ["l"="46.979,31.283"]
"vztu/VIDEVAL" ["l"="46.977,31.269"]
"Tencent/DVQA" ["l"="46.996,31.274"]
"dsoellinger/blind_image_quality_toolbox" ["l"="47.091,31.331"]
"bukalapak/pybrisque" ["l"="47.074,31.336"]
"HuiZeng/BIQA_Toolbox" ["l"="47.042,31.33"]
"ysyscool/SGDNet" ["l"="47.03,31.315"]
"lidq92/CNNIQAplusplus" ["l"="47.049,31.341"]
"zwx8981/DBCNN" ["l"="47.033,31.335"]
"lidq92/WaDIQaM" ["l"="47.033,31.323"]
"gregfreeman/image_quality_toolbox" ["l"="47.149,31.318"]
"lidq92/SFA" ["l"="47.032,31.303"]
"lidq92/LinearityIQA" ["l"="47.011,31.295"]
"lidq92/CNNIQA" ["l"="47.055,31.336"]
"lidq92/VSFA" ["l"="46.986,31.291"]
"zhuhancheng/MetaIQA" ["l"="47.021,31.321"]
"qingsenyangit/Two-stream_IQA" ["l"="47.06,31.306"]
"subpic/koniq" ["l"="47.018,31.314"]
"zwx8981/DBCNN-PyTorch" ["l"="47.009,31.329"]
"xungeer29/No-reference-Image-Quality-Assessment" ["l"="47.053,31.373"]
"jongyookim/IQA_BIECON_release" ["l"="47.052,31.354"]
"zwx8981/UNIQUE" ["l"="47.002,31.323"]
"pavancm/CONTRIQUE" ["l"="46.975,31.335"]
"HuiZeng/Grid-Anchor-based-Image-Cropping" ["l"="46.714,31.294"]
"HuiZeng/Grid-Anchor-based-Image-Cropping-Pytorch" ["l"="46.733,31.3"]
"lld533/Grid-Anchor-based-Image-Cropping-Pytorch" ["l"="46.728,31.289"]
"yiling-chen/flickr-cropping-dataset" ["l"="46.716,31.281"]
"zijunwei/ViewProposalNet" ["l"="46.707,31.302"]
"yiling-chen/view-finding-network" ["l"="46.702,31.286"]
"zijunwei/ViewEvaluationNet" ["l"="46.694,31.297"]
"wuhuikai/TF-A2RL" ["l"="46.721,31.308"]
"CVBase-Bupt/EndtoEndCroppingSystem" ["l"="46.706,31.271"]
"subpic/ava-mlsp" ["l"="46.812,31.334"]
"Openning07/MPADA" ["l"="46.801,31.336"]
"miyamotty/awesome_ImageAesthetics" ["l"="46.828,31.336"]
"zhuhancheng/BLG-PIAA" ["l"="46.809,31.361"]
"bcmi/Image-Composition-Assessment-Dataset-CADB" ["l"="46.73,31.337"]
"alanspike/personalizedImageAesthetics" ["l"="46.838,31.343"]
"fei-aiart/ReLIC" ["l"="46.809,31.35"]
"huangeddie/ML-Aesthetics-NIMA" ["l"="46.782,31.364"]
"HuiZeng/Unified_IAA" ["l"="46.784,31.348"]
"cgtuebingen/will-people-like-your-image" ["l"="46.845,31.315"]
"ryanxingql/image-quality-assessment-toolbox" ["l"="47.043,31.396"]
"krshrimali/No-Reference-Image-Quality-Assessment-using-BRISQUE-Model" ["l"="47.063,31.358"]
"francois-rozet/piqa" ["l"="45.838,31.277"]
"buyizhiyou/NRVQA" ["l"="47.047,31.296"]
"guptapraful/niqe" ["l"="47.072,31.313"]
"BestiVictory/ILGnet" ["l"="46.839,31.326"]
"master/nima" ["l"="46.853,31.359"]
"Adnan1011/NR-IQA-CNN" ["l"="47.042,31.365"]
"woshidandan/TANet-image-aesthetics-and-quality-assessment" ["l"="46.804,31.304"]
"mahdihosseini/FoucsPath" ["l"="47.107,31.462"]
"mahdihosseini/HVS-MaxPol" ["l"="47.113,31.474"]
"sergeyk/vislab" ["l"="46.857,31.283"]
"SenJia/Saliency-CNN-Image-Quality-Assessment" ["l"="47.072,31.323"]
"weizhou-geek/Recent-Image-Quality-Related-Papers" ["l"="46.996,31.331"]
"junyongyou/triq" ["l"="46.995,31.304"]
"jongyookim/IQA_DeepQA_FR_release" ["l"="47.076,31.352"]
"LeonLIU08/DeepQA-with-Pytorch" ["l"="47.086,31.317"]
"Bobholamovic/CNN-FRIQA" ["l"="47.113,31.369"]
"anse3832/MUSIQ" ["l"="46.965,31.342"]
"hejingwenhejingwen/CSRNet" ["l"="-33.578,23.016"]
"bcmi/Awesome-Aesthetic-Evaluation-and-Cropping" ["l"="46.782,31.313"]
"IceClear/CLIP-IQA" ["l"="46.958,31.377"]
"zhenglab/IQA" ["l"="47.086,31.38"]
"kwanyeelin/HIQA" ["l"="47.107,31.32"]
"steffensbola/blind_iqa_contrast" ["l"="47.1,31.234"]
"bcmi/Human-Centric-Image-Cropping" ["l"="46.738,31.285"]
"bo-zhang-cs/CACNet-Pytorch" ["l"="46.747,31.304"]
"vztu/BVQA_Benchmark" ["l"="46.965,31.266"]
"baidut/PatchVQ" ["l"="46.965,31.283"]
"VQAssessment/FAST-VQA-and-FasterVQA" ["l"="46.947,31.348"]
"jarikorhonen/nr-vqa-consumervideo" ["l"="46.965,31.255"]
"zwx8981/TCSVT-2022-BVQA" ["l"="46.951,31.285"]
"woojaekim/DeepVQA_Release" ["l"="46.981,31.251"]
"vztu/RAPIQUE" ["l"="46.952,31.265"]
"sunwei925/SimpleVQA" ["l"="46.921,31.327"]
"vinthony/s2am" ["l"="46.516,31.266"]
"Dominoer/bmvc2020_image_harmonization" ["l"="46.522,31.28"]
"wasidennis/DeepHarmonization" ["l"="46.537,31.272"]
"stefanLeong/S2CRNet" ["l"="46.493,31.291"]
"jflalonde/colorRealism" ["l"="46.529,31.248"]
"prashnani/PerceptualImageError" ["l"="47.052,31.323"]
"dingkeyan93/DISTS" ["l"="47.042,31.313"]
"dingkeyan93/IQA-optimization" ["l"="47.023,31.332"]
"IIGROUP/AHIQ" ["l"="46.989,31.319"]
"HaomingCai/PIPAL-dataset" ["l"="46.999,31.295"]
"rehanguha/brisque" ["l"="47.137,31.361"]
"rendezhous/image-quality-assessment-python" ["l"="47.124,31.343"]
"ocampor/notebooks" ["l"="47.147,31.34"]
"pavancm/vbliinds" ["l"="46.958,31.243"]
"lfovia/NRVQA-NSTSS" ["l"="46.969,31.231"]
"jarikorhonen/cnn-tlvqm" ["l"="46.937,31.235"]
"remorsecs/pytorch-view-finding-network" ["l"="46.676,31.283"]
"Archer-Tatsu/V-CNN" ["l"="64.747,2.041"]
"baidut/paq2piq" ["l"="47.015,31.283"]
"pcpmartins/video-quality-assessment" ["l"="46.938,31.22"]
"baidut/PaQ-2-PiQ" ["l"="47.029,31.288"]
"BestiVictory/DPC-Captions" ["l"="46.822,31.326"]
"kunghunglu/DeepPhotoCritic-ICCV17" ["l"="46.842,31.297"]
"SINRG-Lab/VQA-Deep-Learning" ["l"="47.005,31.226"]
"bo-zhang-cs/CGS-Pytorch" ["l"="46.724,31.273"]
"mahdihosseini/MaxPol" ["l"="47.134,31.49"]
"mahdihosseini/1Shot-MaxPol" ["l"="47.151,31.502"]
"mahdihosseini/FQPath" ["l"="47.131,31.471"]
"isaaccorley/deep-aesthetics-pytorch" ["l"="46.758,31.376"]
"janpf/self-supervised-multi-task-aesthetic-pretraining" ["l"="46.768,31.386"]
"suyukun666/S2CNet" ["l"="46.753,31.295"]
"luwr1022/listwise-view-ranking" ["l"="46.717,31.257"]
"liuxiaoyu1104/UNIC" ["l"="46.738,31.309"]
"Tencent/CenseoQoE" ["l"="46.957,31.296"]
"h4nwei/SPAQ" ["l"="46.982,31.323"]
"isalirezag/TReS" ["l"="46.982,31.342"]
"IIGROUP/MANIQA" ["l"="46.989,31.358"]
"zwx8981/BIQA_CL" ["l"="46.977,31.313"]
"guanghaoyin/CVRKD-IQA" ["l"="46.985,31.311"]
"researchmm/CKDN" ["l"="46.969,31.32"]
"geekyutao/GraphIQA" ["l"="46.957,31.318"]
"cientgu/GIQA" ["l"="47.016,31.303"]
"anse3832/IQT" ["l"="46.978,31.302"]
"zheng-yuwei/RankIQA.PyTorch" ["l"="47.005,31.313"]
"YunanZhu/Pytorch-TestRankIQA" ["l"="47.057,31.246"]
"zwx8981/LIQE" ["l"="46.943,31.372"]
"woshidandan/Image-Color-Aesthetics-and-Quality-Assessment" ["l"="46.795,31.284"]
"mediatechnologycenter/Aestheval" ["l"="46.823,31.354"]
"Dreemurr-T/BAID" ["l"="46.821,31.318"]
"woshidandan/Image-Aesthetics-and-Quality-Assessment" ["l"="46.788,31.272"]
"icbcbicc/FocusLiteNN" ["l"="47.073,31.447"]
"icbcbicc/PyTorch_EPLL" ["l"="47.086,31.468"]
"DXOMARK-Research/PIQ2023" ["l"="46.96,31.331"]
"ZhengyuZhao/koniq-PyTorch" ["l"="47.063,31.281"]
"chaoma99/sr-metric" ["l"="47.106,31.292"]
"EadCat/NIQA" ["l"="47.114,31.268"]
"buyizhiyou/papers" ["l"="47.091,31.272"]
"bcmi/Awesome-Image-Harmonization" ["l"="46.514,31.334"]
"bcmi/Awesome-Image-Composition" ["l"="50.839,2.951"]
"bcmi/Image-Harmonization-Dataset-iHarmony4" ["l"="46.539,31.338"]
"bcmi/BargainNet-Image-Harmonization" ["l"="46.56,31.358"]
"bcmi/Object-Shadow-Generation-Dataset-DESOBA" ["l"="46.536,31.366"]
"bcmi/Awesome-Object-Shadow-Generation" ["l"="46.523,31.366"]
"bcmi/CDTNet-High-Resolution-Image-Harmonization" ["l"="46.531,31.357"]
"SamsungLabs/image_harmonization" ["l"="46.514,31.302"]
"bcmi/libcom" ["l"="46.497,31.358"]
"junleen/RainNet" ["l"="46.495,31.307"]
"chenhaoxing/HDNet" ["l"="46.463,31.311"]
"ZHKKKe/Harmonizer" ["l"="46.475,31.319"]
"bcmi/Awesome-Object-Placement" ["l"="46.519,31.377"]
"bcmi/ControlCom-Image-Composition" ["l"="46.492,31.382"]
"bcmi/Object-Placement-Assessment-Dataset-OPA" ["l"="46.548,31.369"]
"bcmi/DIRL-Inharmonious-Region-Localization" ["l"="46.602,31.35"]
"bcmi/Awesome-Few-Shot-Image-Generation" ["l"="46.537,31.416"]
"bcmi/F2GAN-Few-Shot-Image-Generation" ["l"="46.561,31.394"]
"bcmi/DeltaGAN-Few-Shot-Image-Generation" ["l"="46.529,31.394"]
"WisconsinAIVision/few-shot-gan-adaptation" ["l"="46.516,31.473"]
"bcmi/CaGNet-Zero-Shot-Semantic-Segmentation" ["l"="46.541,31.398"]
"edward3862/LoFGAN-pytorch" ["l"="46.502,31.45"]
"bcmi/MatchingGAN-Few-Shot-Image-Generation" ["l"="46.557,31.404"]
"bcmi/SimFormer-Weak-Shot-Semantic-Segmentation" ["l"="46.536,31.382"]
"bcmi/Video-Harmonization-Dataset-HYouTube" ["l"="46.551,31.376"]
"kobeshegu/awesome-few-shot-generation" ["l"="46.547,31.458"]
"georgosgeorgos/few-shot-diffusion-models" ["l"="46.551,31.491"]
"icbcbicc/IQA-Dataset" ["l"="46.978,31.355"]
"bcmi/GracoNet-Object-Placement" ["l"="46.53,31.376"]
"zhenglab/HarmonyTransformer" ["l"="46.502,31.278"]
"rockeyben/DCCF" ["l"="46.473,31.294"]
"zhenglab/IntrinsicHarmony" ["l"="46.486,31.281"]
"rakutentech/PCT-Net-Image-Harmonization" ["l"="46.461,31.301"]
"VITA-Group/SSHarmonization" ["l"="46.489,31.266"]
"valeoai/ZS3" ["l"="46.486,31.433"]
"subhc/SPNet" ["l"="46.51,31.429"]
"bcmi/Rendered-Image-Harmonization-Dataset-RdHarmony" ["l"="46.602,31.365"]
"photosynthesis-team/piq" ["l"="45.818,31.343"]
"roimehrez/PIRM2018" ["l"="-35.061,21.561"]
"weichen582/RetinexNet" ["l"="-33.656,23.176"]
"yuanjunchai/IKC" ["l"="-35.081,21.523"]
"hitzhangyu/Self-supervised-Image-Enhancement-Network-Training-With-Low-Light-Images-Only" ["l"="-33.701,23.223"]
"sefibk/KernelGAN" ["l"="-35.088,21.527"]
"flyywh/CVPR-2020-Semi-Low-Light" ["l"="-33.687,23.205"]
"owenzlz/DeepImageBlending" ["l"="46.56,31.291"]
"wuhuikai/GP-GAN" ["l"="46.605,31.278"]
"Erkaman/poisson_blend" ["l"="50.604,31.414"]
"RenYurui/StructureFlow" ["l"="44.684,29.283"]
"msinghal34/Image-Blending-using-GP-GANs" ["l"="46.58,31.269"]
"weizhou-geek/VGCN-PyTorch" ["l"="47.019,31.271"]
"xiangjieSui/img2video" ["l"="46.977,31.407"]
"kang-gnak/eva-dataset" ["l"="46.828,31.303"]
"sunwei925/CompressedVQA" ["l"="46.938,31.28"]
"atelili/2BiVQA" ["l"="46.948,31.205"]
"niu-haoran/FLIVE_Database" ["l"="47.049,31.273"]
"RohanDoshi2018/ZeroshotSemanticSegmentation" ["l"="46.442,31.447"]
"Yang-Bob/PMMs" ["l"="62.341,36.503"]
"MendelXu/zsseg.baseline" ["l"="48.725,30.298"]
"valeoai/BUDA" ["l"="46.461,31.455"]
"GuillaumeBalezo/A-Lamp" ["l"="46.768,31.342"]
"DreamvLee/Image-Aesthetic-Assessment-Assisted-by-Attributes-through-Adversarial-Learning" ["l"="46.77,31.353"]
"mahdihosseini/RMSGD" ["l"="47.093,31.488"]
"mahdihosseini/ADP" ["l"="47.107,31.511"]
"pavancm/GREED" ["l"="46.848,31.45"]
"uniqzheng/HFR-BVQA" ["l"="46.86,31.432"]
"ldq9526/ARShadowGAN" ["l"="46.469,31.354"]
"V-Sense/Aesthetic-Image-Captioning-ICCVW-2019" ["l"="46.808,31.377"]
"PengZai/ARIC" ["l"="46.797,31.387"]
"sunwei925/CVIQDatabase" ["l"="46.951,31.502"]
"sunwei925/MC360IQA" ["l"="46.948,31.525"]
"Baoliang93/GSTVQA" ["l"="46.927,31.248"]
"twitter-research/image-crop-analysis" ["l"="46.709,31.235"]
"twitter-research/visual-sentiment-analysis" ["l"="46.696,31.211"]
"YunanZhu/RecycleD" ["l"="47.079,31.216"]
"narthchin/DEIQT" ["l"="46.943,31.324"]
"StevenShaw1999/RSSA" ["l"="46.507,31.494"]
"YBYBZhang/DiFa" ["l"="-35.331,21.127"]
"e-271/few-shot-gan" ["l"="46.492,31.514"]
"woshidandan/IAA_Tutorial" ["l"="46.775,31.274"]
"woshidandan/Pixel-level-No-reference-Image-Exposure-Assessment" ["l"="46.792,31.262"]
"woshidandan/Long-Tail-image-aesthetics-and-quality-assessment" ["l"="46.802,31.271"]
"woshidandan/AK4Prompts" ["l"="46.797,31.254"]
"woshidandan/SR-IAA-image-aesthetics-and-quality-assessment" ["l"="46.781,31.255"]
"YCHang686/SCS-Co-CVPR2022" ["l"="46.472,31.277"]
"finint/RL-Solutions" ["l"="46.592,31.376"]
"smehdia/NTIRE2021-IQA-MACS" ["l"="47.035,31.241"]
"maruiperfect/R-R-Net" ["l"="46.988,31.261"]
"bcmi/RETAB-Weak-Shot-Semantic-Segmentation" ["l"="46.529,31.384"]
"bcmi/TraMaS-Weak-Shot-Object-Detection" ["l"="46.564,31.371"]
"bcmi/FOPA-Fast-Object-Placement-Assessment" ["l"="46.522,31.383"]
"bcmi/SimTrans-Weak-Shot-Classification" ["l"="46.547,31.386"]
"avinabsaha/ReIQA" ["l"="46.955,31.357"]
"IIGROUP/RADN" ["l"="46.962,31.309"]
"miccunifi/ARNIQA" ["l"="46.941,31.338"]
"days1011/HLAGCN" ["l"="46.711,31.361"]
"shedy-pub/hlagcn-jittor" ["l"="46.697,31.355"]
"ryanxingql/blog" ["l"="-39.577,21.849"]
"IIGROUP/AttentionProbe" ["l"="44.761,30.206"]
"bcmi/Object-Shadow-Generation-Dataset-DESOBAv2" ["l"="46.503,31.378"]
"bcmi/PHDiffusion-Painterly-Image-Harmonization" ["l"="46.51,31.37"]
"bcmi/ProPIH-Painterly-Image-Harmonization" ["l"="46.517,31.393"]
"bcmi/ArtoPIH-Painterly-Image-Harmonization" ["l"="46.513,31.386"]
"UniBester/AGE" ["l"="46.523,31.446"]
"reyllama/mixdl" ["l"="46.48,31.471"]
"h4nwei/STI-VQA" ["l"="46.91,31.223"]
"bcmi/MadisNet-Inharmonious-Region-Localization" ["l"="46.622,31.348"]
"atelili/raindrop-detection-on-a-windshield" ["l"="46.943,31.178"]
"junyanz/RealismCNN" ["l"="46.54,31.235"]
"AliRoyat/NTIRE2021-IQA-MACS-Pytorch" ["l"="47.049,31.222"]
"Q-Future/Q-Align" ["l"="46.941,31.396"]
"IceClear/StableSR" ["l"="-35.845,22.204"]
"richzhang/PerceptualSimilarity" ["l"="45.822,31.405"]
"swz30/Restormer" ["l"="-34.985,21.43"]
"DarrenPan/Awesome-CVPR2024-Low-Level-Vision" ["l"="-35.947,22.247"]
"XPixelGroup/BasicSR" ["l"="-34.956,21.539"]
"Kobaayyy/Awesome-CVPR2025-CVPR2024-CVPR2021-CVPR2020-Low-Level-Vision" ["l"="-34.944,21.461"]
"cszn/KAIR" ["l"="-34.992,21.488"]
"Algolzw/daclip-uir" ["l"="-35.907,22.272"]
"ChaofWang/Awesome-Super-Resolution" ["l"="-34.976,21.561"]
"yipoh/AesExpert" ["l"="46.87,31.404"]
"cpf0079/UCDA" ["l"="46.938,31.301"]
"VQAssessment/DOVER" ["l"="46.928,31.373"]
"woshidandan/Prompt-DeT" ["l"="46.806,31.261"]
"woshidandan/Champion-Solution-for-CVPR-NTIRE-2024-Quality-Assessment-on-AIGC" ["l"="46.778,31.262"]
"lixinustc/KVQ-Challenge-CVPR-NTIRE2024" ["l"="46.911,31.364"]
"Q-Future/Q-Bench" ["l"="46.93,31.405"]
"sjtuplayer/few-shot-diffusion" ["l"="46.563,31.522"]
"jiamings/d2c" ["l"="46.543,31.514"]
"lingxiao-li/HAE" ["l"="46.499,31.463"]
"mv-lab/IQA-Conformer-BNS" ["l"="47.029,31.273"]
"VQAssessment/ExplainableVQA" ["l"="46.923,31.389"]
"VQAssessment/BVQI" ["l"="46.913,31.386"]
"Q-Future/Q-Instruct" ["l"="46.914,31.401"]
"sunwei925/RQ-VQA" ["l"="46.899,31.37"]
"scikit-video/scikit-video" ["l"="46.978,31.208"]
"rohitgirdhar/ActionVLAD" ["l"="47.834,33.971"]
"yoosan/video-understanding-dataset" ["l"="47.808,33.92"]
"vadimkantorov/mpegflow" ["l"="47.623,34.105"]
"bo-zhang-cs/GAIC-Pytorch" ["l"="46.743,31.321"]
"sunyasheng/a2rl_pytorch" ["l"="46.743,31.272"]
"bcmi/Awesome-Image-Blending" ["l"="46.503,31.39"]
"bcmi/Awesome-Weak-Shot-Learning" ["l"="46.565,31.383"]
"WindVChen/Solution-For-AISafety-CVPR2022" ["l"="46.351,31.295"]
"WindVChen/VCO-AP" ["l"="46.373,31.291"]
"suhas-srinath/GRepQ" ["l"="46.933,31.319"]
"avinabsaha/HIDRO-VQA" ["l"="46.901,31.357"]
"Q-Future/Co-Instruct" ["l"="46.914,31.412"]
"SaMMyCHoo/Light-VQA-plus" ["l"="46.894,31.4"]
"Q-Future/Visual-Question-Answering-for-Video-Quality-Assessment" ["l"="46.89,31.434"]
"bcmi/DucoNet-Image-Harmonization" ["l"="46.456,31.329"]
"adobe/PIH" ["l"="46.442,31.3"]
"WindVChen/Diff-Harmonization" ["l"="46.435,31.315"]
"taco-group/COVER" ["l"="46.894,31.387"]
"kobeshegu/ECCV2022_WaveGAN" ["l"="46.456,31.487"]
"kobeshegu/FreGAN_NeurIPS2022" ["l"="46.436,31.504"]
"ZHKKKe/NeuralPreset" ["l"="45.115,28.602"]
"WindVChen/INR-Harmonization" ["l"="46.414,31.304"]
"csjliang/PPR10K" ["l"="-33.588,23.004"]
"k-zha14/Zoom-VQA" ["l"="46.907,31.297"]
"winwinwenwen77/ModularBVQA" ["l"="46.884,31.361"]
"Sissuire/SAMA" ["l"="46.877,31.377"]
"woshidandan/ITU-Standard-for-IAA" ["l"="46.78,31.24"]
"woshidandan/Rethinking-Personalized-Aesthetics-Assessment" ["l"="46.789,31.251"]
"mRobotit/M2Beats" ["l"="46.795,31.244"]
"sjtuplayer/Compositional_Neural_Painter" ["l"="46.571,31.542"]
"YuCao16/CRDI" ["l"="46.551,31.544"]
"KyanChen/FunSR" ["l"="46.349,31.277"]
"bcmi/Awesome-Generative-Image-Composition" ["l"="46.465,31.373"]
"bcmi/ObjectStitch-Image-Composition" ["l"="46.455,31.387"]
"bcmi/DreamCom-Image-Composition" ["l"="46.421,31.382"]
"bcmi/Composite-Image-Evaluation" ["l"="46.431,31.363"]
"bcmi/SycoNet-Adaptive-Image-Harmonization" ["l"="46.434,31.346"]
"HiiYL/PiQual" ["l"="46.836,31.288"]
"rawmarshmellows/deep-photo-aesthetics" ["l"="46.853,31.26"]
"GYZHikari/Semantic-Cosegmentation" ["l"="46.513,31.229"]
"GYZHikari/UAV-Saliency" ["l"="46.503,31.209"]
"TianheWu/MLLMs-for-IQA" ["l"="46.933,31.422"]
"XPixelGroup/DepictQA" ["l"="46.943,31.413"]
"lcysyzxdxc/AGIQA-3k-Database" ["l"="46.93,31.469"]
"Q-Future/Compare2Score" ["l"="46.92,31.428"]
"zhiyuanyou/DeQA-Score" ["l"="46.937,31.44"]
"Q-Future/Q-Ground" ["l"="46.909,31.438"]
"ranjiewwen/IQA-paper" ["l"="47.118,31.399"]
"lcysyzxdxc/AGIQA-1k-Database" ["l"="46.937,31.49"]
"wangjiarui153/AIGCIQA2023" ["l"="46.923,31.491"]
"Q-Future/CMC-Bench" ["l"="46.968,31.502"]
"Q-Future/Q-Refine" ["l"="46.899,31.488"]
"zzc-1998/SJTU-H3D" ["l"="46.87,31.481"]
"zzc-1998/MLLM-QA-Papers-with-Code" ["l"="46.883,31.487"]
"yipoh/TAVAR" ["l"="46.852,31.417"]
"yipoh/AesNet" ["l"="46.866,31.419"]
"DreamEditBenchTeam/DreamEdit" ["l"="46.376,31.384"]
"YangiD/DefenseIQA-NT" ["l"="47.013,31.249"]
"TianheWu/Assessor360" ["l"="46.96,31.456"]
"liuxiaoyu1104/AnimateAnywhere" ["l"="-35.282,21.099"]
"mrluin/UniRestorer" ["l"="-35.268,21.124"]
"ZcsrenlongZ/ZoomGS" ["l"="-35.284,21.123"]
"HC-2016/weighted_DCNN_IQA" ["l"="47.067,31.377"]
"GZHU-DVL/AttackVQA" ["l"="47.049,31.178"]
"zwx8981/PerceptualAttack_BIQA" ["l"="47.035,31.205"]
"ShengCN/PixHtLab-Src" ["l"="46.57,31.337"]
"ShengCN/SSN_SoftShadowNet" ["l"="46.592,31.323"]
"zzc-1998/MD-VQA" ["l"="46.839,31.405"]
"Coobiw/TriVQA" ["l"="46.842,31.427"]
"Xuan-World/UniCombine" ["l"="46.419,31.403"]
"miccunifi/QualiCLIP" ["l"="-35.992,20.41"]
"miccunifi/TAPE" ["l"="-36.005,20.383"]
"sunwei925/UIQA" ["l"="46.921,31.303"]
"yipoh/AesBench" ["l"="46.877,31.389"]
"sxfly99/CG-IAA" ["l"="46.85,31.406"]
"KwaiVGI/Uniaa" ["l"="64.226,3.88"]
"zijianchen98/AGIN" ["l"="46.86,31.507"]
"zijianchen98/Awesome-AI-Generated-Image-Tasks" ["l"="46.852,31.528"]
"jhong93/gencrop" ["l"="46.755,31.319"]
"hridayK/Detection-of-AI-generated-images" ["l"="46.471,31.415"]
"bcmi/SSP-AI-Generated-Image-Detection" ["l"="46.5,31.403"]
"showlab/T2VScore" ["l"="46.812,31.461"]
"showlab/Efficient-CLS" ["l"="33.421,31.734"]
"chencn2020/PromptIQA" ["l"="46.958,31.488"]
"chencn2020/SEAGULL" ["l"="46.965,31.515"]
"taco-group/Video-Quality-Assessment-A-Comprehensive-Survey" ["l"="46.863,31.38"]
"lcysyzxdxc/MPD" ["l"="46.87,31.441"]
"BestiVictory/CJS-CNN" ["l"="46.805,31.321"]
"QMME/StableVQA" ["l"="46.85,31.39"]
"h4nwei/2AFC-LMMs" ["l"="47.029,31.221"]
"lcysyzxdxc/MISC" ["l"="46.984,31.52"]
"Q-Future/Chinese-Q-Bench" ["l"="46.879,31.515"]
"lwq20020127/Q-Insight" ["l"="33.121,31.39"]
"zhengchen1999/Grounding-IQA" ["l"="46.9,31.469"]
"Kai-Liu001/Dog-IQA" ["l"="46.897,31.503"]
"chfyfr/PixelPonder" ["l"="46.391,31.415"]
}