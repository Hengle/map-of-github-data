digraph G {
"coin-dataset/annotation-tool" -> "xujinglin/FineDiving"
"coin-dataset/annotation-tool" -> "425776024/VideoLabeling"
"coin-dataset/annotation-tool" -> "nzl-thu/MUSDL"
"pomonam/AttentionCluster" -> "hazeld/rank-aware-attention-network"
"Maluuba/FigureQA" -> "kushalkafle/DVQA_dataset"
"Maluuba/FigureQA" -> "vmichals/FigureQA-baseline"
"vmichals/FigureQA-baseline" -> "Maluuba/FigureQA"
"vmichals/FigureQA-baseline" -> "kushalkafle/DVQA_dataset"
"LisaAnne/Hallucination" -> "AoiDragon/POPE"
"LisaAnne/Hallucination" -> "RUCAIBox/POPE"
"LisaAnne/Hallucination" -> "BillChan226/HALC"
"ParitoshParmar/MTL-AQA" -> "nzl-thu/MUSDL"
"ParitoshParmar/MTL-AQA" -> "yuxumin/CoRe"
"ParitoshParmar/MTL-AQA" -> "ZhouKanglei/Awesome-AQA"
"ParitoshParmar/MTL-AQA" -> "Shunli-Wang/TSA-Net"
"ParitoshParmar/MTL-AQA" -> "xujinglin/FineDiving"
"ParitoshParmar/MTL-AQA" -> "hazeld/rank-aware-attention-network"
"ParitoshParmar/MTL-AQA" -> "shiyi-zh0408/LOGO"
"ParitoshParmar/MTL-AQA" -> "baiyang4/aqa_tpt"
"ParitoshParmar/MTL-AQA" -> "ParitoshParmar/Fitness-AQA"
"kushalkafle/DVQA_dataset" -> "kushalkafle/PReFIL"
"kushalkafle/DVQA_dataset" -> "Maluuba/FigureQA"
"kushalkafle/DVQA_dataset" -> "NiteshMethani/PlotQA"
"kushalkafle/DVQA_dataset" -> "vmichals/FigureQA-baseline"
"hazeld/rank-aware-attention-network" -> "nzl-thu/MUSDL"
"JasonObeid/Chart2Text" -> "vis-nlp/Chart-to-text"
"JasonObeid/Chart2Text" -> "gongliym/data2text-transformer"
"JasonObeid/Chart2Text" -> "tingyaohsu/SciCap"
"JasonObeid/Chart2Text" -> "soap117/DeepRule"
"JasonObeid/Chart2Text" -> "pranonrahman/ChartSumm"
"JasonObeid/Chart2Text" -> "vis-nlp/ChartQA"
"Cvrane/ChartReader" -> "soap117/DeepRule"
"NiteshMethani/PlotQA" -> "kushalkafle/DVQA_dataset"
"NiteshMethani/PlotQA" -> "kushalkafle/PReFIL"
"NiteshMethani/PlotQA" -> "Maluuba/FigureQA"
"SDOlivia/FineGym" -> "Chuhanxx/Temporal_Query_Networks"
"SDOlivia/FineGym" -> "hazeld/rank-aware-attention-network"
"coriverchen/Robust_Steganography" -> "mengtong0110/InferDPT"
"nzl-thu/MUSDL" -> "hazeld/rank-aware-attention-network"
"nzl-thu/MUSDL" -> "yuxumin/CoRe"
"nzl-thu/MUSDL" -> "ParitoshParmar/MTL-AQA"
"nzl-thu/MUSDL" -> "baiyang4/aqa_tpt"
"nzl-thu/MUSDL" -> "Shunli-Wang/TSA-Net"
"soap117/DeepRule" -> "Cvrane/ChartReader"
"soap117/DeepRule" -> "vis-nlp/Chart-to-text"
"soap117/DeepRule" -> "TheJaeLal/LineFormer"
"soap117/DeepRule" -> "vis-nlp/ChartQA"
"soap117/DeepRule" -> "JasonObeid/Chart2Text"
"soap117/DeepRule" -> "bloomberg/scatteract"
"Shunli-Wang/TSA-Net" -> "baiyang4/aqa_tpt"
"Shunli-Wang/TSA-Net" -> "Lyman-Smoker/Awesome-AQA"
"Shunli-Wang/TSA-Net" -> "yuxumin/CoRe"
"Shunli-Wang/TSA-Net" -> "xuangch/CVPR22_GDLT"
"Shunli-Wang/TSA-Net" -> "xujinglin/FineDiving"
"Shunli-Wang/TSA-Net" -> "ParitoshParmar/MTL-AQA"
"Shunli-Wang/TSA-Net" -> "Luciferbobo/DAE-AQA"
"Luciferbobo/DAE-AQA" -> "baiyang4/aqa_tpt"
"Luciferbobo/DAE-AQA" -> "xuangch/CVPR22_GDLT"
"Luciferbobo/DAE-AQA" -> "Shunli-Wang/TSA-Net"
"Luciferbobo/DAE-AQA" -> "yuxumin/CoRe"
"archiki/Robust-E2E-ASR" -> "YUCHEN005/DPSL-ASR"
"archiki/Robust-E2E-ASR" -> "bliunlpr/Robust_e2e_gan"
"yuxumin/CoRe" -> "baiyang4/aqa_tpt"
"yuxumin/CoRe" -> "xujinglin/FineDiving"
"yuxumin/CoRe" -> "nzl-thu/MUSDL"
"yuxumin/CoRe" -> "Shunli-Wang/TSA-Net"
"yuxumin/CoRe" -> "ZhouKanglei/Awesome-AQA"
"yuxumin/CoRe" -> "ParitoshParmar/MTL-AQA"
"yuxumin/CoRe" -> "shiyi-zh0408/LOGO"
"yuxumin/CoRe" -> "xuangch/CVPR22_GDLT"
"yuxumin/CoRe" -> "Luciferbobo/DAE-AQA"
"yuxumin/CoRe" -> "ParitoshParmar/Fitness-AQA"
"yuxumin/CoRe" -> "ZhouKanglei/HGCN_AQA"
"kushalkafle/PReFIL" -> "kushalkafle/DVQA_dataset"
"kahnchana/svt" -> "kahnchana/clippy"
"vis-nlp/ChartQA" -> "vis-nlp/Chart-to-text"
"vis-nlp/ChartQA" -> "soap117/DeepRule"
"vis-nlp/ChartQA" -> "NiteshMethani/PlotQA"
"vis-nlp/ChartQA" -> "tingxueronghua/ChartLlama-code"
"vis-nlp/ChartQA" -> "vis-nlp/UniChart"
"vis-nlp/ChartQA" -> "google-research/pix2struct" ["e"=1]
"vis-nlp/ChartQA" -> "JasonObeid/Chart2Text"
"vis-nlp/ChartQA" -> "tingyaohsu/SciCap"
"vis-nlp/ChartQA" -> "mitvis/vistext"
"vis-nlp/ChartQA" -> "FuxiaoLiu/MMC"
"vis-nlp/ChartQA" -> "zengxingchen/ChartQA-MLLM" ["e"=1]
"vis-nlp/ChartQA" -> "OpenGVLab/ChartAst"
"vis-nlp/ChartQA" -> "princeton-nlp/CharXiv"
"vis-nlp/ChartQA" -> "levymsn/CQA-CRCT"
"vis-nlp/ChartQA" -> "vis-nlp/ChartGemma"
"vis-nlp/Chart-to-text" -> "JasonObeid/Chart2Text"
"vis-nlp/Chart-to-text" -> "pranonrahman/ChartSumm"
"vis-nlp/Chart-to-text" -> "vis-nlp/ChartQA"
"vis-nlp/Chart-to-text" -> "mitvis/vistext"
"vis-nlp/Chart-to-text" -> "tingyaohsu/SciCap"
"vis-nlp/Chart-to-text" -> "soap117/DeepRule"
"vis-nlp/Chart-to-text" -> "vis-nlp/UniChart"
"vis-nlp/Chart-to-text" -> "vis-nlp/ChartInstruct"
"ParitoshParmar/Fitness-AQA" -> "baiyang4/aqa_tpt"
"ParitoshParmar/Fitness-AQA" -> "yuxumin/CoRe"
"ParitoshParmar/Fitness-AQA" -> "Luciferbobo/DAE-AQA"
"ParitoshParmar/Fitness-AQA" -> "Shunli-Wang/TSA-Net"
"ParitoshParmar/Fitness-AQA" -> "ParitoshParmar/MTL-AQA"
"ParitoshParmar/Fitness-AQA" -> "xuangch/CVPR22_GDLT"
"ParitoshParmar/Fitness-AQA" -> "ZhouKanglei/Awesome-AQA"
"YUCHEN005/DPSL-ASR" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"YUCHEN005/DPSL-ASR" -> "YUCHEN005/Gradient-Remedy"
"YUCHEN005/DPSL-ASR" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/DPSL-ASR" -> "archiki/Robust-E2E-ASR"
"xujinglin/FineDiving" -> "yuxumin/CoRe"
"xujinglin/FineDiving" -> "Shunli-Wang/TSA-Net"
"xujinglin/FineDiving" -> "ZhouKanglei/Awesome-AQA"
"xujinglin/FineDiving" -> "shiyi-zh0408/LOGO"
"xujinglin/FineDiving" -> "ParitoshParmar/MTL-AQA"
"xujinglin/FineDiving" -> "baiyang4/aqa_tpt"
"xujinglin/FineDiving" -> "nzl-thu/MUSDL"
"xujinglin/FineDiving" -> "xuangch/CVPR22_GDLT"
"xujinglin/FineDiving" -> "coin-dataset/annotation-tool"
"xujinglin/FineDiving" -> "Luciferbobo/DAE-AQA"
"xujinglin/FineDiving" -> "Lyman-Smoker/Awesome-AQA"
"Ethan00Si/Instrumental-variables-for-recommendation" -> "Ethan00Si/KuaiSAR"
"Ethan00Si/Instrumental-variables-for-recommendation" -> "Ethan00Si/SESREC-SIGIR-2023"
"FuxiaoLiu/Twitter-Video-dataset" -> "FuxiaoLiu/DocumentCLIP"
"xuangch/CVPR22_GDLT" -> "baiyang4/aqa_tpt"
"YUCHEN005/RATS-Channel-A-Speech-Data" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/RATS-Channel-A-Speech-Data" -> "YUCHEN005/DPSL-ASR"
"YUCHEN005/RATS-Channel-A-Speech-Data" -> "YUCHEN005/Gradient-Remedy"
"ZhouKanglei/HGCN_AQA" -> "qinghuannn/PAMFN"
"microsoft/i-Code" -> "microsoft/UDOP" ["e"=1]
"microsoft/i-Code" -> "NExT-GPT/NExT-GPT"
"microsoft/i-Code" -> "facebookresearch/ImageBind" ["e"=1]
"microsoft/i-Code" -> "thu-ml/unidiffuser" ["e"=1]
"microsoft/i-Code" -> "SHI-Labs/Versatile-Diffusion" ["e"=1]
"microsoft/i-Code" -> "DAMO-NLP-SG/Video-LLaMA"
"microsoft/i-Code" -> "AlibabaResearch/AdvancedLiterateMachinery" ["e"=1]
"microsoft/i-Code" -> "baaivision/Emu" ["e"=1]
"microsoft/i-Code" -> "mlfoundations/open_flamingo" ["e"=1]
"microsoft/i-Code" -> "lucidrains/make-a-video-pytorch" ["e"=1]
"microsoft/i-Code" -> "YingqingHe/LVDM" ["e"=1]
"microsoft/i-Code" -> "AILab-CVC/VideoCrafter" ["e"=1]
"microsoft/i-Code" -> "salesforce/LAVIS" ["e"=1]
"microsoft/i-Code" -> "showlab/Show-o" ["e"=1]
"microsoft/i-Code" -> "gligen/GLIGEN" ["e"=1]
"lupantech/ScienceQA" -> "amazon-science/mm-cot" ["e"=1]
"lupantech/ScienceQA" -> "yuweihao/MM-Vet"
"lupantech/ScienceQA" -> "RUCAIBox/POPE"
"lupantech/ScienceQA" -> "wenhuchen/TheoremQA" ["e"=1]
"lupantech/ScienceQA" -> "lupantech/chameleon-llm" ["e"=1]
"lupantech/ScienceQA" -> "lupantech/MathVista"
"lupantech/ScienceQA" -> "ylsung/VL_adapter" ["e"=1]
"lupantech/ScienceQA" -> "FuxiaoLiu/LRV-Instruction"
"lupantech/ScienceQA" -> "lupantech/dl4math" ["e"=1]
"lupantech/ScienceQA" -> "MMMU-Benchmark/MMMU"
"lupantech/ScienceQA" -> "mandyyyyii/scibench" ["e"=1]
"lupantech/ScienceQA" -> "lupantech/IconQA" ["e"=1]
"lupantech/ScienceQA" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"lupantech/ScienceQA" -> "vis-nlp/ChartQA"
"lupantech/ScienceQA" -> "LightChen233/M3CoT"
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "microsoft/GLIP" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "DirtyHarryLYL/LLM-in-Vision"
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "dvlab-research/LISA"
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "KaiyangZhou/CoOp" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "IDEA-Research/awesome-detection-transformer" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "mlfoundations/open_flamingo" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "VainF/Awesome-Anything" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "microsoft/X-Decoder" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "LLaVA-VL/LLaVA-NeXT"
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "salesforce/LAVIS" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "TheShadow29/awesome-grounding" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "baaivision/Painter" ["e"=1]
"Computer-Vision-in-the-Wild/CVinW_Readings" -> "KMnP/vpt" ["e"=1]
"OpenGVLab/InternVideo" -> "OpenGVLab/Ask-Anything"
"OpenGVLab/InternVideo" -> "OpenGVLab/VideoChat-Flash"
"OpenGVLab/InternVideo" -> "OpenGVLab/VideoMAEv2" ["e"=1]
"OpenGVLab/InternVideo" -> "MCG-NJU/VideoMAE" ["e"=1]
"OpenGVLab/InternVideo" -> "DAMO-NLP-SG/Video-LLaMA"
"OpenGVLab/InternVideo" -> "OpenGVLab/unmasked_teacher" ["e"=1]
"OpenGVLab/InternVideo" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"OpenGVLab/InternVideo" -> "PKU-YuanGroup/Video-LLaVA"
"OpenGVLab/InternVideo" -> "OpenGVLab/VideoMamba" ["e"=1]
"OpenGVLab/InternVideo" -> "LLaVA-VL/LLaVA-NeXT"
"OpenGVLab/InternVideo" -> "mbzuai-oryx/Video-ChatGPT"
"OpenGVLab/InternVideo" -> "DAMO-NLP-SG/VideoLLaMA2"
"OpenGVLab/InternVideo" -> "ArrowLuo/CLIP4Clip" ["e"=1]
"OpenGVLab/InternVideo" -> "magic-research/PLLaVA"
"OpenGVLab/InternVideo" -> "SwinTransformer/Video-Swin-Transformer" ["e"=1]
"JialianW/GRiT" -> "showlab/Image2Paragraph" ["e"=1]
"JialianW/GRiT" -> "jshilong/GPT4RoI"
"JialianW/GRiT" -> "davidnvq/grit" ["e"=1]
"JialianW/GRiT" -> "allenai/unified-io-inference"
"JialianW/GRiT" -> "showlab/EgoVLP" ["e"=1]
"JialianW/GRiT" -> "shikras/shikra"
"JialianW/GRiT" -> "X2FD/LVIS-INSTRUCT4V"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "huangb23/VTimeLLM"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "rese1f/MovieChat"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "Ziyang412/VideoTree"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "boheumd/MA-LMM"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "RenShuhuai-Andy/TimeChat"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "md-mohaiminul/VideoRecap"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "MME-Benchmarks/Video-MME"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "daixiangzi/Awesome-Token-Compress"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "Wang-Xiaodong1899/Open-R1-Video"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "JUNJIE99/MLVU"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "EvolvingLMMs-Lab/LongVA"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "egoschema/EgoSchema"
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "j-min/HiREST" ["e"=1]
"ttengwang/Awesome_Long_Form_Video_Understanding" -> "QQ-MM/Video-CCAM"
"allenai/unified-io-inference" -> "allenai/unified-io-2" ["e"=1]
"allenai/unified-io-inference" -> "JialianW/GRiT"
"allenai/unified-io-inference" -> "TencentARC/GVT"
"ch3cook-fdu/Vote2Cap-DETR" -> "Open3DA/LL3DA" ["e"=1]
"ch3cook-fdu/Vote2Cap-DETR" -> "HankYe/AdaptiveDiffusion"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "showlab/Awesome-MLLM-Hallucination"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "DirtyHarryLYL/LLM-in-Vision"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "DAMO-NLP-SG/VCD"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "HillZhang1999/llm-hallucination-survey" ["e"=1]
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "shikiw/OPERA"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "FuxiaoLiu/LRV-Instruction"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "Fancy-MLLM/R1-Onevision"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "TideDra/lmm-r1"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "SinclairCoder/Instruction-Tuning-Papers" ["e"=1]
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "ChaofanTao/Autoregressive-Models-in-Vision-Survey" ["e"=1]
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "Osilly/Vision-R1"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "open-compass/VLMEvalKit"
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"google-deepmind/perception_test" -> "PKU-YuanGroup/Video-Bench" ["e"=1]
"google-deepmind/perception_test" -> "OpenGVLab/VideoChat-Flash"
"google-deepmind/perception_test" -> "Ziyang412/VideoTree"
"google-deepmind/perception_test" -> "OpenGVLab/unmasked_teacher" ["e"=1]
"YUCHEN005/Unified-Enhance-Separation" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/Unified-Enhance-Separation" -> "YUCHEN005/Gradient-Remedy"
"YUCHEN005/Unified-Enhance-Separation" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"baiyang4/aqa_tpt" -> "xuangch/CVPR22_GDLT"
"baiyang4/aqa_tpt" -> "Luciferbobo/DAE-AQA"
"baiyang4/aqa_tpt" -> "yuxumin/CoRe"
"baiyang4/aqa_tpt" -> "Shunli-Wang/TSA-Net"
"HELLORPG/CV-Framework" -> "MCG-NJU/CaReBench"
"AndyTang15/FLAG3D" -> "AndyTang15/FLAG3Dv2"
"Lyman-Smoker/Awesome-AQA" -> "iSEE-Laboratory/Continual-AQA"
"Lyman-Smoker/Awesome-AQA" -> "Run542968/Awesome-3D-Human-Motion-Generation"
"Lyman-Smoker/Awesome-AQA" -> "iSEE-Laboratory/EgoExo-Fitness"
"YUCHEN005/Gradient-Remedy" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/Gradient-Remedy" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"FuxiaoLiu/DocumentCLIP" -> "FuxiaoLiu/Twitter-Video-dataset"
"Alpha-VLLM/LLaMA2-Accessory" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "X-PLUG/mPLUG-Owl"
"Alpha-VLLM/LLaMA2-Accessory" -> "LLaVA-VL/LLaVA-NeXT"
"Alpha-VLLM/LLaMA2-Accessory" -> "InternLM/InternLM-XComposer"
"Alpha-VLLM/LLaMA2-Accessory" -> "mlfoundations/open_flamingo" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "baaivision/Emu" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "QwenLM/Qwen-VL"
"Alpha-VLLM/LLaMA2-Accessory" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "dvlab-research/LISA"
"Alpha-VLLM/LLaMA2-Accessory" -> "DAMO-NLP-SG/Video-LLaMA"
"Alpha-VLLM/LLaMA2-Accessory" -> "salesforce/LAVIS" ["e"=1]
"Alpha-VLLM/LLaMA2-Accessory" -> "PKU-YuanGroup/Video-LLaVA"
"Alpha-VLLM/LLaMA2-Accessory" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"Alpha-VLLM/LLaMA2-Accessory" -> "THUDM/CogVLM"
"Alpha-VLLM/LLaMA2-Accessory" -> "Alpha-VLLM/Lumina-T2X" ["e"=1]
"haotian-liu/LLaVA" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"haotian-liu/LLaVA" -> "salesforce/LAVIS" ["e"=1]
"haotian-liu/LLaVA" -> "openai/CLIP" ["e"=1]
"haotian-liu/LLaVA" -> "Vision-CAIR/MiniGPT-4" ["e"=1]
"haotian-liu/LLaVA" -> "mlfoundations/open_clip" ["e"=1]
"haotian-liu/LLaVA" -> "OpenGVLab/InternVL"
"haotian-liu/LLaVA" -> "IDEA-Research/Grounded-Segment-Anything" ["e"=1]
"haotian-liu/LLaVA" -> "lm-sys/FastChat" ["e"=1]
"haotian-liu/LLaVA" -> "LLaVA-VL/LLaVA-NeXT"
"haotian-liu/LLaVA" -> "QwenLM/Qwen-VL"
"haotian-liu/LLaVA" -> "huggingface/peft" ["e"=1]
"haotian-liu/LLaVA" -> "vllm-project/vllm" ["e"=1]
"haotian-liu/LLaVA" -> "hiyouga/LLaMA-Factory" ["e"=1]
"haotian-liu/LLaVA" -> "THUDM/CogVLM"
"haotian-liu/LLaVA" -> "Dao-AILab/flash-attention" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "mlfoundations/open_flamingo" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "jshilong/GPT4RoI"
"open-mmlab/Multimodal-GPT" -> "microsoft/X-Decoder" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "X-PLUG/mPLUG-Owl"
"open-mmlab/Multimodal-GPT" -> "open-mmlab/mmfewshot" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "InternLM/InternLM-techreport" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "open-mmlab/mmengine" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "open-mmlab/mmeval" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "open-mmlab/playground" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "jshilong/GroupRCNN" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "OpenGVLab/Ask-Anything"
"open-mmlab/Multimodal-GPT" -> "baaivision/Painter" ["e"=1]
"open-mmlab/Multimodal-GPT" -> "shikras/shikra"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "haotian-liu/LLaVA"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "salesforce/LAVIS" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "OpenGVLab/InternVL"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "QwenLM/Qwen-VL"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "openai/CLIP" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "RUCAIBox/LLMSurvey" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "pliang279/awesome-multimodal-ml" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "mlfoundations/open_clip" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "huggingface/peft" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "microsoft/unilm" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "QwenLM/Qwen2.5-VL"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "hiyouga/LLaMA-Factory" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "LLaVA-VL/LLaVA-NeXT"
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "Hannibal046/Awesome-LLM" ["e"=1]
"BradyFU/Awesome-Multimodal-Large-Language-Models" -> "Vision-CAIR/MiniGPT-4" ["e"=1]
"InvincibleWyq/ChatVID" -> "AndyTang15/FLAG3Dv2"
"InvincibleWyq/ChatVID" -> "AndyTang15/FLAG3D"
"InvincibleWyq/ChatVID" -> "SuleBai/SC-CLIP"
"dvlab-research/LISA" -> "mbzuai-oryx/groundingLMM"
"dvlab-research/LISA" -> "LLaVA-VL/LLaVA-NeXT"
"dvlab-research/LISA" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"dvlab-research/LISA" -> "microsoft/GLIP" ["e"=1]
"dvlab-research/LISA" -> "OpenGVLab/VisionLLM"
"dvlab-research/LISA" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["e"=1]
"dvlab-research/LISA" -> "shikras/shikra"
"dvlab-research/LISA" -> "facebookresearch/Mask2Former" ["e"=1]
"dvlab-research/LISA" -> "Liuziyu77/Visual-RFT"
"dvlab-research/LISA" -> "MarkMoHR/Awesome-Referring-Image-Segmentation" ["e"=1]
"dvlab-research/LISA" -> "baaivision/Emu" ["e"=1]
"dvlab-research/LISA" -> "baaivision/Painter" ["e"=1]
"dvlab-research/LISA" -> "baaivision/EVA" ["e"=1]
"dvlab-research/LISA" -> "PKU-YuanGroup/Video-LLaVA"
"dvlab-research/LISA" -> "NVlabs/ODISE" ["e"=1]
"microsoft/MM-REACT" -> "shikras/shikra"
"microsoft/MM-REACT" -> "RUCAIBox/POPE"
"microsoft/MM-REACT" -> "allenai/visprog"
"microsoft/MM-REACT" -> "OptimalScale/DetGPT"
"microsoft/MM-REACT" -> "mlfoundations/open_flamingo" ["e"=1]
"microsoft/MM-REACT" -> "allenai/mmc4" ["e"=1]
"microsoft/MM-REACT" -> "jshilong/GPT4RoI"
"microsoft/MM-REACT" -> "yuweihao/MM-Vet"
"microsoft/MM-REACT" -> "mbzuai-oryx/groundingLMM"
"microsoft/MM-REACT" -> "microsoft/X-Decoder" ["e"=1]
"microsoft/MM-REACT" -> "JialianW/GRiT"
"microsoft/MM-REACT" -> "baaivision/Emu" ["e"=1]
"microsoft/MM-REACT" -> "allenai/unified-io-2" ["e"=1]
"microsoft/MM-REACT" -> "Timothyxxx/Chain-of-ThoughtsPapers" ["e"=1]
"microsoft/MM-REACT" -> "lupantech/chameleon-llm" ["e"=1]
"allenai/visprog" -> "cvlab-columbia/viper" ["e"=1]
"allenai/visprog" -> "jshilong/GPT4RoI"
"allenai/visprog" -> "allenai/unified-io-2" ["e"=1]
"allenai/visprog" -> "microsoft/MM-REACT"
"allenai/visprog" -> "ashkamath/mdetr" ["e"=1]
"allenai/visprog" -> "dvlab-research/LISA"
"allenai/visprog" -> "OptimalScale/DetGPT"
"allenai/visprog" -> "JialianW/GRiT"
"allenai/visprog" -> "Computer-Vision-in-the-Wild/CVinW_Readings"
"allenai/visprog" -> "NVlabs/ODISE" ["e"=1]
"allenai/visprog" -> "microsoft/X-Decoder" ["e"=1]
"allenai/visprog" -> "shikras/shikra"
"allenai/visprog" -> "baaivision/Emu" ["e"=1]
"allenai/visprog" -> "Vision-CAIR/ChatCaptioner" ["e"=1]
"allenai/visprog" -> "penghao-wu/vstar"
"lyuchenyang/Macaw-LLM" -> "DAMO-NLP-SG/Video-LLaMA"
"lyuchenyang/Macaw-LLM" -> "longyuewangdcu/Chinese-Llama-2" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "yxuansu/PandaGPT"
"lyuchenyang/Macaw-LLM" -> "mbzuai-oryx/Video-ChatGPT"
"lyuchenyang/Macaw-LLM" -> "EvolvingLMMs-Lab/Otter" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "X-PLUG/mPLUG-Owl"
"lyuchenyang/Macaw-LLM" -> "OpenGVLab/Ask-Anything"
"lyuchenyang/Macaw-LLM" -> "mlfoundations/open_flamingo" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "Alpha-VLLM/LLaMA2-Accessory"
"lyuchenyang/Macaw-LLM" -> "wxjiao/ParroT" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "bytedance/SALMONN" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "Text-to-Audio/Make-An-Audio" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "PeiranLi0930/TorchProject" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"lyuchenyang/Macaw-LLM" -> "thunlp/WebCPM" ["e"=1]
"NExT-GPT/NExT-GPT" -> "aiwaves-cn/agents" ["e"=1]
"NExT-GPT/NExT-GPT" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"NExT-GPT/NExT-GPT" -> "baaivision/Emu" ["e"=1]
"NExT-GPT/NExT-GPT" -> "QwenLM/Qwen-VL"
"NExT-GPT/NExT-GPT" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"NExT-GPT/NExT-GPT" -> "haotian-liu/LLaVA"
"NExT-GPT/NExT-GPT" -> "PKU-YuanGroup/Video-LLaVA"
"NExT-GPT/NExT-GPT" -> "facebookresearch/ImageBind" ["e"=1]
"NExT-GPT/NExT-GPT" -> "DAMO-NLP-SG/Video-LLaMA"
"NExT-GPT/NExT-GPT" -> "THUDM/CogVLM"
"NExT-GPT/NExT-GPT" -> "Alpha-VLLM/LLaMA2-Accessory"
"NExT-GPT/NExT-GPT" -> "LLaVA-VL/LLaVA-NeXT"
"NExT-GPT/NExT-GPT" -> "williamyang1991/Rerender_A_Video" ["e"=1]
"NExT-GPT/NExT-GPT" -> "salesforce/LAVIS" ["e"=1]
"NExT-GPT/NExT-GPT" -> "OpenMOSS/AnyGPT" ["e"=1]
"QwenLM/Qwen-VL" -> "OpenGVLab/InternVL"
"QwenLM/Qwen-VL" -> "QwenLM/Qwen2.5-VL"
"QwenLM/Qwen-VL" -> "THUDM/CogVLM"
"QwenLM/Qwen-VL" -> "haotian-liu/LLaVA"
"QwenLM/Qwen-VL" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"QwenLM/Qwen-VL" -> "InternLM/InternLM-XComposer"
"QwenLM/Qwen-VL" -> "salesforce/LAVIS" ["e"=1]
"QwenLM/Qwen-VL" -> "LLaVA-VL/LLaVA-NeXT"
"QwenLM/Qwen-VL" -> "QwenLM/Qwen" ["e"=1]
"QwenLM/Qwen-VL" -> "modelscope/ms-swift" ["e"=1]
"QwenLM/Qwen-VL" -> "X-PLUG/mPLUG-Owl"
"QwenLM/Qwen-VL" -> "open-compass/VLMEvalKit"
"QwenLM/Qwen-VL" -> "mlfoundations/open_clip" ["e"=1]
"QwenLM/Qwen-VL" -> "IDEA-Research/GroundingDINO" ["e"=1]
"QwenLM/Qwen-VL" -> "salesforce/BLIP" ["e"=1]
"DAMO-NLP-SG/Video-LLaMA" -> "PKU-YuanGroup/Video-LLaVA"
"DAMO-NLP-SG/Video-LLaMA" -> "OpenGVLab/Ask-Anything"
"DAMO-NLP-SG/Video-LLaMA" -> "mbzuai-oryx/Video-ChatGPT"
"DAMO-NLP-SG/Video-LLaMA" -> "DAMO-NLP-SG/VideoLLaMA2"
"DAMO-NLP-SG/Video-LLaMA" -> "OpenGVLab/InternVideo"
"DAMO-NLP-SG/Video-LLaMA" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"DAMO-NLP-SG/Video-LLaMA" -> "salesforce/LAVIS" ["e"=1]
"DAMO-NLP-SG/Video-LLaMA" -> "LLaVA-VL/LLaVA-NeXT"
"DAMO-NLP-SG/Video-LLaMA" -> "dvlab-research/LLaMA-VID"
"DAMO-NLP-SG/Video-LLaMA" -> "X-PLUG/mPLUG-Owl"
"DAMO-NLP-SG/Video-LLaMA" -> "QwenLM/Qwen-VL"
"DAMO-NLP-SG/Video-LLaMA" -> "PKU-YuanGroup/LanguageBind"
"DAMO-NLP-SG/Video-LLaMA" -> "lyuchenyang/Macaw-LLM"
"DAMO-NLP-SG/Video-LLaMA" -> "mlfoundations/open_flamingo" ["e"=1]
"DAMO-NLP-SG/Video-LLaMA" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "QwenLM/Qwen-VL"
"X-PLUG/mPLUG-Owl" -> "mlfoundations/open_flamingo" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "salesforce/LAVIS" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "OpenGVLab/Ask-Anything"
"X-PLUG/mPLUG-Owl" -> "InternLM/InternLM-XComposer"
"X-PLUG/mPLUG-Owl" -> "X-PLUG/mPLUG-DocOwl"
"X-PLUG/mPLUG-Owl" -> "DAMO-NLP-SG/Video-LLaMA"
"X-PLUG/mPLUG-Owl" -> "LLaVA-VL/LLaVA-NeXT"
"X-PLUG/mPLUG-Owl" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"X-PLUG/mPLUG-Owl" -> "Alpha-VLLM/LLaMA2-Accessory"
"X-PLUG/mPLUG-Owl" -> "open-compass/VLMEvalKit"
"X-PLUG/mPLUG-Owl" -> "OpenGVLab/InternVideo"
"X-PLUG/mPLUG-Owl" -> "haotian-liu/LLaVA"
"X-PLUG/mPLUG-Owl" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"X-PLUG/mPLUG-Owl" -> "baaivision/EVA" ["e"=1]
"AoiDragon/POPE" -> "RUCAIBox/POPE"
"AoiDragon/POPE" -> "LisaAnne/Hallucination"
"AoiDragon/POPE" -> "junyangwang0410/AMBER"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "PKU-YuanGroup/Video-LLaVA"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "DAMO-NLP-SG/VideoLLaMA2"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "LLaVA-VL/LLaVA-NeXT"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "OpenGVLab/InternVideo"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "DAMO-NLP-SG/Video-LLaMA"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "mbzuai-oryx/Video-ChatGPT"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "OpenGVLab/Ask-Anything"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "open-compass/VLMEvalKit"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "MME-Benchmarks/Video-MME"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "RenShuhuai-Andy/TimeChat"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "rese1f/MovieChat"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"yunlong10/Awesome-LLMs-for-Video-Understanding" -> "dvlab-research/LLaMA-VID"
"yxuansu/PandaGPT" -> "CASIA-IVA-Lab/AnomalyGPT" ["e"=1]
"yxuansu/PandaGPT" -> "lyuchenyang/Macaw-LLM"
"yxuansu/PandaGPT" -> "zeroQiaoba/AffectGPT" ["e"=1]
"yxuansu/PandaGPT" -> "luogen1996/LaVIN"
"yxuansu/PandaGPT" -> "mbzuai-oryx/Video-ChatGPT"
"yxuansu/PandaGPT" -> "OptimalScale/DetGPT"
"yxuansu/PandaGPT" -> "open-mmlab/Multimodal-GPT"
"yxuansu/PandaGPT" -> "OpenGVLab/LAMM"
"yxuansu/PandaGPT" -> "0nutation/SpeechGPT" ["e"=1]
"yxuansu/PandaGPT" -> "X-PLUG/mPLUG-Owl"
"yxuansu/PandaGPT" -> "baaivision/Emu" ["e"=1]
"yxuansu/PandaGPT" -> "HenryHZY/Awesome-Multimodal-LLM"
"yxuansu/PandaGPT" -> "microsoft/i-Code"
"yxuansu/PandaGPT" -> "csuhan/OneLLM"
"yxuansu/PandaGPT" -> "LinkSoul-AI/LLaSM" ["e"=1]
"THUDM/CogVLM" -> "QwenLM/Qwen-VL"
"THUDM/CogVLM" -> "haotian-liu/LLaVA"
"THUDM/CogVLM" -> "THUDM/CogVLM2"
"THUDM/CogVLM" -> "THUDM/VisualGLM-6B" ["e"=1]
"THUDM/CogVLM" -> "OpenGVLab/InternVL"
"THUDM/CogVLM" -> "salesforce/LAVIS" ["e"=1]
"THUDM/CogVLM" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"THUDM/CogVLM" -> "InternLM/InternLM-XComposer"
"THUDM/CogVLM" -> "QwenLM/Qwen2.5-VL"
"THUDM/CogVLM" -> "IDEA-Research/GroundingDINO" ["e"=1]
"THUDM/CogVLM" -> "modelscope/ms-swift" ["e"=1]
"THUDM/CogVLM" -> "LLaVA-VL/LLaVA-NeXT"
"THUDM/CogVLM" -> "mlfoundations/open_clip" ["e"=1]
"THUDM/CogVLM" -> "THUDM/ChatGLM3" ["e"=1]
"THUDM/CogVLM" -> "THUDM/GLM-4" ["e"=1]
"invictus717/MetaTransformer" -> "csuhan/OneLLM"
"invictus717/MetaTransformer" -> "facebookresearch/ImageBind" ["e"=1]
"invictus717/MetaTransformer" -> "PKU-YuanGroup/LanguageBind"
"invictus717/MetaTransformer" -> "baaivision/Emu" ["e"=1]
"invictus717/MetaTransformer" -> "NExT-GPT/NExT-GPT"
"invictus717/MetaTransformer" -> "dvlab-research/LISA"
"invictus717/MetaTransformer" -> "Alpha-VLLM/LLaMA2-Accessory"
"invictus717/MetaTransformer" -> "baaivision/Uni3D" ["e"=1]
"invictus717/MetaTransformer" -> "baaivision/EVA" ["e"=1]
"invictus717/MetaTransformer" -> "mlfoundations/open_flamingo" ["e"=1]
"invictus717/MetaTransformer" -> "DAMO-NLP-SG/Video-LLaMA"
"invictus717/MetaTransformer" -> "thu-ml/unidiffuser" ["e"=1]
"invictus717/MetaTransformer" -> "facebookresearch/multimodal" ["e"=1]
"invictus717/MetaTransformer" -> "OpenGVLab/VisionLLM"
"invictus717/MetaTransformer" -> "OpenGVLab/LLaMA-Adapter" ["e"=1]
"InternLM/InternLM-XComposer" -> "OpenGVLab/InternVL"
"InternLM/InternLM-XComposer" -> "QwenLM/Qwen-VL"
"InternLM/InternLM-XComposer" -> "open-compass/VLMEvalKit"
"InternLM/InternLM-XComposer" -> "InternLM/InternLM" ["e"=1]
"InternLM/InternLM-XComposer" -> "LLaVA-VL/LLaVA-NeXT"
"InternLM/InternLM-XComposer" -> "InternLM/xtuner" ["e"=1]
"InternLM/InternLM-XComposer" -> "InternLM/lagent" ["e"=1]
"InternLM/InternLM-XComposer" -> "InternLM/lmdeploy" ["e"=1]
"InternLM/InternLM-XComposer" -> "THUDM/CogVLM"
"InternLM/InternLM-XComposer" -> "Yuliang-Liu/Monkey" ["e"=1]
"InternLM/InternLM-XComposer" -> "cambrian-mllm/cambrian"
"InternLM/InternLM-XComposer" -> "X-PLUG/mPLUG-Owl"
"InternLM/InternLM-XComposer" -> "baaivision/Emu" ["e"=1]
"InternLM/InternLM-XComposer" -> "THUDM/CogVLM2"
"InternLM/InternLM-XComposer" -> "PKU-YuanGroup/Video-LLaVA"
"mbzuai-oryx/Video-ChatGPT" -> "PKU-YuanGroup/Video-LLaVA"
"mbzuai-oryx/Video-ChatGPT" -> "DAMO-NLP-SG/Video-LLaMA"
"mbzuai-oryx/Video-ChatGPT" -> "OpenGVLab/Ask-Anything"
"mbzuai-oryx/Video-ChatGPT" -> "mbzuai-oryx/VideoGPT-plus"
"mbzuai-oryx/Video-ChatGPT" -> "DAMO-NLP-SG/VideoLLaMA2"
"mbzuai-oryx/Video-ChatGPT" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"mbzuai-oryx/Video-ChatGPT" -> "rese1f/MovieChat"
"mbzuai-oryx/Video-ChatGPT" -> "RenShuhuai-Andy/TimeChat"
"mbzuai-oryx/Video-ChatGPT" -> "OpenGVLab/InternVideo"
"mbzuai-oryx/Video-ChatGPT" -> "dvlab-research/LLaMA-VID"
"mbzuai-oryx/Video-ChatGPT" -> "mbzuai-oryx/Video-LLaVA"
"mbzuai-oryx/Video-ChatGPT" -> "mbzuai-oryx/groundingLMM"
"mbzuai-oryx/Video-ChatGPT" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"mbzuai-oryx/Video-ChatGPT" -> "LLaVA-VL/LLaVA-NeXT"
"mbzuai-oryx/Video-ChatGPT" -> "Vision-CAIR/MiniGPT4-video"
"YiyangZhou/LURE" -> "BillChan226/HALC"
"YiyangZhou/LURE" -> "RUCAIBox/POPE"
"YiyangZhou/LURE" -> "YiyangZhou/CSR"
"YiyangZhou/LURE" -> "DAMO-NLP-SG/VCD"
"YiyangZhou/LURE" -> "YiyangZhou/POVID"
"YiyangZhou/LURE" -> "shikiw/OPERA"
"YiyangZhou/LURE" -> "FuxiaoLiu/LRV-Instruction"
"YiyangZhou/LURE" -> "AoiDragon/POPE"
"YiyangZhou/LURE" -> "tianyi-lab/HallusionBench"
"YiyangZhou/LURE" -> "junyangwang0410/AMBER"
"YiyangZhou/LURE" -> "Purshow/Awesome-LVLM-Hallucination"
"X-PLUG/mPLUG-DocOwl" -> "AlibabaResearch/AdvancedLiterateMachinery" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "Yuliang-Liu/Monkey" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "X-PLUG/mPLUG-Owl"
"X-PLUG/mPLUG-DocOwl" -> "Ucas-HaoranWei/Vary"
"X-PLUG/mPLUG-DocOwl" -> "Ucas-HaoranWei/GOT-OCR2.0" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "Yuliang-Liu/MultimodalOCR" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "QwenLM/Qwen-VL"
"X-PLUG/mPLUG-DocOwl" -> "clovaai/donut" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "InternLM/InternLM-XComposer"
"X-PLUG/mPLUG-DocOwl" -> "LukeForeverYoung/UReader" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "OpenGVLab/InternVL"
"X-PLUG/mPLUG-DocOwl" -> "open-compass/VLMEvalKit"
"X-PLUG/mPLUG-DocOwl" -> "opendatalab/DocLayout-YOLO" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "illuin-tech/colpali" ["e"=1]
"X-PLUG/mPLUG-DocOwl" -> "hikopensource/DAVAR-Lab-OCR" ["e"=1]
"FuxiaoLiu/MMC" -> "vis-nlp/UniChart"
"FuxiaoLiu/MMC" -> "FuxiaoLiu/Twitter-Video-dataset"
"FuxiaoLiu/MMC" -> "tingxueronghua/ChartLlama-code"
"FuxiaoLiu/MMC" -> "FuxiaoLiu/DocumentCLIP"
"OpenGVLab/VisionLLM" -> "dvlab-research/LISA"
"OpenGVLab/VisionLLM" -> "OpenGVLab/InternGPT" ["e"=1]
"OpenGVLab/VisionLLM" -> "jshilong/GPT4RoI"
"OpenGVLab/VisionLLM" -> "OptimalScale/DetGPT"
"OpenGVLab/VisionLLM" -> "DirtyHarryLYL/LLM-in-Vision"
"OpenGVLab/VisionLLM" -> "microsoft/GLIP" ["e"=1]
"OpenGVLab/VisionLLM" -> "cientgu/InstructDiffusion" ["e"=1]
"OpenGVLab/VisionLLM" -> "shikras/shikra"
"OpenGVLab/VisionLLM" -> "SkyworkAI/Vitron"
"OpenGVLab/VisionLLM" -> "baaivision/EVA" ["e"=1]
"OpenGVLab/VisionLLM" -> "cambrian-mllm/cambrian"
"OpenGVLab/VisionLLM" -> "microsoft/X-Decoder" ["e"=1]
"OpenGVLab/VisionLLM" -> "lxtGH/OMG-Seg" ["e"=1]
"OpenGVLab/VisionLLM" -> "yuhangzang/ContextDET"
"OpenGVLab/VisionLLM" -> "google-research/pix2seq" ["e"=1]
"YUCHEN005/GILA" -> "YUCHEN005/MIR-GAN"
"YUCHEN005/GILA" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"YUCHEN005/GILA" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/GILA" -> "YUCHEN005/UniVPM"
"PKU-YuanGroup/LanguageBind" -> "PKU-YuanGroup/Video-LLaVA"
"PKU-YuanGroup/LanguageBind" -> "PKU-YuanGroup/Video-Bench" ["e"=1]
"PKU-YuanGroup/LanguageBind" -> "PKU-YuanGroup/MoE-LLaVA"
"PKU-YuanGroup/LanguageBind" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"PKU-YuanGroup/LanguageBind" -> "OpenGVLab/InternVideo"
"PKU-YuanGroup/LanguageBind" -> "csuhan/OneLLM"
"PKU-YuanGroup/LanguageBind" -> "mbzuai-oryx/Video-ChatGPT"
"PKU-YuanGroup/LanguageBind" -> "DAMO-NLP-SG/Video-LLaMA"
"PKU-YuanGroup/LanguageBind" -> "fabawi/ImageBind-LoRA" ["e"=1]
"PKU-YuanGroup/LanguageBind" -> "dvlab-research/LLaMA-VID"
"PKU-YuanGroup/LanguageBind" -> "DAMO-NLP-SG/VideoLLaMA2"
"PKU-YuanGroup/LanguageBind" -> "snap-research/Panda-70M" ["e"=1]
"PKU-YuanGroup/LanguageBind" -> "TXH-mercury/VALOR" ["e"=1]
"PKU-YuanGroup/LanguageBind" -> "RenShuhuai-Andy/TimeChat"
"PKU-YuanGroup/LanguageBind" -> "TXH-mercury/VAST" ["e"=1]
"tsujuifu/pytorch_mgie" -> "apple/ml-mgie"
"tsujuifu/pytorch_mgie" -> "TencentARC/SmartEdit" ["e"=1]
"yuhangzang/ContextDET" -> "jshilong/GPT4RoI"
"rese1f/MovieChat" -> "RenShuhuai-Andy/TimeChat"
"rese1f/MovieChat" -> "boheumd/MA-LMM"
"rese1f/MovieChat" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"rese1f/MovieChat" -> "mbzuai-oryx/Video-ChatGPT"
"rese1f/MovieChat" -> "huangb23/VTimeLLM"
"rese1f/MovieChat" -> "dvlab-research/LLaMA-VID"
"rese1f/MovieChat" -> "magic-research/PLLaVA"
"rese1f/MovieChat" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"rese1f/MovieChat" -> "MME-Benchmarks/Video-MME"
"rese1f/MovieChat" -> "Vision-CAIR/LongVU"
"rese1f/MovieChat" -> "EvolvingLMMs-Lab/LongVA"
"rese1f/MovieChat" -> "VectorSpaceLab/Video-XL"
"rese1f/MovieChat" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"rese1f/MovieChat" -> "DCDmllm/Momentor"
"rese1f/MovieChat" -> "Yui010206/SeViLA"
"modelscope/motionagent" -> "modelscope/DiffSynth-Engine"
"HaozheZhao/MIC" -> "pkunlp-icler/MIC"
"HaozheZhao/MIC" -> "HaozheZhao/MIC_tool"
"HaozheZhao/MIC" -> "pkunlp-icler/PCA-EVAL" ["e"=1]
"HaozheZhao/MIC" -> "X2FD/LVIS-INSTRUCT4V"
"HaozheZhao/MIC" -> "shikras/shikra"
"HaozheZhao/MIC" -> "VT-NLP/MultiInstruct"
"HaozheZhao/MIC" -> "HenryHZY/Awesome-Multimodal-LLM"
"HaozheZhao/MIC" -> "DCDmllm/Cheetah"
"HaozheZhao/MIC" -> "allenai/mmc4" ["e"=1]
"HaozheZhao/MIC" -> "RLHF-V/RLHF-V"
"OpenGVLab/Ask-Anything" -> "DAMO-NLP-SG/Video-LLaMA"
"OpenGVLab/Ask-Anything" -> "OpenGVLab/InternVideo"
"OpenGVLab/Ask-Anything" -> "mbzuai-oryx/Video-ChatGPT"
"OpenGVLab/Ask-Anything" -> "PKU-YuanGroup/Video-LLaVA"
"OpenGVLab/Ask-Anything" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"OpenGVLab/Ask-Anything" -> "LLaVA-VL/LLaVA-NeXT"
"OpenGVLab/Ask-Anything" -> "X-PLUG/mPLUG-Owl"
"OpenGVLab/Ask-Anything" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/Ask-Anything" -> "rese1f/MovieChat"
"OpenGVLab/Ask-Anything" -> "DAMO-NLP-SG/VideoLLaMA2"
"OpenGVLab/Ask-Anything" -> "dvlab-research/LLaMA-VID"
"OpenGVLab/Ask-Anything" -> "OpenGVLab/InternVL"
"OpenGVLab/Ask-Anything" -> "xinyu1205/recognize-anything" ["e"=1]
"OpenGVLab/Ask-Anything" -> "OpenGVLab/InternGPT" ["e"=1]
"OpenGVLab/Ask-Anything" -> "mlfoundations/open_flamingo" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "jshilong/GPT4RoI"
"OpenGVLab/Multi-Modality-Arena" -> "OpenGVLab/LAMM"
"OpenGVLab/Multi-Modality-Arena" -> "baaivision/Emu" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "RUCAIBox/POPE"
"OpenGVLab/Multi-Modality-Arena" -> "shikras/shikra"
"OpenGVLab/Multi-Modality-Arena" -> "FreedomIntelligence/HuatuoGPT-Vision" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "microsoft/LLaVA-Med" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "xiaoman-zhang/PMC-VQA" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "AILab-CVC/SEED" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "OpenGVLab/MMT-Bench"
"OpenGVLab/Multi-Modality-Arena" -> "AILab-CVC/SEED-Bench"
"OpenGVLab/Multi-Modality-Arena" -> "Vision-CAIR/ChatCaptioner" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "BAAI-DCAI/M3D" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "RunpeiDong/DreamLLM" ["e"=1]
"OpenGVLab/Multi-Modality-Arena" -> "HaozheZhao/MIC"
"OpenGVLab/all-seeing" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"OpenGVLab/all-seeing" -> "jshilong/GPT4RoI"
"OpenGVLab/all-seeing" -> "shikras/shikra"
"OpenGVLab/all-seeing" -> "FreedomIntelligence/ALLaVA"
"OpenGVLab/all-seeing" -> "OpenGVLab/OmniCorpus"
"OpenGVLab/all-seeing" -> "SALT-NLP/LLaVAR"
"OpenGVLab/all-seeing" -> "shikras/d-cube" ["e"=1]
"OpenGVLab/all-seeing" -> "tsb0601/MMVP"
"OpenGVLab/all-seeing" -> "mbzuai-oryx/groundingLMM"
"OpenGVLab/all-seeing" -> "FoundationVision/Groma" ["e"=1]
"OpenGVLab/all-seeing" -> "FuxiaoLiu/LRV-Instruction"
"magic-research/bubogpt" -> "AILab-CVC/Animate-A-Story" ["e"=1]
"magic-research/bubogpt" -> "WisconsinAIVision/ViP-LLaVA"
"magic-research/bubogpt" -> "shikras/shikra"
"magic-research/bubogpt" -> "jshilong/GPT4RoI"
"magic-research/bubogpt" -> "OpenGVLab/all-seeing"
"VITA-MLLM/Woodpecker" -> "MME-Benchmarks/Video-MME"
"VITA-MLLM/Woodpecker" -> "shenyunhang/APE" ["e"=1]
"VITA-MLLM/Woodpecker" -> "RUCAIBox/POPE"
"VITA-MLLM/Woodpecker" -> "shikiw/OPERA"
"VITA-MLLM/Woodpecker" -> "FuxiaoLiu/LRV-Instruction"
"VITA-MLLM/Woodpecker" -> "YiyangZhou/LURE"
"VITA-MLLM/Woodpecker" -> "DAMO-NLP-SG/VCD"
"VITA-MLLM/Woodpecker" -> "showlab/Awesome-MLLM-Hallucination"
"VITA-MLLM/Woodpecker" -> "tianyi-lab/HallusionBench"
"VITA-MLLM/Woodpecker" -> "llava-rlhf/LLaVA-RLHF"
"VITA-MLLM/Woodpecker" -> "shikras/shikra"
"VITA-MLLM/Woodpecker" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"VITA-MLLM/Woodpecker" -> "xjtupanda/Sparrow"
"VITA-MLLM/Woodpecker" -> "VITA-MLLM/VITA" ["e"=1]
"VITA-MLLM/Woodpecker" -> "BillChan226/HALC"
"mlpc-ucsd/BLIVA" -> "FreedomIntelligence/ALLaVA"
"egoschema/EgoSchema" -> "doc-doc/NExT-QA" ["e"=1]
"egoschema/EgoSchema" -> "Share14/ShareGemini"
"egoschema/EgoSchema" -> "bigai-nlco/VideoLLaMB"
"jshilong/GPT4RoI" -> "shikras/shikra"
"jshilong/GPT4RoI" -> "OpenGVLab/all-seeing"
"jshilong/GPT4RoI" -> "JialianW/GRiT"
"jshilong/GPT4RoI" -> "jshilong/GroupRCNN" ["e"=1]
"jshilong/GPT4RoI" -> "mbzuai-oryx/groundingLMM"
"jshilong/GPT4RoI" -> "jshilong/DDQ" ["e"=1]
"jshilong/GPT4RoI" -> "microsoft/X-Decoder" ["e"=1]
"jshilong/GPT4RoI" -> "FoundationVision/Groma" ["e"=1]
"jshilong/GPT4RoI" -> "OptimalScale/DetGPT"
"jshilong/GPT4RoI" -> "facebookresearch/VLPart" ["e"=1]
"jshilong/GPT4RoI" -> "jshilong/FisherPruning" ["e"=1]
"jshilong/GPT4RoI" -> "OpenGVLab/VisionLLM"
"jshilong/GPT4RoI" -> "open-mmlab/Multimodal-GPT"
"jshilong/GPT4RoI" -> "OpenGVLab/Multi-Modality-Arena"
"jshilong/GPT4RoI" -> "yuhangzang/ContextDET"
"SkunkworksAI/hydra-moe" -> "hydrallm/llama-moe-v1"
"SkunkworksAI/hydra-moe" -> "r-three/phatgoose"
"SkunkworksAI/hydra-moe" -> "AblateIt/finetune-study"
"SkunkworksAI/hydra-moe" -> "taylorai/galactic" ["e"=1]
"SkunkworksAI/hydra-moe" -> "Cohere-Labs-Community/parameter-efficient-moe" ["e"=1]
"SkunkworksAI/hydra-moe" -> "liuqidong07/MOELoRA-peft" ["e"=1]
"SkunkworksAI/hydra-moe" -> "SkunkworksAI/BakLLaVA"
"DirtyHarryLYL/LLM-in-Vision" -> "ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "mbzuai-oryx/groundingLMM"
"DirtyHarryLYL/LLM-in-Vision" -> "OpenGVLab/VisionLLM"
"DirtyHarryLYL/LLM-in-Vision" -> "baaivision/Emu" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "Computer-Vision-in-the-Wild/CVinW_Readings"
"DirtyHarryLYL/LLM-in-Vision" -> "JindongGu/Awesome-Prompting-on-Vision-Language-Model" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "jy0205/LaVIT" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "Yangyi-Chen/Multimodal-AND-Large-Language-Models"
"DirtyHarryLYL/LLM-in-Vision" -> "HenryHZY/Awesome-Multimodal-LLM"
"DirtyHarryLYL/LLM-in-Vision" -> "DirtyHarryLYL/Transformer-in-Vision" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "dvlab-research/LISA"
"DirtyHarryLYL/LLM-in-Vision" -> "jianzongwu/Awesome-Open-Vocabulary" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "cambrian-mllm/cambrian"
"DirtyHarryLYL/LLM-in-Vision" -> "allenai/unified-io-2" ["e"=1]
"DirtyHarryLYL/LLM-in-Vision" -> "ytongbai/LVM" ["e"=1]
"BAAI-DCAI/Visual-Instruction-Tuning" -> "BAAI-DCAI/DataOptim"
"BAAI-DCAI/Visual-Instruction-Tuning" -> "OpenGVLab/all-seeing"
"shikras/shikra" -> "jshilong/GPT4RoI"
"shikras/shikra" -> "OpenGVLab/all-seeing"
"shikras/shikra" -> "dvlab-research/LISA"
"shikras/shikra" -> "mbzuai-oryx/groundingLMM"
"shikras/shikra" -> "baaivision/Emu" ["e"=1]
"shikras/shikra" -> "FuxiaoLiu/LRV-Instruction"
"shikras/shikra" -> "RUCAIBox/POPE"
"shikras/shikra" -> "luogen1996/LaVIN"
"shikras/shikra" -> "jy0205/LaVIT" ["e"=1]
"shikras/shikra" -> "RunpeiDong/DreamLLM" ["e"=1]
"shikras/shikra" -> "JialianW/GRiT"
"shikras/shikra" -> "OptimalScale/DetGPT"
"shikras/shikra" -> "tsb0601/MMVP"
"shikras/shikra" -> "HaozheZhao/MIC"
"shikras/shikra" -> "microsoft/MM-REACT"
"VPGTrans/VPGTrans" -> "NExT-ChatV/NExT-Chat"
"HenryHZY/Awesome-Multimodal-LLM" -> "vincentlux/Awesome-Multimodal-LLM"
"HenryHZY/Awesome-Multimodal-LLM" -> "RUCAIBox/POPE"
"HenryHZY/Awesome-Multimodal-LLM" -> "HaozheZhao/MIC"
"HenryHZY/Awesome-Multimodal-LLM" -> "VT-NLP/MultiInstruct"
"HenryHZY/Awesome-Multimodal-LLM" -> "DirtyHarryLYL/LLM-in-Vision"
"HenryHZY/Awesome-Multimodal-LLM" -> "AILab-CVC/SEED" ["e"=1]
"SALT-NLP/LLaVAR" -> "FuxiaoLiu/LRV-Instruction"
"SALT-NLP/LLaVAR" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"SALT-NLP/LLaVAR" -> "luogen1996/LaVIN"
"SALT-NLP/LLaVAR" -> "OpenGVLab/all-seeing"
"SALT-NLP/LLaVAR" -> "Yuliang-Liu/MultimodalOCR" ["e"=1]
"SALT-NLP/LLaVAR" -> "thunlp/LLaVA-UHD"
"SALT-NLP/LLaVAR" -> "YuchenLiu98/COMM"
"apitube/docs" -> "mevbotcrypto/mev-bot"
"mevbotcrypto/mev-bot" -> "apitube/docs"
"FuxiaoLiu/LRV-Instruction" -> "tianyi-lab/HallusionBench"
"FuxiaoLiu/LRV-Instruction" -> "RUCAIBox/POPE"
"FuxiaoLiu/LRV-Instruction" -> "Yuqifan1117/HalluciDoctor"
"FuxiaoLiu/LRV-Instruction" -> "shikiw/OPERA"
"FuxiaoLiu/LRV-Instruction" -> "YiyangZhou/LURE"
"FuxiaoLiu/LRV-Instruction" -> "junyangwang0410/AMBER"
"FuxiaoLiu/LRV-Instruction" -> "BillChan226/HALC"
"FuxiaoLiu/LRV-Instruction" -> "X2FD/LVIS-INSTRUCT4V"
"FuxiaoLiu/LRV-Instruction" -> "DAMO-NLP-SG/VCD"
"FuxiaoLiu/LRV-Instruction" -> "FuxiaoLiu/MMC"
"FuxiaoLiu/LRV-Instruction" -> "VITA-MLLM/Woodpecker"
"FuxiaoLiu/LRV-Instruction" -> "SALT-NLP/LLaVAR"
"FuxiaoLiu/LRV-Instruction" -> "llava-rlhf/LLaVA-RLHF"
"FuxiaoLiu/LRV-Instruction" -> "FuxiaoLiu/DocumentCLIP"
"FuxiaoLiu/LRV-Instruction" -> "FreedomIntelligence/ALLaVA"
"open-compass/MMBench" -> "yuweihao/MM-Vet"
"open-compass/MMBench" -> "junyangwang0410/AMBER"
"open-compass/MMBench" -> "RUCAIBox/POPE"
"open-compass/MMBench" -> "open-compass/VLMEvalKit"
"open-compass/MMBench" -> "tianyi-lab/HallusionBench"
"RupertLuo/Valley" -> "DCDmllm/Momentor"
"RupertLuo/Valley" -> "RenShuhuai-Andy/TimeChat"
"RupertLuo/Valley" -> "bytedance/Shot2Story"
"RupertLuo/Valley" -> "PKU-YuanGroup/Video-Bench" ["e"=1]
"RupertLuo/Valley" -> "TimeMarker-LLM/TimeMarker"
"RupertLuo/Valley" -> "huangb23/VTimeLLM"
"RupertLuo/Valley" -> "EvolvingLMMs-Lab/LongVA"
"RupertLuo/Valley" -> "Share14/ShareGemini"
"RUCAIBox/POPE" -> "junyangwang0410/AMBER"
"RUCAIBox/POPE" -> "AoiDragon/POPE"
"RUCAIBox/POPE" -> "YiyangZhou/LURE"
"RUCAIBox/POPE" -> "FuxiaoLiu/LRV-Instruction"
"RUCAIBox/POPE" -> "LisaAnne/Hallucination"
"RUCAIBox/POPE" -> "tianyi-lab/HallusionBench"
"RUCAIBox/POPE" -> "BillChan226/HALC"
"RUCAIBox/POPE" -> "yuweihao/MM-Vet"
"RUCAIBox/POPE" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"RUCAIBox/POPE" -> "shikiw/OPERA"
"RUCAIBox/POPE" -> "DAMO-NLP-SG/VCD"
"RUCAIBox/POPE" -> "VITA-MLLM/Woodpecker"
"lyingCS/UOEP" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"lyingCS/UOEP" -> "OpenGVLab/Multitask-Model-Selector"
"DCDmllm/Cheetah" -> "DCDmllm/MorphTokens"
"DCDmllm/Cheetah" -> "DCDmllm/AnyEdit" ["e"=1]
"DCDmllm/Cheetah" -> "HaozheZhao/MIC"
"OptimalScale/DetGPT" -> "jshilong/GPT4RoI"
"OptimalScale/DetGPT" -> "microsoft/GLIP" ["e"=1]
"OptimalScale/DetGPT" -> "shikras/shikra"
"OptimalScale/DetGPT" -> "OpenGVLab/VisionLLM"
"OptimalScale/DetGPT" -> "IDEA-Research/OpenSeeD" ["e"=1]
"OptimalScale/DetGPT" -> "microsoft/X-Decoder" ["e"=1]
"OptimalScale/DetGPT" -> "dvlab-research/LISA"
"OptimalScale/DetGPT" -> "microsoft/RegionCLIP" ["e"=1]
"OptimalScale/DetGPT" -> "yuhangzang/ContextDET"
"OptimalScale/DetGPT" -> "microsoft/MM-REACT"
"OptimalScale/DetGPT" -> "open-mmlab/Multimodal-GPT"
"OptimalScale/DetGPT" -> "IDEA-Research/GroundingDINO" ["e"=1]
"OptimalScale/DetGPT" -> "witnessai/Awesome-Open-Vocabulary-Object-Detection" ["e"=1]
"OptimalScale/DetGPT" -> "Saiyan-World/grounded-segment-any-parts" ["e"=1]
"OptimalScale/DetGPT" -> "allenai/visprog"
"llava-rlhf/LLaVA-RLHF" -> "RLHF-V/RLHF-V"
"llava-rlhf/LLaVA-RLHF" -> "RLHF-V/RLAIF-V"
"llava-rlhf/LLaVA-RLHF" -> "FuxiaoLiu/LRV-Instruction"
"llava-rlhf/LLaVA-RLHF" -> "TideDra/VL-RLHF"
"llava-rlhf/LLaVA-RLHF" -> "junyangwang0410/AMBER"
"llava-rlhf/LLaVA-RLHF" -> "shikiw/OPERA"
"llava-rlhf/LLaVA-RLHF" -> "RifleZhang/LLaVA-Hound-DPO"
"llava-rlhf/LLaVA-RLHF" -> "tianyi-lab/HallusionBench"
"llava-rlhf/LLaVA-RLHF" -> "FreedomIntelligence/ALLaVA"
"llava-rlhf/LLaVA-RLHF" -> "FanqingM/R1-Multimodal-Journey"
"llava-rlhf/LLaVA-RLHF" -> "yuweihao/MM-Vet"
"llava-rlhf/LLaVA-RLHF" -> "vlf-silkie/VLFeedback"
"llava-rlhf/LLaVA-RLHF" -> "VT-NLP/MultiInstruct"
"llava-rlhf/LLaVA-RLHF" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"llava-rlhf/LLaVA-RLHF" -> "VITA-MLLM/Woodpecker"
"luogen1996/LaVIN" -> "SALT-NLP/LLaVAR"
"luogen1996/LaVIN" -> "shikras/shikra"
"luogen1996/LaVIN" -> "luogen1996/LLaVA-HR"
"luogen1996/LaVIN" -> "luogen1996/RepAdapter" ["e"=1]
"luogen1996/LaVIN" -> "yuweihao/MM-Vet"
"luogen1996/LaVIN" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"luogen1996/LaVIN" -> "luogen1996/SimREC" ["e"=1]
"luogen1996/LaVIN" -> "OpenGVLab/LAMM"
"luogen1996/LaVIN" -> "seanzhuh/SeqTR" ["e"=1]
"luogen1996/LaVIN" -> "VPGTrans/VPGTrans"
"luogen1996/LaVIN" -> "X-PLUG/mPLUG-Owl"
"luogen1996/LaVIN" -> "jshilong/GPT4RoI"
"luogen1996/LaVIN" -> "baaivision/Emu" ["e"=1]
"luogen1996/LaVIN" -> "FuxiaoLiu/LRV-Instruction"
"luogen1996/LaVIN" -> "VITA-MLLM/Woodpecker"
"OpenGVLab/LAMM" -> "OpenGVLab/Multi-Modality-Arena"
"OpenGVLab/LAMM" -> "EvolvingLMMs-Lab/LongVA"
"OpenGVLab/LAMM" -> "IranQin/MP5" ["e"=1]
"OpenGVLab/LAMM" -> "AILab-CVC/SEED-Bench"
"OpenGVLab/LAMM" -> "FreedomIntelligence/ALLaVA"
"OpenGVLab/LAMM" -> "FuxiaoLiu/LRV-Instruction"
"OpenGVLab/LAMM" -> "embodied-generalist/embodied-generalist" ["e"=1]
"AILab-CVC/SEED-Bench" -> "AILab-CVC/SEED" ["e"=1]
"AILab-CVC/SEED-Bench" -> "tianyi-lab/HallusionBench"
"AILab-CVC/SEED-Bench" -> "ChenYi99/EgoPlan" ["e"=1]
"AILab-CVC/SEED-Bench" -> "palchenli/VL-Instruction-Tuning"
"AILab-CVC/SEED-Bench" -> "yuweihao/MM-Vet"
"AILab-CVC/SEED-Bench" -> "OpenGVLab/MM-Interleaved" ["e"=1]
"AILab-CVC/SEED-Bench" -> "tsb0601/MMVP"
"AILab-CVC/SEED-Bench" -> "lupantech/MathVista"
"AILab-CVC/SEED-Bench" -> "open-compass/MMBench"
"Yui010206/SeViLA" -> "antoyang/FrozenBiLM" ["e"=1]
"Yui010206/SeViLA" -> "doc-doc/NExT-GQA" ["e"=1]
"Yui010206/SeViLA" -> "VRU-NExT/VideoQA" ["e"=1]
"Yui010206/SeViLA" -> "minghangz/cpl" ["e"=1]
"Yui010206/SeViLA" -> "Ziyang412/VideoTree"
"Yui010206/SeViLA" -> "j-min/HiREST" ["e"=1]
"Yui010206/SeViLA" -> "mlvlab/Flipped-VQA" ["e"=1]
"Yui010206/SeViLA" -> "klauscc/VindLU" ["e"=1]
"Yui010206/SeViLA" -> "showlab/mist" ["e"=1]
"Yui010206/SeViLA" -> "RenShuhuai-Andy/TimeChat"
"Yui010206/SeViLA" -> "jayleicn/singularity" ["e"=1]
"Yui010206/SeViLA" -> "doc-doc/NExT-QA" ["e"=1]
"Yui010206/SeViLA" -> "showlab/all-in-one" ["e"=1]
"yuweihao/MM-Vet" -> "RUCAIBox/POPE"
"yuweihao/MM-Vet" -> "open-compass/MMBench"
"yuweihao/MM-Vet" -> "tianyi-lab/HallusionBench"
"yuweihao/MM-Vet" -> "tsb0601/MMVP"
"yuweihao/MM-Vet" -> "MMMU-Benchmark/MMMU"
"yuweihao/MM-Vet" -> "FreedomIntelligence/ALLaVA"
"yuweihao/MM-Vet" -> "lupantech/ScienceQA"
"yuweihao/MM-Vet" -> "FuxiaoLiu/LRV-Instruction"
"hydrallm/llama-moe-v1" -> "AblateIt/finetune-study"
"pkunlp-icler/MIC" -> "HaozheZhao/MIC_tool"
"reactorsh/ambrosia" -> "apitube/docs"
"reactorsh/ambrosia" -> "mevbotcrypto/mev-bot"
"reactorsh/ambrosia" -> "AblateIt/finetune-study"
"thunlp/Muffin" -> "RLHF-V/RLHF-V"
"mitvis/vistext" -> "vis-nlp/Chart-to-text"
"mitvis/vistext" -> "hyungkwonko/chart-llm" ["e"=1]
"Ethan00Si/SESREC-SIGIR-2023" -> "Ethan00Si/KuaiSAR"
"Ethan00Si/SESREC-SIGIR-2023" -> "TengShi-RUC/UniSAR"
"Ethan00Si/SESREC-SIGIR-2023" -> "Ethan00Si/Instrumental-variables-for-recommendation"
"Ethan00Si/SESREC-SIGIR-2023" -> "rucliujn/JDsearch" ["e"=1]
"YUCHEN005/NASE" -> "YUCHEN005/Unified-Enhance-Separation"
"YUCHEN005/NASE" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"patrick-tssn/Awesome-Colorful-LLM" -> "bigai-nlco/VideoLLaMB"
"yuezih/Movie101" -> "yuezih/SMILE"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/RobustGER"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/MIR-GAN"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/GILA"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/DPSL-ASR"
"Hypotheses-Paradise/Hypo2Trans" -> "YUCHEN005/UNA-GAN"
"AblateIt/finetune-study" -> "CarperAI/treasure_trove"
"AblateIt/finetune-study" -> "Alignment-Lab-AI/datagen"
"shiyi-zh0408/LOGO" -> "shiyi-zh0408/NAE_CVPR2024"
"shiyi-zh0408/LOGO" -> "ZhouKanglei/Awesome-AQA"
"shiyi-zh0408/LOGO" -> "xuangch/CVPR22_GDLT"
"shiyi-zh0408/LOGO" -> "yuxumin/CoRe"
"shiyi-zh0408/LOGO" -> "xujinglin/FineDiving"
"shiyi-zh0408/LOGO" -> "baiyang4/aqa_tpt"
"shiyi-zh0408/LOGO" -> "AndyTang15/FLAG3Dv2"
"TheJaeLal/LineFormer" -> "MasterAI-EAM/GraphMaster"
"TheJaeLal/LineFormer" -> "pengyu965/ChartDete"
"YUCHEN005/MIR-GAN" -> "YUCHEN005/GILA"
"YUCHEN005/MIR-GAN" -> "YUCHEN005/UNA-GAN"
"YUCHEN005/MIR-GAN" -> "YUCHEN005/UniVPM"
"jonathan-roberts1/GPT4GEO" -> "jonathan-roberts1/charting-new-territories"
"jonathan-roberts1/GPT4GEO" -> "jonathan-roberts1/SciFIBench"
"pengyu965/ChartDete" -> "tdsone/extract-line-chart-data"
"pengyu965/ChartDete" -> "TheJaeLal/LineFormer"
"vis-nlp/UniChart" -> "FuxiaoLiu/MMC"
"vis-nlp/UniChart" -> "Alpha-Innovator/SimChart9K"
"vis-nlp/UniChart" -> "vis-nlp/ChartInstruct"
"vis-nlp/UniChart" -> "tingxueronghua/ChartLlama-code"
"vis-nlp/UniChart" -> "pranonrahman/ChartSumm"
"OpenGVLab/Multitask-Model-Selector" -> "lyingCS/UOEP"
"OpenGVLab/Multitask-Model-Selector" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"OpenGVLab/Multitask-Model-Selector" -> "OpenGVLab/MMIU"
"kahnchana/clippy" -> "kahnchana/mvu"
"khuangaf/ZeroFEC" -> "khuangaf/CHOCOLATE"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "lyingCS/UOEP"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "TengShi-RUC/UniSAR"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "OpenGVLab/Multitask-Model-Selector"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "zhengbw0324/LC-Rec"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "OpenGVLab/MMIU"
"lyingCS/Controllable-Multi-Objective-Reranking" -> "E-qin/GEAR"
"YUCHEN005/UniVPM" -> "YUCHEN005/UNA-GAN"
"jaeill/CVPR23-VNE" -> "SNU-DRL/Attribution-ECG"
"Alpha-Innovator/SimChart9K" -> "Alpha-Innovator/TrustGeoGen"
"apple/ml-ferret" -> "ml-explore/mlx" ["e"=1]
"apple/ml-ferret" -> "cumulo-autumn/StreamDiffusion" ["e"=1]
"apple/ml-ferret" -> "ml-explore/mlx-examples" ["e"=1]
"apple/ml-ferret" -> "haotian-liu/LLaVA"
"apple/ml-ferret" -> "THUDM/CogVLM"
"apple/ml-ferret" -> "apple/ml-mgie"
"apple/ml-ferret" -> "apple/corenet" ["e"=1]
"apple/ml-ferret" -> "TencentQQGYLab/AppAgent" ["e"=1]
"apple/ml-ferret" -> "stanfordnlp/dspy" ["e"=1]
"apple/ml-ferret" -> "mistralai/mistral-inference" ["e"=1]
"apple/ml-ferret" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"apple/ml-ferret" -> "meta-llama/llama-cookbook" ["e"=1]
"apple/ml-ferret" -> "letta-ai/letta" ["e"=1]
"apple/ml-ferret" -> "apple/ml-stable-diffusion" ["e"=1]
"apple/ml-ferret" -> "ShishirPatil/gorilla" ["e"=1]
"LargeWorldModel/LWM" -> "google/magika" ["e"=1]
"LargeWorldModel/LWM" -> "karpathy/minbpe" ["e"=1]
"LargeWorldModel/LWM" -> "facebookresearch/DiT" ["e"=1]
"LargeWorldModel/LWM" -> "PKU-YuanGroup/Open-Sora-Plan" ["e"=1]
"LargeWorldModel/LWM" -> "haotian-liu/LLaVA"
"LargeWorldModel/LWM" -> "Stability-AI/StableCascade" ["e"=1]
"LargeWorldModel/LWM" -> "hpcaitech/Open-Sora" ["e"=1]
"LargeWorldModel/LWM" -> "dvlab-research/MGM"
"LargeWorldModel/LWM" -> "facebookresearch/jepa" ["e"=1]
"LargeWorldModel/LWM" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"LargeWorldModel/LWM" -> "OpenGVLab/InternVL"
"LargeWorldModel/LWM" -> "QwenLM/Qwen-VL"
"LargeWorldModel/LWM" -> "THUDM/CogVLM"
"LargeWorldModel/LWM" -> "mit-han-lab/streaming-llm" ["e"=1]
"LargeWorldModel/LWM" -> "sgl-project/sglang" ["e"=1]
"OpenGVLab/InternVL" -> "QwenLM/Qwen2.5-VL"
"OpenGVLab/InternVL" -> "QwenLM/Qwen-VL"
"OpenGVLab/InternVL" -> "LLaVA-VL/LLaVA-NeXT"
"OpenGVLab/InternVL" -> "haotian-liu/LLaVA"
"OpenGVLab/InternVL" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"OpenGVLab/InternVL" -> "modelscope/ms-swift" ["e"=1]
"OpenGVLab/InternVL" -> "InternLM/InternLM-XComposer"
"OpenGVLab/InternVL" -> "OpenBMB/MiniCPM-o"
"OpenGVLab/InternVL" -> "open-compass/VLMEvalKit"
"OpenGVLab/InternVL" -> "salesforce/LAVIS" ["e"=1]
"OpenGVLab/InternVL" -> "om-ai-lab/VLM-R1"
"OpenGVLab/InternVL" -> "InternLM/lmdeploy" ["e"=1]
"OpenGVLab/InternVL" -> "THUDM/CogVLM"
"OpenGVLab/InternVL" -> "THUDM/CogVLM2"
"OpenGVLab/InternVL" -> "mlfoundations/open_clip" ["e"=1]
"open-compass/VLMEvalKit" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"open-compass/VLMEvalKit" -> "LLaVA-VL/LLaVA-NeXT"
"open-compass/VLMEvalKit" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"open-compass/VLMEvalKit" -> "OpenGVLab/InternVL"
"open-compass/VLMEvalKit" -> "Deep-Agent/R1-V"
"open-compass/VLMEvalKit" -> "InternLM/InternLM-XComposer"
"open-compass/VLMEvalKit" -> "open-compass/opencompass" ["e"=1]
"open-compass/VLMEvalKit" -> "cambrian-mllm/cambrian"
"open-compass/VLMEvalKit" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"open-compass/VLMEvalKit" -> "hiyouga/EasyR1" ["e"=1]
"open-compass/VLMEvalKit" -> "Liuziyu77/Visual-RFT"
"open-compass/VLMEvalKit" -> "TideDra/lmm-r1"
"open-compass/VLMEvalKit" -> "om-ai-lab/VLM-R1"
"open-compass/VLMEvalKit" -> "ModalMinds/MM-EUREKA"
"open-compass/VLMEvalKit" -> "QwenLM/Qwen-VL"
"OpenBMB/MiniCPM-o" -> "OpenBMB/MiniCPM" ["e"=1]
"OpenBMB/MiniCPM-o" -> "OpenGVLab/InternVL"
"OpenBMB/MiniCPM-o" -> "haotian-liu/LLaVA"
"OpenBMB/MiniCPM-o" -> "hiyouga/LLaMA-Factory" ["e"=1]
"OpenBMB/MiniCPM-o" -> "QwenLM/Qwen2.5-VL"
"OpenBMB/MiniCPM-o" -> "hpcaitech/Open-Sora" ["e"=1]
"OpenBMB/MiniCPM-o" -> "fishaudio/fish-speech" ["e"=1]
"OpenBMB/MiniCPM-o" -> "unslothai/unsloth" ["e"=1]
"OpenBMB/MiniCPM-o" -> "vllm-project/vllm" ["e"=1]
"OpenBMB/MiniCPM-o" -> "QwenLM/Qwen3" ["e"=1]
"OpenBMB/MiniCPM-o" -> "stanford-oval/storm" ["e"=1]
"OpenBMB/MiniCPM-o" -> "opendatalab/MinerU" ["e"=1]
"OpenBMB/MiniCPM-o" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"OpenBMB/MiniCPM-o" -> "FoundationAgents/MetaGPT" ["e"=1]
"OpenBMB/MiniCPM-o" -> "2noise/ChatTTS" ["e"=1]
"NVlabs/VILA" -> "LLaVA-VL/LLaVA-NeXT"
"NVlabs/VILA" -> "OpenGVLab/InternVL"
"NVlabs/VILA" -> "open-compass/VLMEvalKit"
"NVlabs/VILA" -> "cambrian-mllm/cambrian"
"NVlabs/VILA" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"NVlabs/VILA" -> "PKU-YuanGroup/Video-LLaVA"
"NVlabs/VILA" -> "InternLM/InternLM-XComposer"
"NVlabs/VILA" -> "mit-han-lab/llm-awq" ["e"=1]
"NVlabs/VILA" -> "openvla/openvla" ["e"=1]
"NVlabs/VILA" -> "showlab/Show-o" ["e"=1]
"NVlabs/VILA" -> "baaivision/Emu3" ["e"=1]
"NVlabs/VILA" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"NVlabs/VILA" -> "DAMO-NLP-SG/VideoLLaMA2"
"NVlabs/VILA" -> "Deep-Agent/R1-V"
"NVlabs/VILA" -> "OpenGVLab/InternVideo"
"apple/ml-mgie" -> "tsujuifu/pytorch_mgie"
"apple/ml-mgie" -> "apple/ml-ferret"
"apple/ml-mgie" -> "FujiwaraChoki/MoneyPrinter" ["e"=1]
"apple/ml-mgie" -> "GoogleCloudPlatform/localllm" ["e"=1]
"apple/ml-mgie" -> "Stability-AI/StableCascade" ["e"=1]
"apple/ml-mgie" -> "metavoiceio/metavoice-src" ["e"=1]
"apple/ml-mgie" -> "ml-explore/mlx" ["e"=1]
"apple/ml-mgie" -> "apple/corenet" ["e"=1]
"apple/ml-mgie" -> "LargeWorldModel/LWM"
"apple/ml-mgie" -> "ml-explore/mlx-examples" ["e"=1]
"apple/ml-mgie" -> "YangLing0818/RPG-DiffusionMaster" ["e"=1]
"apple/ml-mgie" -> "levihsu/OOTDiffusion" ["e"=1]
"apple/ml-mgie" -> "TencentARC/SmartEdit" ["e"=1]
"apple/ml-mgie" -> "Doubiiu/DynamiCrafter" ["e"=1]
"apple/ml-mgie" -> "haotian-liu/LLaVA"
"LLaVA-VL/LLaVA-Interactive-Demo" -> "LLaVA-VL/LLaVA-Plus-Codebase"
"dvlab-research/MGM" -> "LLaVA-VL/LLaVA-NeXT"
"dvlab-research/MGM" -> "cambrian-mllm/cambrian"
"dvlab-research/MGM" -> "InternLM/InternLM-XComposer"
"dvlab-research/MGM" -> "open-compass/VLMEvalKit"
"dvlab-research/MGM" -> "OpenGVLab/InternVL"
"dvlab-research/MGM" -> "QwenLM/Qwen-VL"
"dvlab-research/MGM" -> "THUDM/CogVLM"
"dvlab-research/MGM" -> "NVlabs/VILA"
"dvlab-research/MGM" -> "baaivision/Emu" ["e"=1]
"dvlab-research/MGM" -> "PKU-YuanGroup/MoE-LLaVA"
"dvlab-research/MGM" -> "PKU-YuanGroup/Video-LLaVA"
"dvlab-research/MGM" -> "baaivision/EVA" ["e"=1]
"dvlab-research/MGM" -> "X-PLUG/mPLUG-Owl"
"dvlab-research/MGM" -> "LargeWorldModel/LWM"
"dvlab-research/MGM" -> "FoundationVision/VAR" ["e"=1]
"PKU-YuanGroup/Video-LLaVA" -> "DAMO-NLP-SG/Video-LLaMA"
"PKU-YuanGroup/Video-LLaVA" -> "LLaVA-VL/LLaVA-NeXT"
"PKU-YuanGroup/Video-LLaVA" -> "mbzuai-oryx/Video-ChatGPT"
"PKU-YuanGroup/Video-LLaVA" -> "PKU-YuanGroup/MoE-LLaVA"
"PKU-YuanGroup/Video-LLaVA" -> "PKU-YuanGroup/LanguageBind"
"PKU-YuanGroup/Video-LLaVA" -> "DAMO-NLP-SG/VideoLLaMA2"
"PKU-YuanGroup/Video-LLaVA" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"PKU-YuanGroup/Video-LLaVA" -> "OpenGVLab/InternVideo"
"PKU-YuanGroup/Video-LLaVA" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"PKU-YuanGroup/Video-LLaVA" -> "OpenGVLab/Ask-Anything"
"PKU-YuanGroup/Video-LLaVA" -> "dvlab-research/LLaMA-VID"
"PKU-YuanGroup/Video-LLaVA" -> "haotian-liu/LLaVA"
"PKU-YuanGroup/Video-LLaVA" -> "open-compass/VLMEvalKit"
"PKU-YuanGroup/Video-LLaVA" -> "QwenLM/Qwen-VL"
"PKU-YuanGroup/Video-LLaVA" -> "OpenGVLab/InternVL"
"PKU-YuanGroup/MoE-LLaVA" -> "PKU-YuanGroup/Video-LLaVA"
"PKU-YuanGroup/MoE-LLaVA" -> "PKU-YuanGroup/LanguageBind"
"PKU-YuanGroup/MoE-LLaVA" -> "LLaVA-VL/LLaVA-NeXT"
"PKU-YuanGroup/MoE-LLaVA" -> "TinyLLaVA/TinyLLaVA_Factory"
"PKU-YuanGroup/MoE-LLaVA" -> "open-compass/VLMEvalKit"
"PKU-YuanGroup/MoE-LLaVA" -> "InternLM/InternLM-XComposer"
"PKU-YuanGroup/MoE-LLaVA" -> "cambrian-mllm/cambrian"
"PKU-YuanGroup/MoE-LLaVA" -> "DAMO-NLP-SG/Video-LLaMA"
"PKU-YuanGroup/MoE-LLaVA" -> "QwenLM/Qwen-VL"
"PKU-YuanGroup/MoE-LLaVA" -> "THUDM/CogVLM"
"PKU-YuanGroup/MoE-LLaVA" -> "BAAI-DCAI/Bunny"
"PKU-YuanGroup/MoE-LLaVA" -> "PKU-YuanGroup/LLaVA-CoT"
"PKU-YuanGroup/MoE-LLaVA" -> "baaivision/Emu" ["e"=1]
"PKU-YuanGroup/MoE-LLaVA" -> "NVlabs/VILA"
"PKU-YuanGroup/MoE-LLaVA" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"LLaVA-VL/LLaVA-NeXT" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"LLaVA-VL/LLaVA-NeXT" -> "open-compass/VLMEvalKit"
"LLaVA-VL/LLaVA-NeXT" -> "PKU-YuanGroup/Video-LLaVA"
"LLaVA-VL/LLaVA-NeXT" -> "OpenGVLab/InternVL"
"LLaVA-VL/LLaVA-NeXT" -> "NVlabs/VILA"
"LLaVA-VL/LLaVA-NeXT" -> "haotian-liu/LLaVA"
"LLaVA-VL/LLaVA-NeXT" -> "QwenLM/Qwen2.5-VL"
"LLaVA-VL/LLaVA-NeXT" -> "cambrian-mllm/cambrian"
"LLaVA-VL/LLaVA-NeXT" -> "QwenLM/Qwen-VL"
"LLaVA-VL/LLaVA-NeXT" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"LLaVA-VL/LLaVA-NeXT" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"LLaVA-VL/LLaVA-NeXT" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"LLaVA-VL/LLaVA-NeXT" -> "Deep-Agent/R1-V"
"LLaVA-VL/LLaVA-NeXT" -> "om-ai-lab/VLM-R1"
"LLaVA-VL/LLaVA-NeXT" -> "InternLM/InternLM-XComposer"
"boheumd/MA-LMM" -> "RenShuhuai-Andy/TimeChat"
"boheumd/MA-LMM" -> "rese1f/MovieChat"
"boheumd/MA-LMM" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"boheumd/MA-LMM" -> "IVGSZ/Flash-VStream"
"boheumd/MA-LMM" -> "ziplab/LongVLM"
"boheumd/MA-LMM" -> "MME-Benchmarks/Video-MME"
"boheumd/MA-LMM" -> "OpenGVLab/VideoChat-Flash"
"boheumd/MA-LMM" -> "Yui010206/SeViLA"
"boheumd/MA-LMM" -> "Ziyang412/VideoTree"
"boheumd/MA-LMM" -> "EvolvingLMMs-Lab/LongVA"
"boheumd/MA-LMM" -> "TencentARC/ST-LLM"
"boheumd/MA-LMM" -> "mbzuai-oryx/VideoGPT-plus"
"boheumd/MA-LMM" -> "Vision-CAIR/LongVU"
"boheumd/MA-LMM" -> "doc-doc/NExT-GQA" ["e"=1]
"boheumd/MA-LMM" -> "Vision-CAIR/MiniGPT4-video"
"xk-huang/segment-caption-anything" -> "shiyi-zh0408/NAE_CVPR2024"
"xk-huang/segment-caption-anything" -> "AndyTang15/FLAG3Dv2"
"xk-huang/segment-caption-anything" -> "EternalEvan/DPMesh"
"xk-huang/segment-caption-anything" -> "Tengbo-Yu/AnyBimanual"
"xk-huang/segment-caption-anything" -> "GuanxingLu/vlarl"
"xk-huang/segment-caption-anything" -> "Yxxxb/VoCo-LLaMA"
"xk-huang/segment-caption-anything" -> "SuleBai/SC-CLIP"
"xk-huang/segment-caption-anything" -> "shiyi-zh0408/FlexiAct"
"xk-huang/segment-caption-anything" -> "shiyi-zh0408/LOGO"
"xk-huang/segment-caption-anything" -> "GuanxingLu/ManiGaussian" ["e"=1]
"xk-huang/segment-caption-anything" -> "zhang9302002/Flash-VStream"
"xk-huang/segment-caption-anything" -> "yongliu20/SCAN"
"SkunkworksAI/BakLLaVA" -> "LLaVA-VL/LLaVA-Plus-Codebase"
"SkunkworksAI/BakLLaVA" -> "Fuzzy-Search/realtime-bakllava"
"SkunkworksAI/BakLLaVA" -> "X2FD/LVIS-INSTRUCT4V"
"SkunkworksAI/BakLLaVA" -> "SkunkworksAI/hydra-moe"
"SkunkworksAI/BakLLaVA" -> "dvlab-research/LLaMA-VID"
"SkunkworksAI/BakLLaVA" -> "cognitivecomputations/laserRMT" ["e"=1]
"SkunkworksAI/BakLLaVA" -> "WisconsinAIVision/ViP-LLaVA"
"SkunkworksAI/BakLLaVA" -> "PKU-YuanGroup/MoE-LLaVA"
"Meituan-AutoML/MobileVLM" -> "BAAI-DCAI/Bunny"
"Meituan-AutoML/MobileVLM" -> "TinyLLaVA/TinyLLaVA_Factory"
"Meituan-AutoML/MobileVLM" -> "DLYuanGod/TinyGPT-V"
"Meituan-AutoML/MobileVLM" -> "PKU-YuanGroup/MoE-LLaVA"
"Meituan-AutoML/MobileVLM" -> "open-compass/VLMEvalKit"
"Meituan-AutoML/MobileVLM" -> "LLaVA-VL/LLaVA-NeXT"
"Meituan-AutoML/MobileVLM" -> "xmoanvaf/llava-phi"
"Meituan-AutoML/MobileVLM" -> "THUDM/CogVLM"
"Meituan-AutoML/MobileVLM" -> "TRI-ML/prismatic-vlms" ["e"=1]
"Meituan-AutoML/MobileVLM" -> "chongzhou96/EdgeSAM" ["e"=1]
"Meituan-AutoML/MobileVLM" -> "THUDM/CogVLM2"
"Meituan-AutoML/MobileVLM" -> "LLaVA-VL/LLaVA-Plus-Codebase"
"Meituan-AutoML/MobileVLM" -> "dvlab-research/LISA"
"Meituan-AutoML/MobileVLM" -> "FreedomIntelligence/ALLaVA"
"Meituan-AutoML/MobileVLM" -> "baaivision/Emu" ["e"=1]
"luogen1996/LLaVA-HR" -> "thunlp/LLaVA-UHD"
"luogen1996/LLaVA-HR" -> "YouHuang67/mamba-code-explained" ["e"=1]
"luogen1996/LLaVA-HR" -> "FreedomIntelligence/ALLaVA"
"TinyLLaVA/TinyLLaVA_Factory" -> "BAAI-DCAI/Bunny"
"TinyLLaVA/TinyLLaVA_Factory" -> "xmoanvaf/llava-phi"
"TinyLLaVA/TinyLLaVA_Factory" -> "LLaVA-VL/LLaVA-NeXT"
"TinyLLaVA/TinyLLaVA_Factory" -> "PKU-YuanGroup/MoE-LLaVA"
"TinyLLaVA/TinyLLaVA_Factory" -> "Meituan-AutoML/MobileVLM"
"TinyLLaVA/TinyLLaVA_Factory" -> "mbzuai-oryx/LLaVA-pp"
"TinyLLaVA/TinyLLaVA_Factory" -> "cambrian-mllm/cambrian"
"TinyLLaVA/TinyLLaVA_Factory" -> "zjysteven/lmms-finetune"
"TinyLLaVA/TinyLLaVA_Factory" -> "FreedomIntelligence/ALLaVA"
"TinyLLaVA/TinyLLaVA_Factory" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"TinyLLaVA/TinyLLaVA_Factory" -> "daixiangzi/Awesome-Token-Compress"
"TinyLLaVA/TinyLLaVA_Factory" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"TinyLLaVA/TinyLLaVA_Factory" -> "open-compass/VLMEvalKit"
"TinyLLaVA/TinyLLaVA_Factory" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"TinyLLaVA/TinyLLaVA_Factory" -> "TRI-ML/prismatic-vlms" ["e"=1]
"bfshi/scaling_on_scales" -> "luogen1996/LLaVA-HR"
"bfshi/scaling_on_scales" -> "alibaba/conv-llava"
"bfshi/scaling_on_scales" -> "HJYao00/DenseConnector"
"bfshi/scaling_on_scales" -> "WisconsinAIVision/ViP-LLaVA"
"bfshi/scaling_on_scales" -> "thunlp/LLaVA-UHD"
"bfshi/scaling_on_scales" -> "mbzuai-oryx/LLaVA-pp"
"bfshi/scaling_on_scales" -> "FreedomIntelligence/ALLaVA"
"bfshi/scaling_on_scales" -> "baaivision/EVE" ["e"=1]
"bfshi/scaling_on_scales" -> "SHI-Labs/VCoder"
"gokayfem/awesome-vlm-architectures" -> "gokayfem/ComfyUI_VLM_nodes" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "jingyi0000/VLM_survey" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "DAMO-NLP-SG/VideoLLaMA3"
"gokayfem/awesome-vlm-architectures" -> "JindongGu/Awesome-Prompting-on-Vision-Language-Model" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "NVlabs/VILA"
"gokayfem/awesome-vlm-architectures" -> "open-compass/VLMEvalKit"
"gokayfem/awesome-vlm-architectures" -> "friedrichor/Awesome-Multimodal-Papers" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "LLaVA-VL/LLaVA-NeXT"
"gokayfem/awesome-vlm-architectures" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"gokayfem/awesome-vlm-architectures" -> "zli12321/Vision-Language-Models-Overview"
"gokayfem/awesome-vlm-architectures" -> "TRI-ML/prismatic-vlms" ["e"=1]
"gokayfem/awesome-vlm-architectures" -> "Meituan-AutoML/MobileVLM"
"gokayfem/awesome-vlm-architectures" -> "Deep-Agent/R1-V"
"gokayfem/awesome-vlm-architectures" -> "BAAI-DCAI/Bunny"
"mbzuai-oryx/LLaVA-pp" -> "magic-research/PLLaVA"
"mbzuai-oryx/LLaVA-pp" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"mbzuai-oryx/LLaVA-pp" -> "TinyLLaVA/TinyLLaVA_Factory"
"mbzuai-oryx/LLaVA-pp" -> "BAAI-DCAI/Bunny"
"mbzuai-oryx/LLaVA-pp" -> "mbzuai-oryx/groundingLMM"
"mbzuai-oryx/LLaVA-pp" -> "LLaVA-VL/LLaVA-NeXT"
"mbzuai-oryx/LLaVA-pp" -> "bfshi/scaling_on_scales"
"mbzuai-oryx/LLaVA-pp" -> "xmoanvaf/llava-phi"
"mbzuai-oryx/LLaVA-pp" -> "PKU-YuanGroup/MoE-LLaVA"
"mbzuai-oryx/LLaVA-pp" -> "TRI-ML/prismatic-vlms" ["e"=1]
"mbzuai-oryx/LLaVA-pp" -> "thunlp/LLaVA-UHD"
"mbzuai-oryx/LLaVA-pp" -> "mbzuai-oryx/Video-LLaVA"
"mbzuai-oryx/LLaVA-pp" -> "cambrian-mllm/cambrian"
"mbzuai-oryx/LLaVA-pp" -> "NVlabs/VILA-archive"
"mbzuai-oryx/LLaVA-pp" -> "swordlidev/Efficient-Multimodal-LLMs-Survey"
"THUDM/CogVLM2" -> "THUDM/CogVLM"
"THUDM/CogVLM2" -> "OpenGVLab/InternVL"
"THUDM/CogVLM2" -> "InternLM/InternLM-XComposer"
"THUDM/CogVLM2" -> "THUDM/GLM-4" ["e"=1]
"THUDM/CogVLM2" -> "LLaVA-VL/LLaVA-NeXT"
"THUDM/CogVLM2" -> "QwenLM/Qwen-VL"
"THUDM/CogVLM2" -> "cambrian-mllm/cambrian"
"THUDM/CogVLM2" -> "QwenLM/Qwen2.5-VL"
"THUDM/CogVLM2" -> "THUDM/VisualGLM-6B" ["e"=1]
"THUDM/CogVLM2" -> "modelscope/ms-swift" ["e"=1]
"THUDM/CogVLM2" -> "NVlabs/VILA"
"THUDM/CogVLM2" -> "open-compass/VLMEvalKit"
"THUDM/CogVLM2" -> "X-PLUG/mPLUG-Owl"
"THUDM/CogVLM2" -> "dvlab-research/MGM"
"THUDM/CogVLM2" -> "OpenBMB/MiniCPM-o"
"Ucas-HaoranWei/Vary" -> "Ucas-HaoranWei/Vary-toy"
"Ucas-HaoranWei/Vary" -> "Yuliang-Liu/Monkey" ["e"=1]
"Ucas-HaoranWei/Vary" -> "AlibabaResearch/AdvancedLiterateMachinery" ["e"=1]
"Ucas-HaoranWei/Vary" -> "LingyvKong/OneChart"
"Ucas-HaoranWei/Vary" -> "X-PLUG/mPLUG-DocOwl"
"Ucas-HaoranWei/Vary" -> "Yuliang-Liu/MultimodalOCR" ["e"=1]
"Ucas-HaoranWei/Vary" -> "InternLM/InternLM-XComposer"
"Ucas-HaoranWei/Vary" -> "Ucas-HaoranWei/GOT-OCR2.0" ["e"=1]
"Ucas-HaoranWei/Vary" -> "QwenLM/Qwen-VL"
"Ucas-HaoranWei/Vary" -> "THUDM/CogVLM"
"Ucas-HaoranWei/Vary" -> "open-compass/VLMEvalKit"
"Ucas-HaoranWei/Vary" -> "oh-my-ocr/text_renderer" ["e"=1]
"Ucas-HaoranWei/Vary" -> "OpenGVLab/InternVL"
"Ucas-HaoranWei/Vary" -> "dvlab-research/MGM"
"Ucas-HaoranWei/Vary" -> "THUDM/CogVLM2"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "BillChan226/HALC"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "DAMO-NLP-SG/VCD"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "RUCAIBox/POPE"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "junyangwang0410/AMBER"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "showlab/Awesome-MLLM-Hallucination"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "NishilBalar/Awesome-LVLM-Hallucination"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "LisaAnne/Hallucination"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "LALBJ/PAI"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "Purshow/Awesome-LVLM-Hallucination"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "YiyangZhou/LURE"
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" -> "shikiw/OPERA"
"BillChan226/HALC" -> "YiyangZhou/LURE"
"BillChan226/HALC" -> "shikiw/OPERA"
"BillChan226/HALC" -> "DAMO-NLP-SG/VCD"
"BillChan226/HALC" -> "NishilBalar/Awesome-LVLM-Hallucination"
"BillChan226/HALC" -> "yfzhang114/LLaVA-Align"
"BillChan226/HALC" -> "YiyangZhou/CSR"
"BillChan226/HALC" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"BillChan226/HALC" -> "RUCAIBox/POPE"
"BillChan226/HALC" -> "Ziwei-Zheng/Nullu" ["e"=1]
"BillChan226/HALC" -> "AoiDragon/POPE"
"BillChan226/HALC" -> "Yuqifan1117/HalluciDoctor"
"DAMO-NLP-SG/VCD" -> "shikiw/OPERA"
"DAMO-NLP-SG/VCD" -> "LALBJ/PAI"
"DAMO-NLP-SG/VCD" -> "BillChan226/HALC"
"DAMO-NLP-SG/VCD" -> "YiyangZhou/LURE"
"DAMO-NLP-SG/VCD" -> "tianyi-lab/HallusionBench"
"DAMO-NLP-SG/VCD" -> "showlab/Awesome-MLLM-Hallucination"
"DAMO-NLP-SG/VCD" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"DAMO-NLP-SG/VCD" -> "Purshow/Awesome-LVLM-Hallucination"
"DAMO-NLP-SG/VCD" -> "RUCAIBox/POPE"
"DAMO-NLP-SG/VCD" -> "AoiDragon/POPE"
"DAMO-NLP-SG/VCD" -> "zjunlp/Deco"
"DAMO-NLP-SG/VCD" -> "FuxiaoLiu/LRV-Instruction"
"DAMO-NLP-SG/VCD" -> "voidism/DoLa" ["e"=1]
"DAMO-NLP-SG/VCD" -> "shengliu66/VTI"
"DAMO-NLP-SG/VCD" -> "junyangwang0410/AMBER"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "Kwai-YuanQi/MM-RLHF"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "yfzhang114/SliME"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "ModalMinds/MM-EUREKA"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "rongyaofang/GoT" ["e"=1]
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "MME-Benchmarks/MME-RealWorld"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "modelscope/awesome-deep-reasoning"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "TideDra/lmm-r1"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "showlab/Awesome-Unified-Multimodal-Models" ["e"=1]
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "Liuziyu77/Visual-RFT"
"yfzhang114/Awesome-Multimodal-Large-Language-Models" -> "zzli2022/Awesome-System2-Reasoning-LLM" ["e"=1]
"FreedomIntelligence/ALLaVA" -> "baaivision/CapsFusion" ["e"=1]
"FreedomIntelligence/ALLaVA" -> "WisconsinAIVision/ViP-LLaVA"
"FreedomIntelligence/ALLaVA" -> "thunlp/Muffin"
"FreedomIntelligence/ALLaVA" -> "FuxiaoLiu/LRV-Instruction"
"RLHF-V/RLAIF-V" -> "RLHF-V/RLHF-V"
"RLHF-V/RLAIF-V" -> "thunlp/Muffin"
"RLHF-V/RLAIF-V" -> "TideDra/VL-RLHF"
"RLHF-V/RLAIF-V" -> "llava-rlhf/LLaVA-RLHF"
"RLHF-V/RLAIF-V" -> "YiyangZhou/POVID"
"RLHF-V/RLAIF-V" -> "FreedomIntelligence/ALLaVA"
"RLHF-V/RLAIF-V" -> "YiyangZhou/CSR"
"RLHF-V/RLAIF-V" -> "tianyi-lab/HallusionBench"
"RLHF-V/RLAIF-V" -> "junyangwang0410/AMBER"
"RLHF-V/RLAIF-V" -> "yihedeng9/STIC"
"RLHF-V/RLAIF-V" -> "luka-group/mDPO"
"RLHF-V/RLAIF-V" -> "yuweihao/MM-Vet"
"RLHF-V/RLAIF-V" -> "vlf-silkie/VLFeedback"
"RLHF-V/RLAIF-V" -> "RifleZhang/LLaVA-Hound-DPO"
"RLHF-V/RLAIF-V" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"SkyworkAI/Vitron" -> "scofield7419/Video-of-Thought" ["e"=1]
"SkyworkAI/Vitron" -> "scofield7419/THOR-ISA" ["e"=1]
"SkyworkAI/Vitron" -> "MaverickRen/PixelLM"
"SkyworkAI/Vitron" -> "AILab-CVC/SEED-X" ["e"=1]
"SkyworkAI/Vitron" -> "OpenGVLab/VisionLLM"
"SkyworkAI/Vitron" -> "FoundationVision/Groma" ["e"=1]
"SkyworkAI/Vitron" -> "TencentARC/SmartEdit" ["e"=1]
"SkyworkAI/Vitron" -> "mbzuai-oryx/groundingLMM"
"SkyworkAI/Vitron" -> "mit-han-lab/vila-u" ["e"=1]
"SkyworkAI/Vitron" -> "showlab/Show-o" ["e"=1]
"SkyworkAI/Vitron" -> "FoundationVision/GLEE" ["e"=1]
"SkyworkAI/Vitron" -> "LLaVA-VL/LLaVA-NeXT"
"thunlp/LLaVA-UHD" -> "luogen1996/LLaVA-HR"
"thunlp/LLaVA-UHD" -> "RLHF-V/RLHF-V"
"thunlp/LLaVA-UHD" -> "baaivision/EVE" ["e"=1]
"thunlp/LLaVA-UHD" -> "OpenGVLab/OmniCorpus"
"thunlp/LLaVA-UHD" -> "BAAI-DCAI/Bunny"
"thunlp/LLaVA-UHD" -> "SALT-NLP/LLaVAR"
"thunlp/LLaVA-UHD" -> "RUCAIBox/Virgo"
"thunlp/LLaVA-UHD" -> "ParadoxZW/LLaVA-UHD-Better"
"thunlp/LLaVA-UHD" -> "pkunlp-icler/FastV"
"thunlp/LLaVA-UHD" -> "yfzhang114/SliME"
"thunlp/LLaVA-UHD" -> "bfshi/scaling_on_scales"
"thunlp/LLaVA-UHD" -> "RLHF-V/RLAIF-V"
"thunlp/LLaVA-UHD" -> "yuweihao/MM-Vet"
"NVlabs/LITA" -> "gyxxyg/VTG-LLM"
"NVlabs/LITA" -> "WHB139426/Grounded-Video-LLM"
"NVlabs/LITA" -> "huangb23/VTimeLLM"
"NVlabs/LITA" -> "TimeMarker-LLM/TimeMarker"
"NVlabs/LITA" -> "www-Ye/TimeZero"
"NVlabs/LITA" -> "gyxxyg/TRACE"
"NVlabs/LITA" -> "yellow-binary-tree/HawkEye"
"DLYuanGod/TinyGPT-V" -> "Meituan-AutoML/MobileVLM"
"DLYuanGod/TinyGPT-V" -> "xmoanvaf/llava-phi"
"DLYuanGod/TinyGPT-V" -> "TinyLLaVA/TinyLLaVA_Factory"
"DLYuanGod/TinyGPT-V" -> "MILVLG/imp"
"DLYuanGod/TinyGPT-V" -> "PKU-YuanGroup/MoE-LLaVA"
"DLYuanGod/TinyGPT-V" -> "csuhan/OneLLM"
"DLYuanGod/TinyGPT-V" -> "BAAI-DCAI/Bunny"
"DLYuanGod/TinyGPT-V" -> "PKU-YuanGroup/Video-LLaVA"
"DLYuanGod/TinyGPT-V" -> "OSU-NLP-Group/SeeAct" ["e"=1]
"DLYuanGod/TinyGPT-V" -> "Ucas-HaoranWei/Vary-toy"
"DLYuanGod/TinyGPT-V" -> "eric-ai-lab/MiniGPT-5" ["e"=1]
"DLYuanGod/TinyGPT-V" -> "Flossiee/HonestyLLM"
"DLYuanGod/TinyGPT-V" -> "invictus717/MetaTransformer"
"DLYuanGod/TinyGPT-V" -> "ytongbai/LVM" ["e"=1]
"DLYuanGod/TinyGPT-V" -> "dvmazur/mixtral-offloading" ["e"=1]
"letitiabanana/PnP-OVSS" -> "slonetime/EBSeg"
"Ucas-HaoranWei/Vary-toy" -> "Ucas-HaoranWei/Vary"
"Ucas-HaoranWei/Vary-toy" -> "Ucas-HaoranWei/Vary-family"
"Ucas-HaoranWei/Vary-toy" -> "Ucas-HaoranWei/Vary-tiny-600k"
"Ucas-HaoranWei/Vary-toy" -> "LingyvKong/OneChart"
"Ucas-HaoranWei/Vary-toy" -> "MILVLG/imp"
"Ucas-HaoranWei/Vary-toy" -> "thunlp/LLaVA-UHD"
"Ucas-HaoranWei/Vary-toy" -> "TinyLLaVA/TinyLLaVA_Factory"
"Ucas-HaoranWei/Vary-toy" -> "BAAI-DCAI/Bunny"
"Ucas-HaoranWei/Vary-toy" -> "Yuliang-Liu/Monkey" ["e"=1]
"Ucas-HaoranWei/Vary-toy" -> "Coobiw/MPP-LLaVA"
"Ucas-HaoranWei/Vary-toy" -> "ucaslcl/Fox"
"Ucas-HaoranWei/Vary-toy" -> "Meituan-AutoML/MobileVLM"
"Ucas-HaoranWei/Vary-toy" -> "mbzuai-oryx/groundingLMM"
"Ucas-HaoranWei/Vary-toy" -> "shenyunhang/APE" ["e"=1]
"microsoft/SoM" -> "ddupont808/GPT-4V-Act" ["e"=1]
"microsoft/SoM" -> "mbzuai-oryx/groundingLMM"
"microsoft/SoM" -> "UX-Decoder/Semantic-SAM" ["e"=1]
"microsoft/SoM" -> "dvlab-research/LISA"
"microsoft/SoM" -> "zzxslp/SoM-LLaVA"
"microsoft/SoM" -> "jshilong/GPT4RoI"
"microsoft/SoM" -> "huangwl18/VoxPoser" ["e"=1]
"microsoft/SoM" -> "IDEA-Research/OpenSeeD" ["e"=1]
"microsoft/SoM" -> "shikras/shikra"
"microsoft/SoM" -> "microsoft/GLIP" ["e"=1]
"microsoft/SoM" -> "UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["e"=1]
"microsoft/SoM" -> "huangwl18/ReKep" ["e"=1]
"microsoft/SoM" -> "IDEA-Research/Grounding-DINO-1.5-API" ["e"=1]
"microsoft/SoM" -> "LLaVA-VL/LLaVA-NeXT"
"microsoft/SoM" -> "WisconsinAIVision/ViP-LLaVA"
"yfzhang114/LLaVA-Align" -> "BillChan226/HALC"
"magic-research/PLLaVA" -> "bytedance/tarsier"
"magic-research/PLLaVA" -> "mira-space/MiraData" ["e"=1]
"magic-research/PLLaVA" -> "EvolvingLMMs-Lab/LongVA"
"magic-research/PLLaVA" -> "RenShuhuai-Andy/TimeChat"
"magic-research/PLLaVA" -> "TencentARC/ST-LLM"
"magic-research/PLLaVA" -> "DAMO-NLP-SG/VideoLLaMA2"
"magic-research/PLLaVA" -> "MME-Benchmarks/Video-MME"
"magic-research/PLLaVA" -> "huangb23/VTimeLLM"
"magic-research/PLLaVA" -> "rese1f/MovieChat"
"magic-research/PLLaVA" -> "Vision-CAIR/MiniGPT4-video"
"magic-research/PLLaVA" -> "mbzuai-oryx/LLaVA-pp"
"magic-research/PLLaVA" -> "OpenGVLab/VideoChat-Flash"
"magic-research/PLLaVA" -> "OpenGVLab/InternVideo"
"magic-research/PLLaVA" -> "IVGSZ/Flash-VStream"
"magic-research/PLLaVA" -> "imagegridworth/IG-VLM"
"NExT-ChatV/NExT-Chat" -> "UX-Decoder/LLaVA-Grounding" ["e"=1]
"NExT-ChatV/NExT-Chat" -> "zamling/PSALM"
"NExT-ChatV/NExT-Chat" -> "Meituan-AutoML/Lenna"
"NExT-ChatV/NExT-Chat" -> "mbzuai-oryx/groundingLMM"
"NExT-ChatV/NExT-Chat" -> "lzw-lzw/GroundingGPT"
"Coobiw/MPP-LLaVA" -> "IDEA-FinAI/ChartMoE"
"Coobiw/MPP-LLaVA" -> "zjysteven/lmms-finetune"
"Coobiw/MPP-LLaVA" -> "Vision-CAIR/MiniGPT4-video"
"Coobiw/MPP-LLaVA" -> "TinyLLaVA/TinyLLaVA_Factory"
"Coobiw/MPP-LLaVA" -> "FreedomIntelligence/ALLaVA"
"Coobiw/MPP-LLaVA" -> "shikiw/OPERA"
"Coobiw/MPP-LLaVA" -> "FoundationVision/Groma" ["e"=1]
"Coobiw/MPP-LLaVA" -> "Ucas-HaoranWei/Vary-toy"
"lxe/llavavision" -> "Fuzzy-Search/realtime-bakllava"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "LLaVA-VL/LLaVA-Interactive-Demo"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "llava-rlhf/LLaVA-RLHF"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "SkunkworksAI/BakLLaVA"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "WisconsinAIVision/ViP-LLaVA"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "UX-Decoder/LLaVA-Grounding" ["e"=1]
"LLaVA-VL/LLaVA-Plus-Codebase" -> "PKU-YuanGroup/MoE-LLaVA"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "eric-ai-lab/MiniGPT-5" ["e"=1]
"LLaVA-VL/LLaVA-Plus-Codebase" -> "rese1f/MovieChat"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "SHI-Labs/VCoder"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "mbzuai-oryx/groundingLMM"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "microsoft/LLaVA-Med" ["e"=1]
"LLaVA-VL/LLaVA-Plus-Codebase" -> "baaivision/Emu" ["e"=1]
"LLaVA-VL/LLaVA-Plus-Codebase" -> "NExT-ChatV/NExT-Chat"
"LLaVA-VL/LLaVA-Plus-Codebase" -> "RunpeiDong/DreamLLM" ["e"=1]
"LLaVA-VL/LLaVA-Plus-Codebase" -> "FuxiaoLiu/LRV-Instruction"
"xmoanvaf/llava-phi" -> "MILVLG/imp"
"xmoanvaf/llava-phi" -> "TinyLLaVA/TinyLLaVA_Factory"
"xmoanvaf/llava-phi" -> "mbzuai-oryx/LLaVA-pp"
"xmoanvaf/llava-phi" -> "DLYuanGod/TinyGPT-V"
"xmoanvaf/llava-phi" -> "BAAI-DCAI/Bunny"
"xmoanvaf/llava-phi" -> "FreedomIntelligence/ALLaVA"
"MaverickRen/PixelLM" -> "zamling/PSALM"
"MaverickRen/PixelLM" -> "LeapLabTHU/GSVA" ["e"=1]
"MaverickRen/PixelLM" -> "mbzuai-oryx/groundingLMM"
"MaverickRen/PixelLM" -> "congvvc/HyperSeg" ["e"=1]
"MaverickRen/PixelLM" -> "berkeley-hipie/segllm"
"MaverickRen/PixelLM" -> "mc-lan/Text4Seg"
"ZhouKanglei/Awesome-AQA" -> "baiyang4/aqa_tpt"
"ZhouKanglei/Awesome-AQA" -> "yuxumin/CoRe"
"ZhouKanglei/Awesome-AQA" -> "shiyi-zh0408/LOGO"
"ZhouKanglei/Awesome-AQA" -> "ParitoshParmar/MTL-AQA"
"ZhouKanglei/Awesome-AQA" -> "ZhouKanglei/HGCN_AQA"
"ZhouKanglei/Awesome-AQA" -> "xujinglin/FineDiving"
"ZhouKanglei/Awesome-AQA" -> "Lyman-Smoker/Awesome-AQA"
"ZhouKanglei/Awesome-AQA" -> "Shunli-Wang/TSA-Net"
"ZhouKanglei/Awesome-AQA" -> "xuangch/CVPR22_GDLT"
"showlab/Awesome-MLLM-Hallucination" -> "shikiw/OPERA"
"showlab/Awesome-MLLM-Hallucination" -> "DAMO-NLP-SG/VCD"
"showlab/Awesome-MLLM-Hallucination" -> "NishilBalar/Awesome-LVLM-Hallucination"
"showlab/Awesome-MLLM-Hallucination" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"showlab/Awesome-MLLM-Hallucination" -> "BillChan226/HALC"
"showlab/Awesome-MLLM-Hallucination" -> "shikiw/Awesome-MLLM-Hallucination" ["e"=1]
"showlab/Awesome-MLLM-Hallucination" -> "junyangwang0410/AMBER"
"showlab/Awesome-MLLM-Hallucination" -> "tianyi-lab/HallusionBench"
"showlab/Awesome-MLLM-Hallucination" -> "RUCAIBox/POPE"
"showlab/Awesome-MLLM-Hallucination" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"showlab/Awesome-MLLM-Hallucination" -> "FuxiaoLiu/LRV-Instruction"
"showlab/Awesome-MLLM-Hallucination" -> "YiyangZhou/LURE"
"showlab/Awesome-MLLM-Hallucination" -> "VITA-MLLM/Woodpecker"
"showlab/Awesome-MLLM-Hallucination" -> "Yangyi-Chen/Multimodal-AND-Large-Language-Models"
"showlab/Awesome-MLLM-Hallucination" -> "LuckyyySTA/Awesome-LLM-hallucination" ["e"=1]
"pkunlp-icler/FastV" -> "daixiangzi/Awesome-Token-Compress"
"pkunlp-icler/FastV" -> "42Shawn/LLaVA-PruMerge"
"pkunlp-icler/FastV" -> "Gumpest/SparseVLMs"
"pkunlp-icler/FastV" -> "Cooperx521/PyramidDrop"
"pkunlp-icler/FastV" -> "dvlab-research/VisionZip"
"pkunlp-icler/FastV" -> "Theia-4869/FasterVLM"
"pkunlp-icler/FastV" -> "SUSTechBruce/LOOK-M"
"pkunlp-icler/FastV" -> "lzhxmu/VTW"
"pkunlp-icler/FastV" -> "Yxxxb/VoCo-LLaMA"
"pkunlp-icler/FastV" -> "Beckschen/LLaVolta"
"pkunlp-icler/FastV" -> "ywh187/FitPrune"
"pkunlp-icler/FastV" -> "shikiw/OPERA"
"pkunlp-icler/FastV" -> "EvolvingLMMs-Lab/LongVA"
"pkunlp-icler/FastV" -> "mrwu-mac/ControlMLLM"
"pkunlp-icler/FastV" -> "liuting20/MustDrop" ["e"=1]
"NishilBalar/Awesome-LVLM-Hallucination" -> "BillChan226/HALC"
"NishilBalar/Awesome-LVLM-Hallucination" -> "showlab/Awesome-MLLM-Hallucination"
"NishilBalar/Awesome-LVLM-Hallucination" -> "shengliu66/VTI"
"NishilBalar/Awesome-LVLM-Hallucination" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"NishilBalar/Awesome-LVLM-Hallucination" -> "shikiw/Awesome-MLLM-Hallucination" ["e"=1]
"NishilBalar/Awesome-LVLM-Hallucination" -> "DAMO-NLP-SG/VCD"
"LALBJ/PAI" -> "DAMO-NLP-SG/VCD"
"LALBJ/PAI" -> "shikiw/OPERA"
"LALBJ/PAI" -> "yuezih/less-is-more"
"LALBJ/PAI" -> "shengliu66/VTI"
"mbzuai-oryx/groundingLMM" -> "FoundationVision/Groma" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "dvlab-research/LISA"
"mbzuai-oryx/groundingLMM" -> "mbzuai-oryx/Video-LLaVA"
"mbzuai-oryx/groundingLMM" -> "UX-Decoder/LLaVA-Grounding" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "zamling/PSALM"
"mbzuai-oryx/groundingLMM" -> "lxtGH/OMG-Seg" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "jshilong/GPT4RoI"
"mbzuai-oryx/groundingLMM" -> "CircleRadon/Osprey" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "mbzuai-oryx/Video-ChatGPT"
"mbzuai-oryx/groundingLMM" -> "MaverickRen/PixelLM"
"mbzuai-oryx/groundingLMM" -> "shikras/shikra"
"mbzuai-oryx/groundingLMM" -> "OpenGVLab/all-seeing"
"mbzuai-oryx/groundingLMM" -> "HarborYuan/ovsam" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "magic-research/Sa2VA" ["e"=1]
"mbzuai-oryx/groundingLMM" -> "lzw-lzw/GroundingGPT"
"deepcs233/Visual-CoT" -> "dongyh20/Insight-V"
"deepcs233/Visual-CoT" -> "RupertLuo/VoCoT"
"deepcs233/Visual-CoT" -> "turningpoint-ai/VisualThinker-R1-Zero"
"deepcs233/Visual-CoT" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"deepcs233/Visual-CoT" -> "YiyangZhou/POVID"
"deepcs233/Visual-CoT" -> "Wang-Xiaodong1899/Open-R1-Video"
"deepcs233/Visual-CoT" -> "tsb0601/MMVP"
"deepcs233/Visual-CoT" -> "Osilly/Vision-R1"
"deepcs233/Visual-CoT" -> "luka-group/mDPO"
"deepcs233/Visual-CoT" -> "chancharikmitra/CCoT" ["e"=1]
"deepcs233/Visual-CoT" -> "ModalMinds/MM-EUREKA"
"deepcs233/Visual-CoT" -> "penghao-wu/vstar"
"ggg0919/cantor" -> "zhourax/VEGA"
"ggg0919/cantor" -> "MAC-AutoML/QuoTA"
"vlf-silkie/VLFeedback" -> "yihedeng9/STIC"
"vlf-silkie/VLFeedback" -> "YiyangZhou/POVID"
"BAAI-DCAI/Bunny" -> "TinyLLaVA/TinyLLaVA_Factory"
"BAAI-DCAI/Bunny" -> "Meituan-AutoML/MobileVLM"
"BAAI-DCAI/Bunny" -> "thunlp/LLaVA-UHD"
"BAAI-DCAI/Bunny" -> "FreedomIntelligence/ALLaVA"
"BAAI-DCAI/Bunny" -> "mbzuai-oryx/LLaVA-pp"
"BAAI-DCAI/Bunny" -> "PKU-YuanGroup/MoE-LLaVA"
"BAAI-DCAI/Bunny" -> "open-compass/VLMEvalKit"
"BAAI-DCAI/Bunny" -> "xmoanvaf/llava-phi"
"BAAI-DCAI/Bunny" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"BAAI-DCAI/Bunny" -> "OpenGVLab/all-seeing"
"BAAI-DCAI/Bunny" -> "InternLM/InternLM-XComposer"
"BAAI-DCAI/Bunny" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"BAAI-DCAI/Bunny" -> "dvlab-research/MGM"
"BAAI-DCAI/Bunny" -> "LLaVA-VL/LLaVA-NeXT"
"BAAI-DCAI/Bunny" -> "cambrian-mllm/cambrian"
"aimagelab/freeda" -> "letitiabanana/PnP-OVSS"
"penghao-wu/vstar" -> "FanqingM/R1-Multimodal-Journey"
"penghao-wu/vstar" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"penghao-wu/vstar" -> "tsb0601/MMVP"
"penghao-wu/vstar" -> "deepcs233/Visual-CoT"
"penghao-wu/vstar" -> "jshilong/GPT4RoI"
"penghao-wu/vstar" -> "thunlp/LLaVA-UHD"
"penghao-wu/vstar" -> "pkunlp-icler/FastV"
"penghao-wu/vstar" -> "allenai/unified-io-2" ["e"=1]
"penghao-wu/vstar" -> "cambrian-mllm/cambrian"
"penghao-wu/vstar" -> "dvlab-research/LISA"
"penghao-wu/vstar" -> "mbzuai-oryx/groundingLMM"
"penghao-wu/vstar" -> "WisconsinAIVision/ViP-LLaVA"
"penghao-wu/vstar" -> "EvolvingLMMs-Lab/LongVA"
"penghao-wu/vstar" -> "open-compass/VLMEvalKit"
"penghao-wu/vstar" -> "shikras/shikra"
"FreedomIntelligence/Apollo" -> "FreedomIntelligence/ApolloMoE"
"FreedomIntelligence/Apollo" -> "FreedomIntelligence/MLLM-Bench"
"FreedomIntelligence/Apollo" -> "FreedomIntelligence/CMB" ["e"=1]
"Vision-CAIR/MiniGPT4-video" -> "magic-research/PLLaVA"
"Vision-CAIR/MiniGPT4-video" -> "mbzuai-oryx/Video-ChatGPT"
"Vision-CAIR/MiniGPT4-video" -> "DAMO-NLP-SG/VideoLLaMA2"
"Vision-CAIR/MiniGPT4-video" -> "boheumd/MA-LMM"
"Vision-CAIR/MiniGPT4-video" -> "PKU-YuanGroup/Video-LLaVA"
"Vision-CAIR/MiniGPT4-video" -> "dvlab-research/LLaMA-VID"
"Vision-CAIR/MiniGPT4-video" -> "OpenGVLab/InternVideo"
"Vision-CAIR/MiniGPT4-video" -> "rese1f/MovieChat"
"Vision-CAIR/MiniGPT4-video" -> "EvolvingLMMs-Lab/LongVA"
"Vision-CAIR/MiniGPT4-video" -> "Deaddawn/MovieLLM-code"
"Vision-CAIR/MiniGPT4-video" -> "mbzuai-oryx/VideoGPT-plus"
"Vision-CAIR/MiniGPT4-video" -> "PKU-YuanGroup/MoE-LLaVA"
"Vision-CAIR/MiniGPT4-video" -> "RenShuhuai-Andy/TimeChat"
"Vision-CAIR/MiniGPT4-video" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"Vision-CAIR/MiniGPT4-video" -> "bytedance/tarsier"
"OpenGVLab/VideoChat-Flash" -> "OpenGVLab/InternVideo"
"OpenGVLab/VideoChat-Flash" -> "OpenGVLab/unmasked_teacher" ["e"=1]
"OpenGVLab/VideoChat-Flash" -> "Vision-CAIR/LongVU"
"OpenGVLab/VideoChat-Flash" -> "gls0425/LinVT"
"OpenGVLab/VideoChat-Flash" -> "OpenGVLab/VideoMamba" ["e"=1]
"OpenGVLab/VideoChat-Flash" -> "MME-Benchmarks/Video-MME"
"OpenGVLab/VideoChat-Flash" -> "EvolvingLMMs-Lab/LongVA"
"OpenGVLab/VideoChat-Flash" -> "Wang-Xiaodong1899/Open-R1-Video"
"OpenGVLab/VideoChat-Flash" -> "RenShuhuai-Andy/TimeChat"
"OpenGVLab/VideoChat-Flash" -> "egoschema/EgoSchema"
"OpenGVLab/VideoChat-Flash" -> "bytedance/tarsier"
"OpenGVLab/VideoChat-Flash" -> "VectorSpaceLab/Video-XL"
"OpenGVLab/VideoChat-Flash" -> "Ziyang412/VideoTree"
"OpenGVLab/VideoChat-Flash" -> "magic-research/PLLaVA"
"OpenGVLab/VideoChat-Flash" -> "boheumd/MA-LMM"
"tingxueronghua/ChartLlama-code" -> "vis-nlp/UniChart"
"tingxueronghua/ChartLlama-code" -> "FuxiaoLiu/MMC"
"tingxueronghua/ChartLlama-code" -> "vis-nlp/ChartQA"
"tingxueronghua/ChartLlama-code" -> "OpenGVLab/ChartAst"
"tingxueronghua/ChartLlama-code" -> "hyungkwonko/chart-llm" ["e"=1]
"tingxueronghua/ChartLlama-code" -> "LingyvKong/OneChart"
"tingxueronghua/ChartLlama-code" -> "Alpha-Innovator/SimChart9K"
"tingxueronghua/ChartLlama-code" -> "zengxingchen/ChartQA-MLLM" ["e"=1]
"tingxueronghua/ChartLlama-code" -> "vis-nlp/Chart-to-text"
"tingxueronghua/ChartLlama-code" -> "Alpha-Innovator/ChartVLM"
"tingxueronghua/ChartLlama-code" -> "mitvis/vistext"
"tingxueronghua/ChartLlama-code" -> "findalexli/SciGraphQA" ["e"=1]
"WisconsinAIVision/ViP-LLaVA" -> "FreedomIntelligence/ALLaVA"
"WisconsinAIVision/ViP-LLaVA" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"WisconsinAIVision/ViP-LLaVA" -> "UX-Decoder/LLaVA-Grounding" ["e"=1]
"WisconsinAIVision/ViP-LLaVA" -> "MMStar-Benchmark/MMStar" ["e"=1]
"LingyvKong/OneChart" -> "ucaslcl/Fox"
"LingyvKong/OneChart" -> "Ucas-HaoranWei/Vary-tiny-600k"
"LingyvKong/OneChart" -> "Alpha-Innovator/ChartVLM"
"LingyvKong/OneChart" -> "Ucas-HaoranWei/Slow-Perception"
"LingyvKong/OneChart" -> "Ucas-HaoranWei/Vary"
"LingyvKong/OneChart" -> "zengxingchen/ChartQA-MLLM" ["e"=1]
"LingyvKong/OneChart" -> "Ucas-HaoranWei/Vary-family"
"LingyvKong/OneChart" -> "tingxueronghua/ChartLlama-code"
"LingyvKong/OneChart" -> "1694439208/GOT-OCR-Inference"
"LingyvKong/OneChart" -> "Ucas-HaoranWei/Vary-toy"
"csuhan/OneLLM" -> "PKU-YuanGroup/LanguageBind"
"csuhan/OneLLM" -> "invictus717/MetaTransformer"
"csuhan/OneLLM" -> "TencentARC/ViT-Lens" ["e"=1]
"csuhan/OneLLM" -> "OpenMOSS/AnyGPT" ["e"=1]
"csuhan/OneLLM" -> "ZrrSkywalker/I2P-MAE" ["e"=1]
"csuhan/OneLLM" -> "showlab/Awesome-Unified-Multimodal-Models" ["e"=1]
"csuhan/OneLLM" -> "Alpha-VLLM/LLaMA2-Accessory"
"csuhan/OneLLM" -> "AILab-CVC/SEED-X" ["e"=1]
"csuhan/OneLLM" -> "baaivision/Emu" ["e"=1]
"csuhan/OneLLM" -> "salesforce/ULIP" ["e"=1]
"csuhan/OneLLM" -> "allenai/unified-io-2" ["e"=1]
"csuhan/OneLLM" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"csuhan/OneLLM" -> "DirtyHarryLYL/LLM-in-Vision"
"EvolvingLMMs-Lab/EgoLife" -> "EvolvingLMMs-Lab/multimodal-search-r1"
"EvolvingLMMs-Lab/EgoLife" -> "EvolvingLMMs-Lab/Aero-1" ["e"=1]
"EvolvingLMMs-Lab/EgoLife" -> "EvolvingLMMs-Lab/LongVA"
"lupantech/MathVista" -> "MMMU-Benchmark/MMMU"
"lupantech/MathVista" -> "mathllm/MATH-V"
"lupantech/MathVista" -> "ZrrSkywalker/MathVerse"
"lupantech/MathVista" -> "vis-nlp/UniChart"
"lupantech/MathVista" -> "HZQ950419/Math-LLaVA"
"lupantech/MathVista" -> "pipilurj/G-LLaVA" ["e"=1]
"lupantech/MathVista" -> "AILab-CVC/SEED-Bench"
"lupantech/MathVista" -> "ZrrSkywalker/MAVIS"
"lupantech/MathVista" -> "tianyi-lab/HallusionBench"
"lupantech/MathVista" -> "vis-nlp/ChartQA"
"mathllm/MATH-V" -> "ZrrSkywalker/MathVerse"
"liangyn22/MCUFormer" -> "ChangyuanWang17/APQ-DM"
"dvlab-research/LLaMA-VID" -> "mbzuai-oryx/Video-ChatGPT"
"dvlab-research/LLaMA-VID" -> "rese1f/MovieChat"
"dvlab-research/LLaMA-VID" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"dvlab-research/LLaMA-VID" -> "PKU-YuanGroup/Video-LLaVA"
"dvlab-research/LLaMA-VID" -> "DAMO-NLP-SG/Video-LLaMA"
"dvlab-research/LLaMA-VID" -> "RenShuhuai-Andy/TimeChat"
"dvlab-research/LLaMA-VID" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"dvlab-research/LLaMA-VID" -> "magic-research/PLLaVA"
"dvlab-research/LLaMA-VID" -> "OpenGVLab/Ask-Anything"
"dvlab-research/LLaMA-VID" -> "LLaVA-VL/LLaVA-NeXT"
"dvlab-research/LLaMA-VID" -> "huangb23/VTimeLLM"
"dvlab-research/LLaMA-VID" -> "PKU-YuanGroup/LanguageBind"
"dvlab-research/LLaMA-VID" -> "dvlab-research/LISA"
"dvlab-research/LLaMA-VID" -> "jzhzhang/NaVid-VLN-CE" ["e"=1]
"dvlab-research/LLaMA-VID" -> "RifleZhang/LLaVA-Hound-DPO"
"ChangyuanWang17/APQ-DM" -> "ChangyuanWang17/QVLM"
"OpenGVLab/ChartAst" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"OpenGVLab/ChartAst" -> "lyingCS/UOEP"
"OpenGVLab/ChartAst" -> "OpenGVLab/MMIU"
"OpenGVLab/ChartAst" -> "TengShi-RUC/UniSAR"
"OpenGVLab/ChartAst" -> "OpenGVLab/PhyGenBench" ["e"=1]
"CeeZh/LLoVi" -> "Ziyang412/VideoTree"
"CeeZh/LLoVi" -> "agentic-learning-ai-lab/lifelong-memory"
"CeeZh/LLoVi" -> "jongwoopark7978/LVNet"
"RLHF-V/RLHF-V" -> "RLHF-V/RLAIF-V"
"RLHF-V/RLHF-V" -> "thunlp/Muffin"
"RLHF-V/RLHF-V" -> "llava-rlhf/LLaVA-RLHF"
"RLHF-V/RLHF-V" -> "TideDra/VL-RLHF"
"RLHF-V/RLHF-V" -> "vlf-silkie/VLFeedback"
"RLHF-V/RLHF-V" -> "yihedeng9/STIC"
"RLHF-V/RLHF-V" -> "RifleZhang/LLaVA-Hound-DPO"
"RLHF-V/RLHF-V" -> "FanqingM/R1-Multimodal-Journey"
"RLHF-V/RLHF-V" -> "dongyh20/Insight-V"
"RLHF-V/RLHF-V" -> "junyangwang0410/AMBER"
"RLHF-V/RLHF-V" -> "opendatalab/HA-DPO"
"RLHF-V/RLHF-V" -> "FreedomIntelligence/ALLaVA"
"RLHF-V/RLHF-V" -> "YiyangZhou/POVID"
"RLHF-V/RLHF-V" -> "thunlp/LLaVA-UHD"
"Fuzzy-Search/realtime-bakllava" -> "lxe/llavavision"
"Fuzzy-Search/realtime-bakllava" -> "cocktailpeanut/mirror"
"Fuzzy-Search/realtime-bakllava" -> "SkunkworksAI/BakLLaVA"
"Fuzzy-Search/realtime-bakllava" -> "OneInterface/chat-with-page"
"EternalEvan/FlowIE" -> "EternalEvan/DPMesh"
"EternalEvan/FlowIE" -> "AndyTang15/FLAG3Dv2"
"EternalEvan/FlowIE" -> "AndyTang15/FLAG3D"
"EternalEvan/FlowIE" -> "Tengbo-Yu/AnyBimanual"
"EternalEvan/FlowIE" -> "InvincibleWyq/ChatVID"
"EternalEvan/FlowIE" -> "SuleBai/SC-CLIP"
"YUCHEN005/GenTranslate" -> "YUCHEN005/STAR-Adapt"
"YUCHEN005/GenTranslate" -> "YUCHEN005/RobustGER"
"YUCHEN005/GenTranslate" -> "Hypotheses-Paradise/Hypo2Trans"
"Ucas-HaoranWei/Vary-tiny-600k" -> "Ucas-HaoranWei/Vary-family"
"Ucas-HaoranWei/Vary-tiny-600k" -> "LingyvKong/OneChart"
"yellow-binary-tree/HawkEye" -> "gyxxyg/VTG-LLM"
"Alpha-Innovator/ChartVLM" -> "HankYe/AdaptiveDiffusion"
"Alpha-Innovator/ChartVLM" -> "LingyvKong/OneChart"
"Alpha-Innovator/ChartVLM" -> "OpenGVLab/ChartAst"
"Alpha-Innovator/ChartVLM" -> "Alpha-Innovator/SimChart9K"
"Alpha-Innovator/ChartVLM" -> "Thinklab-SJTU/ML4CO-Kit" ["e"=1]
"Alpha-Innovator/ChartVLM" -> "Alpha-Innovator/SurveyForge"
"Alpha-Innovator/ChartVLM" -> "vis-nlp/UniChart"
"cocktailpeanut/mirror" -> "Fuzzy-Search/realtime-bakllava"
"wusize/F-LMM" -> "Shengcao-Cao/groundLMM"
"wusize/F-LMM" -> "MICV-yonsei/CASS"
"MMMU-Benchmark/MMMU" -> "lupantech/MathVista"
"MMMU-Benchmark/MMMU" -> "yuweihao/MM-Vet"
"MMMU-Benchmark/MMMU" -> "open-compass/MMBench"
"MMMU-Benchmark/MMMU" -> "FuxiaoLiu/LRV-Instruction"
"MMMU-Benchmark/MMMU" -> "FreedomIntelligence/MLLM-Bench"
"MMMU-Benchmark/MMMU" -> "open-compass/VLMEvalKit"
"MMMU-Benchmark/MMMU" -> "AILab-CVC/SEED-Bench"
"EternalEvan/DPMesh" -> "AndyTang15/FLAG3Dv2"
"EternalEvan/DPMesh" -> "RammusLeo/DPMesh"
"EternalEvan/DPMesh" -> "AndyTang15/FLAG3D"
"EternalEvan/DPMesh" -> "EternalEvan/FlowIE"
"yuanzhoulvpi2017/vscode_debug_transformers" -> "yuanzhoulvpi2017/zero_nlp" ["e"=1]
"yuanzhoulvpi2017/vscode_debug_transformers" -> "DAMO-NLP-SG/VCD"
"yongliu20/UniLSeg" -> "yongliu20/SCAN"
"yongliu20/UniLSeg" -> "SuleBai/SC-CLIP"
"TideDra/VL-RLHF" -> "RLHF-V/RLHF-V"
"TideDra/VL-RLHF" -> "vlf-silkie/VLFeedback"
"TideDra/VL-RLHF" -> "NiuTrans/Vision-LLM-Alignment"
"TideDra/VL-RLHF" -> "njucckevin/MM-Self-Improve"
"TideDra/VL-RLHF" -> "RLHF-V/RLAIF-V"
"TideDra/VL-RLHF" -> "thunlp/Muffin"
"TideDra/VL-RLHF" -> "llava-rlhf/LLaVA-RLHF"
"md-mohaiminul/VideoRecap" -> "Ziyang412/VideoTree"
"md-mohaiminul/VideoRecap" -> "j-min/HiREST" ["e"=1]
"md-mohaiminul/VideoRecap" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"shikiw/OPERA" -> "DAMO-NLP-SG/VCD"
"shikiw/OPERA" -> "BillChan226/HALC"
"shikiw/OPERA" -> "showlab/Awesome-MLLM-Hallucination"
"shikiw/OPERA" -> "shikiw/Awesome-MLLM-Hallucination" ["e"=1]
"shikiw/OPERA" -> "YiyangZhou/LURE"
"shikiw/OPERA" -> "RUCAIBox/POPE"
"shikiw/OPERA" -> "FuxiaoLiu/LRV-Instruction"
"shikiw/OPERA" -> "LALBJ/PAI"
"shikiw/OPERA" -> "tianyi-lab/HallusionBench"
"shikiw/OPERA" -> "AoiDragon/POPE"
"shikiw/OPERA" -> "junyangwang0410/AMBER"
"shikiw/OPERA" -> "shikiw/DAM-VP" ["e"=1]
"shikiw/OPERA" -> "VITA-MLLM/Woodpecker"
"shikiw/OPERA" -> "voidism/DoLa" ["e"=1]
"shikiw/OPERA" -> "MMStar-Benchmark/MMStar" ["e"=1]
"YiyangZhou/POVID" -> "YiyangZhou/CSR"
"YiyangZhou/POVID" -> "yihedeng9/STIC"
"RifleZhang/LLaVA-Hound-DPO" -> "EvolvingLMMs-Lab/LongVA"
"RifleZhang/LLaVA-Hound-DPO" -> "YiyangZhou/POVID"
"RifleZhang/LLaVA-Hound-DPO" -> "yonseivnl/vlm-rlaif" ["e"=1]
"RifleZhang/LLaVA-Hound-DPO" -> "RLHF-V/RLHF-V"
"palchenli/VL-Instruction-Tuning" -> "RUCAIBox/ComVint"
"TencentARC/ST-LLM" -> "llyx97/TempCompass"
"TencentARC/ST-LLM" -> "yellow-binary-tree/HawkEye"
"TencentARC/ST-LLM" -> "Becomebright/GroundVQA" ["e"=1]
"TencentARC/ST-LLM" -> "magic-research/PLLaVA"
"TencentARC/ST-LLM" -> "RenShuhuai-Andy/TimeChat"
"TencentARC/ST-LLM" -> "EvolvingLMMs-Lab/LongVA"
"TencentARC/ST-LLM" -> "TimeMarker-LLM/TimeMarker"
"BAAI-DCAI/DataOptim" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"BAAI-DCAI/DataOptim" -> "BAAI-DCAI/Training-Data-Synthesis"
"tsb0601/MMVP" -> "yuweihao/MM-Vet"
"tsb0601/MMVP" -> "mertyg/vision-language-models-are-bows" ["e"=1]
"tsb0601/MMVP" -> "RUCAIBox/POPE"
"tsb0601/MMVP" -> "FreedomIntelligence/ALLaVA"
"tsb0601/MMVP" -> "bronyayang/Law_of_Vision_Representation_in_MLLMs" ["e"=1]
"tsb0601/MMVP" -> "OpenGVLab/all-seeing"
"tsb0601/MMVP" -> "cambrian-mllm/cambrian"
"tsb0601/MMVP" -> "FuxiaoLiu/LRV-Instruction"
"tsb0601/MMVP" -> "deepcs233/Visual-CoT"
"tsb0601/MMVP" -> "showlab/Awesome-MLLM-Hallucination"
"tsb0601/MMVP" -> "baaivision/DIVA"
"tsb0601/MMVP" -> "penghao-wu/vstar"
"MILVLG/imp" -> "xmoanvaf/llava-phi"
"ZrrSkywalker/MathVerse" -> "ZrrSkywalker/MAVIS"
"ZrrSkywalker/MathVerse" -> "mathllm/MATH-V"
"ZrrSkywalker/MathVerse" -> "HZQ950419/Math-LLaVA"
"ZrrSkywalker/MathVerse" -> "lupantech/MathVista"
"DCDmllm/WorldGPT" -> "DCDmllm/MorphTokens"
"mbzuai-oryx/Video-LLaVA" -> "mbzuai-oryx/VideoGLaMM" ["e"=1]
"mbzuai-oryx/Video-LLaVA" -> "huangb23/VTimeLLM"
"mbzuai-oryx/Video-LLaVA" -> "mbzuai-oryx/groundingLMM"
"mbzuai-oryx/Video-LLaVA" -> "hananshafi/llmblueprint" ["e"=1]
"mbzuai-oryx/Video-LLaVA" -> "mbzuai-oryx/VideoGPT-plus"
"mbzuai-oryx/Video-LLaVA" -> "RenShuhuai-Andy/TimeChat"
"mbzuai-oryx/Video-LLaVA" -> "mbzuai-oryx/Video-ChatGPT"
"mbzuai-oryx/Video-LLaVA" -> "showlab/VideoLISA" ["e"=1]
"mbzuai-oryx/Video-LLaVA" -> "TencentARC/ST-LLM"
"mbzuai-oryx/Video-LLaVA" -> "imagegridworth/IG-VLM"
"mbzuai-oryx/Video-LLaVA" -> "rese1f/MovieChat"
"mbzuai-oryx/Video-LLaVA" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"zli12321/qa_metrics" -> "zli12321/VideoHallu"
"BAAI-DCAI/Training-Data-Synthesis" -> "yongchaoz/diffusion_inversion"
"BAAI-DCAI/Training-Data-Synthesis" -> "BAAI-DCAI/DataOptim"
"zamling/PSALM" -> "MaverickRen/PixelLM"
"zamling/PSALM" -> "LeapLabTHU/GSVA" ["e"=1]
"zamling/PSALM" -> "mbzuai-oryx/groundingLMM"
"zamling/PSALM" -> "NExT-ChatV/NExT-Chat"
"zamling/PSALM" -> "heshuting555/DsHmp" ["e"=1]
"zamling/PSALM" -> "congvvc/LaSagnA" ["e"=1]
"zamling/PSALM" -> "wusize/F-LMM"
"zamling/PSALM" -> "congvvc/HyperSeg" ["e"=1]
"imagegridworth/IG-VLM" -> "SNU-DRL/Attribution-ECG"
"imagegridworth/IG-VLM" -> "Ziyang412/VideoTree"
"imagegridworth/IG-VLM" -> "apple/ml-slowfast-llava"
"ziplab/LongVLM" -> "Ziyang412/VideoTree"
"tianyi-lab/HallusionBench" -> "junyangwang0410/AMBER"
"tianyi-lab/HallusionBench" -> "FuxiaoLiu/LRV-Instruction"
"tianyi-lab/HallusionBench" -> "DAMO-NLP-SG/VCD"
"tianyi-lab/HallusionBench" -> "RUCAIBox/POPE"
"tianyi-lab/HallusionBench" -> "shikiw/OPERA"
"tianyi-lab/HallusionBench" -> "YiyangZhou/LURE"
"tianyi-lab/HallusionBench" -> "yuweihao/MM-Vet"
"tianyi-lab/HallusionBench" -> "FuxiaoLiu/MMC"
"tianyi-lab/HallusionBench" -> "showlab/Awesome-MLLM-Hallucination"
"tianyi-lab/HallusionBench" -> "AILab-CVC/SEED-Bench"
"tianyi-lab/HallusionBench" -> "AoiDragon/POPE"
"tianyi-lab/HallusionBench" -> "xieyuquanxx/awesome-Large-MultiModal-Hallucination"
"tianyi-lab/HallusionBench" -> "llava-rlhf/LLaVA-RLHF"
"tianyi-lab/HallusionBench" -> "mertyg/vision-language-models-are-bows" ["e"=1]
"tianyi-lab/HallusionBench" -> "open-compass/MMBench"
"huangb23/VTimeLLM" -> "gyxxyg/VTG-LLM"
"huangb23/VTimeLLM" -> "RenShuhuai-Andy/TimeChat"
"huangb23/VTimeLLM" -> "sudo-Boris/mr-Blip" ["e"=1]
"huangb23/VTimeLLM" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"huangb23/VTimeLLM" -> "NVlabs/LITA"
"huangb23/VTimeLLM" -> "Ziyang412/VideoTree"
"huangb23/VTimeLLM" -> "DCDmllm/Momentor"
"huangb23/VTimeLLM" -> "mbzuai-oryx/Video-LLaVA"
"huangb23/VTimeLLM" -> "wjun0830/CGDETR" ["e"=1]
"huangb23/VTimeLLM" -> "gyxxyg/TRACE"
"huangb23/VTimeLLM" -> "rese1f/MovieChat"
"huangb23/VTimeLLM" -> "TimeMarker-LLM/TimeMarker"
"huangb23/VTimeLLM" -> "wjun0830/QD-DETR" ["e"=1]
"huangb23/VTimeLLM" -> "minghangz/TFVTG"
"huangb23/VTimeLLM" -> "magic-research/PLLaVA"
"lzw-lzw/GroundingGPT" -> "huangb23/VTimeLLM"
"lzw-lzw/GroundingGPT" -> "mbzuai-oryx/groundingLMM"
"lzw-lzw/GroundingGPT" -> "NExT-ChatV/NExT-Chat"
"lzw-lzw/GroundingGPT" -> "UX-Decoder/LLaVA-Grounding" ["e"=1]
"lzw-lzw/GroundingGPT" -> "X2FD/LVIS-INSTRUCT4V"
"lzw-lzw/GroundingGPT" -> "gyxxyg/VTG-LLM"
"lzw-lzw/GroundingGPT" -> "RenShuhuai-Andy/TimeChat"
"lzw-lzw/GroundingGPT" -> "zamling/PSALM"
"mengtong0110/InferDPT" -> "Fish-and-Sheep/Text-Fluoroscopy"
"mengtong0110/InferDPT" -> "coriverchen/Robust_Steganography"
"Dongping-Chen/MLLM-Judge" -> "Flossiee/HonestyLLM"
"qinghuannn/PAMFN" -> "ZhouKanglei/HGCN_AQA"
"nttmdlab-nlp/InstructDoc" -> "ucaslcl/Fox"
"nttmdlab-nlp/InstructDoc" -> "LukeForeverYoung/UReader" ["e"=1]
"OpenGVLab/MMT-Bench" -> "OpenGVLab/MMIU"
"OpenGVLab/MMT-Bench" -> "KainingYing/CTVIS" ["e"=1]
"OpenGVLab/MMT-Bench" -> "OpenGVLab/PhyBench"
"lntzm/MESM" -> "minghangz/TFVTG"
"THUDM/CogCoM" -> "njucckevin/MM-Self-Improve"
"YUCHEN005/RobustGER" -> "YUCHEN005/STAR-Adapt"
"YUCHEN005/RobustGER" -> "Hypotheses-Paradise/Hypo2Trans"
"YUCHEN005/RobustGER" -> "YUCHEN005/GenTranslate"
"RammusLeo/DPMesh" -> "EternalEvan/DPMesh"
"RammusLeo/DPMesh" -> "AndyTang15/FLAG3Dv2"
"RammusLeo/DPMesh" -> "AndyTang15/FLAG3D"
"RenShuhuai-Andy/TimeChat" -> "huangb23/VTimeLLM"
"RenShuhuai-Andy/TimeChat" -> "gyxxyg/VTG-LLM"
"RenShuhuai-Andy/TimeChat" -> "rese1f/MovieChat"
"RenShuhuai-Andy/TimeChat" -> "boheumd/MA-LMM"
"RenShuhuai-Andy/TimeChat" -> "EvolvingLMMs-Lab/LongVA"
"RenShuhuai-Andy/TimeChat" -> "Yui010206/SeViLA"
"RenShuhuai-Andy/TimeChat" -> "magic-research/PLLaVA"
"RenShuhuai-Andy/TimeChat" -> "TencentARC/ST-LLM"
"RenShuhuai-Andy/TimeChat" -> "showlab/UniVTG" ["e"=1]
"RenShuhuai-Andy/TimeChat" -> "mbzuai-oryx/Video-ChatGPT"
"RenShuhuai-Andy/TimeChat" -> "mbzuai-oryx/Video-LLaVA"
"RenShuhuai-Andy/TimeChat" -> "RupertLuo/Valley"
"RenShuhuai-Andy/TimeChat" -> "yellow-binary-tree/HawkEye"
"RenShuhuai-Andy/TimeChat" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"RenShuhuai-Andy/TimeChat" -> "OpenGVLab/VideoChat-Flash"
"opendatalab/HA-DPO" -> "luka-group/mDPO"
"yuezih/less-is-more" -> "yuezih/SMILE"
"yuezih/less-is-more" -> "Lackel/AGLA"
"tpgh24/ag4masses" -> "felixludos/alphageometry"
"tpgh24/ag4masses" -> "foldl/AlphaGeometryRE"
"khuangaf/Awesome-Chart-Understanding" -> "vis-nlp/UniChart"
"khuangaf/Awesome-Chart-Understanding" -> "khuangaf/CHOCOLATE"
"khuangaf/Awesome-Chart-Understanding" -> "FuxiaoLiu/MMC"
"khuangaf/Awesome-Chart-Understanding" -> "OpenGVLab/ChartAst"
"khuangaf/Awesome-Chart-Understanding" -> "IDEA-FinAI/ChartBench"
"khuangaf/Awesome-Chart-Understanding" -> "SpursGoZmy/Table-LLaVA" ["e"=1]
"khuangaf/Awesome-Chart-Understanding" -> "vis-nlp/ChartQA"
"khuangaf/Awesome-Chart-Understanding" -> "Alpha-Innovator/ChartVLM"
"HZQ950419/Math-LLaVA" -> "ZrrSkywalker/MAVIS"
"HZQ950419/Math-LLaVA" -> "pengshuai-rin/MultiMath"
"Ucas-HaoranWei/Vary-family" -> "Ucas-HaoranWei/Vary-tiny-600k"
"KID-22/LLM-IR-Bias-Fairness-Survey" -> "XuChen0427/FairDiverse"
"KID-22/LLM-IR-Bias-Fairness-Survey" -> "KID-22/Cocktail"
"KID-22/LLM-IR-Bias-Fairness-Survey" -> "Ethan00Si/KuaiSAR"
"42Shawn/LLaVA-PruMerge" -> "pkunlp-icler/FastV"
"42Shawn/LLaVA-PruMerge" -> "Gumpest/SparseVLMs"
"42Shawn/LLaVA-PruMerge" -> "Yxxxb/VoCo-LLaMA"
"42Shawn/LLaVA-PruMerge" -> "ichbill/LTDD"
"dongyh20/Chain-of-Spot" -> "liuzuyan/ElasticCache"
"yongliu20/SCAN" -> "shiyi-zh0408/NAE_CVPR2024"
"yongliu20/SCAN" -> "Yxxxb/LAVT-RS"
"yongliu20/SCAN" -> "SuleBai/SC-CLIP"
"yongliu20/SCAN" -> "zhang9302002/Flash-VStream"
"yongliu20/SCAN" -> "yongliu20/UniLSeg"
"yongliu20/SCAN" -> "slonetime/EBSeg"
"HaozheZhao/MIC_tool" -> "kkk-an/COFFTEA"
"HankYe/Once-for-Both" -> "Alpha-Innovator/TrustGeoGen"
"HankYe/Once-for-Both" -> "HankYe/AdaptiveDiffusion"
"shiyi-zh0408/NAE_CVPR2024" -> "AndyTang15/FLAG3Dv2"
"shiyi-zh0408/NAE_CVPR2024" -> "Yxxxb/LAVT-RS"
"shiyi-zh0408/NAE_CVPR2024" -> "zhang9302002/Flash-VStream"
"shiyi-zh0408/NAE_CVPR2024" -> "shiyi-zh0408/LOGO"
"shiyi-zh0408/NAE_CVPR2024" -> "SuleBai/SC-CLIP"
"shiyi-zh0408/NAE_CVPR2024" -> "yongliu20/SCAN"
"shiyi-zh0408/NAE_CVPR2024" -> "AndyTang15/FLAG3D"
"AndyTang15/FLAG3Dv2" -> "AndyTang15/FLAG3D"
"AndyTang15/FLAG3Dv2" -> "EternalEvan/DPMesh"
"AndyTang15/FLAG3Dv2" -> "SuleBai/SC-CLIP"
"AndyTang15/FLAG3Dv2" -> "Yxxxb/LAVT-RS"
"teknium1/transformers-gptq-quant" -> "CarperAI/treasure_trove"
"junyangwang0410/AMBER" -> "RUCAIBox/POPE"
"junyangwang0410/AMBER" -> "tianyi-lab/HallusionBench"
"junyangwang0410/AMBER" -> "AoiDragon/POPE"
"junyangwang0410/AMBER" -> "yfzhang114/LLaVA-Align"
"junyangwang0410/AMBER" -> "wenhuang2000/VHTest"
"junyangwang0410/AMBER" -> "YiyangZhou/CSR"
"junyangwang0410/AMBER" -> "YiyangZhou/LURE"
"junyangwang0410/AMBER" -> "FuxiaoLiu/LRV-Instruction"
"junyangwang0410/AMBER" -> "hendryx-scale/mhal-detect"
"agentic-learning-ai-lab/lifelong-memory" -> "kkahatapitiya/LangRepo"
"kkahatapitiya/LangRepo" -> "kahnchana/mvu"
"jonathan-roberts1/charting-new-territories" -> "NJU-LHRS/ScoreRS"
"jonathan-roberts1/charting-new-territories" -> "xiong-zhitong/GeoLB-SigLIP"
"jonathan-roberts1/charting-new-territories" -> "jonathan-roberts1/GPT4GEO"
"kahnchana/mvu" -> "kkahatapitiya/LangRepo"
"kahnchana/mvu" -> "kahnchana/clippy"
"khuangaf/CHOCOLATE" -> "khuangaf/ZeroFEC"
"zhengbw0324/LC-Rec" -> "TengShi-RUC/UniSAR"
"zhengbw0324/LC-Rec" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"zhengbw0324/LC-Rec" -> "lyingCS/UOEP"
"alibaba/conv-llava" -> "LeapLabTHU/DAT-Jittor" ["e"=1]
"KID-22/Source-Bias" -> "KID-22/Cocktail"
"TengShi-RUC/UniSAR" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"TengShi-RUC/UniSAR" -> "zhengbw0324/LC-Rec"
"TengShi-RUC/UniSAR" -> "lyingCS/UOEP"
"Yxxxb/LAVT-RS" -> "zhang9302002/Flash-VStream"
"Yxxxb/LAVT-RS" -> "AndyTang15/FLAG3Dv2"
"Yxxxb/LAVT-RS" -> "AndyTang15/FLAG3D"
"Yxxxb/LAVT-RS" -> "shiyi-zh0408/NAE_CVPR2024"
"KID-22/Cocktail" -> "KID-22/Source-Bias"
"DAMO-NLP-SG/VideoLLaMA2" -> "DAMO-NLP-SG/VideoLLaMA3"
"DAMO-NLP-SG/VideoLLaMA2" -> "DAMO-NLP-SG/Video-LLaMA"
"DAMO-NLP-SG/VideoLLaMA2" -> "PKU-YuanGroup/Video-LLaVA"
"DAMO-NLP-SG/VideoLLaMA2" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"DAMO-NLP-SG/VideoLLaMA2" -> "mbzuai-oryx/Video-ChatGPT"
"DAMO-NLP-SG/VideoLLaMA2" -> "LLaVA-VL/LLaVA-NeXT"
"DAMO-NLP-SG/VideoLLaMA2" -> "magic-research/PLLaVA"
"DAMO-NLP-SG/VideoLLaMA2" -> "OpenGVLab/InternVideo"
"DAMO-NLP-SG/VideoLLaMA2" -> "EvolvingLMMs-Lab/LongVA"
"DAMO-NLP-SG/VideoLLaMA2" -> "RenShuhuai-Andy/TimeChat"
"DAMO-NLP-SG/VideoLLaMA2" -> "MME-Benchmarks/Video-MME"
"DAMO-NLP-SG/VideoLLaMA2" -> "rese1f/MovieChat"
"DAMO-NLP-SG/VideoLLaMA2" -> "PKU-YuanGroup/Chat-UniVi" ["e"=1]
"DAMO-NLP-SG/VideoLLaMA2" -> "OpenGVLab/Ask-Anything"
"DAMO-NLP-SG/VideoLLaMA2" -> "mbzuai-oryx/VideoGPT-plus"
"allenai/molmo" -> "2U1/Molmo-Finetune"
"allenai/molmo" -> "MMMU-Benchmark/MMMU"
"allenai/molmo" -> "allenai/unified-io-2" ["e"=1]
"allenai/molmo" -> "facebookresearch/perception_models" ["e"=1]
"allenai/molmo" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"mustafaaljadery/llama3v" -> "siddrrsh/ambientGPT" ["e"=1]
"mustafaaljadery/llama3v" -> "mbzuai-oryx/LLaVA-pp"
"QwenLM/Qwen2.5-VL" -> "OpenGVLab/InternVL"
"QwenLM/Qwen2.5-VL" -> "QwenLM/Qwen-VL"
"QwenLM/Qwen2.5-VL" -> "QwenLM/Qwen3" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "LLaVA-VL/LLaVA-NeXT"
"QwenLM/Qwen2.5-VL" -> "om-ai-lab/VLM-R1"
"QwenLM/Qwen2.5-VL" -> "haotian-liu/LLaVA"
"QwenLM/Qwen2.5-VL" -> "modelscope/ms-swift" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"QwenLM/Qwen2.5-VL" -> "OpenBMB/MiniCPM-o"
"QwenLM/Qwen2.5-VL" -> "Deep-Agent/R1-V"
"QwenLM/Qwen2.5-VL" -> "deepseek-ai/Janus" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "salesforce/LAVIS" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "QwenLM/Qwen" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "QwenLM/Qwen-Agent" ["e"=1]
"QwenLM/Qwen2.5-VL" -> "open-compass/VLMEvalKit"
"IVG-SZ/Flash-VStream" -> "IVGSZ/Flash-VStream"
"IVG-SZ/Flash-VStream" -> "AndyTang15/FLAG3Dv2"
"IVGSZ/Flash-VStream" -> "IVG-SZ/Flash-VStream"
"IVGSZ/Flash-VStream" -> "showlab/videollm-online"
"IVGSZ/Flash-VStream" -> "shiyi-zh0408/NAE_CVPR2024"
"IVGSZ/Flash-VStream" -> "Yxxxb/VoCo-LLaMA"
"IVGSZ/Flash-VStream" -> "zhang9302002/Flash-VStream"
"IVGSZ/Flash-VStream" -> "Tengbo-Yu/AnyBimanual"
"IVGSZ/Flash-VStream" -> "Mark12Ding/Dispider"
"IVGSZ/Flash-VStream" -> "Vision-CAIR/LongVU"
"IVGSZ/Flash-VStream" -> "SuleBai/SC-CLIP"
"IVGSZ/Flash-VStream" -> "hmxiong/StreamChat"
"IVGSZ/Flash-VStream" -> "ChangyuanWang17/QVLM"
"IVGSZ/Flash-VStream" -> "Jixuan-Fan/Momentum-GS" ["e"=1]
"IVGSZ/Flash-VStream" -> "AndyTang15/FLAG3Dv2"
"IVGSZ/Flash-VStream" -> "Yxxxb/LAVT-RS"
"IVGSZ/Flash-VStream" -> "yaolinli/TimeChat-Online"
"YueFan1014/VideoAgent" -> "Ziyang412/VideoTree"
"YueFan1014/VideoAgent" -> "wxh1996/VideoAgent"
"YueFan1014/VideoAgent" -> "Leon1207/Video-RAG-master"
"YueFan1014/VideoAgent" -> "bytedance/tarsier"
"PKU-YuanGroup/LLaVA-CoT" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"PKU-YuanGroup/LLaVA-CoT" -> "Deep-Agent/R1-V"
"PKU-YuanGroup/LLaVA-CoT" -> "LLaVA-VL/LLaVA-NeXT"
"PKU-YuanGroup/LLaVA-CoT" -> "open-compass/VLMEvalKit"
"PKU-YuanGroup/LLaVA-CoT" -> "om-ai-lab/VLM-R1"
"PKU-YuanGroup/LLaVA-CoT" -> "TideDra/lmm-r1"
"PKU-YuanGroup/LLaVA-CoT" -> "Osilly/Vision-R1"
"PKU-YuanGroup/LLaVA-CoT" -> "Liuziyu77/Visual-RFT"
"PKU-YuanGroup/LLaVA-CoT" -> "PKU-YuanGroup/Video-LLaVA"
"PKU-YuanGroup/LLaVA-CoT" -> "PKU-YuanGroup/MoE-LLaVA"
"PKU-YuanGroup/LLaVA-CoT" -> "baaivision/Emu3" ["e"=1]
"PKU-YuanGroup/LLaVA-CoT" -> "hiyouga/EasyR1" ["e"=1]
"PKU-YuanGroup/LLaVA-CoT" -> "AIDC-AI/Marco-o1" ["e"=1]
"PKU-YuanGroup/LLaVA-CoT" -> "mbzuai-oryx/LlamaV-o1"
"PKU-YuanGroup/LLaVA-CoT" -> "ModalMinds/MM-EUREKA"
"cambrian-mllm/cambrian" -> "LLaVA-VL/LLaVA-NeXT"
"cambrian-mllm/cambrian" -> "open-compass/VLMEvalKit"
"cambrian-mllm/cambrian" -> "facebookresearch/chameleon" ["e"=1]
"cambrian-mllm/cambrian" -> "baaivision/Emu3" ["e"=1]
"cambrian-mllm/cambrian" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"cambrian-mllm/cambrian" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"cambrian-mllm/cambrian" -> "FoundationVision/LlamaGen" ["e"=1]
"cambrian-mllm/cambrian" -> "NVlabs/VILA"
"cambrian-mllm/cambrian" -> "InternLM/InternLM-XComposer"
"cambrian-mllm/cambrian" -> "OpenGVLab/InternVL"
"cambrian-mllm/cambrian" -> "baaivision/Emu" ["e"=1]
"cambrian-mllm/cambrian" -> "dvlab-research/MGM"
"cambrian-mllm/cambrian" -> "showlab/Show-o" ["e"=1]
"cambrian-mllm/cambrian" -> "tsb0601/MMVP"
"cambrian-mllm/cambrian" -> "Liuziyu77/Visual-RFT"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "daixiangzi/Awesome-Token-Compress"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "luogen1996/LLaVA-HR"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "pkunlp-icler/FastV"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "lxa9867/Awesome-Autoregressive-Visual-Generation" ["e"=1]
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "swordlidev/Evaluation-Multimodal-LLMs-Survey"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "shufangxun/LLaVA-MoD" ["e"=1]
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "Wang-Xiaodong1899/CVPR25-MLLM-Paper-List"
"swordlidev/Efficient-Multimodal-LLMs-Survey" -> "showlab/Awesome-Unified-Multimodal-Models" ["e"=1]
"HJYao00/DenseConnector" -> "Yxxxb/VoCo-LLaMA"
"HJYao00/DenseConnector" -> "mrwu-mac/ControlMLLM"
"HJYao00/DenseConnector" -> "HJYao00/Side4Video"
"ywh187/FitPrune" -> "LaVi-Lab/AIM"
"NVlabs/EAGLE" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"NVlabs/EAGLE" -> "open-compass/VLMEvalKit"
"NVlabs/EAGLE" -> "baaivision/EVE" ["e"=1]
"NVlabs/EAGLE" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"NVlabs/EAGLE" -> "cambrian-mllm/cambrian"
"NVlabs/EAGLE" -> "thunlp/LLaVA-UHD"
"NVlabs/EAGLE" -> "Windsander/ADI-Stable-Diffusion" ["e"=1]
"NVlabs/EAGLE" -> "ByungKwanLee/MoAI" ["e"=1]
"NVlabs/EAGLE" -> "tsb0601/MMVP"
"NVlabs/EAGLE" -> "FoundationVision/Groma" ["e"=1]
"NVlabs/EAGLE" -> "mbzuai-oryx/groundingLMM"
"NVlabs/EAGLE" -> "LLaVA-VL/LLaVA-NeXT"
"NVlabs/EAGLE" -> "HJYao00/DenseConnector"
"NVlabs/EAGLE" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"NVlabs/EAGLE" -> "showlab/Show-o" ["e"=1]
"ZrrSkywalker/MAVIS" -> "HZQ950419/Math-LLaVA"
"ZrrSkywalker/MAVIS" -> "ZrrSkywalker/MathVerse"
"ZrrSkywalker/MAVIS" -> "pengshuai-rin/MultiMath"
"JusticeFighterDance/JusticeFighter110" -> "william-sto/JusticeNeverTooLate"
"JusticeFighterDance/JusticeFighter110" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"JusticeFighterDance/JusticeFighter110" -> "TideDra/lmm-r1"
"JusticeFighterDance/JusticeFighter110" -> "ByteDance-Seed/Triton-distributed" ["e"=1]
"Theia-4869/FasterVLM" -> "Gumpest/SparseVLMs"
"Theia-4869/FasterVLM" -> "KD-TAO/DyCoke"
"mlfoundations/MINT-1T" -> "OpenGVLab/OmniCorpus"
"mlfoundations/MINT-1T" -> "MMMU-Benchmark/MMMU"
"mlfoundations/MINT-1T" -> "cambrian-mllm/cambrian"
"mlfoundations/MINT-1T" -> "baaivision/DenseFusion"
"mlfoundations/MINT-1T" -> "BAAI-DCAI/Bunny"
"mlfoundations/MINT-1T" -> "facebookresearch/chameleon" ["e"=1]
"mlfoundations/MINT-1T" -> "UCSC-VLAA/Recap-DataComp-1B" ["e"=1]
"mlfoundations/MINT-1T" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"mlfoundations/MINT-1T" -> "zzxslp/SoM-LLaVA"
"mlfoundations/MINT-1T" -> "DAMO-NLP-SG/multimodal_textbook" ["e"=1]
"mlfoundations/MINT-1T" -> "open-compass/VLMEvalKit"
"mlfoundations/MINT-1T" -> "RUCAIBox/POPE"
"mlfoundations/MINT-1T" -> "snap-research/Panda-70M" ["e"=1]
"mlfoundations/MINT-1T" -> "JUNJIE99/MLVU"
"daixiangzi/Awesome-Token-Compress" -> "pkunlp-icler/FastV"
"daixiangzi/Awesome-Token-Compress" -> "Theia-4869/FasterVLM"
"daixiangzi/Awesome-Token-Compress" -> "Gumpest/SparseVLMs"
"daixiangzi/Awesome-Token-Compress" -> "dvlab-research/VisionZip"
"daixiangzi/Awesome-Token-Compress" -> "42Shawn/LLaVA-PruMerge"
"daixiangzi/Awesome-Token-Compress" -> "CircleRadon/TokenPacker" ["e"=1]
"daixiangzi/Awesome-Token-Compress" -> "Cooperx521/PyramidDrop"
"daixiangzi/Awesome-Token-Compress" -> "ZLKong/awesome-token-compression-reduction"
"daixiangzi/Awesome-Token-Compress" -> "swordlidev/Efficient-Multimodal-LLMs-Survey"
"daixiangzi/Awesome-Token-Compress" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"daixiangzi/Awesome-Token-Compress" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"daixiangzi/Awesome-Token-Compress" -> "luogen1996/LLaVA-HR"
"daixiangzi/Awesome-Token-Compress" -> "ModalMinds/MM-EUREKA"
"daixiangzi/Awesome-Token-Compress" -> "xuyang-liu16/Awesome-Token-level-Model-Compression" ["e"=1]
"daixiangzi/Awesome-Token-Compress" -> "Vision-CAIR/LongVU"
"baaivision/DIVA" -> "showlab/Awesome-Unified-Multimodal-Models" ["e"=1]
"baaivision/DIVA" -> "tsb0601/MMVP"
"baaivision/DIVA" -> "baaivision/EVE" ["e"=1]
"Yushi-Hu/VisualSketchpad" -> "FanqingM/R1-Multimodal-Journey"
"Vision-CAIR/LongVU" -> "VectorSpaceLab/Video-XL"
"Vision-CAIR/LongVU" -> "egoschema/EgoSchema"
"Vision-CAIR/LongVU" -> "OpenGVLab/VideoChat-Flash"
"Vision-CAIR/LongVU" -> "EvolvingLMMs-Lab/LongVA"
"Vision-CAIR/LongVU" -> "IVGSZ/Flash-VStream"
"Vision-CAIR/LongVU" -> "longvideobench/LongVideoBench"
"Vision-CAIR/LongVU" -> "rese1f/MovieChat"
"Vision-CAIR/LongVU" -> "Ziyang412/VideoTree"
"Vision-CAIR/LongVU" -> "bigai-nlco/VideoLLaMB"
"Vision-CAIR/LongVU" -> "JUNJIE99/MLVU"
"Vision-CAIR/LongVU" -> "TimeMarker-LLM/TimeMarker"
"Vision-CAIR/LongVU" -> "llyx97/TempCompass"
"Vision-CAIR/LongVU" -> "boheumd/MA-LMM"
"Vision-CAIR/LongVU" -> "daixiangzi/Awesome-Token-Compress"
"Vision-CAIR/LongVU" -> "MME-Benchmarks/Video-MME"
"dvlab-research/Lyra" -> "Falling-dow/Unsupervised-Image-Enhancement-with-CNN-and-GAN" ["e"=1]
"dvlab-research/Lyra" -> "Davion-Liu/Awesome-Robustness-in-Information-Retrieval"
"showlab/videollm-online" -> "IVGSZ/Flash-VStream"
"showlab/videollm-online" -> "Mark12Ding/Dispider"
"showlab/videollm-online" -> "EvolvingLMMs-Lab/LongVA"
"showlab/videollm-online" -> "THUNLP-MT/StreamingBench" ["e"=1]
"showlab/videollm-online" -> "OpenGVLab/VideoChat-Flash"
"showlab/videollm-online" -> "hmxiong/StreamChat"
"showlab/videollm-online" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"showlab/videollm-online" -> "RenShuhuai-Andy/TimeChat"
"showlab/videollm-online" -> "boheumd/MA-LMM"
"showlab/videollm-online" -> "MME-Benchmarks/Video-MME"
"showlab/videollm-online" -> "Vision-CAIR/LongVU"
"showlab/videollm-online" -> "JoeLeelyf/OVO-Bench"
"showlab/videollm-online" -> "DAMO-NLP-SG/VideoLLaMA2"
"showlab/videollm-online" -> "TencentARC/ST-LLM"
"showlab/videollm-online" -> "showlab/livecc"
"zjunlp/OneGen" -> "zjunlp/Deco"
"gordonhu608/MQT-LLaVA" -> "42Shawn/LLaVA-PruMerge"
"Yxxxb/VoCo-LLaMA" -> "shiyi-zh0408/NAE_CVPR2024"
"Yxxxb/VoCo-LLaMA" -> "AndyTang15/FLAG3Dv2"
"Yxxxb/VoCo-LLaMA" -> "Yxxxb/LAVT-RS"
"Yxxxb/VoCo-LLaMA" -> "SuleBai/SC-CLIP"
"Yxxxb/VoCo-LLaMA" -> "Tengbo-Yu/AnyBimanual"
"Yxxxb/VoCo-LLaMA" -> "IVGSZ/Flash-VStream"
"Yxxxb/VoCo-LLaMA" -> "EternalEvan/DPMesh"
"Yxxxb/VoCo-LLaMA" -> "Gumpest/SparseVLMs"
"Yxxxb/VoCo-LLaMA" -> "GuanxingLu/vlarl"
"Yxxxb/VoCo-LLaMA" -> "42Shawn/LLaVA-PruMerge"
"Yxxxb/VoCo-LLaMA" -> "HJYao00/DenseConnector"
"MCG-NJU/p-MoD" -> "MCG-NJU/CaReBench"
"zhangfaen/finetune-Qwen2-VL" -> "2U1/Qwen2-VL-Finetune"
"zhangfaen/finetune-Qwen2-VL" -> "wjbmattingly/qwen2-vl-finetune-huggingface"
"zhangfaen/finetune-Qwen2-VL" -> "zhangfaen/finetune-Qwen2.5-VL"
"zhangfaen/finetune-Qwen2-VL" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"zhangfaen/finetune-Qwen2-VL" -> "Fancy-MLLM/R1-Onevision"
"zhangfaen/finetune-Qwen2-VL" -> "sandy1990418/Finetune-Qwen2.5-VL"
"zhangfaen/finetune-Qwen2-VL" -> "OpenGVLab/VideoChat-Flash"
"Ziyang412/VideoTree" -> "CeeZh/LLoVi"
"Ziyang412/VideoTree" -> "wxh1996/VideoAgent"
"Ziyang412/VideoTree" -> "kkahatapitiya/LangRepo"
"Ziyang412/VideoTree" -> "Yui010206/SeViLA"
"MME-Benchmarks/Video-MME" -> "VITA-MLLM/Woodpecker"
"MME-Benchmarks/Video-MME" -> "EvolvingLMMs-Lab/LongVA"
"MME-Benchmarks/Video-MME" -> "shenyunhang/APE" ["e"=1]
"MME-Benchmarks/Video-MME" -> "JUNJIE99/MLVU"
"MME-Benchmarks/Video-MME" -> "VITA-MLLM/Long-VITA"
"MME-Benchmarks/Video-MME" -> "OpenGVLab/VideoChat-Flash"
"MME-Benchmarks/Video-MME" -> "Ziyang412/VideoTree"
"MME-Benchmarks/Video-MME" -> "TencentARC/ST-LLM"
"MME-Benchmarks/Video-MME" -> "VITA-MLLM/VITA" ["e"=1]
"MME-Benchmarks/Video-MME" -> "RenShuhuai-Andy/TimeChat"
"MME-Benchmarks/Video-MME" -> "magic-research/PLLaVA"
"MME-Benchmarks/Video-MME" -> "zhourax/VEGA"
"MME-Benchmarks/Video-MME" -> "DAMO-NLP-SG/VideoLLaMA2"
"MME-Benchmarks/Video-MME" -> "rese1f/MovieChat"
"MME-Benchmarks/Video-MME" -> "longvideobench/LongVideoBench"
"mrwu-mac/ControlMLLM" -> "Cooperx521/PyramidDrop"
"mrwu-mac/ControlMLLM" -> "HJYao00/DenseConnector"
"mrwu-mac/ControlMLLM" -> "saccharomycetes/mllms_know"
"mrwu-mac/ControlMLLM" -> "wusize/F-LMM"
"mrwu-mac/ControlMLLM" -> "LALBJ/PAI"
"EvolvingLMMs-Lab/LongVA" -> "VectorSpaceLab/Video-XL"
"EvolvingLMMs-Lab/LongVA" -> "JUNJIE99/MLVU"
"EvolvingLMMs-Lab/LongVA" -> "MME-Benchmarks/Video-MME"
"EvolvingLMMs-Lab/LongVA" -> "RifleZhang/LLaVA-Hound-DPO"
"EvolvingLMMs-Lab/LongVA" -> "FreedomIntelligence/LongLLaVA"
"EvolvingLMMs-Lab/LongVA" -> "RenShuhuai-Andy/TimeChat"
"EvolvingLMMs-Lab/LongVA" -> "Ziyang412/VideoTree"
"EvolvingLMMs-Lab/LongVA" -> "magic-research/PLLaVA"
"EvolvingLMMs-Lab/LongVA" -> "longvideobench/LongVideoBench"
"EvolvingLMMs-Lab/LongVA" -> "Vision-CAIR/LongVU"
"EvolvingLMMs-Lab/LongVA" -> "TencentARC/ST-LLM"
"EvolvingLMMs-Lab/LongVA" -> "OpenGVLab/VideoChat-Flash"
"EvolvingLMMs-Lab/LongVA" -> "gyxxyg/VTG-LLM"
"EvolvingLMMs-Lab/LongVA" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"EvolvingLMMs-Lab/LongVA" -> "EvolvingLMMs-Lab/EgoLife"
"bytedance/tarsier" -> "magic-research/PLLaVA"
"bytedance/tarsier" -> "Ziyang412/VideoTree"
"bytedance/tarsier" -> "mbzuai-oryx/VideoGPT-plus"
"bytedance/tarsier" -> "OpenGVLab/VideoChat-Flash"
"bytedance/tarsier" -> "MME-Benchmarks/Video-MME"
"bytedance/tarsier" -> "RifleZhang/LLaVA-Hound-DPO"
"bytedance/tarsier" -> "DAMO-NLP-SG/VideoLLaMA3"
"bytedance/tarsier" -> "EvolvingLMMs-Lab/LongVA"
"bytedance/tarsier" -> "IVGSZ/Flash-VStream"
"bytedance/tarsier" -> "QQ-MM/Video-CCAM"
"bytedance/tarsier" -> "VectorSpaceLab/Video-XL"
"bytedance/tarsier" -> "Vision-CAIR/LongVU"
"bytedance/tarsier" -> "YueFan1014/VideoAgent"
"bytedance/tarsier" -> "TimeMarker-LLM/TimeMarker"
"bytedance/tarsier" -> "egoschema/EgoSchema"
"wxh1996/VideoAgent" -> "Ziyang412/VideoTree"
"zjysteven/lmms-finetune" -> "TinyLLaVA/TinyLLaVA_Factory"
"zjysteven/lmms-finetune" -> "xiaoachen98/Open-LLaVA-NeXT" ["e"=1]
"zjysteven/lmms-finetune" -> "bfshi/scaling_on_scales"
"zjysteven/lmms-finetune" -> "Coobiw/MPP-LLaVA"
"VectorSpaceLab/Video-XL" -> "JUNJIE99/MLVU"
"VectorSpaceLab/Video-XL" -> "EvolvingLMMs-Lab/LongVA"
"VectorSpaceLab/Video-XL" -> "Vision-CAIR/LongVU"
"VectorSpaceLab/Video-XL" -> "OpenGVLab/VideoChat-Flash"
"VectorSpaceLab/Video-XL" -> "MME-Benchmarks/Video-MME"
"VectorSpaceLab/Video-XL" -> "rese1f/MovieChat"
"VectorSpaceLab/Video-XL" -> "yeliudev/VideoMind"
"VectorSpaceLab/Video-XL" -> "FreedomIntelligence/LongLLaVA"
"VectorSpaceLab/Video-XL" -> "IVGSZ/Flash-VStream"
"VectorSpaceLab/Video-XL" -> "bytedance/tarsier"
"VectorSpaceLab/Video-XL" -> "ttengwang/Awesome_Long_Form_Video_Understanding"
"VectorSpaceLab/Video-XL" -> "DAMO-NLP-SG/VideoLLaMA3"
"VectorSpaceLab/Video-XL" -> "Ziyang412/VideoTree"
"VectorSpaceLab/Video-XL" -> "RenShuhuai-Andy/TimeChat"
"VectorSpaceLab/Video-XL" -> "TimeMarker-LLM/TimeMarker"
"mc-lan/Text4Seg" -> "wusize/F-LMM"
"mc-lan/Text4Seg" -> "berkeley-hipie/segllm"
"mc-lan/Text4Seg" -> "xuliu-cyber/RSUniVLM"
"Leon1207/Video-RAG-master" -> "MAC-AutoML/QuoTA"
"Leon1207/Video-RAG-master" -> "VITA-MLLM/Sparrow"
"Leon1207/Video-RAG-master" -> "VITA-MLLM/Long-VITA"
"Leon1207/Video-RAG-master" -> "Kwai-YuanQi/MM-RLHF"
"Leon1207/Video-RAG-master" -> "Ziyang412/VideoTree"
"Leon1207/Video-RAG-master" -> "VITA-MLLM/VITA-Audio"
"Leon1207/Video-RAG-master" -> "yongliang-wu/NumPro" ["e"=1]
"AIDC-AI/Ovis" -> "open-compass/VLMEvalKit"
"AIDC-AI/Ovis" -> "showlab/Show-o" ["e"=1]
"AIDC-AI/Ovis" -> "bfshi/scaling_on_scales"
"AIDC-AI/Ovis" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"AIDC-AI/Ovis" -> "Oryx-mllm/Oryx"
"AIDC-AI/Ovis" -> "FanqingM/R1-Multimodal-Journey"
"AIDC-AI/Ovis" -> "THUDM/CogVLM2"
"AIDC-AI/Ovis" -> "LLaVA-VL/LLaVA-NeXT"
"AIDC-AI/Ovis" -> "Liuziyu77/Visual-RFT"
"AIDC-AI/Ovis" -> "cambrian-mllm/cambrian"
"AIDC-AI/Ovis" -> "InternLM/InternLM-XComposer"
"AIDC-AI/Ovis" -> "dongyh20/Insight-V"
"AIDC-AI/Ovis" -> "AIDC-AI/Parrot" ["e"=1]
"AIDC-AI/Ovis" -> "VITA-MLLM/VITA" ["e"=1]
"AIDC-AI/Ovis" -> "ModalMinds/MM-EUREKA"
"Bujiazi/ByTheWay" -> "beichenzbc/BoostStep"
"gyxxyg/VTG-LLM" -> "gyxxyg/TRACE"
"gyxxyg/VTG-LLM" -> "yellow-binary-tree/HawkEye"
"gyxxyg/VTG-LLM" -> "sudo-Boris/mr-Blip" ["e"=1]
"gyxxyg/VTG-LLM" -> "huangb23/VTimeLLM"
"gyxxyg/VTG-LLM" -> "minghangz/TFVTG"
"gyxxyg/VTG-LLM" -> "NVlabs/LITA"
"gyxxyg/VTG-LLM" -> "Becomebright/GroundVQA" ["e"=1]
"gyxxyg/VTG-LLM" -> "RenShuhuai-Andy/TimeChat"
"gyxxyg/VTG-LLM" -> "TimeMarker-LLM/TimeMarker"
"gyxxyg/VTG-LLM" -> "WHB139426/Grounded-Video-LLM"
"rhymes-ai/Aria" -> "rhymes-ai/Allegro" ["e"=1]
"rhymes-ai/Aria" -> "kijai/ComfyUI-MochiWrapper" ["e"=1]
"rhymes-ai/Aria" -> "MME-Benchmarks/Video-MME"
"rhymes-ai/Aria" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"rhymes-ai/Aria" -> "EvolvingLMMs-Lab/LongVA"
"rhymes-ai/Aria" -> "LLaVA-VL/LLaVA-NeXT"
"rhymes-ai/Aria" -> "facebookresearch/chameleon" ["e"=1]
"rhymes-ai/Aria" -> "bytedance/tarsier"
"rhymes-ai/Aria" -> "PKU-YuanGroup/LLaVA-CoT"
"rhymes-ai/Aria" -> "NVlabs/VILA"
"rhymes-ai/Aria" -> "longvideobench/LongVideoBench"
"rhymes-ai/Aria" -> "apple/ml-aim" ["e"=1]
"rhymes-ai/Aria" -> "DAMO-NLP-SG/VideoLLaMA2"
"rhymes-ai/Aria" -> "DAMO-NLP-SG/multimodal_textbook" ["e"=1]
"rhymes-ai/Aria" -> "EvolvingLMMs-Lab/lmms-eval" ["e"=1]
"FreedomIntelligence/LongLLaVA" -> "EvolvingLMMs-Lab/LongVA"
"yfzhang114/SliME" -> "MME-Benchmarks/MME-RealWorld"
"yfzhang114/SliME" -> "ParadoxZW/LLaVA-UHD-Better"
"yfzhang114/SliME" -> "Kwai-YuanQi/MM-RLHF"
"gyxxyg/TRACE" -> "gyxxyg/VTG-LLM"
"gyxxyg/TRACE" -> "yongliang-wu/NumPro" ["e"=1]
"THUDM/LVBench" -> "Share14/ShareGemini"
"rese1f/aurora" -> "Espere-1119-Song/Video-MMLU"
"rese1f/aurora" -> "Share14/ShareGemini"
"ChangyuanWang17/QVLM" -> "ChangyuanWang17/APQ-DM"
"ChangyuanWang17/QVLM" -> "AndyTang15/FLAG3Dv2"
"ChangyuanWang17/QVLM" -> "Tengbo-Yu/AnyBimanual"
"ChangyuanWang17/QVLM" -> "Yxxxb/LAVT-RS"
"ChangyuanWang17/QVLM" -> "shiyi-zh0408/NAE_CVPR2024"
"ChangyuanWang17/QVLM" -> "EternalEvan/DPMesh"
"ChangyuanWang17/QVLM" -> "zhang9302002/Flash-VStream"
"Tengbo-Yu/AnyBimanual" -> "markusgrotz/peract_bimanual" ["e"=1]
"Tengbo-Yu/AnyBimanual" -> "GuanxingLu/vlarl"
"Tengbo-Yu/AnyBimanual" -> "AndyTang15/FLAG3Dv2"
"Tengbo-Yu/AnyBimanual" -> "ManiCM-fast/ManiCM" ["e"=1]
"zjysteven/VLM-Visualizer" -> "zhangbaijin/From-Redundancy-to-Relevance"
"zjysteven/VLM-Visualizer" -> "IntelLabs/lvlm-interpret"
"zjysteven/VLM-Visualizer" -> "saccharomycetes/mllms_know"
"zjysteven/VLM-Visualizer" -> "junyangwang0410/Attention-LLaVA"
"dongyh20/Insight-V" -> "RUCAIBox/Virgo"
"dongyh20/Insight-V" -> "RLHF-V/RLHF-V"
"dongyh20/Insight-V" -> "yihedeng9/STIC"
"dongyh20/Insight-V" -> "deepcs233/Visual-CoT"
"dongyh20/Insight-V" -> "FanqingM/R1-Multimodal-Journey"
"dongyh20/Insight-V" -> "mbzuai-oryx/LlamaV-o1"
"dongyh20/Insight-V" -> "dongyh20/Chain-of-Spot"
"dongyh20/Insight-V" -> "jungao1106/ICoT"
"dongyh20/Insight-V" -> "njucckevin/MM-Self-Improve"
"gls0425/LinVT" -> "SCZwangxiao/video-FlexReduc"
"YUCHEN005/STAR-Adapt" -> "YUCHEN005/GenTranslate"
"YUCHEN005/STAR-Adapt" -> "YUCHEN005/RobustGER"
"njucckevin/MM-Self-Improve" -> "Liac-li/MM-self-improve-qwen2vl"
"2U1/Qwen2-VL-Finetune" -> "zhangfaen/finetune-Qwen2-VL"
"2U1/Qwen2-VL-Finetune" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"2U1/Qwen2-VL-Finetune" -> "Liuziyu77/Visual-RFT"
"2U1/Qwen2-VL-Finetune" -> "sandy1990418/Finetune-Qwen2.5-VL"
"2U1/Qwen2-VL-Finetune" -> "LLaVA-VL/LLaVA-NeXT"
"2U1/Qwen2-VL-Finetune" -> "Fancy-MLLM/R1-Onevision"
"2U1/Qwen2-VL-Finetune" -> "QwenLM/Qwen2.5-VL"
"2U1/Qwen2-VL-Finetune" -> "FanqingM/R1-Multimodal-Journey"
"2U1/Qwen2-VL-Finetune" -> "hiyouga/EasyR1" ["e"=1]
"2U1/Qwen2-VL-Finetune" -> "2U1/Llama3.2-Vision-Finetune"
"2U1/Qwen2-VL-Finetune" -> "zhangfaen/finetune-Qwen2.5-VL"
"2U1/Qwen2-VL-Finetune" -> "open-compass/VLMEvalKit"
"2U1/Qwen2-VL-Finetune" -> "TideDra/lmm-r1"
"2U1/Qwen2-VL-Finetune" -> "om-ai-lab/VLM-R1"
"2U1/Qwen2-VL-Finetune" -> "OpenGVLab/VideoChat-Flash"
"Alpha-Innovator/Chimera" -> "Alpha-Innovator/AdaptiveDiffusion"
"Alpha-Innovator/Chimera" -> "HankYe/AdaptiveDiffusion"
"Alpha-Innovator/Chimera" -> "Alpha-Innovator/OmniCaptioner"
"Alpha-Innovator/Chimera" -> "ch3cook-fdu/Vote2Cap-DETR"
"Alpha-Innovator/Chimera" -> "Alpha-Innovator/SurveyForge"
"Alpha-Innovator/AdaptiveDiffusion" -> "Alpha-Innovator/Chimera"
"Alpha-Innovator/AdaptiveDiffusion" -> "HankYe/AdaptiveDiffusion"
"Alpha-Innovator/AdaptiveDiffusion" -> "Alpha-Innovator/SurveyForge"
"Alpha-Innovator/AdaptiveDiffusion" -> "Alpha-Innovator/DocGenome"
"Alpha-Innovator/AdaptiveDiffusion" -> "Alpha-Innovator/Dolphin"
"zli12321/Vision-Language-Models-Overview" -> "zli12321/qa_metrics"
"zli12321/Vision-Language-Models-Overview" -> "zli12321/VideoHallu"
"XJF2332/GOT-OCR-2-GUI" -> "1694439208/GOT-OCR-Inference"
"shengliu66/VTI" -> "ustc-hyin/ClearSight"
"shengliu66/VTI" -> "TianyunYoung/Hallucination-Attribution"
"zhang9302002/Flash-VStream" -> "Yxxxb/LAVT-RS"
"zhang9302002/Flash-VStream" -> "AndyTang15/FLAG3Dv2"
"zhang9302002/Flash-VStream" -> "shiyi-zh0408/NAE_CVPR2024"
"Oryx-mllm/Oryx" -> "Ola-Omni/Ola"
"Oryx-mllm/Oryx" -> "shiml20/FlowTurbo"
"Oryx-mllm/Oryx" -> "dongyh20/Insight-V"
"dvlab-research/VisionZip" -> "pkunlp-icler/FastV"
"dvlab-research/VisionZip" -> "Gumpest/SparseVLMs"
"dvlab-research/VisionZip" -> "daixiangzi/Awesome-Token-Compress"
"dvlab-research/VisionZip" -> "dvlab-research/Lyra"
"dvlab-research/VisionZip" -> "Theia-4869/FasterVLM"
"dvlab-research/VisionZip" -> "Yangsenqiao/ULDA"
"dvlab-research/VisionZip" -> "42Shawn/LLaVA-PruMerge"
"dvlab-research/VisionZip" -> "dvlab-research/Step-DPO" ["e"=1]
"dvlab-research/VisionZip" -> "Cooperx521/PyramidDrop"
"dvlab-research/VisionZip" -> "Yxxxb/VoCo-LLaMA"
"dvlab-research/VisionZip" -> "saccharomycetes/mllms_know"
"dvlab-research/VisionZip" -> "ictnlp/LLaVA-Mini" ["e"=1]
"dvlab-research/VisionZip" -> "KD-TAO/DyCoke"
"dvlab-research/VisionZip" -> "dvlab-research/LLaMA-VID"
"OpenGVLab/OmniCorpus" -> "OpenGVLab/MM-NIAH"
"OpenGVLab/OmniCorpus" -> "mlfoundations/MINT-1T"
"OpenGVLab/OmniCorpus" -> "BAAI-DCAI/Visual-Instruction-Tuning"
"OpenGVLab/OmniCorpus" -> "OpenGVLab/all-seeing"
"OpenGVLab/OmniCorpus" -> "thunlp/LLaVA-UHD"
"OpenGVLab/OmniCorpus" -> "baaivision/DenseFusion"
"OpenGVLab/OmniCorpus" -> "baaivision/EVE" ["e"=1]
"OpenGVLab/OmniCorpus" -> "FreedomIntelligence/ALLaVA"
"OpenGVLab/OmniCorpus" -> "VisionXLab/STAR-MMRotate" ["e"=1]
"OpenGVLab/OmniCorpus" -> "X2FD/LVIS-INSTRUCT4V"
"NiuTrans/Vision-LLM-Alignment" -> "wangclnlp/DeepSpeed-Chat-Extension"
"NiuTrans/Vision-LLM-Alignment" -> "TideDra/VL-RLHF"
"NiuTrans/Vision-LLM-Alignment" -> "NiuTrans/LaMaTE"
"CaraJ7/MMSearch" -> "MME-Benchmarks/MME-CoT" ["e"=1]
"CaraJ7/MMSearch" -> "CaraJ7/CoMat" ["e"=1]
"CaraJ7/MMSearch" -> "CaraJ7/T2I-R1" ["e"=1]
"CaraJ7/MMSearch" -> "ZrrSkywalker/MathVerse"
"CaraJ7/MMSearch" -> "ZrrSkywalker/MAVIS"
"CaraJ7/MMSearch" -> "EvolvingLMMs-Lab/multimodal-search-r1"
"IntelLabs/lvlm-interpret" -> "nickjiang2378/vl-interp"
"SUSTechBruce/LOOK-M" -> "NastyMarcus/A-Survey-of-Efficient-Diffusion-Models"
"SUSTechBruce/LOOK-M" -> "Cooperx521/PyramidDrop"
"Shengcao-Cao/groundLMM" -> "wusize/F-LMM"
"WHB139426/Grounded-Video-LLM" -> "TimeMarker-LLM/TimeMarker"
"WHB139426/Grounded-Video-LLM" -> "DCDmllm/Momentor"
"WHB139426/Grounded-Video-LLM" -> "minghangz/TFVTG"
"WHB139426/Grounded-Video-LLM" -> "gyxxyg/VTG-LLM"
"rccchoudhury/rlt" -> "Vchitect/FasterCache" ["e"=1]
"rccchoudhury/rlt" -> "contrastive/FreeVideoLLM"
"rccchoudhury/rlt" -> "gls0425/LinVT"
"JiazuoYu/PathWeave" -> "hmxiong/StreamChat"
"slonetime/EBSeg" -> "letitiabanana/PnP-OVSS"
"UMass-Embodied-AGI/FlexAttention" -> "hasanar1f/HiRED"
"kang-wu/SkySensePlusPlus" -> "alipay/POA"
"kang-wu/SkySensePlusPlus" -> "likyoo/awesome-MLLM-for-image-segmentation"
"YiyangZhou/CSR" -> "YiyangZhou/POVID"
"YiyangZhou/CSR" -> "yihedeng9/STIC"
"YiyangZhou/CSR" -> "YuxiXie/V-DPO"
"2U1/Phi3-Vision-Finetune" -> "GaiZhenbiao/Phi3V-Finetuning"
"2U1/Phi3-Vision-Finetune" -> "2U1/Llama3.2-Vision-Finetune"
"2U1/Llama3.2-Vision-Finetune" -> "2U1/Phi3-Vision-Finetune"
"2U1/Llama3.2-Vision-Finetune" -> "2U1/Pixtral-Finetune"
"intsig-textin/parsex-frontend" -> "intsig-textin/markdown_tester"
"intsig-textin/parsex-frontend" -> "intsig-textin/parsex-sdk"
"intsig-textin/markdown_tester" -> "intsig-textin/parsex-sdk"
"intsig-textin/markdown_tester" -> "lutongyv/Textin_Tester"
"intsig-textin/markdown_tester" -> "intsig-textin/parsex-frontend"
"intsig-textin/markdown_tester" -> "ucaslcl/Fox"
"Alpha-Innovator/DocGenome" -> "Alpha-Innovator/AdaptiveDiffusion"
"Alpha-Innovator/DocGenome" -> "Alpha-Innovator/SurveyForge"
"Alpha-Innovator/DocGenome" -> "jiaweizzhao/InRank" ["e"=1]
"Alpha-Innovator/DocGenome" -> "gulucaptain/DynamiCtrl" ["e"=1]
"Alpha-Innovator/DocGenome" -> "Alpha-Innovator/Chimera"
"Run542968/Awesome-3D-Human-Motion-Generation" -> "iSEE-Laboratory/EgoExo-Fitness"
"Run542968/Awesome-3D-Human-Motion-Generation" -> "Lyman-Smoker/Awesome-AQA"
"Gumpest/SparseVLMs" -> "Theia-4869/FasterVLM"
"Gumpest/SparseVLMs" -> "LaVi-Lab/AIM"
"Gumpest/SparseVLMs" -> "liuting20/MustDrop" ["e"=1]
"Gumpest/SparseVLMs" -> "Cooperx521/PyramidDrop"
"Gumpest/SparseVLMs" -> "foundation-multimodal-models/ConBench" ["e"=1]
"Gumpest/SparseVLMs" -> "pkunlp-icler/FastV"
"Gumpest/SparseVLMs" -> "xuyang-liu16/GlobalCom2" ["e"=1]
"Gumpest/SparseVLMs" -> "42Shawn/LLaVA-PruMerge"
"Cooperx521/PyramidDrop" -> "Liuziyu77/MIA-DPO"
"Cooperx521/PyramidDrop" -> "Gumpest/SparseVLMs"
"Cooperx521/PyramidDrop" -> "hasanar1f/HiRED"
"Cooperx521/PyramidDrop" -> "shikiw/Modality-Integration-Rate"
"Cooperx521/PyramidDrop" -> "ywh187/FitPrune"
"Cooperx521/PyramidDrop" -> "Wiselnn570/VideoRoPE"
"Cooperx521/PyramidDrop" -> "SUSTechBruce/LOOK-M"
"longvideobench/LongVideoBench" -> "Q-Future/Co-Instruct" ["e"=1]
"longvideobench/LongVideoBench" -> "JUNJIE99/MLVU"
"MME-Benchmarks/MME-RealWorld" -> "yfzhang114/SliME"
"MME-Benchmarks/MME-RealWorld" -> "Kwai-YuanQi/MM-RLHF"
"mbzuai-oryx/VideoGPT-plus" -> "mbzuai-oryx/Video-ChatGPT"
"mbzuai-oryx/VideoGPT-plus" -> "mbzuai-oryx/Video-LLaVA"
"mbzuai-oryx/VideoGPT-plus" -> "bytedance/tarsier"
"mbzuai-oryx/VideoGPT-plus" -> "Ziyang412/VideoTree"
"mbzuai-oryx/VideoGPT-plus" -> "Amshaker/Mobile-VideoGPT" ["e"=1]
"mbzuai-oryx/VideoGPT-plus" -> "ziplab/LongVLM"
"mbzuai-oryx/VideoGPT-plus" -> "magic-research/PLLaVA"
"mbzuai-oryx/VideoGPT-plus" -> "DAMO-NLP-SG/VideoLLaMA2"
"mbzuai-oryx/VideoGPT-plus" -> "RenShuhuai-Andy/TimeChat"
"mbzuai-oryx/VideoGPT-plus" -> "boheumd/MA-LMM"
"mbzuai-oryx/VideoGPT-plus" -> "mbzuai-oryx/LlamaV-o1"
"mbzuai-oryx/VideoGPT-plus" -> "DCDmllm/Momentor"
"mbzuai-oryx/VideoGPT-plus" -> "Vision-CAIR/LongVU"
"mbzuai-oryx/VideoGPT-plus" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"JUNJIE99/MLVU" -> "VectorSpaceLab/Video-XL"
"JUNJIE99/MLVU" -> "longvideobench/LongVideoBench"
"JUNJIE99/MLVU" -> "EvolvingLMMs-Lab/LongVA"
"JUNJIE99/MLVU" -> "MME-Benchmarks/Video-MME"
"JUNJIE99/MLVU" -> "joez17/VideoNIAH"
"JUNJIE99/MLVU" -> "THUDM/LVBench"
"JUNJIE99/MLVU" -> "SCZwangxiao/video-FlexReduc"
"JUNJIE99/MLVU" -> "egoschema/EgoSchema"
"JUNJIE99/MLVU" -> "OpenGVLab/VideoChat-Flash"
"TimeMarker-LLM/TimeMarker" -> "WHB139426/Grounded-Video-LLM"
"TimeMarker-LLM/TimeMarker" -> "DCDmllm/Momentor"
"apple/ml-slowfast-llava" -> "imagegridworth/IG-VLM"
"apple/ml-slowfast-llava" -> "contrastive/FreeVideoLLM"
"apple/ml-slowfast-llava" -> "huofushuo/C2KD" ["e"=1]
"HowieHwong/UniGen" -> "Flossiee/HonestyLLM"
"InfiMM/Awesome-Multimodal-LLM-for-Math-STEM" -> "pengshuai-rin/MultiMath"
"shikiw/Modality-Integration-Rate" -> "Cooperx521/PyramidDrop"
"shikiw/Modality-Integration-Rate" -> "YUCHEN005/UNA-GAN"
"shikiw/Modality-Integration-Rate" -> "mengtong0110/InferDPT"
"shikiw/Modality-Integration-Rate" -> "YUCHEN005/RATS-Channel-A-Speech-Data"
"shikiw/Modality-Integration-Rate" -> "YUCHEN005/UniVPM"
"shikiw/Modality-Integration-Rate" -> "YUCHEN005/Gradient-Remedy"
"shikiw/Modality-Integration-Rate" -> "YUCHEN005/MIR-GAN"
"xjtupanda/Sparrow" -> "VITA-MLLM/Sparrow"
"xjtupanda/Sparrow" -> "zhourax/VEGA"
"yihedeng9/STIC" -> "YiyangZhou/CSR"
"yihedeng9/STIC" -> "YiyangZhou/POVID"
"JoeLeelyf/OVO-Bench" -> "hmxiong/StreamChat"
"KD-TAO/DyCoke" -> "KD-TAO/VidKV"
"KD-TAO/DyCoke" -> "Visual-AI/PruneVid"
"Liuziyu77/MMDU" -> "songweii/DualToken"
"Liuziyu77/MMDU" -> "Liuziyu77/MIA-DPO"
"Liuziyu77/MMDU" -> "Bujiazi/HiFlow"
"Liuziyu77/MIA-DPO" -> "beichenzbc/BoostStep"
"Liuziyu77/MIA-DPO" -> "Cooperx521/PyramidDrop"
"Liuziyu77/MIA-DPO" -> "SYuan03/MM-IFEngine"
"EvolvingLMMs-Lab/multimodal-sae" -> "nickjiang2378/vl-interp"
"OpenGVLab/MMIU" -> "OpenGVLab/Multitask-Model-Selector"
"OpenGVLab/MMIU" -> "lyingCS/Controllable-Multi-Objective-Reranking"
"OpenGVLab/MMIU" -> "lyingCS/UOEP"
"OpenGVLab/MMIU" -> "E-qin/GEAR"
"ucaslcl/Fox" -> "LingyvKong/OneChart"
"ucaslcl/Fox" -> "nttmdlab-nlp/InstructDoc"
"ucaslcl/Fox" -> "Ucas-HaoranWei/Vary-tiny-600k"
"ucaslcl/Fox" -> "intsig-textin/markdown_tester"
"SuleBai/SC-CLIP" -> "AndyTang15/FLAG3Dv2"
"SuleBai/SC-CLIP" -> "AndyTang15/FLAG3D"
"SuleBai/SC-CLIP" -> "zhang9302002/Flash-VStream"
"SuleBai/SC-CLIP" -> "shiyi-zh0408/NAE_CVPR2024"
"SuleBai/SC-CLIP" -> "Yxxxb/LAVT-RS"
"minghangz/TFVTG" -> "lntzm/MESM"
"tdsone/extract-line-chart-data" -> "pengyu965/ChartDete"
"DreamMr/HR-Bench" -> "DreamMr/RAP"
"berkeley-hipie/segllm" -> "Shengcao-Cao/groundLMM"
"berkeley-hipie/segllm" -> "wusize/F-LMM"
"berkeley-hipie/segllm" -> "mc-lan/Text4Seg"
"NastyMarcus/A-Survey-of-Efficient-Diffusion-Models" -> "AIoT-MLSys-Lab/Famba-V"
"alipay/POA" -> "kang-wu/SkySensePlusPlus"
"intsig-textin/parsex-sdk" -> "intsig-textin/chatdoc"
"ichbill/DQAS" -> "ichbill/LTDD"
"iSEE-Laboratory/EgoExo-Fitness" -> "Run542968/Awesome-3D-Human-Motion-Generation"
"iSEE-Laboratory/EgoExo-Fitness" -> "Lyman-Smoker/Awesome-AQA"
"iSEE-Laboratory/EgoExo-Fitness" -> "iSEE-Laboratory/Continual-AQA"
"ichbill/LTDD" -> "ichbill/DQAS"
"1100111GTH/XG-RAG" -> "modelscope/mcp-central"
"HankYe/AdaptiveDiffusion" -> "HankYe/Once-for-Both"
"HankYe/AdaptiveDiffusion" -> "Alpha-Innovator/TrustGeoGen"
"om-ai-lab/VLM-R1" -> "Deep-Agent/R1-V"
"om-ai-lab/VLM-R1" -> "Liuziyu77/Visual-RFT"
"om-ai-lab/VLM-R1" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"om-ai-lab/VLM-R1" -> "hiyouga/EasyR1" ["e"=1]
"om-ai-lab/VLM-R1" -> "QwenLM/Qwen2.5-VL"
"om-ai-lab/VLM-R1" -> "OpenGVLab/InternVL"
"om-ai-lab/VLM-R1" -> "LLaVA-VL/LLaVA-NeXT"
"om-ai-lab/VLM-R1" -> "open-compass/VLMEvalKit"
"om-ai-lab/VLM-R1" -> "volcengine/verl" ["e"=1]
"om-ai-lab/VLM-R1" -> "TideDra/lmm-r1"
"om-ai-lab/VLM-R1" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"om-ai-lab/VLM-R1" -> "modelscope/ms-swift" ["e"=1]
"om-ai-lab/VLM-R1" -> "OpenRLHF/OpenRLHF" ["e"=1]
"om-ai-lab/VLM-R1" -> "BradyFU/Awesome-Multimodal-Large-Language-Models"
"om-ai-lab/VLM-R1" -> "hkust-nlp/simpleRL-reason" ["e"=1]
"tulerfeng/Video-R1" -> "Wang-Xiaodong1899/Open-R1-Video"
"tulerfeng/Video-R1" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"tulerfeng/Video-R1" -> "www-Ye/TimeZero"
"tulerfeng/Video-R1" -> "OpenGVLab/VideoChat-R1"
"tulerfeng/Video-R1" -> "turningpoint-ai/VisualThinker-R1-Zero"
"tulerfeng/Video-R1" -> "Liuziyu77/Visual-RFT"
"tulerfeng/Video-R1" -> "dvlab-research/Seg-Zero"
"tulerfeng/Video-R1" -> "TideDra/lmm-r1"
"tulerfeng/Video-R1" -> "TencentARC/SEED-Bench-R1" ["e"=1]
"tulerfeng/Video-R1" -> "yaotingwangofficial/Awesome-MCoT"
"tulerfeng/Video-R1" -> "Fancy-MLLM/R1-Onevision"
"tulerfeng/Video-R1" -> "ModalMinds/MM-EUREKA"
"tulerfeng/Video-R1" -> "appletea233/Temporal-R1"
"tulerfeng/Video-R1" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"tulerfeng/Video-R1" -> "Osilly/Vision-R1"
"FanqingM/R1-Multimodal-Journey" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"FanqingM/R1-Multimodal-Journey" -> "ModalMinds/MM-EUREKA"
"FanqingM/R1-Multimodal-Journey" -> "TideDra/lmm-r1"
"FanqingM/R1-Multimodal-Journey" -> "turningpoint-ai/VisualThinker-R1-Zero"
"FanqingM/R1-Multimodal-Journey" -> "Wang-Xiaodong1899/Open-R1-Video"
"FanqingM/R1-Multimodal-Journey" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"FanqingM/R1-Multimodal-Journey" -> "Osilly/Vision-R1"
"FanqingM/R1-Multimodal-Journey" -> "Fancy-MLLM/R1-Onevision"
"FanqingM/R1-Multimodal-Journey" -> "RLHF-V/RLHF-V"
"FanqingM/R1-Multimodal-Journey" -> "OpenRLHF/OpenRLHF-M"
"FanqingM/R1-Multimodal-Journey" -> "dongyh20/Insight-V"
"FanqingM/R1-Multimodal-Journey" -> "modelscope/awesome-deep-reasoning"
"FanqingM/R1-Multimodal-Journey" -> "hiyouga/EasyR1" ["e"=1]
"FanqingM/R1-Multimodal-Journey" -> "LengSicong/MMR1"
"FanqingM/R1-Multimodal-Journey" -> "Deep-Agent/R1-V"
"saccharomycetes/mllms_know" -> "mrwu-mac/ControlMLLM"
"saccharomycetes/mllms_know" -> "zjunlp/Deco"
"saccharomycetes/mllms_know" -> "yu-rp/VisualPerceptionToken" ["e"=1]
"saccharomycetes/mllms_know" -> "DreamMr/HR-Bench"
"saccharomycetes/mllms_know" -> "zjysteven/VLM-Visualizer"
"Wang-Xiaodong1899/CVPR25-MLLM-Paper-List" -> "Wang-Xiaodong1899/Open-R1-Video"
"VITA-MLLM/VITA-Audio" -> "VITA-MLLM/Sparrow"
"VITA-MLLM/VITA-Audio" -> "MAC-AutoML/QuoTA"
"VITA-MLLM/VITA-Audio" -> "VITA-MLLM/Long-VITA"
"VITA-MLLM/VITA-Audio" -> "zhourax/VEGA"
"VITA-MLLM/VITA-Audio" -> "yfzhang114/r1_reward"
"Kwai-YuanQi/MM-RLHF" -> "VITA-MLLM/Long-VITA"
"Kwai-YuanQi/MM-RLHF" -> "VITA-MLLM/Sparrow"
"Kwai-YuanQi/MM-RLHF" -> "yfzhang114/r1_reward"
"Kwai-YuanQi/MM-RLHF" -> "MME-Benchmarks/MME-Unify"
"Kwai-YuanQi/MM-RLHF" -> "MME-Benchmarks/MME-RealWorld"
"Kwai-YuanQi/MM-RLHF" -> "MAC-AutoML/QuoTA"
"Kwai-YuanQi/MM-RLHF" -> "VITA-MLLM/VITA-Audio"
"Kwai-YuanQi/MM-RLHF" -> "Leon1207/Video-RAG-master"
"Kwai-YuanQi/MM-RLHF" -> "yfzhang114/SliME"
"Deep-Agent/R1-V" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Deep-Agent/R1-V" -> "om-ai-lab/VLM-R1"
"Deep-Agent/R1-V" -> "hiyouga/EasyR1" ["e"=1]
"Deep-Agent/R1-V" -> "Liuziyu77/Visual-RFT"
"Deep-Agent/R1-V" -> "TideDra/lmm-r1"
"Deep-Agent/R1-V" -> "open-compass/VLMEvalKit"
"Deep-Agent/R1-V" -> "volcengine/verl" ["e"=1]
"Deep-Agent/R1-V" -> "hkust-nlp/simpleRL-reason" ["e"=1]
"Deep-Agent/R1-V" -> "LLaVA-VL/LLaVA-NeXT"
"Deep-Agent/R1-V" -> "ModalMinds/MM-EUREKA"
"Deep-Agent/R1-V" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Deep-Agent/R1-V" -> "OpenRLHF/OpenRLHF" ["e"=1]
"Deep-Agent/R1-V" -> "Open-Reasoner-Zero/Open-Reasoner-Zero" ["e"=1]
"Deep-Agent/R1-V" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Deep-Agent/R1-V" -> "QwenLM/Qwen2.5-VL"
"ModalMinds/MM-EUREKA" -> "FanqingM/R1-Multimodal-Journey"
"ModalMinds/MM-EUREKA" -> "TideDra/lmm-r1"
"ModalMinds/MM-EUREKA" -> "Osilly/Vision-R1"
"ModalMinds/MM-EUREKA" -> "turningpoint-ai/VisualThinker-R1-Zero"
"ModalMinds/MM-EUREKA" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"ModalMinds/MM-EUREKA" -> "Fancy-MLLM/R1-Onevision"
"ModalMinds/MM-EUREKA" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"ModalMinds/MM-EUREKA" -> "Liuziyu77/Visual-RFT"
"ModalMinds/MM-EUREKA" -> "Wang-Xiaodong1899/Open-R1-Video"
"ModalMinds/MM-EUREKA" -> "Deep-Agent/R1-V"
"ModalMinds/MM-EUREKA" -> "hiyouga/EasyR1" ["e"=1]
"ModalMinds/MM-EUREKA" -> "yaotingwangofficial/Awesome-MCoT"
"ModalMinds/MM-EUREKA" -> "open-compass/VLMEvalKit"
"ModalMinds/MM-EUREKA" -> "tulerfeng/Video-R1"
"ModalMinds/MM-EUREKA" -> "OpenRLHF/OpenRLHF-M"
"zhuang2002/Cobra" -> "shiyi-zh0408/FlexiAct"
"Ola-Omni/Ola" -> "Oryx-mllm/Oryx"
"Ola-Omni/Ola" -> "MoonshotAI/Kimi-VL"
"Ola-Omni/Ola" -> "dongyh20/Insight-V"
"Ola-Omni/Ola" -> "dongyh20/Chain-of-Spot"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "bruno686/Awesome-RL-based-LLM-Reasoning" ["e"=1]
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "TideDra/lmm-r1"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "ModalMinds/MM-EUREKA"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "Osilly/Vision-R1"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "yaotingwangofficial/Awesome-MCoT"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "FanqingM/R1-Multimodal-Journey"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "Liuziyu77/Visual-RFT"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "hiyouga/EasyR1" ["e"=1]
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "Fancy-MLLM/R1-Onevision"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "open-compass/VLMEvalKit"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "Wang-Xiaodong1899/Open-R1-Video"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "Deep-Agent/R1-V"
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" -> "dvlab-research/Seg-Zero"
"SCZwangxiao/video-FlexReduc" -> "gls0425/LinVT"
"modelscope/MCPBench" -> "modelscope/mcp-central"
"modelscope/MCPBench" -> "modelscope/DiffSynth-Engine"
"Liuziyu77/Visual-RFT" -> "om-ai-lab/VLM-R1"
"Liuziyu77/Visual-RFT" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Liuziyu77/Visual-RFT" -> "Deep-Agent/R1-V"
"Liuziyu77/Visual-RFT" -> "hiyouga/EasyR1" ["e"=1]
"Liuziyu77/Visual-RFT" -> "Osilly/Vision-R1"
"Liuziyu77/Visual-RFT" -> "TideDra/lmm-r1"
"Liuziyu77/Visual-RFT" -> "ModalMinds/MM-EUREKA"
"Liuziyu77/Visual-RFT" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Liuziyu77/Visual-RFT" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Liuziyu77/Visual-RFT" -> "Fancy-MLLM/R1-Onevision"
"Liuziyu77/Visual-RFT" -> "tulerfeng/Video-R1"
"Liuziyu77/Visual-RFT" -> "open-compass/VLMEvalKit"
"Liuziyu77/Visual-RFT" -> "dvlab-research/Seg-Zero"
"Liuziyu77/Visual-RFT" -> "LLaVA-VL/LLaVA-NeXT"
"Liuziyu77/Visual-RFT" -> "Wang-Xiaodong1899/Open-R1-Video"
"TideDra/lmm-r1" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"TideDra/lmm-r1" -> "FanqingM/R1-Multimodal-Journey"
"TideDra/lmm-r1" -> "ModalMinds/MM-EUREKA"
"TideDra/lmm-r1" -> "Fancy-MLLM/R1-Onevision"
"TideDra/lmm-r1" -> "turningpoint-ai/VisualThinker-R1-Zero"
"TideDra/lmm-r1" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"TideDra/lmm-r1" -> "OpenRLHF/OpenRLHF-M"
"TideDra/lmm-r1" -> "Osilly/Vision-R1"
"TideDra/lmm-r1" -> "Wang-Xiaodong1899/Open-R1-Video"
"TideDra/lmm-r1" -> "Deep-Agent/R1-V"
"TideDra/lmm-r1" -> "hiyouga/EasyR1" ["e"=1]
"TideDra/lmm-r1" -> "Liuziyu77/Visual-RFT"
"TideDra/lmm-r1" -> "yaotingwangofficial/Awesome-MCoT"
"TideDra/lmm-r1" -> "Open-Reasoner-Zero/Open-Reasoner-Zero" ["e"=1]
"TideDra/lmm-r1" -> "tulerfeng/Video-R1"
"turningpoint-ai/VisualThinker-R1-Zero" -> "ModalMinds/MM-EUREKA"
"turningpoint-ai/VisualThinker-R1-Zero" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"turningpoint-ai/VisualThinker-R1-Zero" -> "TideDra/lmm-r1"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Osilly/Vision-R1"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Fancy-MLLM/R1-Onevision"
"turningpoint-ai/VisualThinker-R1-Zero" -> "FanqingM/R1-Multimodal-Journey"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Wang-Xiaodong1899/Open-R1-Video"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Liuziyu77/Visual-RFT"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"turningpoint-ai/VisualThinker-R1-Zero" -> "tulerfeng/Video-R1"
"turningpoint-ai/VisualThinker-R1-Zero" -> "Deep-Agent/R1-V"
"turningpoint-ai/VisualThinker-R1-Zero" -> "hiyouga/EasyR1" ["e"=1]
"turningpoint-ai/VisualThinker-R1-Zero" -> "MoonshotAI/Kimi-VL"
"turningpoint-ai/VisualThinker-R1-Zero" -> "deepcs233/Visual-CoT"
"turningpoint-ai/VisualThinker-R1-Zero" -> "LengSicong/MMR1"
"HumanMLLM/R1-Omni" -> "HumanMLLM/HumanOmni"
"HumanMLLM/R1-Omni" -> "Liuziyu77/Visual-RFT"
"HumanMLLM/R1-Omni" -> "Fancy-MLLM/R1-Onevision"
"HumanMLLM/R1-Omni" -> "Osilly/Vision-R1"
"HumanMLLM/R1-Omni" -> "QwenLM/Qwen2.5-Omni" ["e"=1]
"HumanMLLM/R1-Omni" -> "Deep-Agent/R1-V"
"HumanMLLM/R1-Omni" -> "tulerfeng/Video-R1"
"HumanMLLM/R1-Omni" -> "turningpoint-ai/VisualThinker-R1-Zero"
"HumanMLLM/R1-Omni" -> "ZebangCheng/Emotion-LLaMA" ["e"=1]
"HumanMLLM/R1-Omni" -> "zeroQiaoba/AffectGPT" ["e"=1]
"HumanMLLM/R1-Omni" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"HumanMLLM/R1-Omni" -> "Wang-Xiaodong1899/Open-R1-Video"
"HumanMLLM/R1-Omni" -> "ModalMinds/MM-EUREKA"
"HumanMLLM/R1-Omni" -> "TideDra/lmm-r1"
"HumanMLLM/R1-Omni" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Osilly/Vision-R1" -> "Fancy-MLLM/R1-Onevision"
"Osilly/Vision-R1" -> "ModalMinds/MM-EUREKA"
"Osilly/Vision-R1" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Osilly/Vision-R1" -> "TideDra/lmm-r1"
"Osilly/Vision-R1" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Osilly/Vision-R1" -> "Liuziyu77/Visual-RFT"
"Osilly/Vision-R1" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Osilly/Vision-R1" -> "LengSicong/MMR1"
"Osilly/Vision-R1" -> "FanqingM/R1-Multimodal-Journey"
"Osilly/Vision-R1" -> "hiyouga/EasyR1" ["e"=1]
"Osilly/Vision-R1" -> "Wang-Xiaodong1899/Open-R1-Video"
"Osilly/Vision-R1" -> "tulerfeng/Video-R1"
"Osilly/Vision-R1" -> "UCSC-VLAA/VLAA-Thinking"
"Osilly/Vision-R1" -> "Deep-Agent/R1-V"
"Osilly/Vision-R1" -> "yaotingwangofficial/Awesome-MCoT"
"dvlab-research/Seg-Zero" -> "tulerfeng/Video-R1"
"dvlab-research/Seg-Zero" -> "Liuziyu77/Visual-RFT"
"dvlab-research/Seg-Zero" -> "mc-lan/Awesome-MLLM-Segmentation"
"dvlab-research/Seg-Zero" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"dvlab-research/Seg-Zero" -> "cilinyan/VISA" ["e"=1]
"dvlab-research/Seg-Zero" -> "Fancy-MLLM/R1-Onevision"
"dvlab-research/Seg-Zero" -> "magic-research/Sa2VA" ["e"=1]
"dvlab-research/Seg-Zero" -> "MaverickRen/PixelLM"
"dvlab-research/Seg-Zero" -> "FanqingM/R1-Multimodal-Journey"
"dvlab-research/Seg-Zero" -> "Osilly/Vision-R1"
"dvlab-research/Seg-Zero" -> "showlab/VideoLISA" ["e"=1]
"dvlab-research/Seg-Zero" -> "TideDra/lmm-r1"
"dvlab-research/Seg-Zero" -> "zamling/PSALM"
"dvlab-research/Seg-Zero" -> "hiyouga/EasyR1" ["e"=1]
"dvlab-research/Seg-Zero" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"SYuan03/MM-IFEngine" -> "PhoenixZ810/OmniAlign-V" ["e"=1]
"SYuan03/MM-IFEngine" -> "Sunleader1997/transflow" ["e"=1]
"SYuan03/MM-IFEngine" -> "liyown/nextjs_stream_demo" ["e"=1]
"yaotingwangofficial/Awesome-MCoT" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"yaotingwangofficial/Awesome-MCoT" -> "Fancy-MLLM/R1-Onevision"
"yaotingwangofficial/Awesome-MCoT" -> "TideDra/lmm-r1"
"yaotingwangofficial/Awesome-MCoT" -> "tulerfeng/Video-R1"
"yaotingwangofficial/Awesome-MCoT" -> "ModalMinds/MM-EUREKA"
"yaotingwangofficial/Awesome-MCoT" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"yaotingwangofficial/Awesome-MCoT" -> "Osilly/Vision-R1"
"yaotingwangofficial/Awesome-MCoT" -> "Liuziyu77/Visual-RFT"
"yaotingwangofficial/Awesome-MCoT" -> "LightChen233/Awesome-Long-Chain-of-Thought-Reasoning" ["e"=1]
"yaotingwangofficial/Awesome-MCoT" -> "hiyouga/EasyR1" ["e"=1]
"yaotingwangofficial/Awesome-MCoT" -> "FanqingM/R1-Multimodal-Journey"
"yaotingwangofficial/Awesome-MCoT" -> "dvlab-research/Seg-Zero"
"yaotingwangofficial/Awesome-MCoT" -> "showlab/Awesome-Unified-Multimodal-Models" ["e"=1]
"yaotingwangofficial/Awesome-MCoT" -> "turningpoint-ai/VisualThinker-R1-Zero"
"yaotingwangofficial/Awesome-MCoT" -> "daixiangzi/Awesome-Token-Compress"
"DAMO-NLP-SG/VideoLLaMA3" -> "DAMO-NLP-SG/VideoLLaMA2"
"DAMO-NLP-SG/VideoLLaMA3" -> "OpenGVLab/VideoChat-Flash"
"DAMO-NLP-SG/VideoLLaMA3" -> "tulerfeng/Video-R1"
"DAMO-NLP-SG/VideoLLaMA3" -> "bytedance/tarsier"
"DAMO-NLP-SG/VideoLLaMA3" -> "MME-Benchmarks/Video-MME"
"DAMO-NLP-SG/VideoLLaMA3" -> "DAMO-NLP-SG/VideoRefer" ["e"=1]
"DAMO-NLP-SG/VideoLLaMA3" -> "VectorSpaceLab/Video-XL"
"DAMO-NLP-SG/VideoLLaMA3" -> "OpenGVLab/InternVideo"
"DAMO-NLP-SG/VideoLLaMA3" -> "magic-research/Sa2VA" ["e"=1]
"DAMO-NLP-SG/VideoLLaMA3" -> "yunlong10/Awesome-LLMs-for-Video-Understanding"
"DAMO-NLP-SG/VideoLLaMA3" -> "EvolvingLMMs-Lab/LongVA"
"DAMO-NLP-SG/VideoLLaMA3" -> "magic-research/PLLaVA"
"DAMO-NLP-SG/VideoLLaMA3" -> "LLaVA-VL/LLaVA-NeXT"
"DAMO-NLP-SG/VideoLLaMA3" -> "NVlabs/VILA"
"DAMO-NLP-SG/VideoLLaMA3" -> "VITA-MLLM/VITA" ["e"=1]
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Deep-Agent/R1-V"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "FanqingM/R1-Multimodal-Journey"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "TideDra/lmm-r1"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Liuziyu77/Visual-RFT"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "ModalMinds/MM-EUREKA"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "hiyouga/EasyR1" ["e"=1]
"EvolvingLMMs-Lab/open-r1-multimodal" -> "turningpoint-ai/VisualThinker-R1-Zero"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "om-ai-lab/VLM-R1"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Fancy-MLLM/R1-Onevision"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Wang-Xiaodong1899/Open-R1-Video"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "Osilly/Vision-R1"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "tulerfeng/Video-R1"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "open-compass/VLMEvalKit"
"EvolvingLMMs-Lab/open-r1-multimodal" -> "LLaVA-VL/LLaVA-NeXT"
"Alpha-Innovator/SurveyForge" -> "Alpha-Innovator/AdaptiveDiffusion"
"Alpha-Innovator/SurveyForge" -> "Alpha-Innovator/DocGenome"
"Alpha-Innovator/SurveyForge" -> "Alpha-Innovator/Chimera"
"beichenzbc/BoostStep" -> "Bujiazi/ByTheWay"
"Wiselnn570/VideoRoPE" -> "beichenzbc/BoostStep"
"Wiselnn570/VideoRoPE" -> "SYuan03/MM-IFEngine"
"Wiselnn570/VideoRoPE" -> "Cooperx521/PyramidDrop"
"Wiselnn570/VideoRoPE" -> "Bujiazi/ByTheWay"
"Wiselnn570/VideoRoPE" -> "Mark12Ding/Dispider"
"Wiselnn570/VideoRoPE" -> "Bujiazi/HiFlow"
"Wiselnn570/VideoRoPE" -> "shikiw/Modality-Integration-Rate"
"Wiselnn570/VideoRoPE" -> "Liuziyu77/MIA-DPO"
"VITA-MLLM/Long-VITA" -> "Kwai-YuanQi/MM-RLHF"
"VITA-MLLM/Long-VITA" -> "VITA-MLLM/Sparrow"
"VITA-MLLM/Long-VITA" -> "VITA-MLLM/VITA-Audio"
"VITA-MLLM/Long-VITA" -> "MAC-AutoML/QuoTA"
"Alpha-Innovator/OmniCaptioner" -> "Alpha-Innovator/Chimera"
"Alpha-Innovator/OmniCaptioner" -> "ch3cook-fdu/Vote2Cap-DETR"
"Alpha-Innovator/OmniCaptioner" -> "HankYe/AdaptiveDiffusion"
"Alpha-Innovator/OmniCaptioner" -> "Alpha-Innovator/AdaptiveDiffusion"
"Video-R1/Awesome-Multimodal-Reasoning" -> "MCG-NJU/CaReBench"
"shiyi-zh0408/FlexiAct" -> "AndyTang15/FLAG3Dv2"
"shiyi-zh0408/FlexiAct" -> "shiyi-zh0408/NAE_CVPR2024"
"shiyi-zh0408/FlexiAct" -> "zhuang2002/Cobra"
"shiyi-zh0408/FlexiAct" -> "Xilluill/KV-Edit" ["e"=1]
"shiyi-zh0408/FlexiAct" -> "ChangyuanWang17/QVLM"
"Fancy-MLLM/R1-Onevision" -> "Osilly/Vision-R1"
"Fancy-MLLM/R1-Onevision" -> "TideDra/lmm-r1"
"Fancy-MLLM/R1-Onevision" -> "ModalMinds/MM-EUREKA"
"Fancy-MLLM/R1-Onevision" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Fancy-MLLM/R1-Onevision" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Fancy-MLLM/R1-Onevision" -> "Wang-Xiaodong1899/Open-R1-Video"
"Fancy-MLLM/R1-Onevision" -> "yaotingwangofficial/Awesome-MCoT"
"Fancy-MLLM/R1-Onevision" -> "FanqingM/R1-Multimodal-Journey"
"Fancy-MLLM/R1-Onevision" -> "Liuziyu77/Visual-RFT"
"Fancy-MLLM/R1-Onevision" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Fancy-MLLM/R1-Onevision" -> "tulerfeng/Video-R1"
"Fancy-MLLM/R1-Onevision" -> "Deep-Agent/R1-V"
"Fancy-MLLM/R1-Onevision" -> "hiyouga/EasyR1" ["e"=1]
"Fancy-MLLM/R1-Onevision" -> "dvlab-research/Seg-Zero"
"Fancy-MLLM/R1-Onevision" -> "yuyq96/R1-Vision"
"mbzuai-oryx/LlamaV-o1" -> "dongyh20/Insight-V"
"mbzuai-oryx/LlamaV-o1" -> "mbzuai-oryx/CVRR-Evaluation-Suite" ["e"=1]
"mbzuai-oryx/LlamaV-o1" -> "VIROBO-15/XM-GAN" ["e"=1]
"mbzuai-oryx/LlamaV-o1" -> "Wang-Xiaodong1899/Open-R1-Video"
"mbzuai-oryx/LlamaV-o1" -> "mbzuai-oryx/VideoGPT-plus"
"mbzuai-oryx/LlamaV-o1" -> "ModalMinds/MM-EUREKA"
"mbzuai-oryx/LlamaV-o1" -> "mbzuai-oryx/ClimateGPT" ["e"=1]
"mbzuai-oryx/LlamaV-o1" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"mc-lan/Awesome-MLLM-Segmentation" -> "likyoo/awesome-MLLM-for-image-segmentation"
"MoonshotAI/Kimi-VL" -> "ByteDance-Seed/Seed-Thinking-v1.5" ["e"=1]
"MoonshotAI/Kimi-VL" -> "turningpoint-ai/VisualThinker-R1-Zero"
"MoonshotAI/Kimi-VL" -> "TideDra/lmm-r1"
"MoonshotAI/Kimi-VL" -> "Osilly/Vision-R1"
"MoonshotAI/Kimi-VL" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"MoonshotAI/Kimi-VL" -> "MoonshotAI/Kimina-Prover-Preview" ["e"=1]
"MoonshotAI/Kimi-VL" -> "FanqingM/R1-Multimodal-Journey"
"MoonshotAI/Kimi-VL" -> "MoonshotAI/Moonlight" ["e"=1]
"MoonshotAI/Kimi-VL" -> "Ola-Omni/Ola"
"MoonshotAI/Kimi-VL" -> "MoonshotAI/MoBA" ["e"=1]
"MoonshotAI/Kimi-VL" -> "Fancy-MLLM/R1-Onevision"
"MoonshotAI/Kimi-VL" -> "Liuziyu77/Visual-RFT"
"MoonshotAI/Kimi-VL" -> "hiyouga/EasyR1" ["e"=1]
"MoonshotAI/Kimi-VL" -> "ByteFlow-AI/TokenFlow" ["e"=1]
"MoonshotAI/Kimi-VL" -> "open-compass/VLMEvalKit"
"modelscope/DiffSynth-Engine" -> "modelscope/MCPBench"
"modelscope/DiffSynth-Engine" -> "modelscope/mcp-central"
"OpenRLHF/OpenRLHF-M" -> "OpenRLHF/OpenRLHF-M"
"OpenRLHF/OpenRLHF-M" -> "TideDra/lmm-r1"
"OpenRLHF/OpenRLHF-M" -> "LengSicong/MMR1"
"modelscope/awesome-deep-reasoning" -> "FanqingM/R1-Multimodal-Journey"
"modelscope/awesome-deep-reasoning" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"modelscope/awesome-deep-reasoning" -> "modelscope/mcp-central"
"modelscope/awesome-deep-reasoning" -> "Osilly/Vision-R1"
"modelscope/awesome-deep-reasoning" -> "Hongcheng-Gao/Awesome-Long2short-on-LRMs" ["e"=1]
"modelscope/awesome-deep-reasoning" -> "RUCAIBox/Slow_Thinking_with_LLMs" ["e"=1]
"modelscope/awesome-deep-reasoning" -> "yfzhang114/Awesome-Multimodal-Large-Language-Models"
"Wang-Xiaodong1899/Open-R1-Video" -> "tulerfeng/Video-R1"
"Wang-Xiaodong1899/Open-R1-Video" -> "TideDra/lmm-r1"
"Wang-Xiaodong1899/Open-R1-Video" -> "EvolvingLMMs-Lab/open-r1-multimodal"
"Wang-Xiaodong1899/Open-R1-Video" -> "Fancy-MLLM/R1-Onevision"
"Wang-Xiaodong1899/Open-R1-Video" -> "FanqingM/R1-Multimodal-Journey"
"Wang-Xiaodong1899/Open-R1-Video" -> "turningpoint-ai/VisualThinker-R1-Zero"
"Wang-Xiaodong1899/Open-R1-Video" -> "ModalMinds/MM-EUREKA"
"Wang-Xiaodong1899/Open-R1-Video" -> "TencentARC/SEED-Bench-R1" ["e"=1]
"Wang-Xiaodong1899/Open-R1-Video" -> "Wang-Xiaodong1899/CVPR25-MLLM-Paper-List"
"Wang-Xiaodong1899/Open-R1-Video" -> "Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs"
"Wang-Xiaodong1899/Open-R1-Video" -> "OpenGVLab/VideoChat-R1"
"Wang-Xiaodong1899/Open-R1-Video" -> "OpenGVLab/VideoChat-Flash"
"Wang-Xiaodong1899/Open-R1-Video" -> "Osilly/Vision-R1"
"Wang-Xiaodong1899/Open-R1-Video" -> "Liuziyu77/Visual-RFT"
"Wang-Xiaodong1899/Open-R1-Video" -> "Hui-design/R1-Video-fixbug"
"bloomberg/scatteract" -> "soap117/DeepRule"
"MAC-AutoML/QuoTA" -> "VITA-MLLM/Sparrow"
"MAC-AutoML/QuoTA" -> "VITA-MLLM/VITA-Audio"
"MAC-AutoML/QuoTA" -> "zhourax/VEGA"
"MAC-AutoML/QuoTA" -> "Kwai-YuanQi/MM-RLHF"
"MAC-AutoML/QuoTA" -> "Leon1207/Video-RAG-master"
"MAC-AutoML/QuoTA" -> "VITA-MLLM/Long-VITA"
"MAC-AutoML/QuoTA" -> "ggg0919/cantor"
"MAC-AutoML/QuoTA" -> "xjtupanda/Sparrow"
"VITA-MLLM/Sparrow" -> "MME-Benchmarks/MME-Unify"
"HumanMLLM/HumanOmni" -> "HumanMLLM/R1-Omni"
"HumanMLLM/HumanOmni" -> "HumanMLLM/Omni-Emotion"
"HumanMLLM/HumanOmni" -> "zeroQiaoba/AffectGPT" ["e"=1]
"songweii/DualToken" -> "fengzi258/Ocean-R1"
"OpenGVLab/VideoChat-R1" -> "www-Ye/TimeZero"
"OpenGVLab/VideoChat-R1" -> "TencentARC/SEED-Bench-R1" ["e"=1]
"OpenGVLab/VideoChat-R1" -> "MCG-NJU/VideoChat-Online"
"OpenGVLab/VideoChat-R1" -> "OpenGVLab/FluxViT"
"OpenGVLab/VideoChat-R1" -> "MCG-NJU/p-MoD"
"modelscope/Nexus-Gen" -> "modelscope/mcp-central"
"foldl/AlphaGeometryRE" -> "tpgh24/ag4masses"
"fengzi258/Ocean-R1" -> "songweii/DualToken"
"GeoGPT-Research-Project/GeoGPT" -> "likyoo/awesome-MLLM-for-image-segmentation"
"LengSicong/MMR1" -> "Osilly/Vision-R1"
"LengSicong/MMR1" -> "OpenRLHF/OpenRLHF-M"
"LengSicong/MMR1" -> "DAMO-NLP-SG/multimodal_textbook" ["e"=1]
"LengSicong/MMR1" -> "John-AI-Lab/NoisyRollout" ["e"=1]
"Mark12Ding/Dispider" -> "yellow-binary-tree/MMDuet"
"Mark12Ding/Dispider" -> "Wiselnn570/VideoRoPE"
"Mark12Ding/Dispider" -> "JoeLeelyf/OVO-Bench"
"Mark12Ding/Dispider" -> "THUNLP-MT/StreamingBench" ["e"=1]
"Mark12Ding/Dispider" -> "xinding-sys/StreamMind"
"Mark12Ding/Dispider" -> "shikiw/Modality-Integration-Rate"
"Mark12Ding/Dispider" -> "Bujiazi/HiFlow"
"showlab/livecc" -> "bigai-nlco/VideoLLaMB"
"yeliudev/VideoMind" -> "TimeMarker-LLM/TimeMarker"
"yeliudev/VideoMind" -> "www-Ye/TimeZero"
"Ucas-HaoranWei/Slow-Perception" -> "dle666/R-CoT"
"Ucas-HaoranWei/Slow-Perception" -> "Ucas-HaoranWei/Vary-family"
"Ucas-HaoranWei/Slow-Perception" -> "felixludos/alphageometry"
"Ucas-HaoranWei/Slow-Perception" -> "Ucas-HaoranWei/Vary-tiny-600k"
"Ucas-HaoranWei/Slow-Perception" -> "mingliangzhang2018/PGDP" ["e"=1]
"yayafengzi/LMM-HiMTok" -> "xuliu-cyber/RSUniVLM"
"yayafengzi/LMM-HiMTok" -> "NJU-LHRS/ScoreRS"
"Bujiazi/HiFlow" -> "Bujiazi/ByTheWay"
"Bujiazi/HiFlow" -> "beichenzbc/BoostStep"
"Bujiazi/HiFlow" -> "SYuan03/MM-IFEngine"
"JoeLeelyf/customize-arxiv-daily" -> "SYuan03/MM-IFEngine"
"ChrisDong-THU/GaussianToken" -> "Yxxxb/LAVT-RS"
"ChrisDong-THU/GaussianToken" -> "VoyageWang/IteRPrimE"
"ChrisDong-THU/GaussianToken" -> "zhang9302002/Flash-VStream"
"www-Ye/TimeZero" -> "appletea233/Temporal-R1"
"www-Ye/TimeZero" -> "OpenGVLab/VideoChat-R1"
"www-Ye/TimeZero" -> "TencentARC/SEED-Bench-R1" ["e"=1]
"www-Ye/TimeZero" -> "yellow-binary-tree/HawkEye"
"modelscope/mcp-central" -> "1100111GTH/XG-RAG"
"GuanxingLu/vlarl" -> "Tengbo-Yu/AnyBimanual"
"GuanxingLu/vlarl" -> "shiyi-zh0408/NAE_CVPR2024"
"NJU-LHRS/ScoreRS" -> "xiong-zhitong/GeoLB-SigLIP"
"NJU-LHRS/ScoreRS" -> "jonathan-roberts1/charting-new-territories"
"MME-Benchmarks/MME-Unify" -> "VITA-MLLM/Sparrow"
"MCG-NJU/VideoChat-Online" -> "yaolinli/TimeChat-Online"
"yaolinli/TimeChat-Online" -> "MCG-NJU/VideoChat-Online"
"jonathan-roberts1/zerobench" -> "jonathan-roberts1/SciFIBench"
"intsig-textin/chatdoc_stack" -> "intsig-textin/chatdoc"
"intsig-textin/chatdoc_stack" -> "intsig-textin/parsex-sdk"
"yfzhang114/r1_reward" -> "Kwai-YuanQi/MM-RLHF"
"yfzhang114/r1_reward" -> "VITA-MLLM/Sparrow"
"yfzhang114/r1_reward" -> "MME-Benchmarks/MME-Unify"
"yfzhang114/r1_reward" -> "VITA-MLLM/VITA-Audio"
"Alpha-Innovator/Dolphin" -> "Alpha-Innovator/TrustGeoGen"
"likyoo/awesome-MLLM-for-image-segmentation" -> "kang-wu/SkySensePlusPlus"
"hmxiong/StreamChat" -> "JiazuoYu/PathWeave"
"intsig-textin/chatdoc" -> "intsig-textin/chatdoc_stack"
"intsig-textin/chatdoc" -> "intsig-textin/parsex-sdk"
"xiong-zhitong/GeoLB-SigLIP" -> "NJU-LHRS/ScoreRS"
"MCG-NJU/CaReBench" -> "MCG-NJU/NeuralSolver" ["e"=1]
"MCG-NJU/CaReBench" -> "HELLORPG/CV-Framework"
"coin-dataset/annotation-tool" ["l"="48.001,30.233"]
"xujinglin/FineDiving" ["l"="47.96,30.225"]
"425776024/VideoLabeling" ["l"="48.031,30.233"]
"nzl-thu/MUSDL" ["l"="47.978,30.238"]
"pomonam/AttentionCluster" ["l"="48.037,30.266"]
"hazeld/rank-aware-attention-network" ["l"="48.011,30.251"]
"Maluuba/FigureQA" ["l"="47.03,30.459"]
"kushalkafle/DVQA_dataset" ["l"="47.044,30.456"]
"vmichals/FigureQA-baseline" ["l"="47.031,30.475"]
"LisaAnne/Hallucination" ["l"="47.322,30.322"]
"AoiDragon/POPE" ["l"="47.318,30.307"]
"RUCAIBox/POPE" ["l"="47.342,30.283"]
"BillChan226/HALC" ["l"="47.332,30.307"]
"ParitoshParmar/MTL-AQA" ["l"="47.96,30.236"]
"yuxumin/CoRe" ["l"="47.944,30.225"]
"ZhouKanglei/Awesome-AQA" ["l"="47.944,30.212"]
"Shunli-Wang/TSA-Net" ["l"="47.97,30.22"]
"shiyi-zh0408/LOGO" ["l"="47.898,30.222"]
"baiyang4/aqa_tpt" ["l"="47.95,30.218"]
"ParitoshParmar/Fitness-AQA" ["l"="47.967,30.212"]
"kushalkafle/PReFIL" ["l"="47.037,30.444"]
"NiteshMethani/PlotQA" ["l"="47.054,30.43"]
"JasonObeid/Chart2Text" ["l"="47.06,30.359"]
"vis-nlp/Chart-to-text" ["l"="47.077,30.343"]
"gongliym/data2text-transformer" ["l"="47.022,30.372"]
"tingyaohsu/SciCap" ["l"="47.078,30.365"]
"soap117/DeepRule" ["l"="47.043,30.378"]
"pranonrahman/ChartSumm" ["l"="47.074,30.331"]
"vis-nlp/ChartQA" ["l"="47.101,30.344"]
"Cvrane/ChartReader" ["l"="47.029,30.405"]
"SDOlivia/FineGym" ["l"="48.071,30.26"]
"Chuhanxx/Temporal_Query_Networks" ["l"="48.106,30.266"]
"coriverchen/Robust_Steganography" ["l"="47.787,30.441"]
"mengtong0110/InferDPT" ["l"="47.788,30.417"]
"TheJaeLal/LineFormer" ["l"="46.982,30.422"]
"bloomberg/scatteract" ["l"="47.002,30.395"]
"Lyman-Smoker/Awesome-AQA" ["l"="47.993,30.206"]
"xuangch/CVPR22_GDLT" ["l"="47.936,30.218"]
"Luciferbobo/DAE-AQA" ["l"="47.956,30.207"]
"archiki/Robust-E2E-ASR" ["l"="47.869,30.455"]
"YUCHEN005/DPSL-ASR" ["l"="47.852,30.431"]
"bliunlpr/Robust_e2e_gan" ["l"="47.882,30.478"]
"ZhouKanglei/HGCN_AQA" ["l"="47.963,30.195"]
"kahnchana/svt" ["l"="47.886,30.068"]
"kahnchana/clippy" ["l"="47.841,30.083"]
"tingxueronghua/ChartLlama-code" ["l"="47.107,30.279"]
"vis-nlp/UniChart" ["l"="47.112,30.306"]
"google-research/pix2struct" ["l"="46.322,5.965"]
"mitvis/vistext" ["l"="47.085,30.322"]
"FuxiaoLiu/MMC" ["l"="47.168,30.298"]
"zengxingchen/ChartQA-MLLM" ["l"="-5.59,-41.828"]
"OpenGVLab/ChartAst" ["l"="47.044,30.306"]
"princeton-nlp/CharXiv" ["l"="47.077,30.392"]
"levymsn/CQA-CRCT" ["l"="47.102,30.368"]
"vis-nlp/ChartGemma" ["l"="47.101,30.386"]
"vis-nlp/ChartInstruct" ["l"="47.101,30.327"]
"YUCHEN005/RATS-Channel-A-Speech-Data" ["l"="47.835,30.419"]
"YUCHEN005/Gradient-Remedy" ["l"="47.818,30.411"]
"YUCHEN005/UNA-GAN" ["l"="47.832,30.408"]
"Ethan00Si/Instrumental-variables-for-recommendation" ["l"="46.884,30.357"]
"Ethan00Si/KuaiSAR" ["l"="46.863,30.365"]
"Ethan00Si/SESREC-SIGIR-2023" ["l"="46.907,30.35"]
"FuxiaoLiu/Twitter-Video-dataset" ["l"="47.197,30.299"]
"FuxiaoLiu/DocumentCLIP" ["l"="47.226,30.293"]
"qinghuannn/PAMFN" ["l"="47.977,30.18"]
"microsoft/i-Code" ["l"="47.583,29.952"]
"microsoft/UDOP" ["l"="46.327,6.043"]
"NExT-GPT/NExT-GPT" ["l"="47.491,29.926"]
"facebookresearch/ImageBind" ["l"="49.068,30.103"]
"thu-ml/unidiffuser" ["l"="45.765,31.528"]
"SHI-Labs/Versatile-Diffusion" ["l"="33.385,31.435"]
"DAMO-NLP-SG/Video-LLaMA" ["l"="47.525,30.006"]
"AlibabaResearch/AdvancedLiterateMachinery" ["l"="46.369,6.029"]
"baaivision/Emu" ["l"="46.521,30.662"]
"mlfoundations/open_flamingo" ["l"="49.028,30.256"]
"lucidrains/make-a-video-pytorch" ["l"="33.657,31.288"]
"YingqingHe/LVDM" ["l"="33.653,31.329"]
"AILab-CVC/VideoCrafter" ["l"="33.589,31.197"]
"salesforce/LAVIS" ["l"="49.008,30.194"]
"showlab/Show-o" ["l"="46.437,30.648"]
"gligen/GLIGEN" ["l"="33.379,31.323"]
"lupantech/ScienceQA" ["l"="47.248,30.316"]
"amazon-science/mm-cot" ["l"="49.134,30.261"]
"yuweihao/MM-Vet" ["l"="47.314,30.258"]
"wenhuchen/TheoremQA" ["l"="37.55,-0.353"]
"lupantech/chameleon-llm" ["l"="36.795,-2.439"]
"lupantech/MathVista" ["l"="47.22,30.34"]
"ylsung/VL_adapter" ["l"="50.197,38.201"]
"FuxiaoLiu/LRV-Instruction" ["l"="47.339,30.264"]
"lupantech/dl4math" ["l"="37.487,-0.344"]
"MMMU-Benchmark/MMMU" ["l"="47.26,30.272"]
"mandyyyyii/scibench" ["l"="37.599,-0.355"]
"lupantech/IconQA" ["l"="56.566,28.826"]
"Timothyxxx/Chain-of-ThoughtsPapers" ["l"="36.759,-2.46"]
"LightChen233/M3CoT" ["l"="47.227,30.36"]
"Computer-Vision-in-the-Wild/CVinW_Readings" ["l"="47.472,30.142"]
"microsoft/GLIP" ["l"="48.866,30.251"]
"ttengwang/Awesome_Prompting_Papers_in_Computer_Vision" ["l"="50.313,38.23"]
"DirtyHarryLYL/LLM-in-Vision" ["l"="47.427,30.163"]
"dvlab-research/LISA" ["l"="47.454,30.124"]
"KaiyangZhou/CoOp" ["l"="50.344,38.24"]
"IDEA-Research/awesome-detection-transformer" ["l"="48.75,30.304"]
"VainF/Awesome-Anything" ["l"="48.929,30.125"]
"microsoft/X-Decoder" ["l"="48.821,30.224"]
"jianzongwu/Awesome-Open-Vocabulary" ["l"="48.681,30.233"]
"LLaVA-VL/LLaVA-NeXT" ["l"="47.414,30.029"]
"TheShadow29/awesome-grounding" ["l"="48.847,31.967"]
"baaivision/Painter" ["l"="48.864,30.163"]
"KMnP/vpt" ["l"="50.273,38.24"]
"OpenGVLab/InternVideo" ["l"="47.549,30.045"]
"OpenGVLab/Ask-Anything" ["l"="47.522,30.03"]
"OpenGVLab/VideoChat-Flash" ["l"="47.552,30.13"]
"OpenGVLab/VideoMAEv2" ["l"="48.083,33.864"]
"MCG-NJU/VideoMAE" ["l"="48.045,33.812"]
"OpenGVLab/unmasked_teacher" ["l"="47.778,32.957"]
"yunlong10/Awesome-LLMs-for-Video-Understanding" ["l"="47.523,30.059"]
"PKU-YuanGroup/Video-LLaVA" ["l"="47.477,30.025"]
"OpenGVLab/VideoMamba" ["l"="49.175,34.184"]
"mbzuai-oryx/Video-ChatGPT" ["l"="47.532,30.076"]
"DAMO-NLP-SG/VideoLLaMA2" ["l"="47.553,30.072"]
"ArrowLuo/CLIP4Clip" ["l"="47.909,32.98"]
"magic-research/PLLaVA" ["l"="47.569,30.119"]
"SwinTransformer/Video-Swin-Transformer" ["l"="48.024,33.802"]
"JialianW/GRiT" ["l"="47.45,30.28"]
"showlab/Image2Paragraph" ["l"="49.024,30.224"]
"jshilong/GPT4RoI" ["l"="47.44,30.215"]
"davidnvq/grit" ["l"="48.639,31.933"]
"allenai/unified-io-inference" ["l"="47.462,30.349"]
"showlab/EgoVLP" ["l"="47.697,32.969"]
"shikras/shikra" ["l"="47.418,30.229"]
"X2FD/LVIS-INSTRUCT4V" ["l"="47.43,30.278"]
"ttengwang/Awesome_Long_Form_Video_Understanding" ["l"="47.576,30.135"]
"huangb23/VTimeLLM" ["l"="47.598,30.106"]
"rese1f/MovieChat" ["l"="47.572,30.105"]
"Ziyang412/VideoTree" ["l"="47.624,30.144"]
"boheumd/MA-LMM" ["l"="47.596,30.128"]
"RenShuhuai-Andy/TimeChat" ["l"="47.583,30.113"]
"md-mohaiminul/VideoRecap" ["l"="47.654,30.138"]
"MME-Benchmarks/Video-MME" ["l"="47.549,30.151"]
"daixiangzi/Awesome-Token-Compress" ["l"="47.547,30.207"]
"Wang-Xiaodong1899/Open-R1-Video" ["l"="47.373,30.13"]
"JUNJIE99/MLVU" ["l"="47.587,30.164"]
"EvolvingLMMs-Lab/LongVA" ["l"="47.562,30.158"]
"egoschema/EgoSchema" ["l"="47.635,30.141"]
"j-min/HiREST" ["l"="47.969,33.095"]
"QQ-MM/Video-CCAM" ["l"="47.614,30.171"]
"allenai/unified-io-2" ["l"="46.539,30.684"]
"TencentARC/GVT" ["l"="47.467,30.392"]
"ch3cook-fdu/Vote2Cap-DETR" ["l"="46.905,30.238"]
"Open3DA/LL3DA" ["l"="65.134,11.739"]
"HankYe/AdaptiveDiffusion" ["l"="46.966,30.242"]
"Yangyi-Chen/Multimodal-AND-Large-Language-Models" ["l"="47.335,30.191"]
"showlab/Awesome-MLLM-Hallucination" ["l"="47.329,30.274"]
"DAMO-NLP-SG/VCD" ["l"="47.352,30.311"]
"Sun-Haoyuan23/Awesome-RL-based-Reasoning-MLLMs" ["l"="47.336,30.127"]
"xieyuquanxx/awesome-Large-MultiModal-Hallucination" ["l"="47.345,30.3"]
"HillZhang1999/llm-hallucination-survey" ["l"="37.656,-6.917"]
"shikiw/OPERA" ["l"="47.362,30.288"]
"Fancy-MLLM/R1-Onevision" ["l"="47.322,30.115"]
"TideDra/lmm-r1" ["l"="47.316,30.101"]
"SinclairCoder/Instruction-Tuning-Papers" ["l"="36.756,-2.518"]
"ChaofanTao/Autoregressive-Models-in-Vision-Survey" ["l"="46.437,30.673"]
"Osilly/Vision-R1" ["l"="47.312,30.127"]
"open-compass/VLMEvalKit" ["l"="47.359,30.06"]
"EvolvingLMMs-Lab/open-r1-multimodal" ["l"="47.343,30.101"]
"google-deepmind/perception_test" ["l"="47.642,30.179"]
"PKU-YuanGroup/Video-Bench" ["l"="64.241,3.9"]
"YUCHEN005/Unified-Enhance-Separation" ["l"="47.831,30.432"]
"HELLORPG/CV-Framework" ["l"="47.635,30.355"]
"MCG-NJU/CaReBench" ["l"="47.625,30.34"]
"AndyTang15/FLAG3D" ["l"="47.79,30.222"]
"AndyTang15/FLAG3Dv2" ["l"="47.781,30.214"]
"iSEE-Laboratory/Continual-AQA" ["l"="48.021,30.191"]
"Run542968/Awesome-3D-Human-Motion-Generation" ["l"="48.007,30.193"]
"iSEE-Laboratory/EgoExo-Fitness" ["l"="48.017,30.204"]
"Alpha-VLLM/LLaMA2-Accessory" ["l"="47.478,29.969"]
"OpenGVLab/LLaMA-Adapter" ["l"="39.851,0.706"]
"X-PLUG/mPLUG-Owl" ["l"="47.444,29.996"]
"InternLM/InternLM-XComposer" ["l"="47.384,30.005"]
"QwenLM/Qwen-VL" ["l"="47.411,29.954"]
"EvolvingLMMs-Lab/Otter" ["l"="50.99,2.78"]
"BradyFU/Awesome-Multimodal-Large-Language-Models" ["l"="47.423,29.9"]
"THUDM/CogVLM" ["l"="47.384,29.926"]
"Alpha-VLLM/Lumina-T2X" ["l"="33.459,31.175"]
"haotian-liu/LLaVA" ["l"="47.375,29.865"]
"openai/CLIP" ["l"="50.642,29.547"]
"Vision-CAIR/MiniGPT-4" ["l"="39.832,0.405"]
"mlfoundations/open_clip" ["l"="48.974,30.216"]
"OpenGVLab/InternVL" ["l"="47.362,29.955"]
"IDEA-Research/Grounded-Segment-Anything" ["l"="48.915,30.081"]
"lm-sys/FastChat" ["l"="40.074,0.427"]
"huggingface/peft" ["l"="40.04,0.52"]
"vllm-project/vllm" ["l"="40.265,0.397"]
"hiyouga/LLaMA-Factory" ["l"="40.278,0.218"]
"Dao-AILab/flash-attention" ["l"="38.876,-0.736"]
"open-mmlab/Multimodal-GPT" ["l"="47.499,30.148"]
"open-mmlab/mmfewshot" ["l"="49.426,29.431"]
"InternLM/InternLM-techreport" ["l"="38.794,-1.827"]
"open-mmlab/mmengine" ["l"="50.421,29.903"]
"open-mmlab/mmeval" ["l"="49.474,29.465"]
"open-mmlab/playground" ["l"="48.845,30.051"]
"jshilong/GroupRCNN" ["l"="49.461,29.481"]
"RUCAIBox/LLMSurvey" ["l"="38.837,-2.036"]
"pliang279/awesome-multimodal-ml" ["l"="48.592,32.051"]
"microsoft/unilm" ["l"="38.785,-0.95"]
"QwenLM/Qwen2.5-VL" ["l"="47.318,29.932"]
"Hannibal046/Awesome-LLM" ["l"="40.2,0.476"]
"InvincibleWyq/ChatVID" ["l"="47.807,30.208"]
"SuleBai/SC-CLIP" ["l"="47.773,30.219"]
"mbzuai-oryx/groundingLMM" ["l"="47.465,30.182"]
"UX-Decoder/Semantic-SAM" ["l"="48.814,30.127"]
"OpenGVLab/VisionLLM" ["l"="47.46,30.162"]
"UX-Decoder/Segment-Everything-Everywhere-All-At-Once" ["l"="48.865,30.127"]
"facebookresearch/Mask2Former" ["l"="48.83,30.207"]
"Liuziyu77/Visual-RFT" ["l"="47.336,30.087"]
"MarkMoHR/Awesome-Referring-Image-Segmentation" ["l"="48.925,31.903"]
"baaivision/EVA" ["l"="48.906,30.24"]
"NVlabs/ODISE" ["l"="48.752,30.251"]
"microsoft/MM-REACT" ["l"="47.433,30.256"]
"allenai/visprog" ["l"="47.462,30.218"]
"OptimalScale/DetGPT" ["l"="47.468,30.2"]
"allenai/mmc4" ["l"="49.046,30.301"]
"cvlab-columbia/viper" ["l"="49.056,30.267"]
"ashkamath/mdetr" ["l"="48.833,31.941"]
"Vision-CAIR/ChatCaptioner" ["l"="49.086,30.262"]
"penghao-wu/vstar" ["l"="47.403,30.173"]
"lyuchenyang/Macaw-LLM" ["l"="47.559,29.998"]
"longyuewangdcu/Chinese-Llama-2" ["l"="50.676,3.032"]
"yxuansu/PandaGPT" ["l"="47.481,30.097"]
"wxjiao/ParroT" ["l"="53.962,25.021"]
"bytedance/SALMONN" ["l"="38.502,2.031"]
"Text-to-Audio/Make-An-Audio" ["l"="50.744,2.954"]
"PeiranLi0930/TorchProject" ["l"="50.651,2.959"]
"thunlp/WebCPM" ["l"="50.705,2.93"]
"aiwaves-cn/agents" ["l"="36.726,-2.215"]
"williamyang1991/Rerender_A_Video" ["l"="33.635,31.168"]
"OpenMOSS/AnyGPT" ["l"="38.484,2.042"]
"QwenLM/Qwen" ["l"="38.989,-1.849"]
"modelscope/ms-swift" ["l"="38.867,-1.929"]
"IDEA-Research/GroundingDINO" ["l"="48.845,30.11"]
"salesforce/BLIP" ["l"="48.991,30.249"]
"dvlab-research/LLaMA-VID" ["l"="47.518,30.09"]
"PKU-YuanGroup/LanguageBind" ["l"="47.504,30.049"]
"X-PLUG/mPLUG-DocOwl" ["l"="47.309,29.975"]
"junyangwang0410/AMBER" ["l"="47.316,30.289"]
"EvolvingLMMs-Lab/lmms-eval" ["l"="51.076,2.828"]
"CASIA-IVA-Lab/AnomalyGPT" ["l"="53.251,14.178"]
"zeroQiaoba/AffectGPT" ["l"="56.513,28.11"]
"luogen1996/LaVIN" ["l"="47.399,30.214"]
"OpenGVLab/LAMM" ["l"="47.389,30.235"]
"0nutation/SpeechGPT" ["l"="38.507,1.994"]
"HenryHZY/Awesome-Multimodal-LLM" ["l"="47.409,30.263"]
"csuhan/OneLLM" ["l"="47.478,30.055"]
"LinkSoul-AI/LLaSM" ["l"="38.455,2.106"]
"THUDM/CogVLM2" ["l"="47.355,29.987"]
"THUDM/VisualGLM-6B" ["l"="39.161,-2.048"]
"THUDM/ChatGLM3" ["l"="39.017,-1.891"]
"THUDM/GLM-4" ["l"="39.032,-1.848"]
"invictus717/MetaTransformer" ["l"="47.494,30.005"]
"baaivision/Uni3D" ["l"="65.179,11.71"]
"facebookresearch/multimodal" ["l"="48.947,30.29"]
"InternLM/InternLM" ["l"="38.916,-1.913"]
"InternLM/xtuner" ["l"="38.848,-1.888"]
"InternLM/lagent" ["l"="38.82,-1.827"]
"InternLM/lmdeploy" ["l"="38.95,-0.593"]
"Yuliang-Liu/Monkey" ["l"="51.19,2.719"]
"cambrian-mllm/cambrian" ["l"="47.383,30.081"]
"mbzuai-oryx/VideoGPT-plus" ["l"="47.556,30.111"]
"mbzuai-oryx/Video-LLaVA" ["l"="47.543,30.119"]
"PKU-YuanGroup/Chat-UniVi" ["l"="-54.539,-12.838"]
"Vision-CAIR/MiniGPT4-video" ["l"="47.553,30.093"]
"YiyangZhou/LURE" ["l"="47.331,30.293"]
"YiyangZhou/CSR" ["l"="47.289,30.267"]
"YiyangZhou/POVID" ["l"="47.309,30.238"]
"tianyi-lab/HallusionBench" ["l"="47.306,30.283"]
"Purshow/Awesome-LVLM-Hallucination" ["l"="47.342,30.337"]
"Ucas-HaoranWei/Vary" ["l"="47.281,30.013"]
"Ucas-HaoranWei/GOT-OCR2.0" ["l"="40.783,-0.011"]
"Yuliang-Liu/MultimodalOCR" ["l"="46.656,7.414"]
"clovaai/donut" ["l"="46.254,6.071"]
"LukeForeverYoung/UReader" ["l"="46.352,5.921"]
"opendatalab/DocLayout-YOLO" ["l"="46.421,5.954"]
"illuin-tech/colpali" ["l"="41.303,0.709"]
"hikopensource/DAVAR-Lab-OCR" ["l"="46.413,6.081"]
"OpenGVLab/InternGPT" ["l"="40.967,-3.607"]
"cientgu/InstructDiffusion" ["l"="33.206,31.412"]
"SkyworkAI/Vitron" ["l"="47.494,30.173"]
"lxtGH/OMG-Seg" ["l"="51.008,2.867"]
"yuhangzang/ContextDET" ["l"="47.491,30.206"]
"google-research/pix2seq" ["l"="48.825,30.345"]
"YUCHEN005/GILA" ["l"="47.849,30.408"]
"YUCHEN005/MIR-GAN" ["l"="47.835,30.397"]
"YUCHEN005/UniVPM" ["l"="47.82,30.392"]
"PKU-YuanGroup/MoE-LLaVA" ["l"="47.445,30.071"]
"fabawi/ImageBind-LoRA" ["l"="52.975,14.35"]
"snap-research/Panda-70M" ["l"="33.584,31.343"]
"TXH-mercury/VALOR" ["l"="47.778,32.932"]
"TXH-mercury/VAST" ["l"="47.793,32.925"]
"tsujuifu/pytorch_mgie" ["l"="47.43,29.677"]
"apple/ml-mgie" ["l"="47.423,29.727"]
"TencentARC/SmartEdit" ["l"="33.215,31.317"]
"Vision-CAIR/LongVU" ["l"="47.607,30.157"]
"VectorSpaceLab/Video-XL" ["l"="47.596,30.143"]
"DCDmllm/Momentor" ["l"="47.624,30.09"]
"Yui010206/SeViLA" ["l"="47.62,30.115"]
"modelscope/motionagent" ["l"="46.949,30.263"]
"modelscope/DiffSynth-Engine" ["l"="47.012,30.217"]
"HaozheZhao/MIC" ["l"="47.396,30.311"]
"pkunlp-icler/MIC" ["l"="47.394,30.362"]
"HaozheZhao/MIC_tool" ["l"="47.38,30.356"]
"pkunlp-icler/PCA-EVAL" ["l"="37.077,-1.18"]
"VT-NLP/MultiInstruct" ["l"="47.375,30.313"]
"DCDmllm/Cheetah" ["l"="47.386,30.394"]
"RLHF-V/RLHF-V" ["l"="47.316,30.212"]
"xinyu1205/recognize-anything" ["l"="48.905,30.145"]
"OpenGVLab/Multi-Modality-Arena" ["l"="47.363,30.271"]
"FreedomIntelligence/HuatuoGPT-Vision" ["l"="62.364,37.678"]
"microsoft/LLaVA-Med" ["l"="62.359,37.614"]
"xiaoman-zhang/PMC-VQA" ["l"="62.331,37.605"]
"AILab-CVC/SEED" ["l"="46.508,30.691"]
"OpenGVLab/MMT-Bench" ["l"="47.182,30.317"]
"AILab-CVC/SEED-Bench" ["l"="47.282,30.295"]
"BAAI-DCAI/M3D" ["l"="62.447,37.637"]
"RunpeiDong/DreamLLM" ["l"="46.515,30.707"]
"OpenGVLab/all-seeing" ["l"="47.38,30.222"]
"BAAI-DCAI/Visual-Instruction-Tuning" ["l"="47.329,30.233"]
"FreedomIntelligence/ALLaVA" ["l"="47.359,30.204"]
"OpenGVLab/OmniCorpus" ["l"="47.353,30.225"]
"SALT-NLP/LLaVAR" ["l"="47.35,30.24"]
"shikras/d-cube" ["l"="48.549,30.21"]
"tsb0601/MMVP" ["l"="47.341,30.208"]
"FoundationVision/Groma" ["l"="50.752,3.019"]
"magic-research/bubogpt" ["l"="47.411,30.288"]
"AILab-CVC/Animate-A-Story" ["l"="33.317,31.109"]
"WisconsinAIVision/ViP-LLaVA" ["l"="47.4,30.245"]
"VITA-MLLM/Woodpecker" ["l"="47.384,30.268"]
"shenyunhang/APE" ["l"="48.647,30.18"]
"llava-rlhf/LLaVA-RLHF" ["l"="47.332,30.247"]
"xjtupanda/Sparrow" ["l"="47.505,30.279"]
"VITA-MLLM/VITA" ["l"="38.446,1.902"]
"mlpc-ucsd/BLIVA" ["l"="47.226,30.226"]
"doc-doc/NExT-QA" ["l"="47.875,33.08"]
"Share14/ShareGemini" ["l"="47.701,30.113"]
"bigai-nlco/VideoLLaMB" ["l"="47.698,30.151"]
"jshilong/DDQ" ["l"="48.679,30.342"]
"facebookresearch/VLPart" ["l"="48.75,30.278"]
"jshilong/FisherPruning" ["l"="49.463,29.505"]
"SkunkworksAI/hydra-moe" ["l"="47.46,30.439"]
"hydrallm/llama-moe-v1" ["l"="47.46,30.504"]
"r-three/phatgoose" ["l"="47.451,30.477"]
"AblateIt/finetune-study" ["l"="47.46,30.541"]
"taylorai/galactic" ["l"="38.489,-0.366"]
"Cohere-Labs-Community/parameter-efficient-moe" ["l"="38.492,-0.299"]
"liuqidong07/MOELoRA-peft" ["l"="38.439,-0.251"]
"SkunkworksAI/BakLLaVA" ["l"="47.471,30.311"]
"JindongGu/Awesome-Prompting-on-Vision-Language-Model" ["l"="50.339,38.212"]
"jy0205/LaVIT" ["l"="46.494,30.675"]
"DirtyHarryLYL/Transformer-in-Vision" ["l"="50.85,29.7"]
"ytongbai/LVM" ["l"="46.493,30.613"]
"BAAI-DCAI/DataOptim" ["l"="47.246,30.253"]
"VPGTrans/VPGTrans" ["l"="47.488,30.272"]
"NExT-ChatV/NExT-Chat" ["l"="47.529,30.23"]
"vincentlux/Awesome-Multimodal-LLM" ["l"="47.424,30.329"]
"thunlp/LLaVA-UHD" ["l"="47.38,30.202"]
"YuchenLiu98/COMM" ["l"="47.234,30.275"]
"apitube/docs" ["l"="47.441,30.638"]
"mevbotcrypto/mev-bot" ["l"="47.454,30.651"]
"Yuqifan1117/HalluciDoctor" ["l"="47.304,30.316"]
"open-compass/MMBench" ["l"="47.294,30.252"]
"RupertLuo/Valley" ["l"="47.652,30.103"]
"bytedance/Shot2Story" ["l"="47.722,30.082"]
"TimeMarker-LLM/TimeMarker" ["l"="47.631,30.109"]
"lyingCS/UOEP" ["l"="47.01,30.329"]
"lyingCS/Controllable-Multi-Objective-Reranking" ["l"="47.009,30.321"]
"OpenGVLab/Multitask-Model-Selector" ["l"="47.023,30.332"]
"DCDmllm/MorphTokens" ["l"="47.359,30.459"]
"DCDmllm/AnyEdit" ["l"="33.109,31.259"]
"IDEA-Research/OpenSeeD" ["l"="48.733,30.218"]
"microsoft/RegionCLIP" ["l"="48.631,30.276"]
"witnessai/Awesome-Open-Vocabulary-Object-Detection" ["l"="48.608,30.245"]
"Saiyan-World/grounded-segment-any-parts" ["l"="48.712,30.23"]
"RLHF-V/RLAIF-V" ["l"="47.305,30.225"]
"TideDra/VL-RLHF" ["l"="47.263,30.23"]
"RifleZhang/LLaVA-Hound-DPO" ["l"="47.428,30.187"]
"FanqingM/R1-Multimodal-Journey" ["l"="47.308,30.139"]
"vlf-silkie/VLFeedback" ["l"="47.281,30.239"]
"luogen1996/LLaVA-HR" ["l"="47.44,30.228"]
"luogen1996/RepAdapter" ["l"="50.203,38.237"]
"luogen1996/SimREC" ["l"="49.12,31.875"]
"seanzhuh/SeqTR" ["l"="49.029,31.903"]
"IranQin/MP5" ["l"="41.004,-4.541"]
"embodied-generalist/embodied-generalist" ["l"="65.084,11.742"]
"ChenYi99/EgoPlan" ["l"="59.571,16.531"]
"palchenli/VL-Instruction-Tuning" ["l"="47.263,30.362"]
"OpenGVLab/MM-Interleaved" ["l"="46.561,30.699"]
"antoyang/FrozenBiLM" ["l"="47.853,32.988"]
"doc-doc/NExT-GQA" ["l"="47.85,33.05"]
"VRU-NExT/VideoQA" ["l"="47.854,33.09"]
"minghangz/cpl" ["l"="48.047,33.108"]
"mlvlab/Flipped-VQA" ["l"="-35.077,23.278"]
"klauscc/VindLU" ["l"="47.796,32.981"]
"showlab/mist" ["l"="47.823,33.104"]
"jayleicn/singularity" ["l"="47.846,32.965"]
"showlab/all-in-one" ["l"="47.833,32.976"]
"reactorsh/ambrosia" ["l"="47.451,30.612"]
"thunlp/Muffin" ["l"="47.289,30.212"]
"hyungkwonko/chart-llm" ["l"="-5.542,-41.781"]
"TengShi-RUC/UniSAR" ["l"="46.982,30.326"]
"rucliujn/JDsearch" ["l"="-2.534,8.893"]
"YUCHEN005/NASE" ["l"="47.841,30.452"]
"patrick-tssn/Awesome-Colorful-LLM" ["l"="47.77,30.142"]
"yuezih/Movie101" ["l"="47.377,30.521"]
"yuezih/SMILE" ["l"="47.382,30.485"]
"Hypotheses-Paradise/Hypo2Trans" ["l"="47.878,30.428"]
"YUCHEN005/RobustGER" ["l"="47.913,30.453"]
"CarperAI/treasure_trove" ["l"="47.475,30.575"]
"Alignment-Lab-AI/datagen" ["l"="47.452,30.565"]
"shiyi-zh0408/NAE_CVPR2024" ["l"="47.796,30.217"]
"MasterAI-EAM/GraphMaster" ["l"="46.956,30.426"]
"pengyu965/ChartDete" ["l"="46.959,30.443"]
"jonathan-roberts1/GPT4GEO" ["l"="47.638,30.612"]
"jonathan-roberts1/charting-new-territories" ["l"="47.63,30.587"]
"jonathan-roberts1/SciFIBench" ["l"="47.65,30.638"]
"tdsone/extract-line-chart-data" ["l"="46.941,30.458"]
"Alpha-Innovator/SimChart9K" ["l"="47.068,30.272"]
"OpenGVLab/MMIU" ["l"="47.046,30.324"]
"kahnchana/mvu" ["l"="47.803,30.097"]
"khuangaf/ZeroFEC" ["l"="47.017,30.35"]
"khuangaf/CHOCOLATE" ["l"="47.037,30.337"]
"zhengbw0324/LC-Rec" ["l"="46.99,30.335"]
"E-qin/GEAR" ["l"="47.022,30.315"]
"jaeill/CVPR23-VNE" ["l"="47.733,30.011"]
"SNU-DRL/Attribution-ECG" ["l"="47.706,30.035"]
"Alpha-Innovator/TrustGeoGen" ["l"="47,30.256"]
"apple/ml-ferret" ["l"="47.375,29.761"]
"ml-explore/mlx" ["l"="40.274,0.591"]
"cumulo-autumn/StreamDiffusion" ["l"="33.639,30.968"]
"ml-explore/mlx-examples" ["l"="27.528,-21.061"]
"apple/corenet" ["l"="39.202,-0.546"]
"TencentQQGYLab/AppAgent" ["l"="40.729,0.325"]
"stanfordnlp/dspy" ["l"="40.726,0.466"]
"mistralai/mistral-inference" ["l"="38.79,-0.727"]
"meta-llama/llama-cookbook" ["l"="40.401,0.438"]
"letta-ai/letta" ["l"="40.762,0.35"]
"apple/ml-stable-diffusion" ["l"="27.398,-20.985"]
"ShishirPatil/gorilla" ["l"="41.126,-3.931"]
"LargeWorldModel/LWM" ["l"="47.44,29.845"]
"google/magika" ["l"="-13.239,-7.636"]
"karpathy/minbpe" ["l"="40.261,0.682"]
"facebookresearch/DiT" ["l"="45.849,31.545"]
"PKU-YuanGroup/Open-Sora-Plan" ["l"="33.524,31.053"]
"Stability-AI/StableCascade" ["l"="33.544,30.971"]
"hpcaitech/Open-Sora" ["l"="33.39,32.96"]
"dvlab-research/MGM" ["l"="47.407,29.986"]
"facebookresearch/jepa" ["l"="49.119,30.148"]
"mit-han-lab/streaming-llm" ["l"="38.853,-0.645"]
"sgl-project/sglang" ["l"="38.933,-0.652"]
"OpenBMB/MiniCPM-o" ["l"="47.272,29.853"]
"om-ai-lab/VLM-R1" ["l"="47.323,30.014"]
"Deep-Agent/R1-V" ["l"="47.321,30.059"]
"open-compass/opencompass" ["l"="38.902,-2.019"]
"hiyouga/EasyR1" ["l"="37.16,-0.534"]
"ModalMinds/MM-EUREKA" ["l"="47.343,30.116"]
"OpenBMB/MiniCPM" ["l"="51.395,2.802"]
"fishaudio/fish-speech" ["l"="38.438,1.562"]
"unslothai/unsloth" ["l"="40.533,0.197"]
"QwenLM/Qwen3" ["l"="38.923,-1.766"]
"stanford-oval/storm" ["l"="40.862,0.041"]
"opendatalab/MinerU" ["l"="40.716,-0.19"]
"FoundationAgents/MetaGPT" ["l"="40.43,0.067"]
"2noise/ChatTTS" ["l"="38.426,1.48"]
"NVlabs/VILA" ["l"="47.441,30.034"]
"mit-han-lab/llm-awq" ["l"="38.87,-0.434"]
"openvla/openvla" ["l"="59.342,16.633"]
"baaivision/Emu3" ["l"="46.418,30.643"]
"FujiwaraChoki/MoneyPrinter" ["l"="40.638,-0.235"]
"GoogleCloudPlatform/localllm" ["l"="40.581,-0.463"]
"metavoiceio/metavoice-src" ["l"="38.601,1.733"]
"YangLing0818/RPG-DiffusionMaster" ["l"="33.405,31.259"]
"levihsu/OOTDiffusion" ["l"="33.575,30.956"]
"Doubiiu/DynamiCrafter" ["l"="33.511,31.173"]
"LLaVA-VL/LLaVA-Interactive-Demo" ["l"="47.502,30.311"]
"LLaVA-VL/LLaVA-Plus-Codebase" ["l"="47.468,30.239"]
"FoundationVision/VAR" ["l"="51.232,2.921"]
"TinyLLaVA/TinyLLaVA_Factory" ["l"="47.406,30.116"]
"BAAI-DCAI/Bunny" ["l"="47.39,30.104"]
"PKU-YuanGroup/LLaVA-CoT" ["l"="47.386,30.057"]
"IVGSZ/Flash-VStream" ["l"="47.693,30.192"]
"ziplab/LongVLM" ["l"="47.631,30.125"]
"TencentARC/ST-LLM" ["l"="47.608,30.132"]
"xk-huang/segment-caption-anything" ["l"="47.801,30.234"]
"EternalEvan/DPMesh" ["l"="47.771,30.23"]
"Tengbo-Yu/AnyBimanual" ["l"="47.753,30.222"]
"GuanxingLu/vlarl" ["l"="47.76,30.239"]
"Yxxxb/VoCo-LLaMA" ["l"="47.702,30.234"]
"shiyi-zh0408/FlexiAct" ["l"="47.832,30.213"]
"GuanxingLu/ManiGaussian" ["l"="59.551,16.646"]
"zhang9302002/Flash-VStream" ["l"="47.779,30.206"]
"yongliu20/SCAN" ["l"="47.817,30.224"]
"Fuzzy-Search/realtime-bakllava" ["l"="47.506,30.431"]
"cognitivecomputations/laserRMT" ["l"="38.471,-0.19"]
"Meituan-AutoML/MobileVLM" ["l"="47.409,30.083"]
"DLYuanGod/TinyGPT-V" ["l"="47.424,30.061"]
"xmoanvaf/llava-phi" ["l"="47.417,30.103"]
"TRI-ML/prismatic-vlms" ["l"="59.418,16.641"]
"chongzhou96/EdgeSAM" ["l"="48.723,29.949"]
"YouHuang67/mamba-code-explained" ["l"="53.109,30.404"]
"mbzuai-oryx/LLaVA-pp" ["l"="47.428,30.125"]
"zjysteven/lmms-finetune" ["l"="47.39,30.154"]
"xiaoachen98/Open-LLaVA-NeXT" ["l"="50.725,3.192"]
"bfshi/scaling_on_scales" ["l"="47.42,30.207"]
"alibaba/conv-llava" ["l"="47.437,30.304"]
"HJYao00/DenseConnector" ["l"="47.583,30.244"]
"baaivision/EVE" ["l"="46.476,30.715"]
"SHI-Labs/VCoder" ["l"="47.472,30.286"]
"gokayfem/awesome-vlm-architectures" ["l"="47.373,30.036"]
"gokayfem/ComfyUI_VLM_nodes" ["l"="32.663,32.815"]
"jingyi0000/VLM_survey" ["l"="50.954,2.79"]
"zhengli97/Awesome-Prompt-Adapter-Learning-for-VLMs" ["l"="50.383,38.257"]
"DAMO-NLP-SG/VideoLLaMA3" ["l"="47.523,30.108"]
"friedrichor/Awesome-Multimodal-Papers" ["l"="48.543,29.881"]
"zli12321/Vision-Language-Models-Overview" ["l"="47.231,29.966"]
"NVlabs/VILA-archive" ["l"="47.258,30.073"]
"swordlidev/Efficient-Multimodal-LLMs-Survey" ["l"="47.518,30.217"]
"Ucas-HaoranWei/Vary-toy" ["l"="47.285,30.125"]
"LingyvKong/OneChart" ["l"="47.152,30.148"]
"oh-my-ocr/text_renderer" ["l"="46.459,7.308"]
"NishilBalar/Awesome-LVLM-Hallucination" ["l"="47.336,30.326"]
"LALBJ/PAI" ["l"="47.393,30.338"]
"yfzhang114/LLaVA-Align" ["l"="47.312,30.338"]
"Ziwei-Zheng/Nullu" ["l"="49.316,32.993"]
"zjunlp/Deco" ["l"="47.495,30.375"]
"voidism/DoLa" ["l"="37.648,-6.864"]
"shengliu66/VTI" ["l"="47.353,30.36"]
"yfzhang114/Awesome-Multimodal-Large-Language-Models" ["l"="47.35,30.165"]
"Kwai-YuanQi/MM-RLHF" ["l"="47.509,30.26"]
"yfzhang114/SliME" ["l"="47.447,30.245"]
"rongyaofang/GoT" ["l"="46.399,30.723"]
"MME-Benchmarks/MME-RealWorld" ["l"="47.465,30.257"]
"modelscope/awesome-deep-reasoning" ["l"="47.26,30.152"]
"showlab/Awesome-Unified-Multimodal-Models" ["l"="46.419,30.688"]
"zzli2022/Awesome-System2-Reasoning-LLM" ["l"="37.192,-0.543"]
"baaivision/CapsFusion" ["l"="46.532,30.74"]
"yihedeng9/STIC" ["l"="47.284,30.226"]
"luka-group/mDPO" ["l"="47.263,30.193"]
"scofield7419/Video-of-Thought" ["l"="47.777,32.115"]
"scofield7419/THOR-ISA" ["l"="51.344,-0.544"]
"MaverickRen/PixelLM" ["l"="47.492,30.241"]
"AILab-CVC/SEED-X" ["l"="46.466,30.681"]
"mit-han-lab/vila-u" ["l"="46.447,30.695"]
"FoundationVision/GLEE" ["l"="48.677,30.134"]
"RUCAIBox/Virgo" ["l"="47.288,30.189"]
"ParadoxZW/LLaVA-UHD-Better" ["l"="47.414,30.247"]
"pkunlp-icler/FastV" ["l"="47.583,30.26"]
"NVlabs/LITA" ["l"="47.614,30.079"]
"gyxxyg/VTG-LLM" ["l"="47.614,30.099"]
"WHB139426/Grounded-Video-LLM" ["l"="47.647,30.083"]
"www-Ye/TimeZero" ["l"="47.528,30.132"]
"gyxxyg/TRACE" ["l"="47.634,30.07"]
"yellow-binary-tree/HawkEye" ["l"="47.596,30.094"]
"MILVLG/imp" ["l"="47.369,30.095"]
"OSU-NLP-Group/SeeAct" ["l"="36.785,-1.484"]
"eric-ai-lab/MiniGPT-5" ["l"="46.568,30.723"]
"Flossiee/HonestyLLM" ["l"="47.528,29.955"]
"dvmazur/mixtral-offloading" ["l"="38.805,-0.477"]
"letitiabanana/PnP-OVSS" ["l"="47.9,30.263"]
"slonetime/EBSeg" ["l"="47.875,30.25"]
"Ucas-HaoranWei/Vary-family" ["l"="47.168,30.119"]
"Ucas-HaoranWei/Vary-tiny-600k" ["l"="47.152,30.125"]
"Coobiw/MPP-LLaVA" ["l"="47.375,30.166"]
"ucaslcl/Fox" ["l"="47.115,30.133"]
"microsoft/SoM" ["l"="47.404,30.19"]
"ddupont808/GPT-4V-Act" ["l"="36.813,-1.531"]
"zzxslp/SoM-LLaVA" ["l"="47.312,30.19"]
"huangwl18/VoxPoser" ["l"="59.456,16.583"]
"huangwl18/ReKep" ["l"="59.371,16.593"]
"IDEA-Research/Grounding-DINO-1.5-API" ["l"="48.72,30.116"]
"bytedance/tarsier" ["l"="47.579,30.148"]
"mira-space/MiraData" ["l"="33.596,31.403"]
"imagegridworth/IG-VLM" ["l"="47.667,30.078"]
"UX-Decoder/LLaVA-Grounding" ["l"="-55.506,-13.083"]
"zamling/PSALM" ["l"="47.498,30.224"]
"Meituan-AutoML/Lenna" ["l"="47.604,30.239"]
"lzw-lzw/GroundingGPT" ["l"="47.536,30.187"]
"IDEA-FinAI/ChartMoE" ["l"="47.438,30.195"]
"lxe/llavavision" ["l"="47.539,30.471"]
"LeapLabTHU/GSVA" ["l"="49.299,32.932"]
"congvvc/HyperSeg" ["l"="33.362,31.758"]
"berkeley-hipie/segllm" ["l"="47.532,30.328"]
"mc-lan/Text4Seg" ["l"="47.538,30.349"]
"shikiw/Awesome-MLLM-Hallucination" ["l"="38.283,-0.098"]
"LuckyyySTA/Awesome-LLM-hallucination" ["l"="37.64,-6.906"]
"42Shawn/LLaVA-PruMerge" ["l"="47.651,30.251"]
"Gumpest/SparseVLMs" ["l"="47.638,30.269"]
"Cooperx521/PyramidDrop" ["l"="47.674,30.31"]
"dvlab-research/VisionZip" ["l"="47.628,30.253"]
"Theia-4869/FasterVLM" ["l"="47.616,30.266"]
"SUSTechBruce/LOOK-M" ["l"="47.652,30.326"]
"lzhxmu/VTW" ["l"="47.604,30.296"]
"Beckschen/LLaVolta" ["l"="47.614,30.31"]
"ywh187/FitPrune" ["l"="47.637,30.299"]
"mrwu-mac/ControlMLLM" ["l"="47.577,30.316"]
"liuting20/MustDrop" ["l"="39.096,0.153"]
"yuezih/less-is-more" ["l"="47.387,30.433"]
"CircleRadon/Osprey" ["l"="64.134,11.38"]
"HarborYuan/ovsam" ["l"="48.712,30.143"]
"magic-research/Sa2VA" ["l"="50.832,3.039"]
"deepcs233/Visual-CoT" ["l"="47.312,30.165"]
"dongyh20/Insight-V" ["l"="47.275,30.163"]
"RupertLuo/VoCoT" ["l"="47.244,30.175"]
"turningpoint-ai/VisualThinker-R1-Zero" ["l"="47.304,30.113"]
"chancharikmitra/CCoT" ["l"="46.285,5.799"]
"ggg0919/cantor" ["l"="47.57,30.283"]
"zhourax/VEGA" ["l"="47.549,30.244"]
"MAC-AutoML/QuoTA" ["l"="47.545,30.267"]
"aimagelab/freeda" ["l"="47.927,30.282"]
"FreedomIntelligence/Apollo" ["l"="47.05,30.274"]
"FreedomIntelligence/ApolloMoE" ["l"="47.013,30.277"]
"FreedomIntelligence/MLLM-Bench" ["l"="47.139,30.275"]
"FreedomIntelligence/CMB" ["l"="55.54,27.501"]
"Deaddawn/MovieLLM-code" ["l"="47.637,30.029"]
"gls0425/LinVT" ["l"="47.686,30.094"]
"Alpha-Innovator/ChartVLM" ["l"="47.066,30.242"]
"findalexli/SciGraphQA" ["l"="51.477,-0.583"]
"MMStar-Benchmark/MMStar" ["l"="38.964,0.533"]
"Ucas-HaoranWei/Slow-Perception" ["l"="47.101,30.103"]
"1694439208/GOT-OCR-Inference" ["l"="47.067,30.114"]
"TencentARC/ViT-Lens" ["l"="33.425,31.75"]
"ZrrSkywalker/I2P-MAE" ["l"="65.294,11.693"]
"salesforce/ULIP" ["l"="65.237,11.688"]
"EvolvingLMMs-Lab/EgoLife" ["l"="47.529,30.253"]
"EvolvingLMMs-Lab/multimodal-search-r1" ["l"="47.416,30.364"]
"EvolvingLMMs-Lab/Aero-1" ["l"="50.071,38.423"]
"mathllm/MATH-V" ["l"="47.2,30.384"]
"ZrrSkywalker/MathVerse" ["l"="47.224,30.392"]
"HZQ950419/Math-LLaVA" ["l"="47.204,30.409"]
"pipilurj/G-LLaVA" ["l"="64.964,12.242"]
"ZrrSkywalker/MAVIS" ["l"="47.226,30.414"]
"liangyn22/MCUFormer" ["l"="47.858,30.274"]
"ChangyuanWang17/APQ-DM" ["l"="47.82,30.253"]
"jzhzhang/NaVid-VLN-CE" ["l"="60.26,17.623"]
"ChangyuanWang17/QVLM" ["l"="47.784,30.229"]
"OpenGVLab/PhyGenBench" ["l"="63.76,3.449"]
"CeeZh/LLoVi" ["l"="47.701,30.13"]
"agentic-learning-ai-lab/lifelong-memory" ["l"="47.735,30.116"]
"jongwoopark7978/LVNet" ["l"="47.742,30.13"]
"opendatalab/HA-DPO" ["l"="47.237,30.204"]
"cocktailpeanut/mirror" ["l"="47.504,30.467"]
"OneInterface/chat-with-page" ["l"="47.516,30.497"]
"EternalEvan/FlowIE" ["l"="47.79,30.203"]
"YUCHEN005/GenTranslate" ["l"="47.933,30.448"]
"YUCHEN005/STAR-Adapt" ["l"="47.943,30.47"]
"Thinklab-SJTU/ML4CO-Kit" ["l"="51.035,26.507"]
"Alpha-Innovator/SurveyForge" ["l"="46.962,30.224"]
"wusize/F-LMM" ["l"="47.552,30.326"]
"Shengcao-Cao/groundLMM" ["l"="47.559,30.348"]
"MICV-yonsei/CASS" ["l"="47.569,30.361"]
"RammusLeo/DPMesh" ["l"="47.786,30.242"]
"yuanzhoulvpi2017/vscode_debug_transformers" ["l"="47.322,30.4"]
"yuanzhoulvpi2017/zero_nlp" ["l"="39.013,-2.112"]
"yongliu20/UniLSeg" ["l"="47.832,30.236"]
"NiuTrans/Vision-LLM-Alignment" ["l"="47.199,30.242"]
"njucckevin/MM-Self-Improve" ["l"="47.194,30.204"]
"shikiw/DAM-VP" ["l"="38.305,-0.105"]
"yonseivnl/vlm-rlaif" ["l"="33.12,30.885"]
"RUCAIBox/ComVint" ["l"="47.255,30.392"]
"llyx97/TempCompass" ["l"="47.669,30.155"]
"Becomebright/GroundVQA" ["l"="33.06,30.919"]
"BAAI-DCAI/Training-Data-Synthesis" ["l"="47.199,30.269"]
"mertyg/vision-language-models-are-bows" ["l"="38.248,-0.115"]
"bronyayang/Law_of_Vision_Representation_in_MLLMs" ["l"="46.347,30.725"]
"baaivision/DIVA" ["l"="47.261,30.211"]
"DCDmllm/WorldGPT" ["l"="47.341,30.503"]
"mbzuai-oryx/VideoGLaMM" ["l"="50.492,38.311"]
"hananshafi/llmblueprint" ["l"="50.534,38.33"]
"showlab/VideoLISA" ["l"="33.367,31.698"]
"mbzuai-oryx/ClimateGPT" ["l"="48.882,33.03"]
"zli12321/qa_metrics" ["l"="47.187,29.944"]
"zli12321/VideoHallu" ["l"="47.202,29.953"]
"yongchaoz/diffusion_inversion" ["l"="47.16,30.278"]
"heshuting555/DsHmp" ["l"="47.633,34.539"]
"congvvc/LaSagnA" ["l"="33.344,31.774"]
"apple/ml-slowfast-llava" ["l"="47.726,30.048"]
"sudo-Boris/mr-Blip" ["l"="48.04,33.152"]
"wjun0830/CGDETR" ["l"="48.016,33.11"]
"wjun0830/QD-DETR" ["l"="48.009,33.121"]
"minghangz/TFVTG" ["l"="47.654,30.066"]
"Fish-and-Sheep/Text-Fluoroscopy" ["l"="47.803,30.436"]
"Dongping-Chen/MLLM-Judge" ["l"="47.58,29.908"]
"nttmdlab-nlp/InstructDoc" ["l"="47.077,30.136"]
"KainingYing/CTVIS" ["l"="50.693,30.683"]
"OpenGVLab/PhyBench" ["l"="47.156,30.333"]
"lntzm/MESM" ["l"="47.681,30.049"]
"THUDM/CogCoM" ["l"="47.125,30.213"]
"showlab/UniVTG" ["l"="60.48,17.581"]
"Lackel/AGLA" ["l"="47.387,30.464"]
"tpgh24/ag4masses" ["l"="46.988,30.057"]
"felixludos/alphageometry" ["l"="47.037,30.079"]
"foldl/AlphaGeometryRE" ["l"="46.965,30.048"]
"khuangaf/Awesome-Chart-Understanding" ["l"="47.08,30.302"]
"IDEA-FinAI/ChartBench" ["l"="47.057,30.296"]
"SpursGoZmy/Table-LLaVA" ["l"="46.293,24.819"]
"pengshuai-rin/MultiMath" ["l"="47.2,30.444"]
"KID-22/LLM-IR-Bias-Fairness-Survey" ["l"="46.82,30.378"]
"XuChen0427/FairDiverse" ["l"="46.806,30.393"]
"KID-22/Cocktail" ["l"="46.791,30.383"]
"ichbill/LTDD" ["l"="47.684,30.274"]
"dongyh20/Chain-of-Spot" ["l"="47.18,30.159"]
"liuzuyan/ElasticCache" ["l"="47.131,30.169"]
"Yxxxb/LAVT-RS" ["l"="47.767,30.211"]
"kkk-an/COFFTEA" ["l"="47.372,30.381"]
"HankYe/Once-for-Both" ["l"="46.982,30.251"]
"teknium1/transformers-gptq-quant" ["l"="47.487,30.599"]
"wenhuang2000/VHTest" ["l"="47.287,30.32"]
"hendryx-scale/mhal-detect" ["l"="47.288,30.335"]
"kkahatapitiya/LangRepo" ["l"="47.749,30.11"]
"NJU-LHRS/ScoreRS" ["l"="47.62,30.559"]
"xiong-zhitong/GeoLB-SigLIP" ["l"="47.624,30.574"]
"LeapLabTHU/DAT-Jittor" ["l"="49.285,32.958"]
"KID-22/Source-Bias" ["l"="46.772,30.387"]
"allenai/molmo" ["l"="47.175,30.359"]
"2U1/Molmo-Finetune" ["l"="47.151,30.394"]
"facebookresearch/perception_models" ["l"="64.107,3.01"]
"mustafaaljadery/llama3v" ["l"="47.236,30.05"]
"siddrrsh/ambientGPT" ["l"="27.635,-20.94"]
"deepseek-ai/Janus" ["l"="40.156,-0.309"]
"QwenLM/Qwen-Agent" ["l"="40.896,0.064"]
"IVG-SZ/Flash-VStream" ["l"="47.736,30.201"]
"showlab/videollm-online" ["l"="47.64,30.159"]
"Mark12Ding/Dispider" ["l"="47.732,30.273"]
"hmxiong/StreamChat" ["l"="47.712,30.182"]
"Jixuan-Fan/Momentum-GS" ["l"="63.92,3.395"]
"yaolinli/TimeChat-Online" ["l"="47.657,30.209"]
"YueFan1014/VideoAgent" ["l"="47.62,30.189"]
"wxh1996/VideoAgent" ["l"="47.661,30.174"]
"Leon1207/Video-RAG-master" ["l"="47.566,30.238"]
"AIDC-AI/Marco-o1" ["l"="37.253,-0.466"]
"mbzuai-oryx/LlamaV-o1" ["l"="47.392,30.128"]
"facebookresearch/chameleon" ["l"="46.478,30.635"]
"FoundationVision/LlamaGen" ["l"="46.44,30.619"]
"lxa9867/Awesome-Autoregressive-Visual-Generation" ["l"="46.41,30.677"]
"swordlidev/Evaluation-Multimodal-LLMs-Survey" ["l"="47.559,30.294"]
"shufangxun/LLaVA-MoD" ["l"="48.873,34.285"]
"Wang-Xiaodong1899/CVPR25-MLLM-Paper-List" ["l"="47.44,30.174"]
"HJYao00/Side4Video" ["l"="47.616,30.282"]
"LaVi-Lab/AIM" ["l"="47.655,30.299"]
"NVlabs/EAGLE" ["l"="47.413,30.144"]
"Windsander/ADI-Stable-Diffusion" ["l"="50.812,2.921"]
"ByungKwanLee/MoAI" ["l"="40.622,5.155"]
"JusticeFighterDance/JusticeFighter110" ["l"="47.202,30.051"]
"william-sto/JusticeNeverTooLate" ["l"="47.156,30.029"]
"ByteDance-Seed/Triton-distributed" ["l"="39.013,-0.386"]
"KD-TAO/DyCoke" ["l"="47.665,30.288"]
"mlfoundations/MINT-1T" ["l"="47.362,30.186"]
"baaivision/DenseFusion" ["l"="47.366,30.247"]
"UCSC-VLAA/Recap-DataComp-1B" ["l"="49.046,30.556"]
"DAMO-NLP-SG/multimodal_textbook" ["l"="64.083,11.461"]
"CircleRadon/TokenPacker" ["l"="64.16,11.396"]
"ZLKong/awesome-token-compression-reduction" ["l"="47.59,30.219"]
"xuyang-liu16/Awesome-Token-level-Model-Compression" ["l"="39.077,0.116"]
"Yushi-Hu/VisualSketchpad" ["l"="47.207,30.159"]
"longvideobench/LongVideoBench" ["l"="47.569,30.173"]
"dvlab-research/Lyra" ["l"="47.75,30.301"]
"Falling-dow/Unsupervised-Image-Enhancement-with-CNN-and-GAN" ["l"="50.8,3.125"]
"Davion-Liu/Awesome-Robustness-in-Information-Retrieval" ["l"="47.818,30.322"]
"THUNLP-MT/StreamingBench" ["l"="-55.462,-10.768"]
"JoeLeelyf/OVO-Bench" ["l"="47.706,30.212"]
"showlab/livecc" ["l"="47.723,30.155"]
"zjunlp/OneGen" ["l"="47.529,30.412"]
"gordonhu608/MQT-LLaVA" ["l"="47.703,30.268"]
"MCG-NJU/p-MoD" ["l"="47.589,30.277"]
"zhangfaen/finetune-Qwen2-VL" ["l"="47.299,30.05"]
"2U1/Qwen2-VL-Finetune" ["l"="47.342,30.038"]
"wjbmattingly/qwen2-vl-finetune-huggingface" ["l"="47.229,30.017"]
"zhangfaen/finetune-Qwen2.5-VL" ["l"="47.284,30.036"]
"sandy1990418/Finetune-Qwen2.5-VL" ["l"="47.264,30.034"]
"VITA-MLLM/Long-VITA" ["l"="47.553,30.255"]
"saccharomycetes/mllms_know" ["l"="47.601,30.37"]
"FreedomIntelligence/LongLLaVA" ["l"="47.597,30.187"]
"yeliudev/VideoMind" ["l"="47.647,30.12"]
"xuliu-cyber/RSUniVLM" ["l"="47.573,30.433"]
"VITA-MLLM/Sparrow" ["l"="47.535,30.275"]
"VITA-MLLM/VITA-Audio" ["l"="47.555,30.274"]
"yongliang-wu/NumPro" ["l"="38.473,-7.025"]
"AIDC-AI/Ovis" ["l"="47.308,30.081"]
"Oryx-mllm/Oryx" ["l"="47.197,30.108"]
"AIDC-AI/Parrot" ["l"="34.313,31.923"]
"Bujiazi/ByTheWay" ["l"="47.764,30.342"]
"beichenzbc/BoostStep" ["l"="47.749,30.342"]
"rhymes-ai/Aria" ["l"="47.496,30.113"]
"rhymes-ai/Allegro" ["l"="50.916,2.927"]
"kijai/ComfyUI-MochiWrapper" ["l"="32.948,32.934"]
"apple/ml-aim" ["l"="46.514,30.627"]
"THUDM/LVBench" ["l"="47.681,30.139"]
"rese1f/aurora" ["l"="47.773,30.089"]
"Espere-1119-Song/Video-MMLU" ["l"="47.803,30.077"]
"markusgrotz/peract_bimanual" ["l"="59.551,16.62"]
"ManiCM-fast/ManiCM" ["l"="59.471,16.681"]
"zjysteven/VLM-Visualizer" ["l"="47.644,30.438"]
"zhangbaijin/From-Redundancy-to-Relevance" ["l"="47.658,30.475"]
"IntelLabs/lvlm-interpret" ["l"="47.684,30.499"]
"junyangwang0410/Attention-LLaVA" ["l"="47.665,30.455"]
"jungao1106/ICoT" ["l"="47.223,30.176"]
"SCZwangxiao/video-FlexReduc" ["l"="47.674,30.117"]
"Liac-li/MM-self-improve-qwen2vl" ["l"="47.162,30.209"]
"2U1/Llama3.2-Vision-Finetune" ["l"="47.481,29.88"]
"Alpha-Innovator/Chimera" ["l"="46.929,30.231"]
"Alpha-Innovator/AdaptiveDiffusion" ["l"="46.945,30.234"]
"Alpha-Innovator/OmniCaptioner" ["l"="46.921,30.249"]
"Alpha-Innovator/DocGenome" ["l"="46.934,30.213"]
"Alpha-Innovator/Dolphin" ["l"="46.968,30.252"]
"XJF2332/GOT-OCR-2-GUI" ["l"="47.01,30.093"]
"ustc-hyin/ClearSight" ["l"="47.352,30.392"]
"TianyunYoung/Hallucination-Attribution" ["l"="47.341,30.384"]
"Ola-Omni/Ola" ["l"="47.206,30.128"]
"shiml20/FlowTurbo" ["l"="47.145,30.088"]
"Yangsenqiao/ULDA" ["l"="47.664,30.267"]
"dvlab-research/Step-DPO" ["l"="37.324,-0.361"]
"ictnlp/LLaVA-Mini" ["l"="-55.153,-10.684"]
"OpenGVLab/MM-NIAH" ["l"="47.267,30.253"]
"VisionXLab/STAR-MMRotate" ["l"="53.279,31.922"]
"wangclnlp/DeepSpeed-Chat-Extension" ["l"="47.166,30.253"]
"NiuTrans/LaMaTE" ["l"="47.163,30.24"]
"CaraJ7/MMSearch" ["l"="47.284,30.421"]
"MME-Benchmarks/MME-CoT" ["l"="46.34,30.773"]
"CaraJ7/CoMat" ["l"="33.47,31.548"]
"CaraJ7/T2I-R1" ["l"="46.369,30.74"]
"nickjiang2378/vl-interp" ["l"="47.71,30.541"]
"NastyMarcus/A-Survey-of-Efficient-Diffusion-Models" ["l"="47.676,30.368"]
"rccchoudhury/rlt" ["l"="47.764,30.052"]
"Vchitect/FasterCache" ["l"="39.097,-0.046"]
"contrastive/FreeVideoLLM" ["l"="47.77,30.029"]
"JiazuoYu/PathWeave" ["l"="47.742,30.18"]
"UMass-Embodied-AGI/FlexAttention" ["l"="47.718,30.384"]
"hasanar1f/HiRED" ["l"="47.701,30.355"]
"kang-wu/SkySensePlusPlus" ["l"="47.576,29.88"]
"alipay/POA" ["l"="47.597,29.866"]
"likyoo/awesome-MLLM-for-image-segmentation" ["l"="47.547,29.901"]
"YuxiXie/V-DPO" ["l"="47.244,30.295"]
"2U1/Phi3-Vision-Finetune" ["l"="47.511,29.835"]
"GaiZhenbiao/Phi3V-Finetuning" ["l"="47.532,29.797"]
"2U1/Pixtral-Finetune" ["l"="47.504,29.855"]
"intsig-textin/parsex-frontend" ["l"="46.996,30.13"]
"intsig-textin/markdown_tester" ["l"="47.034,30.128"]
"intsig-textin/parsex-sdk" ["l"="46.978,30.12"]
"lutongyv/Textin_Tester" ["l"="47.009,30.117"]
"jiaweizzhao/InRank" ["l"="65.145,3.409"]
"gulucaptain/DynamiCtrl" ["l"="65.1,3.396"]
"foundation-multimodal-models/ConBench" ["l"="53.527,33.364"]
"xuyang-liu16/GlobalCom2" ["l"="39.096,0.137"]
"Liuziyu77/MIA-DPO" ["l"="47.726,30.339"]
"shikiw/Modality-Integration-Rate" ["l"="47.774,30.367"]
"Wiselnn570/VideoRoPE" ["l"="47.735,30.323"]
"Q-Future/Co-Instruct" ["l"="46.914,31.412"]
"Amshaker/Mobile-VideoGPT" ["l"="48.869,33.013"]
"joez17/VideoNIAH" ["l"="47.637,30.202"]
"huofushuo/C2KD" ["l"="38.316,-0.122"]
"HowieHwong/UniGen" ["l"="47.559,29.919"]
"InfiMM/Awesome-Multimodal-LLM-for-Math-STEM" ["l"="47.183,30.481"]
"KD-TAO/VidKV" ["l"="47.693,30.301"]
"Visual-AI/PruneVid" ["l"="47.693,30.32"]
"Liuziyu77/MMDU" ["l"="47.791,30.35"]
"songweii/DualToken" ["l"="47.839,30.362"]
"Bujiazi/HiFlow" ["l"="47.762,30.328"]
"SYuan03/MM-IFEngine" ["l"="47.752,30.36"]
"EvolvingLMMs-Lab/multimodal-sae" ["l"="47.73,30.57"]
"DreamMr/HR-Bench" ["l"="47.614,30.404"]
"DreamMr/RAP" ["l"="47.62,30.425"]
"AIoT-MLSys-Lab/Famba-V" ["l"="47.692,30.398"]
"intsig-textin/chatdoc" ["l"="46.958,30.117"]
"ichbill/DQAS" ["l"="47.701,30.286"]
"1100111GTH/XG-RAG" ["l"="47.071,30.191"]
"modelscope/mcp-central" ["l"="47.09,30.187"]
"volcengine/verl" ["l"="37.143,-0.472"]
"OpenRLHF/OpenRLHF" ["l"="37.161,-0.425"]
"hkust-nlp/simpleRL-reason" ["l"="37.177,-0.469"]
"tulerfeng/Video-R1" ["l"="47.365,30.117"]
"OpenGVLab/VideoChat-R1" ["l"="47.515,30.177"]
"dvlab-research/Seg-Zero" ["l"="47.362,30.136"]
"TencentARC/SEED-Bench-R1" ["l"="46.391,30.796"]
"yaotingwangofficial/Awesome-MCoT" ["l"="47.341,30.143"]
"appletea233/Temporal-R1" ["l"="47.445,30.141"]
"OpenRLHF/OpenRLHF-M" ["l"="47.284,30.111"]
"LengSicong/MMR1" ["l"="47.263,30.13"]
"yu-rp/VisualPerceptionToken" ["l"="38.971,0.409"]
"yfzhang114/r1_reward" ["l"="47.538,30.29"]
"MME-Benchmarks/MME-Unify" ["l"="47.525,30.295"]
"Open-Reasoner-Zero/Open-Reasoner-Zero" ["l"="37.209,-0.473"]
"zhuang2002/Cobra" ["l"="47.871,30.204"]
"MoonshotAI/Kimi-VL" ["l"="47.261,30.105"]
"bruno686/Awesome-RL-based-LLM-Reasoning" ["l"="37.207,-0.592"]
"modelscope/MCPBench" ["l"="47.03,30.201"]
"HumanMLLM/R1-Omni" ["l"="47.284,30.092"]
"HumanMLLM/HumanOmni" ["l"="47.21,30.078"]
"QwenLM/Qwen2.5-Omni" ["l"="38.436,1.868"]
"ZebangCheng/Emotion-LLaMA" ["l"="56.488,28.114"]
"UCSC-VLAA/VLAA-Thinking" ["l"="47.231,30.133"]
"mc-lan/Awesome-MLLM-Segmentation" ["l"="47.468,29.995"]
"cilinyan/VISA" ["l"="33.364,31.739"]
"PhoenixZ810/OmniAlign-V" ["l"="-55.528,-10.757"]
"Sunleader1997/transflow" ["l"="-55.323,-10.594"]
"liyown/nextjs_stream_demo" ["l"="-55.343,-10.704"]
"LightChen233/Awesome-Long-Chain-of-Thought-Reasoning" ["l"="37.201,-0.642"]
"DAMO-NLP-SG/VideoRefer" ["l"="64.157,11.426"]
"Video-R1/Awesome-Multimodal-Reasoning" ["l"="47.647,30.381"]
"Xilluill/KV-Edit" ["l"="33.164,31.232"]
"yuyq96/R1-Vision" ["l"="47.238,30.098"]
"mbzuai-oryx/CVRR-Evaluation-Suite" ["l"="50.472,38.302"]
"VIROBO-15/XM-GAN" ["l"="39.553,-7.487"]
"ByteDance-Seed/Seed-Thinking-v1.5" ["l"="37.217,-0.551"]
"MoonshotAI/Kimina-Prover-Preview" ["l"="-21.258,-19.151"]
"MoonshotAI/Moonlight" ["l"="39.002,-0.403"]
"MoonshotAI/MoBA" ["l"="39.065,-0.332"]
"ByteFlow-AI/TokenFlow" ["l"="46.433,30.686"]
"Hongcheng-Gao/Awesome-Long2short-on-LRMs" ["l"="37.175,-0.649"]
"RUCAIBox/Slow_Thinking_with_LLMs" ["l"="37.259,-0.484"]
"Hui-design/R1-Video-fixbug" ["l"="47.332,30.157"]
"HumanMLLM/Omni-Emotion" ["l"="47.168,30.066"]
"fengzi258/Ocean-R1" ["l"="47.862,30.367"]
"MCG-NJU/VideoChat-Online" ["l"="47.613,30.208"]
"OpenGVLab/FluxViT" ["l"="47.562,30.195"]
"modelscope/Nexus-Gen" ["l"="47.053,30.181"]
"GeoGPT-Research-Project/GeoGPT" ["l"="47.58,29.855"]
"John-AI-Lab/NoisyRollout" ["l"="36.747,-0.307"]
"yellow-binary-tree/MMDuet" ["l"="47.773,30.285"]
"xinding-sys/StreamMind" ["l"="47.759,30.277"]
"dle666/R-CoT" ["l"="47.051,30.065"]
"mingliangzhang2018/PGDP" ["l"="64.93,12.299"]
"yayafengzi/LMM-HiMTok" ["l"="47.598,30.503"]
"JoeLeelyf/customize-arxiv-daily" ["l"="47.77,30.395"]
"ChrisDong-THU/GaussianToken" ["l"="47.81,30.186"]
"VoyageWang/IteRPrimE" ["l"="47.837,30.175"]
"jonathan-roberts1/zerobench" ["l"="47.658,30.662"]
"intsig-textin/chatdoc_stack" ["l"="46.942,30.114"]
"MCG-NJU/NeuralSolver" ["l"="46.297,30.764"]
}