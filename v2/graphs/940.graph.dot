digraph G {
"x4nth055/pythoncode-tutorials" -> "x4nth055/emotion-recognition-using-speech" ["e"=1]
"sherleens/EmotionDistributionLearning" -> "lucinda-lim/Image-Emotion-Classification"
"sherleens/EmotionDistributionLearning" -> "akhileshydv/Dependency-Exploitation-A-Unified-CNN-RNN-Approach-for-Visual-Emotion-Recognition"
"maelfabien/Multimodal-Emotion-Recognition" -> "tzirakis/Multimodal-Emotion-Recognition"
"maelfabien/Multimodal-Emotion-Recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"maelfabien/Multimodal-Emotion-Recognition" -> "otaha178/Emotion-recognition" ["e"=1]
"maelfabien/Multimodal-Emotion-Recognition" -> "declare-lab/MELD"
"maelfabien/Multimodal-Emotion-Recognition" -> "david-yoon/multimodal-speech-emotion"
"maelfabien/Multimodal-Emotion-Recognition" -> "declare-lab/multimodal-deep-learning"
"maelfabien/Multimodal-Emotion-Recognition" -> "atulapra/Emotion-detection" ["e"=1]
"maelfabien/Multimodal-Emotion-Recognition" -> "thuiar/MMSA"
"maelfabien/Multimodal-Emotion-Recognition" -> "x4nth055/emotion-recognition-using-speech"
"maelfabien/Multimodal-Emotion-Recognition" -> "soujanyaporia/multimodal-sentiment-analysis"
"maelfabien/Multimodal-Emotion-Recognition" -> "declare-lab/conv-emotion"
"maelfabien/Multimodal-Emotion-Recognition" -> "katerynaCh/multimodal-emotion-recognition"
"maelfabien/Multimodal-Emotion-Recognition" -> "ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION"
"maelfabien/Multimodal-Emotion-Recognition" -> "A2Zadeh/CMU-MultimodalSDK"
"maelfabien/Multimodal-Emotion-Recognition" -> "Renovamen/Speech-Emotion-Recognition"
"declare-lab/conv-emotion" -> "declare-lab/MELD"
"declare-lab/conv-emotion" -> "declare-lab/awesome-emotion-recognition-in-conversations"
"declare-lab/conv-emotion" -> "declare-lab/RECCON" ["e"=1]
"declare-lab/conv-emotion" -> "A2Zadeh/CMU-MultimodalSDK"
"declare-lab/conv-emotion" -> "yaohungt/Multimodal-Transformer"
"declare-lab/conv-emotion" -> "soujanyaporia/multimodal-sentiment-analysis"
"declare-lab/conv-emotion" -> "declare-lab/multimodal-deep-learning"
"declare-lab/conv-emotion" -> "Demfier/multimodal-speech-emotion-recognition"
"declare-lab/conv-emotion" -> "thuiar/MMSA"
"declare-lab/conv-emotion" -> "facebookresearch/EmpatheticDialogues" ["e"=1]
"declare-lab/conv-emotion" -> "declare-lab/dialogue-understanding" ["e"=1]
"declare-lab/conv-emotion" -> "maelfabien/Multimodal-Emotion-Recognition"
"declare-lab/conv-emotion" -> "david-yoon/multimodal-speech-emotion"
"declare-lab/conv-emotion" -> "soujanyaporia/MUStARD"
"declare-lab/conv-emotion" -> "shenwzh3/DAG-ERC"
"xunan0812/MIMN" -> "PreferredAI/vista-net"
"xunan0812/MIMN" -> "jefferyYu/TomBERT"
"xunan0812/MIMN" -> "headacheboy/data-of-multimodal-sarcasm-detection"
"xunan0812/MIMN" -> "xunan0812/MultiSentiNet"
"pliang279/awesome-multimodal-ml" -> "A2Zadeh/CMU-MultimodalSDK" ["e"=1]
"otaha178/Emotion-recognition" -> "maelfabien/Multimodal-Emotion-Recognition" ["e"=1]
"otaha178/Emotion-recognition" -> "Renovamen/Speech-Emotion-Recognition" ["e"=1]
"otaha178/Emotion-recognition" -> "tzirakis/Multimodal-Emotion-Recognition" ["e"=1]
"x4nth055/emotion-recognition-using-speech" -> "Renovamen/Speech-Emotion-Recognition"
"x4nth055/emotion-recognition-using-speech" -> "xuanjihe/speech-emotion-recognition"
"x4nth055/emotion-recognition-using-speech" -> "hkveeranki/speech-emotion-recognition"
"x4nth055/emotion-recognition-using-speech" -> "Demfier/multimodal-speech-emotion-recognition"
"x4nth055/emotion-recognition-using-speech" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"x4nth055/emotion-recognition-using-speech" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"x4nth055/emotion-recognition-using-speech" -> "marcogdepinto/emotion-classification-from-audio-files"
"x4nth055/emotion-recognition-using-speech" -> "david-yoon/multimodal-speech-emotion"
"x4nth055/emotion-recognition-using-speech" -> "maelfabien/Multimodal-Emotion-Recognition"
"x4nth055/emotion-recognition-using-speech" -> "amanbasu/speech-emotion-recognition"
"x4nth055/emotion-recognition-using-speech" -> "SuyashMore/MevonAI-Speech-Emotion-Recognition"
"x4nth055/emotion-recognition-using-speech" -> "SuperKogito/SER-datasets"
"x4nth055/emotion-recognition-using-speech" -> "b04901014/FT-w2v2-ser"
"x4nth055/emotion-recognition-using-speech" -> "PiotrSobczak/speech-emotion-recognition"
"x4nth055/emotion-recognition-using-speech" -> "IliaZenkov/transformer-cnn-emotion-recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "Renovamen/Speech-Emotion-Recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "x4nth055/emotion-recognition-using-speech"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "xuanjihe/speech-emotion-recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "Demfier/multimodal-speech-emotion-recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "marcogdepinto/emotion-classification-from-audio-files"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "hkveeranki/speech-emotion-recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "david-yoon/multimodal-speech-emotion"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "maelfabien/Multimodal-Emotion-Recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "rezachu/emotion_recognition_cnn"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "declare-lab/conv-emotion"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "declare-lab/MELD"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "crhung/Voice-Emotion-Detector"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "amanbasu/speech-emotion-recognition"
"MiteshPuthran/Speech-Emotion-Analyzer" -> "SuperKogito/SER-datasets"
"Demfier/multimodal-speech-emotion-recognition" -> "david-yoon/multimodal-speech-emotion"
"Demfier/multimodal-speech-emotion-recognition" -> "xuanjihe/speech-emotion-recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "aris-ai/Audio-and-text-based-emotion-recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "PiotrSobczak/speech-emotion-recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "shamanez/BERT-like-is-All-You-Need"
"Demfier/multimodal-speech-emotion-recognition" -> "tzirakis/Multimodal-Emotion-Recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"Demfier/multimodal-speech-emotion-recognition" -> "Renovamen/Speech-Emotion-Recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "x4nth055/emotion-recognition-using-speech"
"Demfier/multimodal-speech-emotion-recognition" -> "IliaZenkov/transformer-cnn-emotion-recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"Demfier/multimodal-speech-emotion-recognition" -> "habla-liaa/ser-with-w2v2"
"Demfier/multimodal-speech-emotion-recognition" -> "maelfabien/Multimodal-Emotion-Recognition"
"Demfier/multimodal-speech-emotion-recognition" -> "SuperKogito/SER-datasets"
"Demfier/multimodal-speech-emotion-recognition" -> "hkveeranki/speech-emotion-recognition"
"Renovamen/Speech-Emotion-Recognition" -> "x4nth055/emotion-recognition-using-speech"
"Renovamen/Speech-Emotion-Recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"Renovamen/Speech-Emotion-Recognition" -> "xuanjihe/speech-emotion-recognition"
"Renovamen/Speech-Emotion-Recognition" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"Renovamen/Speech-Emotion-Recognition" -> "yeyupiaoling/SpeechEmotionRecognition-Pytorch" ["e"=1]
"Renovamen/Speech-Emotion-Recognition" -> "hkveeranki/speech-emotion-recognition"
"Renovamen/Speech-Emotion-Recognition" -> "david-yoon/multimodal-speech-emotion"
"Renovamen/Speech-Emotion-Recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"Renovamen/Speech-Emotion-Recognition" -> "Jiaxin-Ye/TIM-Net_SER"
"Renovamen/Speech-Emotion-Recognition" -> "zlzhang1124/AcousticFeatureExtraction"
"Renovamen/Speech-Emotion-Recognition" -> "ddlBoJack/emotion2vec" ["e"=1]
"Renovamen/Speech-Emotion-Recognition" -> "Vincent-ZHQ/CA-MSER"
"Renovamen/Speech-Emotion-Recognition" -> "hotelll/speech-emotion-recognition"
"Renovamen/Speech-Emotion-Recognition" -> "maelfabien/Multimodal-Emotion-Recognition"
"Renovamen/Speech-Emotion-Recognition" -> "yingdajun/SpeechEmotionAndPeopleAnalyse" ["e"=1]
"savoirfairelinux/num2words" -> "jonatasgrosman/huggingsound" ["e"=1]
"RayanWang/Speech_emotion_recognition_BLSTM" -> "xuanjihe/speech-emotion-recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "hkveeranki/speech-emotion-recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "amanbasu/speech-emotion-recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "MarioRuggieri/Emotion-Recognition-from-Speech"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "david-yoon/multimodal-speech-emotion"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "tzaiyang/SpeechEmoRec"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "Demfier/multimodal-speech-emotion-recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "PiotrSobczak/speech-emotion-recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "x4nth055/emotion-recognition-using-speech"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "Renovamen/Speech-Emotion-Recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "vladimir-chernykh/emotion_recognition"
"RayanWang/Speech_emotion_recognition_BLSTM" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"thoughtworksarts/EmoPy" -> "maelfabien/Multimodal-Emotion-Recognition" ["e"=1]
"seth814/Audio-Classification" -> "marcogdepinto/emotion-classification-from-audio-files" ["e"=1]
"david-yoon/multimodal-speech-emotion" -> "Demfier/multimodal-speech-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "aris-ai/Audio-and-text-based-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "xuanjihe/speech-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"david-yoon/multimodal-speech-emotion" -> "shamanez/BERT-like-is-All-You-Need"
"david-yoon/multimodal-speech-emotion" -> "tzirakis/Multimodal-Emotion-Recognition"
"david-yoon/multimodal-speech-emotion" -> "PiotrSobczak/speech-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "david-yoon/attentive-modality-hopping-for-SER"
"david-yoon/multimodal-speech-emotion" -> "mmakiuchi/multimodal_emotion_recognition"
"david-yoon/multimodal-speech-emotion" -> "hkveeranki/speech-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"david-yoon/multimodal-speech-emotion" -> "amanbasu/speech-emotion-recognition"
"david-yoon/multimodal-speech-emotion" -> "Renovamen/Speech-Emotion-Recognition"
"david-yoon/multimodal-speech-emotion" -> "x4nth055/emotion-recognition-using-speech"
"david-yoon/multimodal-speech-emotion" -> "maelfabien/Multimodal-Emotion-Recognition"
"PreferredAI/cornac" -> "PreferredAI/tutorials" ["e"=1]
"covarep/covarep" -> "A2Zadeh/CMU-MultimodalSDK" ["e"=1]
"covarep/covarep" -> "thuiar/Cross-Modal-BERT" ["e"=1]
"yaohungt/Multimodal-Transformer" -> "A2Zadeh/CMU-MultimodalSDK"
"yaohungt/Multimodal-Transformer" -> "thuiar/MMSA"
"yaohungt/Multimodal-Transformer" -> "declare-lab/MISA"
"yaohungt/Multimodal-Transformer" -> "WasifurRahman/BERT_multimodal_transformer"
"yaohungt/Multimodal-Transformer" -> "declare-lab/multimodal-deep-learning"
"yaohungt/Multimodal-Transformer" -> "thuiar/Self-MM"
"yaohungt/Multimodal-Transformer" -> "pliang279/MultiBench"
"yaohungt/Multimodal-Transformer" -> "soujanyaporia/multimodal-sentiment-analysis"
"yaohungt/Multimodal-Transformer" -> "Justin1904/Low-rank-Multimodal-Fusion"
"yaohungt/Multimodal-Transformer" -> "pliang279/MFN"
"yaohungt/Multimodal-Transformer" -> "Justin1904/TensorFusionNetworks"
"yaohungt/Multimodal-Transformer" -> "declare-lab/Multimodal-Infomax"
"yaohungt/Multimodal-Transformer" -> "LeMei/UniMSE"
"yaohungt/Multimodal-Transformer" -> "thuiar/MMSA-FET"
"yaohungt/Multimodal-Transformer" -> "CMU-MultiComp-Lab/CMU-MultimodalSDK"
"hkveeranki/speech-emotion-recognition" -> "xuanjihe/speech-emotion-recognition"
"hkveeranki/speech-emotion-recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"hkveeranki/speech-emotion-recognition" -> "x4nth055/emotion-recognition-using-speech"
"hkveeranki/speech-emotion-recognition" -> "david-yoon/multimodal-speech-emotion"
"hkveeranki/speech-emotion-recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"hkveeranki/speech-emotion-recognition" -> "Renovamen/Speech-Emotion-Recognition"
"hkveeranki/speech-emotion-recognition" -> "amanbasu/speech-emotion-recognition"
"hkveeranki/speech-emotion-recognition" -> "marcogdepinto/emotion-classification-from-audio-files"
"hkveeranki/speech-emotion-recognition" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"hkveeranki/speech-emotion-recognition" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"hkveeranki/speech-emotion-recognition" -> "tzaiyang/SpeechEmoRec"
"hkveeranki/speech-emotion-recognition" -> "MarioRuggieri/Emotion-Recognition-from-Speech"
"hkveeranki/speech-emotion-recognition" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"hkveeranki/speech-emotion-recognition" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"hkveeranki/speech-emotion-recognition" -> "PiotrSobczak/speech-emotion-recognition"
"PiotrSobczak/speech-emotion-recognition" -> "ShaheenPerveen/speech-emotion-recognition-iemocap"
"PiotrSobczak/speech-emotion-recognition" -> "david-yoon/attentive-modality-hopping-for-SER"
"PiotrSobczak/speech-emotion-recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"PiotrSobczak/speech-emotion-recognition" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"petercunha/Emotion" -> "RayanWang/Speech_emotion_recognition_BLSTM" ["e"=1]
"petercunha/Emotion" -> "tzirakis/Multimodal-Emotion-Recognition" ["e"=1]
"petercunha/Emotion" -> "marcogdepinto/emotion-classification-from-audio-files" ["e"=1]
"petercunha/Emotion" -> "maelfabien/Multimodal-Emotion-Recognition" ["e"=1]
"Justin1904/Low-rank-Multimodal-Fusion" -> "Justin1904/TensorFusionNetworks"
"Justin1904/Low-rank-Multimodal-Fusion" -> "yaohungt/Multimodal-Transformer"
"Justin1904/Low-rank-Multimodal-Fusion" -> "pliang279/MFN"
"Justin1904/Low-rank-Multimodal-Fusion" -> "pliang279/factorized"
"Justin1904/Low-rank-Multimodal-Fusion" -> "declare-lab/MISA"
"Justin1904/Low-rank-Multimodal-Fusion" -> "A2Zadeh/CMU-MultimodalSDK"
"Justin1904/Low-rank-Multimodal-Fusion" -> "WasifurRahman/BERT_multimodal_transformer"
"Justin1904/Low-rank-Multimodal-Fusion" -> "TmacMai/ARGF_multimodal_fusion"
"Justin1904/Low-rank-Multimodal-Fusion" -> "jiajiatang0000/HPFN"
"Justin1904/Low-rank-Multimodal-Fusion" -> "thuiar/Self-MM"
"Justin1904/Low-rank-Multimodal-Fusion" -> "soujanyaporia/multimodal-sentiment-analysis"
"Justin1904/Low-rank-Multimodal-Fusion" -> "declare-lab/Multimodal-Infomax"
"Justin1904/Low-rank-Multimodal-Fusion" -> "declare-lab/multimodal-deep-learning"
"Justin1904/Low-rank-Multimodal-Fusion" -> "soujanyaporia/contextual-multimodal-fusion"
"Justin1904/Low-rank-Multimodal-Fusion" -> "thuiar/MMSA-FET"
"CheyneyComputerScience/CREMA-D" -> "declare-lab/MELD" ["e"=1]
"CheyneyComputerScience/CREMA-D" -> "SuperKogito/SER-datasets" ["e"=1]
"declare-lab/MELD" -> "declare-lab/conv-emotion"
"declare-lab/MELD" -> "A2Zadeh/CMU-MultimodalSDK"
"declare-lab/MELD" -> "tzirakis/Multimodal-Emotion-Recognition"
"declare-lab/MELD" -> "maelfabien/Multimodal-Emotion-Recognition"
"declare-lab/MELD" -> "declare-lab/awesome-emotion-recognition-in-conversations"
"declare-lab/MELD" -> "yaohungt/Multimodal-Transformer"
"declare-lab/MELD" -> "Demfier/multimodal-speech-emotion-recognition"
"declare-lab/MELD" -> "thuiar/MMSA"
"declare-lab/MELD" -> "declare-lab/RECCON" ["e"=1]
"declare-lab/MELD" -> "CheyneyComputerScience/CREMA-D" ["e"=1]
"declare-lab/MELD" -> "declare-lab/multimodal-deep-learning"
"declare-lab/MELD" -> "declare-lab/MISA"
"declare-lab/MELD" -> "hujingwen6666/MMGCN"
"declare-lab/MELD" -> "soujanyaporia/MUStARD"
"declare-lab/MELD" -> "LeMei/UniMSE"
"Eurus-Holmes/Awesome-Multimodal-Research" -> "A2Zadeh/CMU-MultimodalSDK" ["e"=1]
"Eurus-Holmes/Awesome-Multimodal-Research" -> "yaohungt/Multimodal-Transformer" ["e"=1]
"Eurus-Holmes/Awesome-Multimodal-Research" -> "declare-lab/multimodal-deep-learning" ["e"=1]
"Eurus-Holmes/Awesome-Multimodal-Research" -> "soujanyaporia/multimodal-sentiment-analysis" ["e"=1]
"Eurus-Holmes/Awesome-Multimodal-Research" -> "thuiar/MMSA" ["e"=1]
"wxjiao/HiGRUs" -> "wxjiao/AGHMN"
"wxjiao/HiGRUs" -> "wxjiao/Pre-CODE"
"soujanyaporia/multimodal-sentiment-analysis" -> "declare-lab/contextual-utterance-level-multimodal-sentiment-analysis"
"soujanyaporia/multimodal-sentiment-analysis" -> "A2Zadeh/CMU-MultimodalSDK"
"soujanyaporia/multimodal-sentiment-analysis" -> "declare-lab/multimodal-deep-learning"
"soujanyaporia/multimodal-sentiment-analysis" -> "thuiar/MMSA"
"soujanyaporia/multimodal-sentiment-analysis" -> "Justin1904/TensorFusionNetworks"
"soujanyaporia/multimodal-sentiment-analysis" -> "declare-lab/Multimodal-Infomax"
"soujanyaporia/multimodal-sentiment-analysis" -> "yaohungt/Multimodal-Transformer"
"soujanyaporia/multimodal-sentiment-analysis" -> "WasifurRahman/BERT_multimodal_transformer"
"soujanyaporia/multimodal-sentiment-analysis" -> "declare-lab/MISA"
"soujanyaporia/multimodal-sentiment-analysis" -> "thuiar/Self-MM"
"soujanyaporia/multimodal-sentiment-analysis" -> "soujanyaporia/contextual-multimodal-fusion"
"soujanyaporia/multimodal-sentiment-analysis" -> "PreferredAI/vista-net"
"soujanyaporia/multimodal-sentiment-analysis" -> "declare-lab/hfusion"
"soujanyaporia/multimodal-sentiment-analysis" -> "pliang279/MFN"
"soujanyaporia/multimodal-sentiment-analysis" -> "CodeREWorld/Multimodal-Sentiment-Analysis"
"WasifurRahman/BERT_multimodal_transformer" -> "declare-lab/MISA"
"WasifurRahman/BERT_multimodal_transformer" -> "yaohungt/Multimodal-Transformer"
"WasifurRahman/BERT_multimodal_transformer" -> "declare-lab/BBFN"
"WasifurRahman/BERT_multimodal_transformer" -> "thuiar/Self-MM"
"WasifurRahman/BERT_multimodal_transformer" -> "declare-lab/Multimodal-Infomax"
"WasifurRahman/BERT_multimodal_transformer" -> "thuiar/MMSA-FET"
"WasifurRahman/BERT_multimodal_transformer" -> "victorywys/RAVEN"
"WasifurRahman/BERT_multimodal_transformer" -> "thuiar/AWESOME-MSA"
"WasifurRahman/BERT_multimodal_transformer" -> "A2Zadeh/CMU-MultimodalSDK"
"WasifurRahman/BERT_multimodal_transformer" -> "thuiar/Cross-Modal-BERT"
"WasifurRahman/BERT_multimodal_transformer" -> "pliang279/MFN"
"WasifurRahman/BERT_multimodal_transformer" -> "thuiar/MMSA"
"WasifurRahman/BERT_multimodal_transformer" -> "soujanyaporia/multimodal-sentiment-analysis"
"WasifurRahman/BERT_multimodal_transformer" -> "pliang279/factorized"
"WasifurRahman/BERT_multimodal_transformer" -> "declare-lab/multimodal-deep-learning"
"end2you/end2you" -> "tzirakis/Multimodal-Emotion-Recognition" ["e"=1]
"ihpdep/LDES" -> "zhanxinrui/HDN"
"ihpdep/LDES" -> "zhan-xu/CFNN"
"ihpdep/LDES" -> "594422814/UDT" ["e"=1]
"soujanyaporia/MUStARD" -> "headacheboy/data-of-multimodal-sarcasm-detection"
"soujanyaporia/MUStARD" -> "ROC-HCI/UR-FUNNY"
"soujanyaporia/MUStARD" -> "cfiltnlp/MUStARD_Plus_Plus"
"soujanyaporia/MUStARD" -> "declare-lab/multimodal-deep-learning"
"soujanyaporia/MUStARD" -> "thuiar/Self-MM"
"soujanyaporia/MUStARD" -> "declare-lab/BBFN"
"soujanyaporia/MUStARD" -> "thuiar/MMSA"
"soujanyaporia/MUStARD" -> "WasifurRahman/BERT_multimodal_transformer"
"soujanyaporia/MUStARD" -> "A2Zadeh/CMU-MultimodalSDK"
"soujanyaporia/MUStARD" -> "LeMei/UniMSE"
"soujanyaporia/MUStARD" -> "declare-lab/Multimodal-Infomax"
"soujanyaporia/MUStARD" -> "yaohungt/Multimodal-Transformer"
"soujanyaporia/MUStARD" -> "soujanyaporia/multimodal-sentiment-analysis"
"soujanyaporia/MUStARD" -> "zerohd4869/MM-DFN"
"soujanyaporia/MUStARD" -> "pliang279/MultiBench"
"cnunlp/Chinese-Simile-Recognition-Dataset" -> "mrzjy/writing-polishment-with-simile"
"cnunlp/Chinese-Simile-Recognition-Dataset" -> "DeepLearnXMU/Cyclic"
"asfathermou/human-computer-interaction" -> "CodeREWorld/Multimodal-Sentiment-Analysis"
"asfathermou/human-computer-interaction" -> "Robin-WZQ/multimodal-emotion-recognition-DEMO"
"asfathermou/human-computer-interaction" -> "tzirakis/Multimodal-Emotion-Recognition"
"xuanjihe/speech-emotion-recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"xuanjihe/speech-emotion-recognition" -> "hkveeranki/speech-emotion-recognition"
"xuanjihe/speech-emotion-recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"xuanjihe/speech-emotion-recognition" -> "david-yoon/multimodal-speech-emotion"
"xuanjihe/speech-emotion-recognition" -> "x4nth055/emotion-recognition-using-speech"
"xuanjihe/speech-emotion-recognition" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"xuanjihe/speech-emotion-recognition" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"xuanjihe/speech-emotion-recognition" -> "amanbasu/speech-emotion-recognition"
"xuanjihe/speech-emotion-recognition" -> "Renovamen/Speech-Emotion-Recognition"
"xuanjihe/speech-emotion-recognition" -> "MarioRuggieri/Emotion-Recognition-from-Speech"
"xuanjihe/speech-emotion-recognition" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"xuanjihe/speech-emotion-recognition" -> "PiotrSobczak/speech-emotion-recognition"
"xuanjihe/speech-emotion-recognition" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"xuanjihe/speech-emotion-recognition" -> "KrishnaDN/speech-emotion-recognition-using-self-attention"
"xuanjihe/speech-emotion-recognition" -> "Chien-Hung/Speech-Emotion-Recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "Demfier/multimodal-speech-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "x4nth055/emotion-recognition-using-speech"
"marcogdepinto/emotion-classification-from-audio-files" -> "MiteshPuthran/Speech-Emotion-Analyzer"
"marcogdepinto/emotion-classification-from-audio-files" -> "david-yoon/multimodal-speech-emotion"
"marcogdepinto/emotion-classification-from-audio-files" -> "hkveeranki/speech-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "xuanjihe/speech-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch"
"marcogdepinto/emotion-classification-from-audio-files" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"marcogdepinto/emotion-classification-from-audio-files" -> "seth814/Audio-Classification" ["e"=1]
"marcogdepinto/emotion-classification-from-audio-files" -> "rezachu/emotion_recognition_cnn"
"marcogdepinto/emotion-classification-from-audio-files" -> "mkosaka1/Speech_Emotion_Recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "amanbasu/speech-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "IliaZenkov/transformer-cnn-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "aris-ai/Audio-and-text-based-emotion-recognition"
"marcogdepinto/emotion-classification-from-audio-files" -> "maelfabien/Multimodal-Emotion-Recognition"
"mhw32/multimodal-vae-public" -> "iffsid/mmvae"
"mhw32/multimodal-vae-public" -> "seqam-lab/DMVAE"
"mhw32/multimodal-vae-public" -> "pliang279/factorized"
"mhw32/multimodal-vae-public" -> "thomassutter/MoPoE"
"mhw32/multimodal-vae-public" -> "ztangent/multimodal-dmm"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "xuanjihe/speech-emotion-recognition"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "RicardoP0/Speech2dCNN_LSTM"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "KrishnaDN/speech-emotion-recognition-using-self-attention"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "PiotrSobczak/speech-emotion-recognition"
"vandana-rajan/1D-Speech-Emotion-Recognition" -> "praweshd/speech_emotion_recognition"
"amanbasu/speech-emotion-recognition" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"amanbasu/speech-emotion-recognition" -> "xuanjihe/speech-emotion-recognition"
"amanbasu/speech-emotion-recognition" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"amanbasu/speech-emotion-recognition" -> "Samarth-Tripathi/IEMOCAP-Emotion-Detection"
"amanbasu/speech-emotion-recognition" -> "david-yoon/multimodal-speech-emotion"
"amanbasu/speech-emotion-recognition" -> "MarioRuggieri/Emotion-Recognition-from-Speech"
"amanbasu/speech-emotion-recognition" -> "vyassu/DeepSentiment"
"amanbasu/speech-emotion-recognition" -> "hkveeranki/speech-emotion-recognition"
"amanbasu/speech-emotion-recognition" -> "flaviorainhoavila/IEMOCAPspeechEmotionRecognition"
"yihong-chen/DREAM" -> "RandolphVI/Next-Basket-Recommendation"
"victorywys/RAVEN" -> "A2Zadeh/Factorized-Multimodal-Transformer"
"victorywys/RAVEN" -> "hainow/MCTN"
"victorywys/RAVEN" -> "pliang279/factorized"
"victorywys/RAVEN" -> "pliang279/MFN"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "soujanyaporia/MUStARD"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "wrk226/pytorch-multimodal_sarcasm_detection"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "less-and-less-bugs/HKEmodel"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "xunan0812/MIMN"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "ROC-HCI/UR-FUNNY"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "JoeYing1019/MMSD2.0"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "HITSZ-HLT/CMGCN"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "marvel2120/MsdBert"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "TIAN-viola/DynRT"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "YangXiaocui1215/MVAN"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "ZLJ2015106/pytorch-multimodal_sarcasm_detection"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "Link-Li/CLMLF"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "downdric/MSD"
"headacheboy/data-of-multimodal-sarcasm-detection" -> "jefferyYu/TomBERT"
"HaojiHu/Sets2Sets" -> "HaojiHu/TIFUKNN"
"HaojiHu/Sets2Sets" -> "PreferredAI/beacon"
"PreferredAI/tutorials" -> "PreferredAI/mp-simrank"
"PreferredAI/tutorials" -> "PreferredAI/cornac" ["e"=1]
"PreferredAI/tutorials" -> "PreferredAI/cerebro"
"PreferredAI/tutorials" -> "PreferredAI/recommendation-retrieval"
"PreferredAI/tutorials" -> "PreferredAI/mrg"
"PreferredAI/tutorials" -> "PreferredAI/beacon"
"PreferredAI/tutorials" -> "PreferredAI/venom"
"PreferredAI/venom" -> "PreferredAI/mp-simrank"
"PreferredAI/venom" -> "PreferredAI/venom-tutorial"
"PreferredAI/venom" -> "PreferredAI/venom-examples"
"PreferredAI/venom" -> "PreferredAI/compare-lda"
"PreferredAI/venom" -> "PreferredAI/cerebro"
"PreferredAI/venom" -> "PreferredAI/cbs"
"PreferredAI/venom" -> "PreferredAI/beacon"
"PreferredAI/mp-simrank" -> "PreferredAI/venom-tutorial"
"PreferredAI/venom-tutorial" -> "PreferredAI/mp-simrank"
"PreferredAI/venom-tutorial" -> "PreferredAI/cbs"
"PreferredAI/venom-examples" -> "PreferredAI/cbs"
"PreferredAI/venom-examples" -> "PreferredAI/mp-simrank"
"PreferredAI/venom-examples" -> "PreferredAI/venom-tutorial"
"PreferredAI/venom-examples" -> "PreferredAI/compare-lda"
"PreferredAI/vista-net" -> "xunan0812/MIMN"
"PreferredAI/vista-net" -> "PreferredAI/compare-lda"
"PreferredAI/vista-net" -> "PreferredAI/cbs"
"PreferredAI/vista-net" -> "PreferredAI/mp-simrank"
"PreferredAI/vista-net" -> "PreferredAI/venom-tutorial"
"PreferredAI/vista-net" -> "jefferyYu/TomBERT"
"PreferredAI/vista-net" -> "PreferredAI/mrg"
"PreferredAI/vs-cnn" -> "PreferredAI/venom-examples"
"PreferredAI/vs-cnn" -> "PreferredAI/cbs"
"PreferredAI/vs-cnn" -> "PreferredAI/mp-simrank"
"PreferredAI/vs-cnn" -> "PreferredAI/venom-tutorial"
"PreferredAI/vs-cnn" -> "PreferredAI/compare-lda"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/mp-simrank"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/venom-examples"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/cbs"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/venom-tutorial"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/compare-lda"
"PreferredAI/recommendation-retrieval" -> "PreferredAI/cerebro"
"PreferredAI/compare-lda" -> "PreferredAI/cbs"
"PreferredAI/compare-lda" -> "PreferredAI/mp-simrank"
"PreferredAI/compare-lda" -> "PreferredAI/venom-tutorial"
"PreferredAI/compare-lda" -> "PreferredAI/venom-examples"
"PreferredAI/mrg" -> "PreferredAI/venom-examples"
"PreferredAI/mrg" -> "PreferredAI/cbs"
"PreferredAI/mrg" -> "PreferredAI/mp-simrank"
"PreferredAI/mrg" -> "PreferredAI/venom-tutorial"
"PreferredAI/mrg" -> "PreferredAI/compare-lda"
"PreferredAI/mrg" -> "PreferredAI/beacon"
"PreferredAI/mrg" -> "lipiji/NRT-theano"
"PreferredAI/cbs" -> "PreferredAI/mp-simrank"
"PreferredAI/cerebro" -> "PreferredAI/mp-simrank"
"PreferredAI/cerebro" -> "PreferredAI/cbs"
"PreferredAI/cerebro" -> "PreferredAI/venom-tutorial"
"PreferredAI/cerebro" -> "PreferredAI/compare-lda"
"PreferredAI/cerebro" -> "PreferredAI/venom-examples"
"Justin1904/TensorFusionNetworks" -> "Justin1904/Low-rank-Multimodal-Fusion"
"Justin1904/TensorFusionNetworks" -> "A2Zadeh/TensorFusionNetwork"
"Justin1904/TensorFusionNetworks" -> "A2Zadeh/CMU-MultimodalSDK"
"Justin1904/TensorFusionNetworks" -> "declare-lab/contextual-utterance-level-multimodal-sentiment-analysis"
"Justin1904/TensorFusionNetworks" -> "pliang279/MFN"
"Justin1904/TensorFusionNetworks" -> "declare-lab/MISA"
"Justin1904/TensorFusionNetworks" -> "declare-lab/Multimodal-Infomax"
"Justin1904/TensorFusionNetworks" -> "soujanyaporia/multimodal-sentiment-analysis"
"Justin1904/TensorFusionNetworks" -> "thuiar/Self-MM"
"Justin1904/TensorFusionNetworks" -> "victorywys/RAVEN"
"Justin1904/TensorFusionNetworks" -> "declare-lab/multimodal-deep-learning"
"Justin1904/TensorFusionNetworks" -> "yaohungt/Multimodal-Transformer"
"Justin1904/TensorFusionNetworks" -> "PreferredAI/vista-net"
"Justin1904/TensorFusionNetworks" -> "WasifurRahman/BERT_multimodal_transformer"
"Justin1904/TensorFusionNetworks" -> "declare-lab/BBFN"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "xuanjihe/speech-emotion-recognition"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "vladimir-chernykh/emotion_recognition"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "vyassu/DeepSentiment"
"MarioRuggieri/Emotion-Recognition-from-Speech" -> "amanbasu/speech-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "PiotrSobczak/speech-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "xuanjihe/speech-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "Demfier/multimodal-speech-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "david-yoon/multimodal-speech-emotion"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "amanbasu/speech-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "ShaheenPerveen/speech-emotion-recognition-iemocap"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "KrishnaDN/speech-emotion-recognition-using-self-attention"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "akhil2495/multi-modal-emotion-recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "flaviorainhoavila/IEMOCAPspeechEmotionRecognition"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "david-yoon/attentive-modality-hopping-for-SER"
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" -> "batikim09/LIVE_SER"
"A2Zadeh/TensorFusionNetwork" -> "A2Zadeh/MFN"
"A2Zadeh/TensorFusionNetwork" -> "A2Zadeh/MARN"
"A2Zadeh/MARN" -> "A2Zadeh/MFN"
"A2Zadeh/MARN" -> "A2Zadeh/TensorFusionNetwork"
"pliang279/MFN" -> "hainow/MCTN"
"pliang279/MFN" -> "victorywys/RAVEN"
"pliang279/MFN" -> "Justin1904/CMU-MultimodalSDK-Tutorials"
"pliang279/MFN" -> "Justin1904/TensorFusionNetworks"
"pliang279/MFN" -> "ROC-HCI/UR-FUNNY"
"pliang279/MFN" -> "thuiar/Self-MM"
"pliang279/MFN" -> "A2Zadeh/CMU-MultimodalSDK"
"pliang279/MFN" -> "declare-lab/MISA"
"pliang279/MFN" -> "WasifurRahman/BERT_multimodal_transformer"
"pliang279/MFN" -> "pliang279/factorized"
"pliang279/MFN" -> "declare-lab/Multimodal-Infomax"
"pliang279/MFN" -> "yaohungt/Multimodal-Transformer"
"YJango/speech-emotion-recognition-exercise" -> "lmingde/speech-emotion-recognition-exercise"
"YJango/speech-emotion-recognition-exercise" -> "PiotrSobczak/speech-emotion-recognition"
"hainow/MCTN" -> "pliang279/factorized"
"hainow/MCTN" -> "AIM3-RUC/MMIN"
"hainow/MCTN" -> "pliang279/MFN"
"hainow/MCTN" -> "victorywys/RAVEN"
"hainow/MCTN" -> "JaydenZeng/TATE"
"hainow/MCTN" -> "thuiar/TFR-Net"
"soujanyaporia/contextual-multimodal-fusion" -> "declare-lab/hfusion"
"soujanyaporia/contextual-multimodal-fusion" -> "GussailRaat/EMNLP-18-MMMU-BA"
"batikim09/LIVE_SER" -> "RedHenLab/multi-modal-emotion-prediction"
"rezachu/emotion_recognition_cnn" -> "rajamohanharesh/Emotion-Recognition"
"liuhuanyong/ChineseHumorSentiment" -> "qingbonlp/qingbo_CCL2019-Chinese-Humor-Computation"
"liuhuanyong/ChineseHumorSentiment" -> "pln-fing-udelar/pghumor" ["e"=1]
"liuhuanyong/ChineseHumorSentiment" -> "orionw/RedditHumorDetection"
"liuhuanyong/ChineseHumorSentiment" -> "Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection"
"liuhuanyong/ChineseHumorSentiment" -> "DUTIR-Emotion-Group/CCL2018-Chinese-Metaphor-Analysis"
"sherleens/WSCNet" -> "Jie-su/WSCNet"
"sherleens/WSCNet" -> "lucinda-lim/Image-Emotion-Classification"
"eesungkim/Speech_Emotion_Recognition_DNN-ELM" -> "RayanWang/Speech_emotion_recognition_BLSTM"
"multi30k/dataset" -> "libeineu/fairseq_mmt"
"multi30k/dataset" -> "iacercalixto/MultimodalNMT"
"multi30k/dataset" -> "cooelf/UVR-NMT"
"multi30k/dataset" -> "ZihengZZH/awesome-multimodal-machine-translation"
"multi30k/dataset" -> "DeepLearnXMU/DCCN"
"RandolphVI/Next-Basket-Recommendation" -> "HaojiHu/TIFUKNN"
"RandolphVI/Next-Basket-Recommendation" -> "HaojiHu/Sets2Sets"
"A2Zadeh/CE-CLM" -> "A2Zadeh/MFN"
"A2Zadeh/CE-CLM" -> "A2Zadeh/MARN"
"Justin1904/CMU-MultimodalSDK-Tutorials" -> "victorywys/RAVEN"
"Justin1904/CMU-MultimodalSDK-Tutorials" -> "pliang279/MFN"
"Justin1904/CMU-MultimodalSDK-Tutorials" -> "A2Zadeh/CMU-MultimodalSDK"
"pliang279/factorized" -> "hainow/MCTN"
"pliang279/factorized" -> "A2Zadeh/Factorized-Multimodal-Transformer"
"pliang279/factorized" -> "victorywys/RAVEN"
"ruidan/IMN-E2E-ABSA" -> "DeepLearnXMU/PSSAttention" ["e"=1]
"A2Zadeh/MFN" -> "A2Zadeh/MARN"
"A2Zadeh/MFN" -> "A2Zadeh/TensorFusionNetwork"
"iacercalixto/MultimodalNMT" -> "iacercalixto/variational_mmt"
"iacercalixto/MultimodalNMT" -> "cooelf/UVR-NMT"
"iacercalixto/MultimodalNMT" -> "Eurus-Holmes/MNMT" ["e"=1]
"iacercalixto/MultimodalNMT" -> "nlab-mpg/Flickr30kEnt-JP"
"lmingde/speech-emotion-recognition-exercise" -> "YJango/speech-emotion-recognition-exercise"
"declare-lab/hfusion" -> "soujanyaporia/contextual-multimodal-fusion"
"MengtingWan/grocery" -> "HaojiHu/TIFUKNN"
"MengtingWan/grocery" -> "JimLiu96/MITGNN"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/WDCNMT"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/ABD-NMT"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/VNMT"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/VarNDRR"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/MNMT"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/CG-ASED"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/GMNMT"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/embedding-transfer"
"DeepLearnXMU/RRWEL" -> "DeepLearnXMU/Otem-Utem"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/WDCNMT"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/VNMT"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/Structure-Self-Aware"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/RRWEL"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/CG-RL"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/MNMT"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/CG-ASED"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/embedding-transfer"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/NSEG"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/ABD-NMT"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/PSSAttention" -> "DeepLearnXMU/IRSEG"
"DeepLearnXMU/ABD-NMT" -> "DeepLearnXMU/WDCNMT"
"DeepLearnXMU/ABD-NMT" -> "DeepLearnXMU/VNMT"
"DeepLearnXMU/ABD-NMT" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/ABD-NMT" -> "DeepLearnXMU/ABDNMT-RNMT"
"DeepLearnXMU/ABD-NMT" -> "DeepLearnXMU/ABDNMT-Transformer"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/BattRAE"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/ABDNMT-Transformer"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/ABDNMT-RNMT" -> "DeepLearnXMU/CAEncoder-NMT"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/MNMT"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/Otem-Utem"
"DeepLearnXMU/NSEG" -> "DeepLearnXMU/CG-ASED"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/VNMT"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/ABD-NMT"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/Structure-Self-Aware"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/VarNDRR"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/CG-ASED"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/RRWEL"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/Otem-Utem"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/IRSEG"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/GMNMT"
"DeepLearnXMU/WDCNMT" -> "DeepLearnXMU/embedding-transfer"
"declare-lab/awesome-sentiment-analysis" -> "declare-lab/awesome-emotion-recognition-in-conversations" ["e"=1]
"declare-lab/awesome-sentiment-analysis" -> "declare-lab/conv-emotion" ["e"=1]
"declare-lab/awesome-sentiment-analysis" -> "soujanyaporia/multimodal-sentiment-analysis" ["e"=1]
"hellonlp/sentiment-analysis" -> "YeexiaoZheng/Multimodal-Sentiment-Analysis" ["e"=1]
"jbdel/MOSEI_UMONS" -> "jbdel/modulated_fusion_transformer"
"jbdel/MOSEI_UMONS" -> "amanshenoy/multilogue-net"
"jbdel/MOSEI_UMONS" -> "declare-lab/BBFN"
"jbdel/MOSEI_UMONS" -> "Justin1904/CMU-MultimodalSDK-Tutorials"
"jbdel/MOSEI_UMONS" -> "kniter1/TAILOR"
"yikaiw/CEN" -> "declare-lab/Multimodal-Infomax" ["e"=1]
"yikaiw/CEN" -> "declare-lab/multimodal-deep-learning" ["e"=1]
"aris-ai/Audio-and-text-based-emotion-recognition" -> "david-yoon/multimodal-speech-emotion"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "mmakiuchi/multimodal_emotion_recognition"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "Vincent-ZHQ/CA-MSER"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "Sreyan88/MMER"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "shamanez/BERT-like-is-All-You-Need"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "PiotrSobczak/speech-emotion-recognition"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "b04901014/FT-w2v2-ser"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch"
"aris-ai/Audio-and-text-based-emotion-recognition" -> "raulsteleac/Speech_Emotion_Recognition"
"thuiar/MMSA" -> "thuiar/MMSA-FET"
"thuiar/MMSA" -> "thuiar/Self-MM"
"thuiar/MMSA" -> "declare-lab/multimodal-deep-learning"
"thuiar/MMSA" -> "LeMei/UniMSE"
"thuiar/MMSA" -> "yaohungt/Multimodal-Transformer"
"thuiar/MMSA" -> "declare-lab/MISA"
"thuiar/MMSA" -> "soujanyaporia/multimodal-sentiment-analysis"
"thuiar/MMSA" -> "XpastaX/ConFEDE"
"thuiar/MMSA" -> "A2Zadeh/CMU-MultimodalSDK"
"thuiar/MMSA" -> "thuiar/M-SENA"
"thuiar/MMSA" -> "thuiar/ch-sims-v2"
"thuiar/MMSA" -> "CMU-MultiComp-Lab/CMU-MultimodalSDK"
"thuiar/MMSA" -> "pliang279/MultiBench"
"thuiar/MMSA" -> "declare-lab/Multimodal-Infomax"
"thuiar/MMSA" -> "thuiar/AWESOME-MSA"
"KrishnaDN/speech-emotion-recognition-using-self-attention" -> "david-yoon/attentive-modality-hopping-for-SER"
"declare-lab/MISA" -> "thuiar/Self-MM"
"declare-lab/MISA" -> "declare-lab/Multimodal-Infomax"
"declare-lab/MISA" -> "LeMei/UniMSE"
"declare-lab/MISA" -> "thuiar/MMSA"
"declare-lab/MISA" -> "yaohungt/Multimodal-Transformer"
"declare-lab/MISA" -> "WasifurRahman/BERT_multimodal_transformer"
"declare-lab/MISA" -> "declare-lab/multimodal-deep-learning"
"declare-lab/MISA" -> "mdswyz/DMD"
"declare-lab/MISA" -> "declare-lab/BBFN"
"declare-lab/MISA" -> "Haoyu-ha/ALMT"
"declare-lab/MISA" -> "AIM3-RUC/MMIN"
"declare-lab/MISA" -> "thuiar/MMSA-FET"
"declare-lab/MISA" -> "A2Zadeh/CMU-MultimodalSDK"
"declare-lab/MISA" -> "Justin1904/TensorFusionNetworks"
"declare-lab/MISA" -> "XpastaX/ConFEDE"
"filippogiruzzi/voice_activity_detection" -> "zlzhang1124/voice_activity_detection" ["e"=1]
"SuyashMore/MevonAI-Speech-Emotion-Recognition" -> "MeidanGR/SpeechEmotionRecognition_Realtime"
"face-analysis/emonet" -> "EvelynFan/AWESOME-MER" ["e"=1]
"face-analysis/emonet" -> "zeroQiaoba/gpt4v-emotion" ["e"=1]
"face-analysis/emonet" -> "rkosti/emotic" ["e"=1]
"woosual/multiModalityFusionForClassification" -> "kitsch231/pytorch_fake_news_Classification_mml"
"thuiar/AWESOME-MSA" -> "thuiar/MMSA-FET"
"thuiar/AWESOME-MSA" -> "thuiar/Self-MM"
"thuiar/AWESOME-MSA" -> "WasifurRahman/BERT_multimodal_transformer"
"thuiar/AWESOME-MSA" -> "Kaicheng-Yang0828/Multimodal-Sentiment-Analysis-Paper-list"
"thuiar/AWESOME-MSA" -> "thuiar/MMSA"
"mailong25/self-supervised-speech-recognition" -> "m3hrdadfi/soxan" ["e"=1]
"mailong25/self-supervised-speech-recognition" -> "khanld/ASR-Wav2vec-Finetune" ["e"=1]
"maysonma/VAANet" -> "nku-zhichengzhang/CTEN"
"maysonma/VAANet" -> "kittenish/Frame-Transformer-Network"
"maysonma/VAANet" -> "vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch"
"maysonma/VAANet" -> "affect2mm/emotion-timeseries"
"maysonma/VAANet" -> "ZizhouJia/PDANet"
"georgian-io/Multimodal-Toolkit" -> "WasifurRahman/BERT_multimodal_transformer" ["e"=1]
"declare-lab/awesome-emotion-recognition-in-conversations" -> "declare-lab/dialogue-understanding" ["e"=1]
"declare-lab/awesome-emotion-recognition-in-conversations" -> "declare-lab/conv-emotion"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "declare-lab/RECCON" ["e"=1]
"declare-lab/awesome-emotion-recognition-in-conversations" -> "declare-lab/awesome-sentiment-analysis" ["e"=1]
"declare-lab/awesome-emotion-recognition-in-conversations" -> "wxjiao/HiGRUs"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "zerohd4869/DialogueCRN"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "declare-lab/MELD"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "shenwzh3/DialogXL"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "tae898/erc"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "caskcsg/SPCL"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "Sahandfer/EMPaper" ["e"=1]
"declare-lab/awesome-emotion-recognition-in-conversations" -> "shenwzh3/DAG-ERC"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "soujanyaporia/multimodal-sentiment-analysis"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "soujanyaporia/MUStARD"
"declare-lab/awesome-emotion-recognition-in-conversations" -> "somethingx678/TodKat"
"liyucheng09/Metaphor_Generator" -> "cnunlp/Chinese-Simile-Recognition-Dataset"
"liyucheng09/Metaphor_Generator" -> "DUTIR-Emotion-Group/CCL2018-Chinese-Metaphor-Analysis"
"liyucheng09/Metaphor_Generator" -> "JasonShao55/Chinese_Metaphor_Explanation"
"facebookresearch/mmbt" -> "WasifurRahman/BERT_multimodal_transformer" ["e"=1]
"ROC-HCI/UR-FUNNY" -> "headacheboy/data-of-multimodal-sarcasm-detection"
"ROC-HCI/UR-FUNNY" -> "soujanyaporia/MUStARD"
"ROC-HCI/UR-FUNNY" -> "pliang279/MFN"
"ROC-HCI/UR-FUNNY" -> "declare-lab/BBFN"
"ROC-HCI/UR-FUNNY" -> "declare-lab/Multimodal-Infomax"
"ROC-HCI/UR-FUNNY" -> "declare-lab/MISA"
"ROC-HCI/UR-FUNNY" -> "thuiar/Self-MM"
"ROC-HCI/UR-FUNNY" -> "hainow/MCTN"
"ROC-HCI/UR-FUNNY" -> "orionw/RedditHumorDetection"
"ROC-HCI/UR-FUNNY" -> "A2Zadeh/CMU-MultimodalSDK"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "YeexiaoZheng/Multimodal-Sentiment-Analysis"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "cindyhu-cyber/Multimodal-Sentiment-Analysis"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "Robin-WZQ/multimodal-emotion-recognition-DEMO"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "liyunfan1223/multimodal-sentiment-analysis"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "asfathermou/human-computer-interaction"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "Iwhappy/MultiModal-Sentiment-Analysis"
"CodeREWorld/Multimodal-Sentiment-Analysis" -> "soujanyaporia/multimodal-sentiment-analysis"
"mkosaka1/Speech_Emotion_Recognition" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"SuperKogito/SER-datasets" -> "HLTSingapore/Emotional-Speech-Data" ["e"=1]
"SuperKogito/SER-datasets" -> "habla-liaa/ser-with-w2v2"
"SuperKogito/SER-datasets" -> "b04901014/FT-w2v2-ser"
"SuperKogito/SER-datasets" -> "glam-imperial/EmotionalConversionStarGAN" ["e"=1]
"SuperKogito/SER-datasets" -> "Demfier/multimodal-speech-emotion-recognition"
"SuperKogito/SER-datasets" -> "Vincent-ZHQ/CA-MSER"
"SuperKogito/SER-datasets" -> "shamanez/BERT-like-is-All-You-Need"
"SuperKogito/SER-datasets" -> "emo-box/EmoBox" ["e"=1]
"SuperKogito/SER-datasets" -> "ddlBoJack/emotion2vec" ["e"=1]
"SuperKogito/SER-datasets" -> "Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch"
"SuperKogito/SER-datasets" -> "numediart/EmoV-DB" ["e"=1]
"SuperKogito/SER-datasets" -> "audeering/w2v2-how-to" ["e"=1]
"SuperKogito/SER-datasets" -> "m3hrdadfi/soxan"
"SuperKogito/SER-datasets" -> "abikaki/awesome-speech-emotion-recognition"
"shamanez/BERT-like-is-All-You-Need" -> "habla-liaa/ser-with-w2v2"
"shamanez/BERT-like-is-All-You-Need" -> "shamanez/Self-Supervised-Embedding-Fusion-Transformer"
"shamanez/BERT-like-is-All-You-Need" -> "Demfier/multimodal-speech-emotion-recognition"
"shamanez/BERT-like-is-All-You-Need" -> "b04901014/FT-w2v2-ser"
"shamanez/BERT-like-is-All-You-Need" -> "lessonxmk/head_fusion"
"shamanez/BERT-like-is-All-You-Need" -> "david-yoon/multimodal-speech-emotion"
"shamanez/BERT-like-is-All-You-Need" -> "KrishnaDN/speech-emotion-recognition-using-self-attention"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "IliaZenkov/transformer-cnn-emotion-recognition"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "b04901014/FT-w2v2-ser"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "Demfier/multimodal-speech-emotion-recognition"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "aris-ai/Audio-and-text-based-emotion-recognition"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "m3hrdadfi/soxan"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "SuperKogito/SER-datasets"
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" -> "shamanez/BERT-like-is-All-You-Need"
"EvelynFan/AWESOME-MER" -> "maysonma/VAANet"
"EvelynFan/AWESOME-MER" -> "NickyFot/EmoCLIP"
"EvelynFan/AWESOME-MER" -> "wtomin/MIMAMO-Net" ["e"=1]
"EvelynFan/AWESOME-MER" -> "shamanez/Self-Supervised-Embedding-Fusion-Transformer"
"EvelynFan/AWESOME-MER" -> "ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION"
"zlzhang1124/AcousticFeatureExtraction" -> "zlzhang1124/voice_activity_detection"
"zlzhang1124/AcousticFeatureExtraction" -> "Vincent-ZHQ/CA-MSER"
"zlzhang1124/AcousticFeatureExtraction" -> "Renovamen/Speech-Emotion-Recognition"
"iffsid/mmvae" -> "mhw32/multimodal-vae-public"
"iffsid/mmvae" -> "thomassutter/MoPoE"
"iffsid/mmvae" -> "epalu/mmvaeplus"
"iffsid/mmvae" -> "gabinsane/multimodal-vae-comparison"
"iffsid/mmvae" -> "kodaim1115/scMM"
"iffsid/mmvae" -> "thomassutter/mmjsd"
"iffsid/mmvae" -> "pliang279/factorized"
"iffsid/mmvae" -> "seqam-lab/DMVAE"
"amanshenoy/multilogue-net" -> "jbdel/MOSEI_UMONS"
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" -> "shamanez/BERT-like-is-All-You-Need"
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" -> "wenliangdai/Modality-Transferable-MER"
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" -> "katerynaCh/multimodal-emotion-recognition"
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" -> "zerohd4869/MM-DFN"
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" -> "EvelynFan/AWESOME-MER"
"PreferredAI/beacon" -> "PreferredAI/cbs"
"PreferredAI/beacon" -> "PreferredAI/mp-simrank"
"PreferredAI/beacon" -> "PreferredAI/venom-tutorial"
"PreferredAI/beacon" -> "PreferredAI/compare-lda"
"PreferredAI/beacon" -> "PreferredAI/venom-examples"
"PreferredAI/beacon" -> "PreferredAI/mrg"
"HaojiHu/TIFUKNN" -> "HaojiHu/Sets2Sets"
"HaojiHu/TIFUKNN" -> "RandolphVI/Next-Basket-Recommendation"
"HaojiHu/TIFUKNN" -> "MengtingWan/grocery"
"HaojiHu/TIFUKNN" -> "QYQ-bot/CLEA"
"jefferyYu/TomBERT" -> "codezakh/exploiting-BERT-thru-translation"
"jefferyYu/TomBERT" -> "xunan0812/MIMN"
"jefferyYu/TomBERT" -> "NUSTM/VLP-MABSA"
"jefferyYu/TomBERT" -> "PreferredAI/vista-net"
"TmacMai/ARGF_multimodal_fusion" -> "TmacMai/multimodal-fusion"
"TmacMai/ARGF_multimodal_fusion" -> "jiajiatang0000/HPFN"
"zlzhang1124/voice_activity_detection" -> "zlzhang1124/AcousticFeatureExtraction"
"lessonxmk/Optimized_attention_for_SER" -> "lessonxmk/head_fusion"
"lessonxmk/Optimized_attention_for_SER" -> "lixiangucas01/GLAM"
"Tandon-A/emotic" -> "rkosti/emotic"
"Tandon-A/emotic" -> "ndkhanh360/CAER"
"Tandon-A/emotic" -> "ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION"
"Tandon-A/emotic" -> "chenxindaaa/emotic"
"thuiar/Cross-Modal-BERT" -> "thuiar/Self-MM"
"thuiar/Cross-Modal-BERT" -> "WasifurRahman/BERT_multimodal_transformer"
"ShaheenPerveen/speech-emotion-recognition-iemocap" -> "PiotrSobczak/speech-emotion-recognition"
"DeepLearnXMU/Cyclic" -> "DeepLearnXMU/BattRAE"
"DeepLearnXMU/Cyclic" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/Cyclic" -> "DeepLearnXMU/ABDNMT-RNMT"
"DeepLearnXMU/Cyclic" -> "DeepLearnXMU/CAEncoder-NMT"
"wenliangdai/Modality-Transferable-MER" -> "wenliangdai/Multimodal-End2end-Sparse"
"ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION" -> "EvelynFan/AWESOME-MER"
"cvlab-stonybrook/Emotion-Prediction" -> "lucinda-lim/Image-Emotion-Classification"
"ivyha010/emotionprediction" -> "ivyha010/AttendAffectNet"
"ivyha010/emotionprediction" -> "kittenish/Frame-Transformer-Network"
"david-yoon/attentive-modality-hopping-for-SER" -> "glam-imperial/semantic_speech_emotion_recognition"
"vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch" -> "LW-Ricarido/Emotion_SDK"
"A2Zadeh/Factorized-Multimodal-Transformer" -> "victorywys/RAVEN"
"DeepLearnXMU/GMNMT" -> "DeepLearnXMU/Pairwise"
"cooelf/UVR-NMT" -> "libeineu/fairseq_mmt"
"cooelf/UVR-NMT" -> "iacercalixto/variational_mmt"
"cooelf/UVR-NMT" -> "iacercalixto/MultimodalNMT"
"cooelf/UVR-NMT" -> "ictnlp/PLUVR"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/WDCNMT"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/VNMT"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/ABD-NMT"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/RRWEL"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/GMNMT"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/Structure-Self-Aware"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/DCCN" -> "DeepLearnXMU/IRSEG"
"Jie-su/WSCNet" -> "sherleens/WSCNet"
"orionw/rJokesData" -> "orionw/RedditHumorDetection"
"marvel2120/MsdBert" -> "wjq-learning/MSTI"
"declare-lab/dialogue-understanding" -> "declare-lab/awesome-emotion-recognition-in-conversations" ["e"=1]
"orionw/RedditHumorDetection" -> "Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection"
"orionw/RedditHumorDetection" -> "orionw/rJokesData"
"Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection" -> "orionw/RedditHumorDetection"
"ZizhouJia/PDANet" -> "lucinda-lim/Image-Emotion-Classification"
"ZizhouJia/PDANet" -> "sherleens/WSCNet"
"lessonxmk/head_fusion" -> "lessonxmk/Optimized_attention_for_SER"
"iyuge2/M-SENA-Backend" -> "Columbine21/NIAT"
"LW-Ricarido/Emotion_SDK" -> "vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch"
"DeepLearnXMU/IMM" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/IMM" -> "DeepLearnXMU/DAMAML"
"MANLP-suda/MMESGN" -> "MANLP-suda/HHMPN"
"sb-ai-lab/EmotiEffLib" -> "maelfabien/Multimodal-Emotion-Recognition" ["e"=1]
"IliaZenkov/sklearn-audio-classification" -> "IliaZenkov/transformer-cnn-emotion-recognition"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "IliaZenkov/sklearn-audio-classification"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "PiotrSobczak/speech-emotion-recognition"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "b04901014/FT-w2v2-ser"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "Jiaxin-Ye/TIM-Net_SER"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "Vincent-ZHQ/CA-MSER"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "cdezapasquale/transfomer-audio-classification"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "shamanez/Self-Supervised-Embedding-Fusion-Transformer"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "vandana-rajan/1D-Speech-Emotion-Recognition"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "HoseinAzad/Transformer-based-SER"
"IliaZenkov/transformer-cnn-emotion-recognition" -> "TideDancer/interspeech21_emotion"
"thuiar/Self-MM" -> "declare-lab/MISA"
"thuiar/Self-MM" -> "thuiar/MMSA"
"thuiar/Self-MM" -> "declare-lab/Multimodal-Infomax"
"thuiar/Self-MM" -> "LeMei/UniMSE"
"thuiar/Self-MM" -> "thuiar/MMSA-FET"
"thuiar/Self-MM" -> "declare-lab/BBFN"
"thuiar/Self-MM" -> "WasifurRahman/BERT_multimodal_transformer"
"thuiar/Self-MM" -> "thuiar/AWESOME-MSA"
"thuiar/Self-MM" -> "thuiar/TFR-Net"
"thuiar/Self-MM" -> "declare-lab/multimodal-deep-learning"
"thuiar/Self-MM" -> "thuiar/M-SENA"
"thuiar/Self-MM" -> "mdswyz/DMD"
"thuiar/Self-MM" -> "XpastaX/ConFEDE"
"thuiar/Self-MM" -> "thuiar/Cross-Modal-BERT"
"thuiar/Self-MM" -> "thuiar/ch-sims-v2"
"audeering/opensmile" -> "zlzhang1124/AcousticFeatureExtraction" ["e"=1]
"audeering/opensmile" -> "declare-lab/MELD" ["e"=1]
"audeering/opensmile" -> "Demfier/multimodal-speech-emotion-recognition" ["e"=1]
"habla-liaa/ser-with-w2v2" -> "b04901014/FT-w2v2-ser"
"habla-liaa/ser-with-w2v2" -> "shamanez/BERT-like-is-All-You-Need"
"habla-liaa/ser-with-w2v2" -> "TideDancer/interspeech21_emotion"
"habla-liaa/ser-with-w2v2" -> "m3hrdadfi/soxan"
"habla-liaa/ser-with-w2v2" -> "Sreyan88/MMER"
"habla-liaa/ser-with-w2v2" -> "SuperKogito/SER-datasets"
"habla-liaa/ser-with-w2v2" -> "AryaAftab/LIGHT-SERNET"
"habla-liaa/ser-with-w2v2" -> "lessonxmk/Optimized_attention_for_SER"
"jonatasgrosman/wav2vec2-sprint" -> "jonatasgrosman/huggingsound"
"jonatasgrosman/wav2vec2-sprint" -> "m3hrdadfi/soxan"
"deep-real/SMIL" -> "AIM3-RUC/MMIN"
"deep-real/SMIL" -> "YiLunLee/missing_aware_prompts"
"deep-real/SMIL" -> "mdswyz/DiCMoR"
"deep-real/SMIL" -> "han-liu/awesome-missing-modality-for-medical-images"
"deep-real/SMIL" -> "billhhh/ShaSpec"
"deep-real/SMIL" -> "shicaiwei123/MMANet-CVPR2023"
"deep-real/SMIL" -> "hainow/MCTN"
"deep-real/SMIL" -> "pliang279/factorized"
"deep-real/SMIL" -> "JaydenZeng/TATE"
"deep-real/SMIL" -> "thuiar/TFR-Net"
"deep-real/SMIL" -> "deepsuperviser/CTFN"
"pliang279/MultiBench" -> "CMU-MultiComp-Lab/CMU-MultimodalSDK"
"pliang279/MultiBench" -> "yaohungt/Multimodal-Transformer"
"pliang279/MultiBench" -> "thuiar/MMSA"
"pliang279/MultiBench" -> "declare-lab/multimodal-deep-learning"
"pliang279/MultiBench" -> "declare-lab/MISA"
"pliang279/MultiBench" -> "LeMei/UniMSE"
"pliang279/MultiBench" -> "A2Zadeh/CMU-MultimodalSDK"
"pliang279/MultiBench" -> "declare-lab/Multimodal-Infomax"
"pliang279/MultiBench" -> "thuiar/Self-MM"
"pliang279/MultiBench" -> "GeWu-Lab/OGM-GE_CVPR2022" ["e"=1]
"pliang279/MultiBench" -> "pliang279/PID"
"pliang279/MultiBench" -> "zeroQiaoba/AffectGPT"
"pliang279/MultiBench" -> "pliang279/HighMMT"
"pliang279/MultiBench" -> "soujanyaporia/MUStARD"
"pliang279/MultiBench" -> "thuiar/MMSA-FET"
"hujingwen6666/MMGCN" -> "zerohd4869/MM-DFN"
"hujingwen6666/MMGCN" -> "Exploration-Lab/COGMEN"
"hujingwen6666/MMGCN" -> "butterfliesss/SDT"
"hujingwen6666/MMGCN" -> "feiyuchen7/M3NET"
"declare-lab/RECCON" -> "LeqsNaN/KEC" ["e"=1]
"declare-lab/RECCON" -> "declare-lab/awesome-emotion-recognition-in-conversations" ["e"=1]
"declare-lab/RECCON" -> "declare-lab/conv-emotion" ["e"=1]
"declare-lab/RECCON" -> "NUSTM/MECPE" ["e"=1]
"declare-lab/RECCON" -> "shenwzh3/DAG-ERC" ["e"=1]
"wenliangdai/Multimodal-End2end-Sparse" -> "wenliangdai/Modality-Transferable-MER"
"wenliangdai/Multimodal-End2end-Sparse" -> "tzirakis/Multimodal-Emotion-Recognition"
"tae898/erc" -> "tae898/multimodal-datasets"
"tae898/erc" -> "zerohd4869/DialogueCRN"
"tae898/erc" -> "caskcsg/SPCL"
"tae898/erc" -> "TaoShi1998/MultiEMO"
"tae898/erc" -> "LIN-SHANG/InstructERC"
"tae898/erc" -> "somethingx678/TodKat"
"tae898/erc" -> "fpcsong/emotionflow"
"tae898/erc" -> "rungjoo/CoMPM"
"tae898/erc" -> "wxjiao/AGHMN"
"MeidanGR/SpeechEmotionRecognition_Realtime" -> "AbdulBasit-MrRobo/Real-Time-Speech-Emotion-Recognition"
"MeidanGR/SpeechEmotionRecognition_Realtime" -> "ShaheenPerveen/speech-emotion-recognition-iemocap"
"thuiar/M-SENA" -> "thuiar/MMSA-FET"
"thuiar/M-SENA" -> "FlameSky-S/M-SENA-frontend"
"thuiar/M-SENA" -> "iyuge2/M-SENA-Backend"
"thuiar/M-SENA" -> "thuiar/Self-MM"
"m3hrdadfi/soxan" -> "habla-liaa/ser-with-w2v2"
"m3hrdadfi/soxan" -> "b04901014/FT-w2v2-ser"
"m3hrdadfi/soxan" -> "Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch"
"m3hrdadfi/soxan" -> "cristinalunaj/MMEmotionRecognition"
"m3hrdadfi/soxan" -> "SuperKogito/SER-datasets"
"m3hrdadfi/soxan" -> "mailong25/self-supervised-speech-recognition" ["e"=1]
"m3hrdadfi/soxan" -> "jonatasgrosman/wav2vec2-sprint"
"m3hrdadfi/soxan" -> "Edresson/Wav2Vec-Wrapper"
"m3hrdadfi/soxan" -> "TideDancer/interspeech21_emotion"
"DUTIR-Emotion-Group/CCL2018-Chinese-Metaphor-Analysis" -> "JasonShao55/Chinese_Metaphor_Explanation"
"DUTIR-Emotion-Group/CCL2018-Chinese-Metaphor-Analysis" -> "veronica320/Chinese-Metaphor"
"TideDancer/interspeech21_emotion" -> "b04901014/FT-w2v2-ser"
"TideDancer/interspeech21_emotion" -> "habla-liaa/ser-with-w2v2"
"TideDancer/interspeech21_emotion" -> "AryaAftab/LIGHT-SERNET"
"TideDancer/interspeech21_emotion" -> "Sreyan88/MMER"
"TideDancer/interspeech21_emotion" -> "Vincent-ZHQ/CA-MSER"
"TideDancer/interspeech21_emotion" -> "HappyColor/Vesper"
"TideDancer/interspeech21_emotion" -> "lessonxmk/Optimized_attention_for_SER"
"TideDancer/interspeech21_emotion" -> "lixiangucas01/GLAM"
"kensho-technologies/pyctcdecode" -> "patrickvonplaten/Wav2Vec2_PyCTCDecode" ["e"=1]
"AIM3-RUC/MMIN" -> "deep-real/SMIL"
"AIM3-RUC/MMIN" -> "hainow/MCTN"
"AIM3-RUC/MMIN" -> "ZhuoYulang/IF-MMIN"
"AIM3-RUC/MMIN" -> "thuiar/TFR-Net"
"AIM3-RUC/MMIN" -> "JaydenZeng/EMMR"
"AIM3-RUC/MMIN" -> "JaydenZeng/TATE"
"AIM3-RUC/MMIN" -> "Haoyu-ha/LNLN"
"AIM3-RUC/MMIN" -> "deepsuperviser/CTFN"
"QYQ-bot/CLEA" -> "pmleffers/TIFUKNN"
"oliverguhr/wav2vec2-live" -> "Edresson/Wav2Vec-Wrapper"
"oliverguhr/wav2vec2-live" -> "kensho-technologies/pyctcdecode" ["e"=1]
"oliverguhr/wav2vec2-live" -> "jonatasgrosman/huggingsound"
"oliverguhr/wav2vec2-live" -> "vietai/ASR" ["e"=1]
"oliverguhr/wav2vec2-live" -> "ccoreilly/wav2vec2-service"
"oliverguhr/wav2vec2-live" -> "patrickvonplaten/Wav2Vec2_PyCTCDecode"
"oliverguhr/wav2vec2-live" -> "m3hrdadfi/soxan"
"oliverguhr/wav2vec2-live" -> "mailong25/self-supervised-speech-recognition" ["e"=1]
"oliverguhr/wav2vec2-live" -> "jonatasgrosman/wav2vec2-sprint"
"oliverguhr/wav2vec2-live" -> "khanld/ASR-Wav2vec-Finetune"
"oliverguhr/wav2vec2-live" -> "chuachinhon/wav2vec2_transformers"
"oliverguhr/wav2vec2-live" -> "bhattbhavesh91/wav2vec2-huggingface-demo"
"Robin-WZQ/multimodal-emotion-recognition-DEMO" -> "katerynaCh/multimodal-emotion-recognition"
"Robin-WZQ/multimodal-emotion-recognition-DEMO" -> "CodeREWorld/Multimodal-Sentiment-Analysis"
"Robin-WZQ/multimodal-emotion-recognition-DEMO" -> "maysonma/VAANet"
"YangXiaocui1215/MGNNS" -> "YangXiaocui1215/MVAN"
"declare-lab/BBFN" -> "declare-lab/Multimodal-Infomax"
"declare-lab/BBFN" -> "kiva12138/CubeMLP"
"declare-lab/BBFN" -> "georgepar/mmlatch"
"declare-lab/BBFN" -> "XpastaX/ConFEDE"
"shenwzh3/DAG-ERC" -> "shenwzh3/DialogXL"
"shenwzh3/DAG-ERC" -> "zerohd4869/DialogueCRN"
"shenwzh3/DAG-ERC" -> "somethingx678/TodKat"
"shenwzh3/DAG-ERC" -> "LeqsNaN/KEC"
"shenwzh3/DAG-ERC" -> "KomorebiLHX/Emotion-Recognition-in-Conversations"
"shenwzh3/DAG-ERC" -> "caskcsg/SPCL"
"shenwzh3/DAG-ERC" -> "SteveKGYang/SCCL"
"shenwzh3/DAG-ERC" -> "LeqsNaN/SKAIG-ERC"
"shenwzh3/DAG-ERC" -> "circle-hit/CauAIN"
"thu-coai/EVA" -> "scutcyr/CPED" ["e"=1]
"HLTSingapore/Emotional-Speech-Data" -> "SuperKogito/SER-datasets" ["e"=1]
"shenwzh3/DialogXL" -> "shenwzh3/DAG-ERC"
"shenwzh3/DialogXL" -> "zerohd4869/DialogueCRN"
"shenwzh3/DialogXL" -> "SteveKGYang/SCCL"
"shenwzh3/DialogXL" -> "somethingx678/TodKat"
"KomorebiLHX/Emotion-Recognition-in-Conversations" -> "shenwzh3/DAG-ERC"
"mrzjy/writing-polishment-with-simile" -> "cnunlp/Chinese-Simile-Recognition-Dataset"
"mrzjy/writing-polishment-with-simile" -> "DeepLearnXMU/Cyclic"
"cindyhu-cyber/Multimodal-Sentiment-Analysis" -> "Miaheeee/AI_lab5"
"ivyha010/AttendAffectNet" -> "ivyha010/emotionprediction"
"seqam-lab/DMVAE" -> "OpenNLPLab/MMVAE-AVS"
"lstappen/MuSe2021" -> "EIHW/MuSe2022"
"lstappen/MuSe2021" -> "lstappen/MuSe2020"
"lstappen/MuSe2021" -> "youcaiSUN/MuSe-Wild_2020"
"somethingx678/TodKat" -> "zerohd4869/DialogueCRN"
"somethingx678/TodKat" -> "LeqsNaN/SKAIG-ERC"
"somethingx678/TodKat" -> "caskcsg/SPCL"
"somethingx678/TodKat" -> "shenwzh3/DAG-ERC"
"somethingx678/TodKat" -> "shenwzh3/DialogXL"
"alawryaguila/multi-view-AE" -> "epalu/mmvaeplus"
"wrk226/pytorch-multimodal_sarcasm_detection" -> "headacheboy/data-of-multimodal-sarcasm-detection"
"LividWo/Revisit-MMT" -> "libeineu/fairseq_mmt"
"zerohd4869/DialogueCRN" -> "somethingx678/TodKat"
"zerohd4869/DialogueCRN" -> "zerohd4869/MM-DFN"
"zerohd4869/DialogueCRN" -> "shenwzh3/DAG-ERC"
"zerohd4869/DialogueCRN" -> "caskcsg/SPCL"
"zerohd4869/DialogueCRN" -> "shenwzh3/DialogXL"
"zerohd4869/DialogueCRN" -> "zerohd4869/SACL"
"DeepLearnXMU/Structure-Self-Aware" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/Structure-Self-Aware" -> "DeepLearnXMU/DAMAML"
"MANLP-suda/HHMPN" -> "MANLP-suda/MMESGN"
"DeepLearnXMU/embedding-transfer" -> "DeepLearnXMU/multisource_cg_md"
"ljynlp/HiTrans" -> "LeqsNaN/SKAIG-ERC"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/embedding-transfer"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/DAMAML"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/MNMT"
"DeepLearnXMU/CG-RL" -> "DeepLearnXMU/CG-ASED"
"jonatasgrosman/huggingsound" -> "jonatasgrosman/wav2vec2-sprint"
"jonatasgrosman/huggingsound" -> "huggingface/speechbox"
"jonatasgrosman/huggingsound" -> "oliverguhr/wav2vec2-live"
"jonatasgrosman/huggingsound" -> "jonatasgrosman/asrecognition"
"jonatasgrosman/huggingsound" -> "lumaku/ctc-segmentation" ["e"=1]
"jonatasgrosman/huggingsound" -> "mailong25/self-supervised-speech-recognition" ["e"=1]
"jonatasgrosman/huggingsound" -> "ccoreilly/wav2vec2-service"
"jonatasgrosman/huggingsound" -> "farisalasmary/wav2vec2-kenlm"
"jonatasgrosman/huggingsound" -> "spring-media/DeepPhonemizer" ["e"=1]
"zerohd4869/MM-DFN" -> "hujingwen6666/MMGCN"
"zerohd4869/MM-DFN" -> "zerohd4869/DialogueCRN"
"zerohd4869/MM-DFN" -> "feiyuchen7/M3NET"
"zerohd4869/MM-DFN" -> "butterfliesss/SDT"
"zerohd4869/MM-DFN" -> "TaoShi1998/MultiEMO"
"zerohd4869/MM-DFN" -> "Exploration-Lab/COGMEN"
"zerohd4869/MM-DFN" -> "caskcsg/SPCL"
"fpcsong/emotionflow" -> "rungjoo/CoMPM"
"audeering/w2v2-how-to" -> "b04901014/FT-w2v2-ser" ["e"=1]
"audeering/w2v2-how-to" -> "SuperKogito/SER-datasets" ["e"=1]
"audeering/w2v2-how-to" -> "TideDancer/interspeech21_emotion" ["e"=1]
"audeering/w2v2-how-to" -> "habla-liaa/ser-with-w2v2" ["e"=1]
"katerynaCh/multimodal-emotion-recognition" -> "MultimodalAffectiveComputing/FV2ES"
"katerynaCh/multimodal-emotion-recognition" -> "Robin-WZQ/multimodal-emotion-recognition-DEMO"
"katerynaCh/multimodal-emotion-recognition" -> "katerynaCh/MMA-DFER" ["e"=1]
"katerynaCh/multimodal-emotion-recognition" -> "praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion"
"katerynaCh/multimodal-emotion-recognition" -> "tzirakis/Multimodal-Emotion-Recognition"
"katerynaCh/multimodal-emotion-recognition" -> "She-yh/End-to-End-Multimodal-emotion-recognition"
"katerynaCh/multimodal-emotion-recognition" -> "cristinalunaj/MMEmotionRecognition"
"smartcameras/SelfCrossAttn" -> "david-yoon/attentive-modality-hopping-for-SER"
"smartcameras/SelfCrossAttn" -> "glam-imperial/semantic_speech_emotion_recognition"
"NUSTM/VLP-MABSA" -> "SilyRab/AoM"
"NUSTM/VLP-MABSA" -> "YangXiaocui1215/MGNNS"
"NUSTM/VLP-MABSA" -> "Link-Li/CLMLF"
"NUSTM/VLP-MABSA" -> "jefferyYu/TomBERT"
"NUSTM/VLP-MABSA" -> "MANLP-suda/JML"
"NUSTM/VLP-MABSA" -> "NUSTM/ITM"
"NUSTM/VLP-MABSA" -> "XpastaX/ConFEDE"
"NUSTM/VLP-MABSA" -> "YangXiaocui1215/GMP"
"NUSTM/VLP-MABSA" -> "NUSTM/HIMT"
"AIM3-RUC/RUCM3ED" -> "AIM3-RUC/MERC_Challenge_CCAC2023"
"AIM3-RUC/RUCM3ED" -> "scutcyr/CPED"
"AIM3-RUC/RUCM3ED" -> "EIHW/MuSe2022"
"declare-lab/multimodal-deep-learning" -> "thuiar/MMSA"
"declare-lab/multimodal-deep-learning" -> "soujanyaporia/multimodal-sentiment-analysis"
"declare-lab/multimodal-deep-learning" -> "declare-lab/MISA"
"declare-lab/multimodal-deep-learning" -> "declare-lab/Multimodal-Infomax"
"declare-lab/multimodal-deep-learning" -> "yaohungt/Multimodal-Transformer"
"declare-lab/multimodal-deep-learning" -> "thuiar/Self-MM"
"declare-lab/multimodal-deep-learning" -> "A2Zadeh/CMU-MultimodalSDK"
"declare-lab/multimodal-deep-learning" -> "LeMei/UniMSE"
"declare-lab/multimodal-deep-learning" -> "pliang279/MultiBench"
"declare-lab/multimodal-deep-learning" -> "thuiar/MMSA-FET"
"declare-lab/multimodal-deep-learning" -> "Justin1904/TensorFusionNetworks"
"declare-lab/multimodal-deep-learning" -> "declare-lab/BBFN"
"declare-lab/multimodal-deep-learning" -> "WasifurRahman/BERT_multimodal_transformer"
"declare-lab/multimodal-deep-learning" -> "YeexiaoZheng/Multimodal-Sentiment-Analysis"
"declare-lab/multimodal-deep-learning" -> "soujanyaporia/MUStARD"
"sucv/ABAW3" -> "praveena2j/RJCMA"
"sucv/ABAW3" -> "sucv/ABAW2"
"speechandlanguageprocessing/ICASSP2022-Depression" -> "HappyColor/SpeechFormer" ["e"=1]
"BladeDancer957/TSAM" -> "LeqsNaN/KEC"
"AryaAftab/LIGHT-SERNET" -> "lixiangucas01/GLAM"
"AryaAftab/LIGHT-SERNET" -> "Vincent-ZHQ/CA-MSER"
"AryaAftab/LIGHT-SERNET" -> "scutcsq/DWFormer"
"AryaAftab/LIGHT-SERNET" -> "Jiaxin-Ye/TIM-Net_SER"
"AryaAftab/LIGHT-SERNET" -> "lessonxmk/Optimized_attention_for_SER"
"AryaAftab/LIGHT-SERNET" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"AryaAftab/LIGHT-SERNET" -> "ECNU-Cross-Innovation-Lab/ENT"
"AryaAftab/LIGHT-SERNET" -> "julianyulu/icassp2021-mscnn-spu"
"AryaAftab/LIGHT-SERNET" -> "b04901014/FT-w2v2-ser"
"AryaAftab/LIGHT-SERNET" -> "Jiaxin-Ye/GM-TCNet"
"khanld/ASR-Wav2vec-Finetune" -> "khanld/Wav2vec2-Pretraining"
"khanld/ASR-Wav2vec-Finetune" -> "qinyuenlp/wav2vec_finetune"
"facebookresearch/multimodal" -> "declare-lab/multimodal-deep-learning" ["e"=1]
"GeWu-Lab/OGM-GE_CVPR2022" -> "pliang279/MultiBench" ["e"=1]
"thuiar/MMSA-FET" -> "thuiar/M-SENA"
"thuiar/MMSA-FET" -> "thuiar/MMSA"
"thuiar/MMSA-FET" -> "thuiar/Self-MM"
"thuiar/MMSA-FET" -> "thuiar/ch-sims-v2"
"thuiar/MMSA-FET" -> "sunlicai/EMT-DLFR"
"thuiar/MMSA-FET" -> "LeMei/UniMSE"
"thuiar/MMSA-FET" -> "CMU-MultiComp-Lab/CMU-MultimodalSDK"
"thuiar/MMSA-FET" -> "declare-lab/Multimodal-Infomax"
"thuiar/MMSA-FET" -> "thuiar/AWESOME-MSA"
"thuiar/MMSA-FET" -> "WasifurRahman/BERT_multimodal_transformer"
"thuiar/MMSA-FET" -> "Haoyu-ha/ALMT"
"thuiar/MMSA-FET" -> "thuiar/TFR-Net"
"thuiar/MMSA-FET" -> "XpastaX/ConFEDE"
"thuiar/MMSA-FET" -> "declare-lab/MISA"
"thuiar/MMSA-FET" -> "albertwy/SWRM"
"Exploration-Lab/COGMEN" -> "hujingwen6666/MMGCN"
"Exploration-Lab/COGMEN" -> "zerohd4869/MM-DFN"
"Exploration-Lab/COGMEN" -> "leson502/CORECT_EMNLP2023"
"Exploration-Lab/COGMEN" -> "feiyuchen7/M3NET"
"Exploration-Lab/COGMEN" -> "Yu-Fangxu/EACL"
"Exploration-Lab/COGMEN" -> "butterfliesss/SDT"
"Exploration-Lab/COGMEN" -> "NUSTM/FacialMMT"
"Exploration-Lab/COGMEN" -> "LeMei/UniMSE"
"metaphysicser/PS-Mixer" -> "JackAILab/TMBL"
"Sreyan88/MMER" -> "scutcsq/DWFormer"
"Sreyan88/MMER" -> "HappyColor/Vesper"
"Sreyan88/MMER" -> "Vincent-ZHQ/CA-MSER"
"Sreyan88/MMER" -> "HappyColor/DST"
"scutcyr/CPED" -> "AIM3-RUC/RUCM3ED"
"scutcyr/CPED" -> "sunlightsgy/MEmoR"
"scutcyr/CPED" -> "thu-coai/EVA" ["e"=1]
"scutcyr/CPED" -> "thu-coai/Emotional-Support-Conversation" ["e"=1]
"scutcyr/CPED" -> "AIM3-RUC/MERC_Challenge_CCAC2023"
"scutcyr/CPED" -> "XiaoMi/C3KG" ["e"=1]
"scutcyr/CPED" -> "LIN-SHANG/InstructERC"
"scutcyr/CPED" -> "zeroQiaoba/MERTools"
"scutcyr/CPED" -> "caskcsg/SPCL"
"scutcyr/CPED" -> "shenwzh3/DAG-ERC"
"scutcyr/CPED" -> "Sahandfer/CEM" ["e"=1]
"LeqsNaN/SKAIG-ERC" -> "LeqsNaN/KEC"
"Link-Li/CLMLF" -> "YangXiaocui1215/MVAN"
"Link-Li/CLMLF" -> "NUSTM/VLP-MABSA"
"Link-Li/CLMLF" -> "SilyRab/AoM"
"hbzju/PiCO" -> "zeroQiaoba/ALIM" ["e"=1]
"declare-lab/Multimodal-Infomax" -> "LeMei/UniMSE"
"declare-lab/Multimodal-Infomax" -> "declare-lab/MISA"
"declare-lab/Multimodal-Infomax" -> "thuiar/Self-MM"
"declare-lab/Multimodal-Infomax" -> "declare-lab/BBFN"
"declare-lab/Multimodal-Infomax" -> "sunlicai/EMT-DLFR"
"declare-lab/Multimodal-Infomax" -> "declare-lab/multimodal-deep-learning"
"declare-lab/Multimodal-Infomax" -> "thuiar/MMSA-FET"
"declare-lab/Multimodal-Infomax" -> "WasifurRahman/BERT_multimodal_transformer"
"declare-lab/Multimodal-Infomax" -> "Justin1904/TensorFusionNetworks"
"declare-lab/Multimodal-Infomax" -> "Haoyu-ha/ALMT"
"declare-lab/Multimodal-Infomax" -> "declare-lab/MSA-Robustness"
"declare-lab/Multimodal-Infomax" -> "thuiar/ch-sims-v2"
"declare-lab/Multimodal-Infomax" -> "thuiar/MMSA"
"declare-lab/Multimodal-Infomax" -> "soujanyaporia/multimodal-sentiment-analysis"
"declare-lab/Multimodal-Infomax" -> "ROC-HCI/UR-FUNNY"
"kniter1/TAILOR" -> "MANLP-suda/HHMPN"
"drmuskangarg/Multimodal-datasets" -> "AIM3-RUC/RUCM3ED"
"drmuskangarg/Multimodal-datasets" -> "headacheboy/data-of-multimodal-sarcasm-detection"
"drmuskangarg/Multimodal-datasets" -> "caskcsg/SPCL"
"drmuskangarg/Multimodal-datasets" -> "zeroQiaoba/AffectGPT"
"farisalasmary/wav2vec2-kenlm" -> "patrickvonplaten/Wav2Vec2_PyCTCDecode"
"HappyColor/SpeechFormer" -> "HappyColor/SpeechFormer2"
"HappyColor/SpeechFormer" -> "HappyColor/Vesper"
"HappyColor/SpeechFormer" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"HappyColor/SpeechFormer" -> "ECNU-Cross-Innovation-Lab/ENT"
"patrickvonplaten/Wav2Vec2_PyCTCDecode" -> "farisalasmary/wav2vec2-kenlm"
"RecklessRonan/MuSE" -> "dawn0815/UniSA"
"Vincent-ZHQ/CA-MSER" -> "Jiaxin-Ye/TIM-Net_SER"
"Vincent-ZHQ/CA-MSER" -> "AryaAftab/LIGHT-SERNET"
"Vincent-ZHQ/CA-MSER" -> "lixiangucas01/GLAM"
"Vincent-ZHQ/CA-MSER" -> "b04901014/FT-w2v2-ser"
"Vincent-ZHQ/CA-MSER" -> "scutcsq/DWFormer"
"Vincent-ZHQ/CA-MSER" -> "Sreyan88/MMER"
"Vincent-ZHQ/CA-MSER" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"Vincent-ZHQ/CA-MSER" -> "TideDancer/interspeech21_emotion"
"Vincent-ZHQ/CA-MSER" -> "ASolitaryMan/HFLEA"
"cristinalunaj/MMEmotionRecognition" -> "b04901014/FT-w2v2-ser"
"cristinalunaj/MMEmotionRecognition" -> "katerynaCh/multimodal-emotion-recognition"
"cristinalunaj/MMEmotionRecognition" -> "TideDancer/interspeech21_emotion"
"b04901014/FT-w2v2-ser" -> "habla-liaa/ser-with-w2v2"
"b04901014/FT-w2v2-ser" -> "Vincent-ZHQ/CA-MSER"
"b04901014/FT-w2v2-ser" -> "lixiangucas01/GLAM"
"b04901014/FT-w2v2-ser" -> "AryaAftab/LIGHT-SERNET"
"b04901014/FT-w2v2-ser" -> "TideDancer/interspeech21_emotion"
"b04901014/FT-w2v2-ser" -> "Jiaxin-Ye/TIM-Net_SER"
"b04901014/FT-w2v2-ser" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"b04901014/FT-w2v2-ser" -> "Sreyan88/MMER"
"b04901014/FT-w2v2-ser" -> "shamanez/BERT-like-is-All-You-Need"
"b04901014/FT-w2v2-ser" -> "cristinalunaj/MMEmotionRecognition"
"b04901014/FT-w2v2-ser" -> "HappyColor/Vesper"
"b04901014/FT-w2v2-ser" -> "audeering/w2v2-how-to" ["e"=1]
"b04901014/FT-w2v2-ser" -> "m3hrdadfi/soxan"
"b04901014/FT-w2v2-ser" -> "glam-imperial/EmotionalConversionStarGAN" ["e"=1]
"rungjoo/CoMPM" -> "fpcsong/emotionflow"
"rungjoo/CoMPM" -> "rungjoo/Emotion_not_One"
"praveena2j/Cross-Attentional-AV-Fusion" -> "praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion"
"HITSZ-HLT/CMGCN" -> "less-and-less-bugs/HKEmodel"
"HITSZ-HLT/CMGCN" -> "JoeYing1019/MMSD2.0"
"HITSZ-HLT/CMGCN" -> "marvel2120/MsdBert"
"HITSZ-HLT/CMGCN" -> "TIAN-viola/DynRT"
"praveena2j/JointCrossAttentional-AV-Fusion" -> "praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion"
"lixiangucas01/GLAM" -> "lessonxmk/Optimized_attention_for_SER"
"lixiangucas01/GLAM" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"lixiangucas01/GLAM" -> "HappyColor/Vesper"
"lixiangucas01/GLAM" -> "AryaAftab/LIGHT-SERNET"
"EIHW/MuSe2022" -> "lstappen/MuSe2021"
"zhanxinrui/HDN" -> "nku-zhichengzhang/MPOT"
"thuiar/TFR-Net" -> "JaydenZeng/TATE"
"thuiar/TFR-Net" -> "sunlicai/EMT-DLFR"
"LeqsNaN/KEC" -> "circle-hit/KBCIN"
"LeqsNaN/KEC" -> "LeqsNaN/SKAIG-ERC"
"LeqsNaN/KEC" -> "NUSTM/SHARK"
"JaydenZeng/TATE" -> "JaydenZeng/EMMR"
"JaydenZeng/TATE" -> "sunlicai/EMT-DLFR"
"ictnlp/PLUVR" -> "libeineu/fairseq_mmt"
"libeineu/fairseq_mmt" -> "ictnlp/PLUVR"
"libeineu/fairseq_mmt" -> "LividWo/Revisit-MMT"
"libeineu/fairseq_mmt" -> "cooelf/UVR-NMT"
"saharmor/whisper-playground" -> "oliverguhr/wav2vec2-live" ["e"=1]
"AlibabaResearch/DAMO-ConvAI" -> "LeMei/UniMSE" ["e"=1]
"muzairkhattak/multimodal-prompt-learning" -> "YiLunLee/missing_aware_prompts" ["e"=1]
"linzhiqiu/cross_modal_adaptation" -> "YiLunLee/missing_aware_prompts" ["e"=1]
"huggingface/speechbox" -> "jonatasgrosman/huggingsound"
"huggingface/speechbox" -> "sanchit-gandhi/seq2seq-speech"
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Renovamen/Speech-Emotion-Recognition" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Vincent-ZHQ/CA-MSER" ["e"=1]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" -> "Jiaxin-Ye/TIM-Net_SER" ["e"=1]
"thuiar/ch-sims-v2" -> "thuiar/MMSA-FET"
"thuiar/ch-sims-v2" -> "Haoyu-ha/ALMT"
"thuiar/ch-sims-v2" -> "dingchaoyue/AcFormer"
"thuiar/ch-sims-v2" -> "XpastaX/ConFEDE"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "liyunfan1223/multimodal-sentiment-analysis"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "CodeREWorld/Multimodal-Sentiment-Analysis"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "thuiar/MMSA"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "cindyhu-cyber/Multimodal-Sentiment-Analysis"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "declare-lab/multimodal-deep-learning"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "soujanyaporia/multimodal-sentiment-analysis"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "Link-Li/CLMLF"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "NUSTM/VLP-MABSA"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "declare-lab/MISA"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "zehuiwu/MMML"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "Robin-WZQ/multimodal-emotion-recognition-DEMO"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "declare-lab/Multimodal-Infomax"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "thuiar/MMSA-FET"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "kitsch231/pytorch_fake_news_Classification_mml"
"YeexiaoZheng/Multimodal-Sentiment-Analysis" -> "Feuoy/sentiment-analysis" ["e"=1]
"yinruiqing/pyannote-whisper" -> "huggingface/speechbox" ["e"=1]
"Jiaxin-Ye/TIM-Net_SER" -> "Vincent-ZHQ/CA-MSER"
"Jiaxin-Ye/TIM-Net_SER" -> "AryaAftab/LIGHT-SERNET"
"Jiaxin-Ye/TIM-Net_SER" -> "scutcsq/DWFormer"
"Jiaxin-Ye/TIM-Net_SER" -> "b04901014/FT-w2v2-ser"
"Jiaxin-Ye/TIM-Net_SER" -> "Sreyan88/MMER"
"Jiaxin-Ye/TIM-Net_SER" -> "lixiangucas01/GLAM"
"Jiaxin-Ye/TIM-Net_SER" -> "JabuMlDev/Speaker-VGG-CCT"
"Jiaxin-Ye/TIM-Net_SER" -> "PiotrSobczak/speech-emotion-recognition"
"Jiaxin-Ye/TIM-Net_SER" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"Jiaxin-Ye/TIM-Net_SER" -> "Jiaxin-Ye/GM-TCNet"
"Jiaxin-Ye/TIM-Net_SER" -> "HappyColor/SpeechFormer"
"LeMei/UniMSE" -> "declare-lab/Multimodal-Infomax"
"LeMei/UniMSE" -> "thuiar/Self-MM"
"LeMei/UniMSE" -> "XpastaX/ConFEDE"
"LeMei/UniMSE" -> "zehuiwu/MMML"
"LeMei/UniMSE" -> "Haoyu-ha/ALMT"
"LeMei/UniMSE" -> "dawn0815/UniSA"
"LeMei/UniMSE" -> "declare-lab/MISA"
"LeMei/UniMSE" -> "thuiar/MMSA"
"LeMei/UniMSE" -> "thuiar/MMSA-FET"
"LeMei/UniMSE" -> "hujingwen6666/MMGCN"
"LeMei/UniMSE" -> "sunlicai/EMT-DLFR"
"LeMei/UniMSE" -> "Exploration-Lab/COGMEN"
"LeMei/UniMSE" -> "mdswyz/DMD"
"LeMei/UniMSE" -> "CMU-MultiComp-Lab/CMU-MultimodalSDK"
"LeMei/UniMSE" -> "declare-lab/BBFN"
"zeroQiaoba/GCNet" -> "zeroQiaoba/IRNet"
"zeroQiaoba/GCNet" -> "zeroQiaoba/ALIM"
"zeroQiaoba/GCNet" -> "mdswyz/DiCMoR"
"zeroQiaoba/GCNet" -> "mdswyz/IMDer"
"zeroQiaoba/GCNet" -> "ZhuoYulang/CIF-MMIN"
"zeroQiaoba/GCNet" -> "sunlicai/EMT-DLFR"
"zeroQiaoba/GCNet" -> "zeroQiaoba/gpt4v-emotion"
"scutcsq/DWFormer" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"scutcsq/DWFormer" -> "ECNU-Cross-Innovation-Lab/ENT"
"scutcsq/DWFormer" -> "HappyColor/DST"
"scutcsq/DWFormer" -> "ASolitaryMan/HFLEA"
"serycjon/WOFT" -> "zhanxinrui/HDN"
"HappyColor/DST" -> "scutcsq/DWFormer"
"shirayu/whispering" -> "oliverguhr/wav2vec2-live" ["e"=1]
"vyassu/DeepSentiment" -> "hcmlab/emovoice"
"vyassu/DeepSentiment" -> "eesungkim/Speech_Emotion_Recognition_DNN-ELM"
"vyassu/DeepSentiment" -> "MarioRuggieri/Emotion-Recognition-from-Speech"
"liyunfan1223/multimodal-sentiment-analysis" -> "GentleCold/multimodal_sentiment_analysis"
"liyunfan1223/multimodal-sentiment-analysis" -> "Linshou99/Multimodal-sentiment-analysis"
"liyunfan1223/multimodal-sentiment-analysis" -> "Iwhappy/MultiModal-Sentiment-Analysis"
"liyunfan1223/multimodal-sentiment-analysis" -> "YeexiaoZheng/Multimodal-Sentiment-Analysis"
"ChangdeDu/BraVL" -> "thomassutter/MoPoE" ["e"=1]
"kiva12138/CubeMLP" -> "XpastaX/ConFEDE"
"praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion" -> "praveena2j/JointCrossAttentional-AV-Fusion"
"praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion" -> "praveena2j/RJCMA"
"praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion" -> "praveena2j/Cross-Attentional-AV-Fusion"
"JaydenZeng/EMMR" -> "JaydenZeng/TATE"
"butterfliesss/SDT" -> "feiyuchen7/M3NET"
"butterfliesss/SDT" -> "TaoShi1998/MultiEMO"
"butterfliesss/SDT" -> "zerohd4869/MM-DFN"
"NUSTM/MECPE" -> "NUSTM/SemEval-2024_ECAC"
"NUSTM/MECPE" -> "LeqsNaN/KEC"
"yingqichao/fnd-bootstrap" -> "less-and-less-bugs/LogicMD" ["e"=1]
"kitsch231/pytorch_fake_news_Classification_mml" -> "woosual/multiModalityFusionForClassification"
"less-and-less-bugs/HKEmodel" -> "TIAN-viola/DynRT"
"less-and-less-bugs/HKEmodel" -> "HITSZ-HLT/CMGCN"
"less-and-less-bugs/HKEmodel" -> "downdric/MSD"
"less-and-less-bugs/HKEmodel" -> "less-and-less-bugs/LogicMD"
"less-and-less-bugs/HKEmodel" -> "ZLJ2015106/pytorch-multimodal_sarcasm_detection"
"less-and-less-bugs/HKEmodel" -> "JoeYing1019/MMSD2.0"
"less-and-less-bugs/HKEmodel" -> "marvel2120/MsdBert"
"HappyColor/SpeechFormer2" -> "HappyColor/SpeechFormer"
"caskcsg/SPCL" -> "fpcsong/emotionflow"
"caskcsg/SPCL" -> "somethingx678/TodKat"
"caskcsg/SPCL" -> "zerohd4869/SACL"
"caskcsg/SPCL" -> "zerohd4869/DialogueCRN"
"caskcsg/SPCL" -> "ShawX825/HiDialog"
"caskcsg/SPCL" -> "shenwzh3/DAG-ERC"
"caskcsg/SPCL" -> "zerohd4869/MM-DFN"
"caskcsg/SPCL" -> "rungjoo/CoMPM"
"khanld/Wav2vec2-Pretraining" -> "khanld/ASR-Wav2vec-Finetune"
"circle-hit/KBCIN" -> "LeqsNaN/KEC"
"nku-zhichengzhang/TSL300" -> "nku-zhichengzhang/MPOT"
"zeroQiaoba/MERTools" -> "zeroQiaoba/AffectGPT"
"zeroQiaoba/MERTools" -> "zeroQiaoba/gpt4v-emotion"
"zeroQiaoba/MERTools" -> "ZebangCheng/Emotion-LLaMA"
"zeroQiaoba/MERTools" -> "sunlicai/HiCMAE"
"zeroQiaoba/MERTools" -> "zeroQiaoba/GCNet"
"zeroQiaoba/MERTools" -> "mdswyz/DMD"
"zeroQiaoba/MERTools" -> "sunlicai/MAE-DFER" ["e"=1]
"zeroQiaoba/MERTools" -> "LeMei/UniMSE"
"zeroQiaoba/MERTools" -> "thuiar/ch-sims-v2"
"zeroQiaoba/MERTools" -> "butterfliesss/SDT"
"zeroQiaoba/MERTools" -> "thuiar/MMSA-FET"
"zeroQiaoba/MERTools" -> "thuiar/MMSA"
"zeroQiaoba/MERTools" -> "AIM3-RUC/RUCM3ED"
"zeroQiaoba/MERTools" -> "zerohd4869/MM-DFN"
"AIM3-RUC/MERC_Challenge_CCAC2023" -> "AIM3-RUC/RUCM3ED"
"AIM3-RUC/MERC_Challenge_CCAC2023" -> "NLPWM-WHU/MPLP"
"yxuansu/PandaGPT" -> "zeroQiaoba/AffectGPT" ["e"=1]
"nku-zhichengzhang/PlaneSeg" -> "nku-zhichengzhang/TSL300"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "pliang279/MultiBench"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "thuiar/MMSA-FET"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "thuiar/MMSA"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "zehuiwu/MMML"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "LeMei/UniMSE"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "pakoromilas/MultimodalSDK_loader"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "thuiar/Self-MM"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "yaohungt/Multimodal-Transformer"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "zeroQiaoba/MERTools"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "Justin1904/CMU-MultimodalSDK-Tutorials"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "declare-lab/Multimodal-Infomax"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "Haoyu-ha/ALMT"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "WasifurRahman/BERT_multimodal_transformer"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "declare-lab/multimodal-deep-learning"
"CMU-MultiComp-Lab/CMU-MultimodalSDK" -> "sunlicai/EMT-DLFR"
"pliang279/PID" -> "pliang279/FactorCL"
"scutcyr/SoulChat" -> "scutcyr/CPED" ["e"=1]
"vtuber-plan/langport" -> "FrostMiKu/Nole"
"vtuber-plan/langport" -> "zeroQiaoba/IRNet"
"YiLunLee/missing_aware_prompts" -> "deep-real/SMIL"
"YiLunLee/missing_aware_prompts" -> "billhhh/ShaSpec"
"YiLunLee/missing_aware_prompts" -> "Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" ["e"=1]
"YiLunLee/missing_aware_prompts" -> "Haoyu-ha/LNLN"
"YiLunLee/missing_aware_prompts" -> "AIM3-RUC/MMIN"
"YiLunLee/missing_aware_prompts" -> "zrguo/MPLMM"
"YiLunLee/missing_aware_prompts" -> "QingyangZhang/QMF" ["e"=1]
"YiLunLee/missing_aware_prompts" -> "muzairkhattak/multimodal-prompt-learning" ["e"=1]
"YiLunLee/missing_aware_prompts" -> "JaydenZeng/TATE"
"YiLunLee/missing_aware_prompts" -> "shicaiwei123/MMANet-CVPR2023"
"zengqunzhao/DFER-CLIP" -> "NickyFot/EmoCLIP" ["e"=1]
"LIN-SHANG/InstructERC" -> "butterfliesss/SDT"
"LIN-SHANG/InstructERC" -> "caskcsg/SPCL"
"LIN-SHANG/InstructERC" -> "NUSTM/FacialMMT"
"LIN-SHANG/InstructERC" -> "zerohd4869/SACL"
"LIN-SHANG/InstructERC" -> "yingjie7/BiosERC"
"LIN-SHANG/InstructERC" -> "tae898/erc"
"LIN-SHANG/InstructERC" -> "leson502/CORECT_EMNLP2023"
"LIN-SHANG/InstructERC" -> "AIM3-RUC/RUCM3ED"
"sunlicai/EMT-DLFR" -> "JaydenZeng/TATE"
"sunlicai/EMT-DLFR" -> "thuiar/TFR-Net"
"sunlicai/EMT-DLFR" -> "YetZzzzzz/GLoMo"
"sunlicai/EMT-DLFR" -> "JackAILab/TMBL"
"sunlicai/EMT-DLFR" -> "Say2L/CENet"
"Vaibhavs10/fast-whisper-finetuning" -> "huggingface/speechbox" ["e"=1]
"Vaibhavs10/fast-whisper-finetuning" -> "jonatasgrosman/wav2vec2-sprint" ["e"=1]
"zeroQiaoba/AffectGPT" -> "zeroQiaoba/MERTools"
"zeroQiaoba/AffectGPT" -> "ZebangCheng/Emotion-LLaMA"
"zeroQiaoba/AffectGPT" -> "zeroQiaoba/gpt4v-emotion"
"zeroQiaoba/AffectGPT" -> "zeroQiaoba/GCNet"
"zeroQiaoba/AffectGPT" -> "zeroQiaoba/IRNet"
"zeroQiaoba/AffectGPT" -> "MIPS-COLT/MER-MCE"
"zeroQiaoba/AffectGPT" -> "AIM3-RUC/RUCM3ED"
"zeroQiaoba/AffectGPT" -> "JackYFL/EmoLA"
"zeroQiaoba/AffectGPT" -> "sunlicai/HiCMAE"
"zeroQiaoba/AffectGPT" -> "sunlicai/MAE-DFER" ["e"=1]
"kdhht2334/awesome-SOTA-FER" -> "NickyFot/EmoCLIP" ["e"=1]
"zeroQiaoba/ALIM" -> "zeroQiaoba/IRNet"
"sunlicai/MAE-DFER" -> "sunlicai/HiCMAE" ["e"=1]
"sunlicai/MAE-DFER" -> "zeroQiaoba/gpt4v-emotion" ["e"=1]
"sunlicai/MAE-DFER" -> "zeroQiaoba/MERTools" ["e"=1]
"dawn0815/SAEval-Benchmark" -> "dawn0815/UniSA"
"dawn0815/UniSA" -> "dawn0815/SAEval-Benchmark"
"dawn0815/UniSA" -> "RecklessRonan/MuSE"
"SilyRab/AoM" -> "NUSTM/HIMT"
"XpastaX/ConFEDE" -> "Haoyu-ha/ALMT"
"XpastaX/ConFEDE" -> "dingchaoyue/AcFormer"
"XpastaX/ConFEDE" -> "LeMei/UniMSE"
"XpastaX/ConFEDE" -> "kiva12138/CubeMLP"
"XpastaX/ConFEDE" -> "Haoyu-ha/LNLN"
"NUSTM/SemEval-2024_ECAC" -> "NUSTM/MECPE"
"zehuiwu/MMML" -> "LeMei/UniMSE"
"zehuiwu/MMML" -> "Haoyu-ha/ALMT"
"zehuiwu/MMML" -> "MKMaS-GUET/KuDA"
"zehuiwu/MMML" -> "AZYoung233/CLGSI"
"zehuiwu/MMML" -> "XpastaX/ConFEDE"
"feiyuchen7/M3NET" -> "butterfliesss/SDT"
"MCG-NKU/AMT" -> "downdric/MSD" ["e"=1]
"mdswyz/DMD" -> "mdswyz/DiCMoR"
"mdswyz/DMD" -> "declare-lab/MISA"
"mdswyz/DMD" -> "butterfliesss/SDT"
"mdswyz/DMD" -> "mdswyz/IMDer"
"mdswyz/DMD" -> "zeroQiaoba/MERTools"
"mdswyz/DMD" -> "thuiar/Self-MM"
"mdswyz/DMD" -> "sunlicai/EMT-DLFR"
"mdswyz/DMD" -> "Haoyu-ha/ALMT"
"mdswyz/DMD" -> "declare-lab/MSA-Robustness"
"mdswyz/DMD" -> "LeMei/UniMSE"
"hcmlab/nova" -> "hcmlab/ssi"
"ECNU-Cross-Innovation-Lab/ShiftSER" -> "scutcsq/DWFormer"
"ECNU-Cross-Innovation-Lab/ShiftSER" -> "ECNU-Cross-Innovation-Lab/ENT"
"ECNU-Cross-Innovation-Lab/ShiftSER" -> "HappyColor/Vesper"
"ECNU-Cross-Innovation-Lab/ShiftSER" -> "lixiangucas01/GLAM"
"TIAN-viola/DynRT" -> "less-and-less-bugs/HKEmodel"
"TIAN-viola/DynRT" -> "downdric/MSD"
"TIAN-viola/DynRT" -> "JoeYing1019/MMSD2.0"
"shicaiwei123/MMANet-CVPR2023" -> "shicaiwei123/ECCV2024-DMRNet"
"downdric/MSD" -> "TIAN-viola/DynRT"
"downdric/MSD" -> "less-and-less-bugs/HKEmodel"
"downdric/MSD" -> "JoeYing1019/MMSD2.0"
"NUSTM/FacialMMT" -> "TaoShi1998/MultiEMO"
"NUSTM/FacialMMT" -> "Yu-Fangxu/EACL"
"mdswyz/IMDer" -> "mdswyz/DiCMoR"
"mdswyz/IMDer" -> "ZhuoYulang/CIF-MMIN"
"mdswyz/IMDer" -> "chengzju/CARAT"
"mdswyz/IMDer" -> "Haoyu-ha/LNLN"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/WDCNMT"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/ABD-NMT"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/MNMT"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/Pairwise"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/IRSEG"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/Structure-Self-Aware"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/RRWEL"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/IMM"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/VarNDRR"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/CG-RL"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/CG-ASED"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/GMNMT"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/multisource_cg_md"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/DCCN"
"DeepLearnXMU/VNMT" -> "DeepLearnXMU/embedding-transfer"
"nku-zhichengzhang/CTEN" -> "nku-zhichengzhang/TSL300"
"nku-zhichengzhang/CTEN" -> "maysonma/VAANet"
"nku-zhichengzhang/CTEN" -> "nku-zhichengzhang/MART"
"HappyColor/Vesper" -> "ECNU-Cross-Innovation-Lab/ENT"
"HappyColor/Vesper" -> "ECNU-Cross-Innovation-Lab/ShiftSER"
"HappyColor/Vesper" -> "HappyColor/SpeechFormer"
"DeepLearnXMU/VarNDRR" -> "DeepLearnXMU/Pairwise"
"vladimir-chernykh/emotion_recognition" -> "sterling239/audio-emotion-recognition"
"JoeYing1019/MMSD2.0" -> "TIAN-viola/DynRT"
"JoeYing1019/MMSD2.0" -> "HITSZ-HLT/CMGCN"
"zeroQiaoba/IRNet" -> "zeroQiaoba/ALIM"
"nku-zhichengzhang/MPOT" -> "nku-zhichengzhang/TSL300"
"mdswyz/DiCMoR" -> "ZhuoYulang/CIF-MMIN"
"ASolitaryMan/HFLEA" -> "ECNU-Cross-Innovation-Lab/ENT"
"ZhuoYulang/CIF-MMIN" -> "mdswyz/DiCMoR"
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" -> "Haoyu-ha/LNLN" ["e"=1]
"leson502/CORECT_EMNLP2023" -> "feiyuchen7/M3NET"
"FrostMiKu/Nole" -> "zeroQiaoba/IRNet"
"SenticNet/personality-detection" -> "declare-lab/MELD" ["e"=1]
"han-liu/awesome-missing-modality-for-medical-images" -> "shicaiwei123/MMANet-CVPR2023"
"sunlicai/HiCMAE" -> "sunlicai/MAE-DFER" ["e"=1]
"sunlicai/HiCMAE" -> "zeroQiaoba/gpt4v-emotion"
"sunlicai/HiCMAE" -> "zeroQiaoba/MERTools"
"Haoyu-ha/ALMT" -> "XpastaX/ConFEDE"
"Haoyu-ha/ALMT" -> "Haoyu-ha/LNLN"
"Haoyu-ha/ALMT" -> "JackAILab/TMBL"
"Haoyu-ha/ALMT" -> "MKMaS-GUET/KuDA"
"Haoyu-ha/ALMT" -> "LeMei/UniMSE"
"Haoyu-ha/ALMT" -> "zehuiwu/MMML"
"Haoyu-ha/ALMT" -> "sunlicai/EMT-DLFR"
"Haoyu-ha/ALMT" -> "dingchaoyue/AcFormer"
"Haoyu-ha/ALMT" -> "thuiar/ch-sims-v2"
"TaoShi1998/MultiEMO" -> "TaoShi1998/SSLCL"
"TaoShi1998/MultiEMO" -> "butterfliesss/SDT"
"TaoShi1998/MultiEMO" -> "feiyuchen7/M3NET"
"TaoShi1998/MultiEMO" -> "zerohd4869/MM-DFN"
"TaoShi1998/MultiEMO" -> "NUSTM/FacialMMT"
"zeroQiaoba/gpt4v-emotion" -> "zeroQiaoba/MERTools"
"zeroQiaoba/gpt4v-emotion" -> "zeroQiaoba/AffectGPT"
"zeroQiaoba/gpt4v-emotion" -> "sunlicai/HiCMAE"
"zeroQiaoba/gpt4v-emotion" -> "sunlicai/MAE-DFER" ["e"=1]
"zeroQiaoba/gpt4v-emotion" -> "zeroQiaoba/GCNet"
"zeroQiaoba/gpt4v-emotion" -> "zeroQiaoba/IRNet"
"Iwhappy/MultiModal-Sentiment-Analysis" -> "GentleCold/multimodal_sentiment_analysis"
"zrguo/MPLMM" -> "Haoyu-ha/LNLN"
"zrguo/MPLMM" -> "sunlicai/EMT-DLFR"
"zrguo/MPLMM" -> "JaydenZeng/TATE"
"zrguo/MPLMM" -> "XpastaX/ConFEDE"
"zrguo/MPLMM" -> "ZhuoYulang/CIF-MMIN"
"ZebangCheng/Emotion-LLaMA" -> "zeroQiaoba/AffectGPT"
"ZebangCheng/Emotion-LLaMA" -> "zeroQiaoba/MERTools"
"ZebangCheng/Emotion-LLaMA" -> "sunlicai/HiCMAE"
"ZebangCheng/Emotion-LLaMA" -> "zeroQiaoba/gpt4v-emotion"
"ZebangCheng/Emotion-LLaMA" -> "lzw108/EmoLLMs" ["e"=1]
"ZebangCheng/Emotion-LLaMA" -> "mdswyz/DMD"
"ZebangCheng/Emotion-LLaMA" -> "sunlicai/MAE-DFER" ["e"=1]
"ZebangCheng/Emotion-LLaMA" -> "MIPS-COLT/MER-MCE"
"ZebangCheng/Emotion-LLaMA" -> "MC-EIU/MC-EIU" ["e"=1]
"ZebangCheng/Emotion-LLaMA" -> "thuhcsi/SECap" ["e"=1]
"ZebangCheng/Emotion-LLaMA" -> "aimmemotion/EmoVIT"
"ZebangCheng/Emotion-LLaMA" -> "JackYFL/EmoLA"
"ZebangCheng/Emotion-LLaMA" -> "Lum1104/EIBench"
"amoudgl/short-jokes-dataset" -> "amoudgl/funnybot"
"amoudgl/short-jokes-dataset" -> "taivop/joke-dataset"
"amoudgl/short-jokes-dataset" -> "CrowdTruth/Short-Text-Corpus-For-Humor-Detection"
"amoudgl/short-jokes-dataset" -> "orionw/RedditHumorDetection"
"taivop/joke-dataset" -> "amoudgl/short-jokes-dataset"
"taivop/joke-dataset" -> "liuhuanyong/ChineseHumorSentiment"
"taivop/joke-dataset" -> "CrowdTruth/Short-Text-Corpus-For-Humor-Detection"
"taivop/joke-dataset" -> "orionw/rJokesData"
"taivop/joke-dataset" -> "ROC-HCI/UR-FUNNY"
"taivop/joke-dataset" -> "openai/requests-for-research" ["e"=1]
"taivop/joke-dataset" -> "amoudgl/funnybot"
"taivop/joke-dataset" -> "codekansas/seqgan-text-tensorflow" ["e"=1]
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "soujanyaporia/multimodal-sentiment-analysis"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "roshansridhar/Multimodal-Sentiment-Analysis"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "HaohanWang/SelectAdditiveLearning"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "Justin1904/TensorFusionNetworks"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "soujanyaporia/contextual-multimodal-fusion"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "A2Zadeh/TensorFusionNetwork"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "hainow/MCTN"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "declare-lab/hfusion"
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" -> "A2Zadeh/CMU-MultimodalSDK"
"hcmlab/ssi" -> "hcmlab/emovoice"
"Haoyu-ha/LNLN" -> "zrguo/MPLMM"
"Haoyu-ha/LNLN" -> "Haoyu-ha/ALMT"
"Haoyu-ha/LNLN" -> "pwang322/DLF"
"Haoyu-ha/LNLN" -> "MKMaS-GUET/KuDA"
"kittenish/Frame-Transformer-Network" -> "ivyha010/emotionprediction"
"atulapra/Emotion-detection" -> "maelfabien/Multimodal-Emotion-Recognition" ["e"=1]
"HumanMLLM/R1-Omni" -> "ZebangCheng/Emotion-LLaMA" ["e"=1]
"HumanMLLM/R1-Omni" -> "zeroQiaoba/AffectGPT" ["e"=1]
"A2Zadeh/CMU-MultimodalSDK" -> "yaohungt/Multimodal-Transformer"
"A2Zadeh/CMU-MultimodalSDK" -> "soujanyaporia/multimodal-sentiment-analysis"
"A2Zadeh/CMU-MultimodalSDK" -> "Justin1904/TensorFusionNetworks"
"A2Zadeh/CMU-MultimodalSDK" -> "declare-lab/multimodal-deep-learning"
"A2Zadeh/CMU-MultimodalSDK" -> "WasifurRahman/BERT_multimodal_transformer"
"A2Zadeh/CMU-MultimodalSDK" -> "declare-lab/MISA"
"A2Zadeh/CMU-MultimodalSDK" -> "thuiar/MMSA"
"A2Zadeh/CMU-MultimodalSDK" -> "pliang279/MFN"
"A2Zadeh/CMU-MultimodalSDK" -> "declare-lab/MELD"
"A2Zadeh/CMU-MultimodalSDK" -> "thuiar/Self-MM"
"A2Zadeh/CMU-MultimodalSDK" -> "Justin1904/CMU-MultimodalSDK-Tutorials"
"A2Zadeh/CMU-MultimodalSDK" -> "declare-lab/contextual-utterance-level-multimodal-sentiment-analysis"
"A2Zadeh/CMU-MultimodalSDK" -> "victorywys/RAVEN"
"A2Zadeh/CMU-MultimodalSDK" -> "pliang279/MultiBench"
"A2Zadeh/CMU-MultimodalSDK" -> "declare-lab/conv-emotion"
"tzirakis/Multimodal-Emotion-Recognition" -> "end2you/end2you" ["e"=1]
"tzirakis/Multimodal-Emotion-Recognition" -> "katerynaCh/multimodal-emotion-recognition"
"tzirakis/Multimodal-Emotion-Recognition" -> "wenliangdai/Multimodal-End2end-Sparse"
"tzirakis/Multimodal-Emotion-Recognition" -> "Demfier/multimodal-speech-emotion-recognition"
"tzirakis/Multimodal-Emotion-Recognition" -> "david-yoon/multimodal-speech-emotion"
"tzirakis/Multimodal-Emotion-Recognition" -> "maelfabien/Multimodal-Emotion-Recognition"
"tzirakis/Multimodal-Emotion-Recognition" -> "zeroQiaoba/EmotiW2018" ["e"=1]
"tzirakis/Multimodal-Emotion-Recognition" -> "ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION"
"tzirakis/Multimodal-Emotion-Recognition" -> "EvelynFan/AWESOME-MER"
"tzirakis/Multimodal-Emotion-Recognition" -> "wenliangdai/Modality-Transferable-MER"
"tzirakis/Multimodal-Emotion-Recognition" -> "shamanez/Self-Supervised-Embedding-Fusion-Transformer"
"tzirakis/Multimodal-Emotion-Recognition" -> "declare-lab/MELD"
"tzirakis/Multimodal-Emotion-Recognition" -> "soujanyaporia/multimodal-sentiment-analysis"
"tzirakis/Multimodal-Emotion-Recognition" -> "asfathermou/human-computer-interaction"
"tzirakis/Multimodal-Emotion-Recognition" -> "MultimodalAffectiveComputing/FV2ES"
"HumanMLLM/HumanOmni" -> "zeroQiaoba/AffectGPT" ["e"=1]
"rkosti/emotic" -> "Tandon-A/emotic"
"rkosti/emotic" -> "ndkhanh360/CAER"
"rkosti/emotic" -> "EvelynFan/AWESOME-MER"
"ebadawy/EmotiW2017" -> "LW-Ricarido/Emotion_SDK" ["e"=1]
"pwang322/DLF" -> "Haoyu-ha/LNLN"
"pwang322/DLF" -> "zrguo/CASP"
"pwang322/DLF" -> "MKMaS-GUET/KuDA"
"hcmlab/emovoice" -> "hcmlab/ssi"
"hcmlab/emovoice" -> "vyassu/DeepSentiment"
"x4nth055/pythoncode-tutorials" ["l"="-47.392,-27.604", "c"=97]
"x4nth055/emotion-recognition-using-speech" ["l"="56.827,27.968"]
"sherleens/EmotionDistributionLearning" ["l"="56.81,27.702"]
"lucinda-lim/Image-Emotion-Classification" ["l"="56.79,27.727"]
"akhileshydv/Dependency-Exploitation-A-Unified-CNN-RNN-Approach-for-Visual-Emotion-Recognition" ["l"="56.819,27.684"]
"maelfabien/Multimodal-Emotion-Recognition" ["l"="56.74,27.996"]
"tzirakis/Multimodal-Emotion-Recognition" ["l"="56.751,27.984"]
"Demfier/multimodal-speech-emotion-recognition" ["l"="56.819,27.981"]
"otaha178/Emotion-recognition" ["l"="56.042,27.294", "c"=486]
"declare-lab/MELD" ["l"="56.668,28.03"]
"david-yoon/multimodal-speech-emotion" ["l"="56.812,27.965"]
"declare-lab/multimodal-deep-learning" ["l"="56.62,28.026"]
"atulapra/Emotion-detection" ["l"="56.018,27.316", "c"=486]
"thuiar/MMSA" ["l"="56.601,28.035"]
"soujanyaporia/multimodal-sentiment-analysis" ["l"="56.637,28.009"]
"declare-lab/conv-emotion" ["l"="56.695,28.033"]
"katerynaCh/multimodal-emotion-recognition" ["l"="56.788,28.005"]
"ankurbhatia24/MULTIMODAL-EMOTION-RECOGNITION" ["l"="56.734,27.934"]
"A2Zadeh/CMU-MultimodalSDK" ["l"="56.618,28.005"]
"Renovamen/Speech-Emotion-Recognition" ["l"="56.834,27.996"]
"declare-lab/awesome-emotion-recognition-in-conversations" ["l"="56.649,28.101"]
"declare-lab/RECCON" ["l"="56.882,28.924", "c"=310]
"yaohungt/Multimodal-Transformer" ["l"="56.603,28.018"]
"facebookresearch/EmpatheticDialogues" ["l"="56.796,28.959", "c"=310]
"declare-lab/dialogue-understanding" ["l"="56.925,28.938", "c"=310]
"soujanyaporia/MUStARD" ["l"="56.62,28.053"]
"shenwzh3/DAG-ERC" ["l"="56.645,28.159"]
"xunan0812/MIMN" ["l"="56.702,28.093"]
"PreferredAI/vista-net" ["l"="56.717,28.104"]
"jefferyYu/TomBERT" ["l"="56.699,28.071"]
"headacheboy/data-of-multimodal-sarcasm-detection" ["l"="56.658,28.09"]
"xunan0812/MultiSentiNet" ["l"="56.737,28.108"]
"pliang279/awesome-multimodal-ml" ["l"="48.592,32.051", "c"=300]
"xuanjihe/speech-emotion-recognition" ["l"="56.848,27.956"]
"hkveeranki/speech-emotion-recognition" ["l"="56.831,27.954"]
"MiteshPuthran/Speech-Emotion-Analyzer" ["l"="56.792,27.969"]
"RayanWang/Speech_emotion_recognition_BLSTM" ["l"="56.841,27.975"]
"marcogdepinto/emotion-classification-from-audio-files" ["l"="56.817,27.943"]
"amanbasu/speech-emotion-recognition" ["l"="56.852,27.968"]
"SuyashMore/MevonAI-Speech-Emotion-Recognition" ["l"="56.89,27.887"]
"SuperKogito/SER-datasets" ["l"="56.893,27.99"]
"b04901014/FT-w2v2-ser" ["l"="56.913,27.975"]
"PiotrSobczak/speech-emotion-recognition" ["l"="56.856,27.938"]
"IliaZenkov/transformer-cnn-emotion-recognition" ["l"="56.879,27.978"]
"rezachu/emotion_recognition_cnn" ["l"="56.792,27.907"]
"crhung/Voice-Emotion-Detector" ["l"="56.771,27.928"]
"aris-ai/Audio-and-text-based-emotion-recognition" ["l"="56.872,27.955"]
"shamanez/BERT-like-is-All-You-Need" ["l"="56.863,27.978"]
"Samarth-Tripathi/IEMOCAP-Emotion-Detection" ["l"="56.839,27.936"]
"habla-liaa/ser-with-w2v2" ["l"="56.914,27.988"]
"yeyupiaoling/SpeechEmotionRecognition-Pytorch" ["l"="39.546,5.349", "c"=593]
"Jiaxin-Ye/TIM-Net_SER" ["l"="56.923,27.949"]
"zlzhang1124/AcousticFeatureExtraction" ["l"="56.876,28.035"]
"ddlBoJack/emotion2vec" ["l"="38.422,2.038", "c"=54]
"Vincent-ZHQ/CA-MSER" ["l"="56.919,27.965"]
"hotelll/speech-emotion-recognition" ["l"="56.892,27.948"]
"yingdajun/SpeechEmotionAndPeopleAnalyse" ["l"="39.467,5.312", "c"=593]
"savoirfairelinux/num2words" ["l"="35.733,2.418", "c"=308]
"jonatasgrosman/huggingsound" ["l"="57.1,27.975"]
"eesungkim/Speech_Emotion_Recognition_DNN-ELM" ["l"="56.858,27.989"]
"MarioRuggieri/Emotion-Recognition-from-Speech" ["l"="56.859,28"]
"tzaiyang/SpeechEmoRec" ["l"="56.817,27.924"]
"vandana-rajan/1D-Speech-Emotion-Recognition" ["l"="56.872,27.943"]
"vladimir-chernykh/emotion_recognition" ["l"="56.849,28.03"]
"thoughtworksarts/EmoPy" ["l"="56.057,27.309", "c"=486]
"seth814/Audio-Classification" ["l"="39.668,5.325", "c"=593]
"david-yoon/attentive-modality-hopping-for-SER" ["l"="56.842,27.907"]
"mmakiuchi/multimodal_emotion_recognition" ["l"="56.851,27.921"]
"PreferredAI/cornac" ["l"="59.469,23.675", "c"=235]
"PreferredAI/tutorials" ["l"="56.791,28.181"]
"covarep/covarep" ["l"="37.194,2.163", "c"=117]
"thuiar/Cross-Modal-BERT" ["l"="56.598,28.054"]
"declare-lab/MISA" ["l"="56.58,28.018"]
"WasifurRahman/BERT_multimodal_transformer" ["l"="56.588,28.008"]
"thuiar/Self-MM" ["l"="56.574,28.03"]
"pliang279/MultiBench" ["l"="56.58,28.053"]
"Justin1904/Low-rank-Multimodal-Fusion" ["l"="56.587,27.983"]
"pliang279/MFN" ["l"="56.577,27.998"]
"Justin1904/TensorFusionNetworks" ["l"="56.604,27.996"]
"declare-lab/Multimodal-Infomax" ["l"="56.584,28.028"]
"LeMei/UniMSE" ["l"="56.567,28.046"]
"thuiar/MMSA-FET" ["l"="56.561,28.024"]
"CMU-MultiComp-Lab/CMU-MultimodalSDK" ["l"="56.557,28.035"]
"ShaheenPerveen/speech-emotion-recognition-iemocap" ["l"="56.875,27.906"]
"petercunha/Emotion" ["l"="55.992,27.307", "c"=486]
"pliang279/factorized" ["l"="56.535,27.953"]
"TmacMai/ARGF_multimodal_fusion" ["l"="56.563,27.926"]
"jiajiatang0000/HPFN" ["l"="56.573,27.944"]
"soujanyaporia/contextual-multimodal-fusion" ["l"="56.618,27.956"]
"CheyneyComputerScience/CREMA-D" ["l"="31.904,30.466", "c"=297]
"hujingwen6666/MMGCN" ["l"="56.604,28.085"]
"Eurus-Holmes/Awesome-Multimodal-Research" ["l"="48.677,32.034", "c"=300]
"wxjiao/HiGRUs" ["l"="56.681,28.161"]
"wxjiao/AGHMN" ["l"="56.658,28.181"]
"wxjiao/Pre-CODE" ["l"="56.695,28.185"]
"declare-lab/contextual-utterance-level-multimodal-sentiment-analysis" ["l"="56.605,27.969"]
"declare-lab/hfusion" ["l"="56.634,27.961"]
"CodeREWorld/Multimodal-Sentiment-Analysis" ["l"="56.672,27.964"]
"declare-lab/BBFN" ["l"="56.567,28.01"]
"victorywys/RAVEN" ["l"="56.564,27.97"]
"thuiar/AWESOME-MSA" ["l"="56.559,28.001"]
"end2you/end2you" ["l"="37.173,2.033", "c"=117]
"ihpdep/LDES" ["l"="56.703,27.606"]
"zhanxinrui/HDN" ["l"="56.715,27.638"]
"zhan-xu/CFNN" ["l"="56.699,27.585"]
"594422814/UDT" ["l"="54.65,33.642", "c"=298]
"ROC-HCI/UR-FUNNY" ["l"="56.576,28.066"]
"cfiltnlp/MUStARD_Plus_Plus" ["l"="56.639,28.073"]
"zerohd4869/MM-DFN" ["l"="56.615,28.104"]
"cnunlp/Chinese-Simile-Recognition-Dataset" ["l"="56.326,28.463"]
"mrzjy/writing-polishment-with-simile" ["l"="56.315,28.483"]
"DeepLearnXMU/Cyclic" ["l"="56.298,28.512"]
"asfathermou/human-computer-interaction" ["l"="56.712,27.965"]
"Robin-WZQ/multimodal-emotion-recognition-DEMO" ["l"="56.717,27.949"]
"KrishnaDN/speech-emotion-recognition-using-self-attention" ["l"="56.866,27.926"]
"Chien-Hung/Speech-Emotion-Recognition" ["l"="56.886,27.921"]
"Data-Science-kosta/Speech-Emotion-Classification-with-PyTorch" ["l"="56.895,27.966"]
"mkosaka1/Speech_Emotion_Recognition" ["l"="56.856,27.896"]
"mhw32/multimodal-vae-public" ["l"="56.492,27.872"]
"iffsid/mmvae" ["l"="56.465,27.866"]
"seqam-lab/DMVAE" ["l"="56.472,27.842"]
"thomassutter/MoPoE" ["l"="56.483,27.85"]
"ztangent/multimodal-dmm" ["l"="56.502,27.845"]
"RicardoP0/Speech2dCNN_LSTM" ["l"="56.878,27.988"]
"praweshd/speech_emotion_recognition" ["l"="56.9,27.907"]
"vyassu/DeepSentiment" ["l"="56.893,28.026"]
"flaviorainhoavila/IEMOCAPspeechEmotionRecognition" ["l"="56.835,27.921"]
"yihong-chen/DREAM" ["l"="56.856,28.325"]
"RandolphVI/Next-Basket-Recommendation" ["l"="56.835,28.295"]
"A2Zadeh/Factorized-Multimodal-Transformer" ["l"="56.55,27.945"]
"hainow/MCTN" ["l"="56.537,27.984"]
"wrk226/pytorch-multimodal_sarcasm_detection" ["l"="56.682,28.093"]
"less-and-less-bugs/HKEmodel" ["l"="56.688,28.13"]
"JoeYing1019/MMSD2.0" ["l"="56.679,28.11"]
"HITSZ-HLT/CMGCN" ["l"="56.695,28.114"]
"marvel2120/MsdBert" ["l"="56.703,28.124"]
"TIAN-viola/DynRT" ["l"="56.681,28.12"]
"YangXiaocui1215/MVAN" ["l"="56.672,28.061"]
"ZLJ2015106/pytorch-multimodal_sarcasm_detection" ["l"="56.665,28.118"]
"Link-Li/CLMLF" ["l"="56.679,28.019"]
"downdric/MSD" ["l"="56.671,28.128"]
"HaojiHu/Sets2Sets" ["l"="56.821,28.256"]
"HaojiHu/TIFUKNN" ["l"="56.844,28.281"]
"PreferredAI/beacon" ["l"="56.775,28.183"]
"PreferredAI/mp-simrank" ["l"="56.763,28.161"]
"PreferredAI/cerebro" ["l"="56.777,28.164"]
"PreferredAI/recommendation-retrieval" ["l"="56.771,28.171"]
"PreferredAI/mrg" ["l"="56.771,28.153"]
"PreferredAI/venom" ["l"="56.761,28.181"]
"PreferredAI/venom-tutorial" ["l"="56.758,28.151"]
"PreferredAI/venom-examples" ["l"="56.76,28.17"]
"PreferredAI/compare-lda" ["l"="56.75,28.161"]
"PreferredAI/cbs" ["l"="56.75,28.154"]
"PreferredAI/vs-cnn" ["l"="56.744,28.174"]
"lipiji/NRT-theano" ["l"="56.8,28.156"]
"A2Zadeh/TensorFusionNetwork" ["l"="56.588,27.923"]
"akhil2495/multi-modal-emotion-recognition" ["l"="56.827,27.902"]
"batikim09/LIVE_SER" ["l"="56.828,27.877"]
"A2Zadeh/MFN" ["l"="56.588,27.896"]
"A2Zadeh/MARN" ["l"="56.576,27.896"]
"Justin1904/CMU-MultimodalSDK-Tutorials" ["l"="56.563,27.983"]
"YJango/speech-emotion-recognition-exercise" ["l"="56.885,27.861"]
"lmingde/speech-emotion-recognition-exercise" ["l"="56.895,27.837"]
"AIM3-RUC/MMIN" ["l"="56.498,27.983"]
"JaydenZeng/TATE" ["l"="56.491,27.996"]
"thuiar/TFR-Net" ["l"="56.516,28.004"]
"GussailRaat/EMNLP-18-MMMU-BA" ["l"="56.624,27.929"]
"RedHenLab/multi-modal-emotion-prediction" ["l"="56.827,27.845"]
"rajamohanharesh/Emotion-Recognition" ["l"="56.79,27.869"]
"liuhuanyong/ChineseHumorSentiment" ["l"="56.448,28.264"]
"qingbonlp/qingbo_CCL2019-Chinese-Humor-Computation" ["l"="56.432,28.29"]
"pln-fing-udelar/pghumor" ["l"="52.439,27.27", "c"=60]
"orionw/RedditHumorDetection" ["l"="56.491,28.208"]
"Moradnejad/ColBERT-Using-BERT-Sentence-Embedding-for-Humor-Detection" ["l"="56.478,28.244"]
"DUTIR-Emotion-Group/CCL2018-Chinese-Metaphor-Analysis" ["l"="56.397,28.344"]
"sherleens/WSCNet" ["l"="56.773,27.734"]
"Jie-su/WSCNet" ["l"="56.768,27.717"]
"multi30k/dataset" ["l"="56.211,28.644"]
"libeineu/fairseq_mmt" ["l"="56.204,28.676"]
"iacercalixto/MultimodalNMT" ["l"="56.174,28.656"]
"cooelf/UVR-NMT" ["l"="56.19,28.664"]
"ZihengZZH/awesome-multimodal-machine-translation" ["l"="56.233,28.66"]
"DeepLearnXMU/DCCN" ["l"="56.247,28.595"]
"A2Zadeh/CE-CLM" ["l"="56.576,27.871"]
"ruidan/IMN-E2E-ABSA" ["l"="54.211,28.152", "c"=707]
"DeepLearnXMU/PSSAttention" ["l"="56.278,28.581"]
"iacercalixto/variational_mmt" ["l"="56.176,28.644"]
"Eurus-Holmes/MNMT" ["l"="51.251,27.528", "c"=104]
"nlab-mpg/Flickr30kEnt-JP" ["l"="56.15,28.665"]
"MengtingWan/grocery" ["l"="56.868,28.291"]
"JimLiu96/MITGNN" ["l"="56.889,28.304"]
"DeepLearnXMU/RRWEL" ["l"="56.265,28.586"]
"DeepLearnXMU/WDCNMT" ["l"="56.257,28.578"]
"DeepLearnXMU/DAMAML" ["l"="56.274,28.589"]
"DeepLearnXMU/ABD-NMT" ["l"="56.261,28.562"]
"DeepLearnXMU/VNMT" ["l"="56.267,28.573"]
"DeepLearnXMU/IMM" ["l"="56.282,28.564"]
"DeepLearnXMU/VarNDRR" ["l"="56.248,28.563"]
"DeepLearnXMU/MNMT" ["l"="56.292,28.593"]
"DeepLearnXMU/CG-ASED" ["l"="56.275,28.567"]
"DeepLearnXMU/multisource_cg_md" ["l"="56.281,28.572"]
"DeepLearnXMU/Pairwise" ["l"="56.272,28.558"]
"DeepLearnXMU/GMNMT" ["l"="56.244,28.573"]
"DeepLearnXMU/embedding-transfer" ["l"="56.284,28.591"]
"DeepLearnXMU/Otem-Utem" ["l"="56.275,28.6"]
"DeepLearnXMU/Structure-Self-Aware" ["l"="56.262,28.595"]
"DeepLearnXMU/CG-RL" ["l"="56.295,28.573"]
"DeepLearnXMU/NSEG" ["l"="56.294,28.582"]
"DeepLearnXMU/IRSEG" ["l"="56.245,28.583"]
"DeepLearnXMU/ABDNMT-RNMT" ["l"="56.282,28.542"]
"DeepLearnXMU/ABDNMT-Transformer" ["l"="56.261,28.541"]
"DeepLearnXMU/BattRAE" ["l"="56.282,28.522"]
"DeepLearnXMU/CAEncoder-NMT" ["l"="56.298,28.528"]
"declare-lab/awesome-sentiment-analysis" ["l"="54.17,28.196", "c"=707]
"hellonlp/sentiment-analysis" ["l"="50.015,22.132", "c"=890]
"YeexiaoZheng/Multimodal-Sentiment-Analysis" ["l"="56.634,27.983"]
"jbdel/MOSEI_UMONS" ["l"="56.505,27.939"]
"jbdel/modulated_fusion_transformer" ["l"="56.475,27.919"]
"amanshenoy/multilogue-net" ["l"="56.495,27.912"]
"kniter1/TAILOR" ["l"="56.445,27.91"]
"yikaiw/CEN" ["l"="47.797,35.682", "c"=695]
"Sreyan88/MMER" ["l"="56.936,27.956"]
"raulsteleac/Speech_Emotion_Recognition" ["l"="56.916,27.919"]
"XpastaX/ConFEDE" ["l"="56.546,28.021"]
"thuiar/M-SENA" ["l"="56.536,28.04"]
"thuiar/ch-sims-v2" ["l"="56.547,28.046"]
"mdswyz/DMD" ["l"="56.536,28.059"]
"Haoyu-ha/ALMT" ["l"="56.529,28.026"]
"filippogiruzzi/voice_activity_detection" ["l"="36.736,4.556", "c"=128]
"zlzhang1124/voice_activity_detection" ["l"="56.895,28.065"]
"MeidanGR/SpeechEmotionRecognition_Realtime" ["l"="56.916,27.865"]
"face-analysis/emonet" ["l"="56.168,27.294", "c"=486]
"EvelynFan/AWESOME-MER" ["l"="56.75,27.917"]
"zeroQiaoba/gpt4v-emotion" ["l"="56.496,28.099"]
"rkosti/emotic" ["l"="56.734,27.867"]
"woosual/multiModalityFusionForClassification" ["l"="56.624,27.871"]
"kitsch231/pytorch_fake_news_Classification_mml" ["l"="56.627,27.901"]
"Kaicheng-Yang0828/Multimodal-Sentiment-Analysis-Paper-list" ["l"="56.523,27.968"]
"mailong25/self-supervised-speech-recognition" ["l"="35.768,2.319", "c"=308]
"m3hrdadfi/soxan" ["l"="56.96,27.991"]
"khanld/ASR-Wav2vec-Finetune" ["l"="57.133,28.04"]
"maysonma/VAANet" ["l"="56.737,27.826"]
"nku-zhichengzhang/CTEN" ["l"="56.726,27.778"]
"kittenish/Frame-Transformer-Network" ["l"="56.743,27.79"]
"vishaal27/Multimodal-Video-Emotion-Recognition-Pytorch" ["l"="56.717,27.802"]
"affect2mm/emotion-timeseries" ["l"="56.749,27.807"]
"ZizhouJia/PDANet" ["l"="56.768,27.763"]
"georgian-io/Multimodal-Toolkit" ["l"="45.988,24.742", "c"=1262]
"zerohd4869/DialogueCRN" ["l"="56.628,28.14"]
"shenwzh3/DialogXL" ["l"="56.651,28.144"]
"tae898/erc" ["l"="56.618,28.169"]
"caskcsg/SPCL" ["l"="56.611,28.153"]
"Sahandfer/EMPaper" ["l"="56.824,28.916", "c"=310]
"somethingx678/TodKat" ["l"="56.634,28.155"]
"liyucheng09/Metaphor_Generator" ["l"="56.364,28.399"]
"JasonShao55/Chinese_Metaphor_Explanation" ["l"="56.38,28.372"]
"facebookresearch/mmbt" ["l"="48.546,32.059", "c"=300]
"cindyhu-cyber/Multimodal-Sentiment-Analysis" ["l"="56.646,27.939"]
"liyunfan1223/multimodal-sentiment-analysis" ["l"="56.656,27.948"]
"Iwhappy/MultiModal-Sentiment-Analysis" ["l"="56.673,27.938"]
"HLTSingapore/Emotional-Speech-Data" ["l"="38.382,2.277", "c"=54]
"glam-imperial/EmotionalConversionStarGAN" ["l"="37.339,2.794", "c"=117]
"emo-box/EmoBox" ["l"="38.314,2.127", "c"=54]
"numediart/EmoV-DB" ["l"="38.355,2.333", "c"=54]
"audeering/w2v2-how-to" ["l"="38.317,2.056", "c"=54]
"abikaki/awesome-speech-emotion-recognition" ["l"="56.948,28.03"]
"shamanez/Self-Supervised-Embedding-Fusion-Transformer" ["l"="56.778,27.989"]
"lessonxmk/head_fusion" ["l"="56.921,28.001"]
"NickyFot/EmoCLIP" ["l"="56.75,27.886"]
"wtomin/MIMAMO-Net" ["l"="56.066,27.327", "c"=486]
"epalu/mmvaeplus" ["l"="56.434,27.831"]
"gabinsane/multimodal-vae-comparison" ["l"="56.434,27.85"]
"kodaim1115/scMM" ["l"="56.452,27.841"]
"thomassutter/mmjsd" ["l"="56.438,27.864"]
"wenliangdai/Modality-Transferable-MER" ["l"="56.766,28.009"]
"QYQ-bot/CLEA" ["l"="56.835,28.313"]
"codezakh/exploiting-BERT-thru-translation" ["l"="56.737,28.081"]
"NUSTM/VLP-MABSA" ["l"="56.666,28.011"]
"TmacMai/multimodal-fusion" ["l"="56.547,27.899"]
"lessonxmk/Optimized_attention_for_SER" ["l"="56.943,27.994"]
"lixiangucas01/GLAM" ["l"="56.95,27.975"]
"Tandon-A/emotic" ["l"="56.712,27.872"]
"ndkhanh360/CAER" ["l"="56.719,27.849"]
"chenxindaaa/emotic" ["l"="56.696,27.85"]
"wenliangdai/Multimodal-End2end-Sparse" ["l"="56.751,28.019"]
"cvlab-stonybrook/Emotion-Prediction" ["l"="56.791,27.707"]
"ivyha010/emotionprediction" ["l"="56.744,27.768"]
"ivyha010/AttendAffectNet" ["l"="56.741,27.751"]
"glam-imperial/semantic_speech_emotion_recognition" ["l"="56.849,27.872"]
"LW-Ricarido/Emotion_SDK" ["l"="56.705,27.79"]
"ictnlp/PLUVR" ["l"="56.189,28.685"]
"orionw/rJokesData" ["l"="56.481,28.225"]
"wjq-learning/MSTI" ["l"="56.723,28.14"]
"iyuge2/M-SENA-Backend" ["l"="56.489,28.056"]
"Columbine21/NIAT" ["l"="56.452,28.063"]
"MANLP-suda/MMESGN" ["l"="56.393,27.886"]
"MANLP-suda/HHMPN" ["l"="56.411,27.895"]
"sb-ai-lab/EmotiEffLib" ["l"="56.103,27.275", "c"=486]
"IliaZenkov/sklearn-audio-classification" ["l"="56.906,28.008"]
"cdezapasquale/transfomer-audio-classification" ["l"="56.907,28.02"]
"HoseinAzad/Transformer-based-SER" ["l"="56.924,28.018"]
"TideDancer/interspeech21_emotion" ["l"="56.933,27.981"]
"audeering/opensmile" ["l"="37.201,2.114", "c"=117]
"AryaAftab/LIGHT-SERNET" ["l"="56.944,27.965"]
"jonatasgrosman/wav2vec2-sprint" ["l"="57.042,27.984"]
"deep-real/SMIL" ["l"="56.476,27.976"]
"YiLunLee/missing_aware_prompts" ["l"="56.454,27.984"]
"mdswyz/DiCMoR" ["l"="56.482,28.04"]
"han-liu/awesome-missing-modality-for-medical-images" ["l"="56.441,27.949"]
"billhhh/ShaSpec" ["l"="56.427,27.978"]
"shicaiwei123/MMANet-CVPR2023" ["l"="56.431,27.963"]
"deepsuperviser/CTFN" ["l"="56.482,27.961"]
"GeWu-Lab/OGM-GE_CVPR2022" ["l"="39.505,5.611", "c"=593]
"pliang279/PID" ["l"="56.469,28.071"]
"zeroQiaoba/AffectGPT" ["l"="56.513,28.11"]
"pliang279/HighMMT" ["l"="56.522,28.079"]
"Exploration-Lab/COGMEN" ["l"="56.58,28.098"]
"butterfliesss/SDT" ["l"="56.577,28.113"]
"feiyuchen7/M3NET" ["l"="56.593,28.115"]
"LeqsNaN/KEC" ["l"="56.654,28.226"]
"NUSTM/MECPE" ["l"="56.651,28.271"]
"tae898/multimodal-datasets" ["l"="56.624,28.208"]
"TaoShi1998/MultiEMO" ["l"="56.598,28.134"]
"LIN-SHANG/InstructERC" ["l"="56.58,28.164"]
"fpcsong/emotionflow" ["l"="56.604,28.185"]
"rungjoo/CoMPM" ["l"="56.604,28.2"]
"AbdulBasit-MrRobo/Real-Time-Speech-Emotion-Recognition" ["l"="56.939,27.841"]
"FlameSky-S/M-SENA-frontend" ["l"="56.503,28.05"]
"cristinalunaj/MMEmotionRecognition" ["l"="56.882,28.005"]
"Edresson/Wav2Vec-Wrapper" ["l"="57.024,28.006"]
"veronica320/Chinese-Metaphor" ["l"="56.379,28.351"]
"HappyColor/Vesper" ["l"="56.964,27.963"]
"kensho-technologies/pyctcdecode" ["l"="35.725,2.346", "c"=308]
"patrickvonplaten/Wav2Vec2_PyCTCDecode" ["l"="57.121,28.01"]
"ZhuoYulang/IF-MMIN" ["l"="56.468,27.953"]
"JaydenZeng/EMMR" ["l"="56.472,27.99"]
"Haoyu-ha/LNLN" ["l"="56.488,28.015"]
"pmleffers/TIFUKNN" ["l"="56.829,28.333"]
"oliverguhr/wav2vec2-live" ["l"="57.075,28.005"]
"vietai/ASR" ["l"="52.611,-0.238", "c"=810]
"ccoreilly/wav2vec2-service" ["l"="57.1,27.998"]
"chuachinhon/wav2vec2_transformers" ["l"="57.096,28.026"]
"bhattbhavesh91/wav2vec2-huggingface-demo" ["l"="57.077,28.033"]
"YangXiaocui1215/MGNNS" ["l"="56.685,28.053"]
"kiva12138/CubeMLP" ["l"="56.529,27.999"]
"georgepar/mmlatch" ["l"="56.543,27.969"]
"KomorebiLHX/Emotion-Recognition-in-Conversations" ["l"="56.644,28.185"]
"SteveKGYang/SCCL" ["l"="56.664,28.166"]
"LeqsNaN/SKAIG-ERC" ["l"="56.651,28.2"]
"circle-hit/CauAIN" ["l"="56.671,28.19"]
"thu-coai/EVA" ["l"="56.774,29.037", "c"=310]
"scutcyr/CPED" ["l"="56.557,28.169"]
"Miaheeee/AI_lab5" ["l"="56.648,27.91"]
"OpenNLPLab/MMVAE-AVS" ["l"="56.465,27.816"]
"lstappen/MuSe2021" ["l"="56.421,28.178"]
"EIHW/MuSe2022" ["l"="56.457,28.169"]
"lstappen/MuSe2020" ["l"="56.394,28.19"]
"youcaiSUN/MuSe-Wild_2020" ["l"="56.394,28.175"]
"alawryaguila/multi-view-AE" ["l"="56.413,27.81"]
"LividWo/Revisit-MMT" ["l"="56.21,28.695"]
"zerohd4869/SACL" ["l"="56.603,28.169"]
"ljynlp/HiTrans" ["l"="56.671,28.221"]
"huggingface/speechbox" ["l"="57.136,27.948"]
"jonatasgrosman/asrecognition" ["l"="57.137,27.973"]
"lumaku/ctc-segmentation" ["l"="35.757,2.357", "c"=308]
"farisalasmary/wav2vec2-kenlm" ["l"="57.134,27.994"]
"spring-media/DeepPhonemizer" ["l"="37.32,2.25", "c"=117]
"MultimodalAffectiveComputing/FV2ES" ["l"="56.774,28.024"]
"katerynaCh/MMA-DFER" ["l"="56.261,27.201", "c"=486]
"praveena2j/Joint-Cross-Attention-for-Audio-Visual-Fusion" ["l"="56.838,28.085"]
"She-yh/End-to-End-Multimodal-emotion-recognition" ["l"="56.798,28.033"]
"smartcameras/SelfCrossAttn" ["l"="56.851,27.857"]
"SilyRab/AoM" ["l"="56.696,28.003"]
"MANLP-suda/JML" ["l"="56.682,27.979"]
"NUSTM/ITM" ["l"="56.695,27.988"]
"YangXiaocui1215/GMP" ["l"="56.666,27.986"]
"NUSTM/HIMT" ["l"="56.681,27.994"]
"AIM3-RUC/RUCM3ED" ["l"="56.526,28.154"]
"AIM3-RUC/MERC_Challenge_CCAC2023" ["l"="56.526,28.179"]
"sucv/ABAW3" ["l"="56.892,28.146"]
"praveena2j/RJCMA" ["l"="56.869,28.12"]
"sucv/ABAW2" ["l"="56.907,28.164"]
"speechandlanguageprocessing/ICASSP2022-Depression" ["l"="37.154,1.894", "c"=117]
"HappyColor/SpeechFormer" ["l"="56.985,27.944"]
"BladeDancer957/TSAM" ["l"="56.664,28.255"]
"scutcsq/DWFormer" ["l"="56.948,27.941"]
"ECNU-Cross-Innovation-Lab/ShiftSER" ["l"="56.953,27.955"]
"ECNU-Cross-Innovation-Lab/ENT" ["l"="56.97,27.948"]
"julianyulu/icassp2021-mscnn-spu" ["l"="56.992,27.969"]
"Jiaxin-Ye/GM-TCNet" ["l"="56.96,27.941"]
"khanld/Wav2vec2-Pretraining" ["l"="57.158,28.044"]
"qinyuenlp/wav2vec_finetune" ["l"="57.148,28.061"]
"facebookresearch/multimodal" ["l"="48.947,30.29", "c"=191]
"sunlicai/EMT-DLFR" ["l"="56.51,28.026"]
"albertwy/SWRM" ["l"="56.508,28.038"]
"leson502/CORECT_EMNLP2023" ["l"="56.576,28.13"]
"Yu-Fangxu/EACL" ["l"="56.559,28.121"]
"NUSTM/FacialMMT" ["l"="56.58,28.141"]
"metaphysicser/PS-Mixer" ["l"="56.423,28.03"]
"JackAILab/TMBL" ["l"="56.471,28.029"]
"HappyColor/DST" ["l"="56.965,27.928"]
"sunlightsgy/MEmoR" ["l"="56.547,28.208"]
"thu-coai/Emotional-Support-Conversation" ["l"="56.842,28.897", "c"=310]
"XiaoMi/C3KG" ["l"="56.84,28.955", "c"=310]
"zeroQiaoba/MERTools" ["l"="56.536,28.093"]
"Sahandfer/CEM" ["l"="56.84,28.932", "c"=310]
"hbzju/PiCO" ["l"="51.636,30.575", "c"=83]
"zeroQiaoba/ALIM" ["l"="56.449,28.091"]
"declare-lab/MSA-Robustness" ["l"="56.553,28.069"]
"drmuskangarg/Multimodal-datasets" ["l"="56.559,28.141"]
"HappyColor/SpeechFormer2" ["l"="57.012,27.93"]
"RecklessRonan/MuSE" ["l"="56.608,28.123"]
"dawn0815/UniSA" ["l"="56.598,28.101"]
"ASolitaryMan/HFLEA" ["l"="56.951,27.93"]
"rungjoo/Emotion_not_One" ["l"="56.598,28.228"]
"praveena2j/Cross-Attentional-AV-Fusion" ["l"="56.856,28.098"]
"praveena2j/JointCrossAttentional-AV-Fusion" ["l"="56.841,28.108"]
"nku-zhichengzhang/MPOT" ["l"="56.717,27.683"]
"circle-hit/KBCIN" ["l"="56.646,28.244"]
"NUSTM/SHARK" ["l"="56.671,28.243"]
"saharmor/whisper-playground" ["l"="40.413,3.17", "c"=908]
"AlibabaResearch/DAMO-ConvAI" ["l"="37.511,-1.528", "c"=999]
"muzairkhattak/multimodal-prompt-learning" ["l"="50.364,38.261", "c"=684]
"linzhiqiu/cross_modal_adaptation" ["l"="50.35,38.288", "c"=684]
"sanchit-gandhi/seq2seq-speech" ["l"="57.165,27.934"]
"dingchaoyue/AcFormer" ["l"="56.52,28.041"]
"zehuiwu/MMML" ["l"="56.542,28.01"]
"Feuoy/sentiment-analysis" ["l"="50.01,22.254", "c"=890]
"yinruiqing/pyannote-whisper" ["l"="40.437,3.157", "c"=908]
"JabuMlDev/Speaker-VGG-CCT" ["l"="56.947,27.914"]
"zeroQiaoba/GCNet" ["l"="56.485,28.078"]
"zeroQiaoba/IRNet" ["l"="56.458,28.104"]
"mdswyz/IMDer" ["l"="56.474,28.054"]
"ZhuoYulang/CIF-MMIN" ["l"="56.461,28.045"]
"serycjon/WOFT" ["l"="56.733,27.619"]
"shirayu/whispering" ["l"="40.393,3.138", "c"=908]
"hcmlab/emovoice" ["l"="56.937,28.065"]
"GentleCold/multimodal_sentiment_analysis" ["l"="56.662,27.926"]
"Linshou99/Multimodal-sentiment-analysis" ["l"="56.666,27.914"]
"ChangdeDu/BraVL" ["l"="62.711,34.381", "c"=1109]
"NUSTM/SemEval-2024_ECAC" ["l"="56.652,28.29"]
"yingqichao/fnd-bootstrap" ["l"="52.478,26.757", "c"=1052]
"less-and-less-bugs/LogicMD" ["l"="56.707,28.158"]
"ShawX825/HiDialog" ["l"="56.621,28.186"]
"nku-zhichengzhang/TSL300" ["l"="56.717,27.716"]
"ZebangCheng/Emotion-LLaMA" ["l"="56.488,28.114"]
"sunlicai/HiCMAE" ["l"="56.508,28.123"]
"sunlicai/MAE-DFER" ["l"="56.198,27.241", "c"=486]
"NLPWM-WHU/MPLP" ["l"="56.519,28.2"]
"yxuansu/PandaGPT" ["l"="47.481,30.097", "c"=254]
"nku-zhichengzhang/PlaneSeg" ["l"="56.705,27.699"]
"pakoromilas/MultimodalSDK_loader" ["l"="56.513,28.059"]
"pliang279/FactorCL" ["l"="56.418,28.078"]
"scutcyr/SoulChat" ["l"="56.872,28.87", "c"=310]
"vtuber-plan/langport" ["l"="56.408,28.116"]
"FrostMiKu/Nole" ["l"="56.427,28.111"]
"Cecile-hi/Multimodal-Learning-with-Alternating-Unimodal-Adaptation" ["l"="39.45,5.62", "c"=593]
"zrguo/MPLMM" ["l"="56.474,28.013"]
"QingyangZhang/QMF" ["l"="52.909,30.048", "c"=547]
"zengqunzhao/DFER-CLIP" ["l"="56.223,27.227", "c"=486]
"yingjie7/BiosERC" ["l"="56.573,28.195"]
"YetZzzzzz/GLoMo" ["l"="56.485,28.03"]
"Say2L/CENet" ["l"="56.455,28.028"]
"Vaibhavs10/fast-whisper-finetuning" ["l"="40.684,2.952", "c"=908]
"MIPS-COLT/MER-MCE" ["l"="56.479,28.13"]
"JackYFL/EmoLA" ["l"="56.492,28.136"]
"kdhht2334/awesome-SOTA-FER" ["l"="56.179,27.262", "c"=486]
"dawn0815/SAEval-Benchmark" ["l"="56.618,28.115"]
"MKMaS-GUET/KuDA" ["l"="56.499,28.009"]
"AZYoung233/CLGSI" ["l"="56.515,27.984"]
"MCG-NKU/AMT" ["l"="-35.902,20.972", "c"=597]
"hcmlab/nova" ["l"="57.001,28.119"]
"hcmlab/ssi" ["l"="56.967,28.091"]
"shicaiwei123/ECCV2024-DMRNet" ["l"="56.398,27.953"]
"chengzju/CARAT" ["l"="56.432,28.055"]
"nku-zhichengzhang/MART" ["l"="56.715,27.758"]
"sterling239/audio-emotion-recognition" ["l"="56.858,28.063"]
"SenticNet/personality-detection" ["l"="52.435,24.659", "c"=172]
"TaoShi1998/SSLCL" ["l"="56.594,28.155"]
"lzw108/EmoLLMs" ["l"="56.82,28.806", "c"=310]
"MC-EIU/MC-EIU" ["l"="53.033,26.494", "c"=60]
"thuhcsi/SECap" ["l"="38.351,2.144", "c"=54]
"aimmemotion/EmoVIT" ["l"="56.449,28.128"]
"Lum1104/EIBench" ["l"="56.462,28.134"]
"amoudgl/short-jokes-dataset" ["l"="56.447,28.226"]
"amoudgl/funnybot" ["l"="56.432,28.21"]
"taivop/joke-dataset" ["l"="56.462,28.201"]
"CrowdTruth/Short-Text-Corpus-For-Humor-Detection" ["l"="56.425,28.224"]
"openai/requests-for-research" ["l"="57.37,18.041", "c"=45]
"codekansas/seqgan-text-tensorflow" ["l"="57.85,29.363", "c"=1082]
"roshansridhar/Multimodal-Sentiment-Analysis" ["l"="56.607,27.931"]
"HaohanWang/SelectAdditiveLearning" ["l"="56.595,27.941"]
"pwang322/DLF" ["l"="56.452,28.01"]
"HumanMLLM/R1-Omni" ["l"="47.284,30.092", "c"=254]
"zeroQiaoba/EmotiW2018" ["l"="55.93,27.212", "c"=486]
"HumanMLLM/HumanOmni" ["l"="47.21,30.078", "c"=254]
"ebadawy/EmotiW2017" ["l"="55.915,27.224", "c"=486]
"zrguo/CASP" ["l"="56.414,28.005"]
}