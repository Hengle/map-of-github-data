digraph G {
"nryant/dscore" -> "BUTSpeechFIT/VBx"
"nryant/dscore" -> "joonson/voxconverse"
"nryant/dscore" -> "hitachi-speech/EEND"
"nryant/dscore" -> "desh2608/dover-lap"
"nryant/dscore" -> "wq2012/SpectralCluster"
"nryant/dscore" -> "Jamiroquai88/VBDiarization"
"nryant/dscore" -> "HuangZiliAndy/RPNSD"
"nryant/dscore" -> "nttcslab-sp/EEND-vector-clustering"
"nryant/dscore" -> "pyannote/pyannote-metrics"
"nryant/dscore" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"nryant/dscore" -> "FlorianKrey/DNC"
"nryant/dscore" -> "Xflick/EEND_PyTorch"
"nryant/dscore" -> "yufan-aslp/AliMeeting"
"nryant/dscore" -> "wq2012/awesome-diarization"
"nryant/dscore" -> "google/speaker-id"
"wq2012/awesome-diarization" -> "google/uis-rnn"
"wq2012/awesome-diarization" -> "taylorlu/Speaker-Diarization"
"wq2012/awesome-diarization" -> "wq2012/SpectralCluster"
"wq2012/awesome-diarization" -> "hitachi-speech/EEND"
"wq2012/awesome-diarization" -> "pyannote/pyannote-audio" ["e"=1]
"wq2012/awesome-diarization" -> "Snowdar/asv-subtools"
"wq2012/awesome-diarization" -> "HarryVolek/PyTorch_Speaker_Verification"
"wq2012/awesome-diarization" -> "clovaai/voxceleb_trainer"
"wq2012/awesome-diarization" -> "nryant/dscore"
"wq2012/awesome-diarization" -> "BUTSpeechFIT/VBx"
"wq2012/awesome-diarization" -> "google/speaker-id"
"wq2012/awesome-diarization" -> "DongKeon/Awesome-Speaker-Diarization"
"wq2012/awesome-diarization" -> "juanmc2005/diart" ["e"=1]
"wq2012/awesome-diarization" -> "philipperemy/deep-speaker"
"wq2012/awesome-diarization" -> "lhotse-speech/lhotse" ["e"=1]
"neelkshah/MIPS-Processor" -> "zslwyuan/Basic-SIMD-Processor-Verilog-Tutorial" ["e"=1]
"neelkshah/MIPS-Processor" -> "adibis/DDR2_Controller" ["e"=1]
"neelkshah/MIPS-Processor" -> "madhavtummala/SS-Lab"
"neelkshah/MIPS-Processor" -> "jhultman/signals-and-systems"
"neelkshah/MIPS-Processor" -> "aliasad059/Signals-Systems"
"neelkshah/MIPS-Processor" -> "izlandman/iVector"
"neelkshah/MIPS-Processor" -> "TheSUPERCD/8bit_MicroComputer_Verilog"
"neelkshah/MIPS-Processor" -> "JoseRZapata/SyS"
"neelkshah/MIPS-Processor" -> "tokheim/iVector"
"neelkshah/MIPS-Processor" -> "tiagofrepereira2012/ivector_example"
"neelkshah/MIPS-Processor" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"neelkshah/MIPS-Processor" -> "d-dimos/microprocessors_laboratory_ntua"
"neelkshah/MIPS-Processor" -> "ZeyadTarekk/The86-Pgame"
"mravanelli/SincNet" -> "mravanelli/pytorch-kaldi" ["e"=1]
"mravanelli/SincNet" -> "clovaai/voxceleb_trainer"
"mravanelli/SincNet" -> "HarryVolek/PyTorch_Speaker_Verification"
"mravanelli/SincNet" -> "Jungjee/RawNet"
"mravanelli/SincNet" -> "santi-pdp/pase" ["e"=1]
"mravanelli/SincNet" -> "philipperemy/deep-speaker"
"mravanelli/SincNet" -> "WeidiXie/VGG-Speaker-Recognition"
"mravanelli/SincNet" -> "Snowdar/asv-subtools"
"mravanelli/SincNet" -> "wq2012/awesome-diarization"
"mravanelli/SincNet" -> "google/uis-rnn"
"mravanelli/SincNet" -> "KarelVesely84/kaldi-io-for-python" ["e"=1]
"mravanelli/SincNet" -> "manojpamk/pytorch_xvectors"
"mravanelli/SincNet" -> "pykaldi/pykaldi" ["e"=1]
"mravanelli/SincNet" -> "grausof/keras-sincnet"
"mravanelli/SincNet" -> "s3prl/s3prl" ["e"=1]
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "qqueing/DeepSpeaker-pytorch"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "jymsuper/SpeakerRecognition_tutorial"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "HarryVolek/PyTorch_Speaker_Verification"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "Aurora11111/speaker-recognition-pytorch"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "funcwj/ge2e-speaker-verification"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "zacharyclam/speaker_recognition"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "Suhee05/Text-Independent-Speaker-Verification"
"astorfi/3D-convolutional-speaker-recognition-pytorch" -> "Dannynis/xvector_pytorch"
"Jungjee/RawNet" -> "VITA-Group/AutoSpeech"
"Jungjee/RawNet" -> "Snowdar/asv-subtools"
"Jungjee/RawNet" -> "clovaai/voxceleb_trainer"
"Jungjee/RawNet" -> "asvspoof-challenge/2021" ["e"=1]
"Jungjee/RawNet" -> "sasv-challenge/SASVC2022_Baseline" ["e"=1]
"Jungjee/RawNet" -> "clovaai/aasist" ["e"=1]
"Jungjee/RawNet" -> "mravanelli/SincNet"
"Jungjee/RawNet" -> "WeidiXie/VGG-Speaker-Recognition"
"Jungjee/RawNet" -> "TakHemlata/SSL_Anti-spoofing" ["e"=1]
"Jungjee/RawNet" -> "TaoRuijie/ECAPA-TDNN"
"Jungjee/RawNet" -> "HarryVolek/PyTorch_Speaker_Verification"
"Jungjee/RawNet" -> "joonson/voxceleb_unsupervised"
"Jungjee/RawNet" -> "seongmin-kye/meta-SR"
"Jungjee/RawNet" -> "Janghyun1230/Speaker_Verification"
"Jungjee/RawNet" -> "manojpamk/pytorch_xvectors"
"Janghyun1230/Speaker_Verification" -> "HarryVolek/PyTorch_Speaker_Verification"
"Janghyun1230/Speaker_Verification" -> "philipperemy/deep-speaker"
"Janghyun1230/Speaker_Verification" -> "funcwj/ge2e-speaker-verification"
"Janghyun1230/Speaker_Verification" -> "WeidiXie/VGG-Speaker-Recognition"
"Janghyun1230/Speaker_Verification" -> "jymsuper/SpeakerRecognition_tutorial"
"Janghyun1230/Speaker_Verification" -> "rajathkmp/speaker-verification"
"Janghyun1230/Speaker_Verification" -> "qqueing/DeepSpeaker-pytorch"
"Janghyun1230/Speaker_Verification" -> "taylorlu/Speaker-Diarization"
"Janghyun1230/Speaker_Verification" -> "google/uis-rnn"
"Janghyun1230/Speaker_Verification" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"Janghyun1230/Speaker_Verification" -> "Jungjee/RawNet"
"Janghyun1230/Speaker_Verification" -> "wq2012/SpectralCluster"
"Janghyun1230/Speaker_Verification" -> "astorfi/3D-convolutional-speaker-recognition"
"Janghyun1230/Speaker_Verification" -> "Suhee05/Text-Independent-Speaker-Verification"
"Janghyun1230/Speaker_Verification" -> "yistLin/dvector"
"HarryVolek/PyTorch_Speaker_Verification" -> "Janghyun1230/Speaker_Verification"
"HarryVolek/PyTorch_Speaker_Verification" -> "qqueing/DeepSpeaker-pytorch"
"HarryVolek/PyTorch_Speaker_Verification" -> "google/uis-rnn"
"HarryVolek/PyTorch_Speaker_Verification" -> "philipperemy/deep-speaker"
"HarryVolek/PyTorch_Speaker_Verification" -> "funcwj/ge2e-speaker-verification"
"HarryVolek/PyTorch_Speaker_Verification" -> "WeidiXie/VGG-Speaker-Recognition"
"HarryVolek/PyTorch_Speaker_Verification" -> "manojpamk/pytorch_xvectors"
"HarryVolek/PyTorch_Speaker_Verification" -> "taylorlu/Speaker-Diarization"
"HarryVolek/PyTorch_Speaker_Verification" -> "jymsuper/SpeakerRecognition_tutorial"
"HarryVolek/PyTorch_Speaker_Verification" -> "clovaai/voxceleb_trainer"
"HarryVolek/PyTorch_Speaker_Verification" -> "wq2012/awesome-diarization"
"HarryVolek/PyTorch_Speaker_Verification" -> "mravanelli/SincNet"
"HarryVolek/PyTorch_Speaker_Verification" -> "wq2012/SpectralCluster"
"HarryVolek/PyTorch_Speaker_Verification" -> "astorfi/3D-convolutional-speaker-recognition-pytorch"
"HarryVolek/PyTorch_Speaker_Verification" -> "Snowdar/asv-subtools"
"RDShi/voiceprint" -> "prajual/Master-Voice_Prints"
"google/uis-rnn" -> "wq2012/awesome-diarization"
"google/uis-rnn" -> "taylorlu/Speaker-Diarization"
"google/uis-rnn" -> "wq2012/SpectralCluster"
"google/uis-rnn" -> "HarryVolek/PyTorch_Speaker_Verification"
"google/uis-rnn" -> "hitachi-speech/EEND"
"google/uis-rnn" -> "philipperemy/deep-speaker"
"google/uis-rnn" -> "Janghyun1230/Speaker_Verification"
"google/uis-rnn" -> "mravanelli/pytorch-kaldi" ["e"=1]
"google/uis-rnn" -> "Snowdar/asv-subtools"
"google/uis-rnn" -> "mravanelli/SincNet"
"google/uis-rnn" -> "wiseman/py-webrtcvad" ["e"=1]
"google/uis-rnn" -> "nryant/dscore"
"google/uis-rnn" -> "maum-ai/voicefilter" ["e"=1]
"google/uis-rnn" -> "pyannote/pyannote-audio" ["e"=1]
"google/uis-rnn" -> "WeidiXie/VGG-Speaker-Recognition"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "GauravWaghmare/Speaker-Identification"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "abhijeet3922/Speaker-identification-using-GMMs"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "oscarknagg/voicemap"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "jymsuper/SpeakerRecognition_tutorial"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "SuperKogito/Voice-based-speaker-identification"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "HarryVolek/PyTorch_Speaker_Verification"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "orchidas/Speaker-Recognition"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "Janghyun1230/Speaker_Verification"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "ppwwyyxx/speaker-recognition"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "VaibhavBhapkar/Speaker-Identification-Using-Machine-Learning"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "Speaker-Identification/You-Only-Speak-Once"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "crouchred/speaker-recognition-py3"
"Atul-Anand-Jha/Speaker-Identification-Python" -> "linhdvu14/vggvox-speaker-identification"
"oscarknagg/voicemap" -> "Atul-Anand-Jha/Speaker-Identification-Python"
"oscarknagg/voicemap" -> "PiotrTa/Huawei-Challenge-Speaker-Identification"
"oscarknagg/voicemap" -> "jymsuper/SpeakerRecognition_tutorial"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "qqueing/DeepSpeaker-pytorch"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "philipperemy/deep-speaker"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "WeidiXie/VGG-Speaker-Recognition"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "jymsuper/SpeakerRecognition_tutorial"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "bjfu-ai-institute/speaker-recognition-papers"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "zacharyclam/speaker_recognition"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "astorfi/3D-convolutional-speaker-recognition-pytorch"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "crouchred/speaker-recognition-py3"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "HarryVolek/PyTorch_Speaker_Verification"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "a-nagrani/VGGVox"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "Janghyun1230/Speaker_Verification"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "andabi/voice-vector"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "linhdvu14/vggvox-speaker-identification"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "wangleiai/dVectorSpeakerRecognition"
"Walleclipse/Deep_Speaker-speaker_recognition_system" -> "taylorlu/Speaker-Diarization"
"google/speaker-id" -> "wq2012/SpectralCluster"
"google/speaker-id" -> "hitachi-speech/EEND"
"google/speaker-id" -> "nryant/dscore"
"google/speaker-id" -> "taylorlu/Speaker-Diarization"
"google/speaker-id" -> "BUTSpeechFIT/EEND"
"google/speaker-id" -> "DongKeon/Awesome-Speaker-Diarization"
"google/speaker-id" -> "wq2012/awesome-diarization"
"google/speaker-id" -> "BUTSpeechFIT/VBx"
"google/speaker-id" -> "joonson/voxconverse"
"google/speaker-id" -> "huggingface/diarizers"
"google/speaker-id" -> "nttcslab-sp/EEND-vector-clustering"
"google/speaker-id" -> "Audio-WestlakeU/FS-EEND"
"google/speaker-id" -> "BUTSpeechFIT/DiariZen"
"google/speaker-id" -> "Snowdar/asv-subtools"
"google/speaker-id" -> "dodohow1011/TS-VAD"
"jymsuper/SpeakerRecognition_tutorial" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"jymsuper/SpeakerRecognition_tutorial" -> "HarryVolek/PyTorch_Speaker_Verification"
"jymsuper/SpeakerRecognition_tutorial" -> "seongmin-kye/meta-SR"
"jymsuper/SpeakerRecognition_tutorial" -> "cvqluu/TDNN"
"jymsuper/SpeakerRecognition_tutorial" -> "qqueing/DeepSpeaker-pytorch"
"jymsuper/SpeakerRecognition_tutorial" -> "astorfi/3D-convolutional-speaker-recognition-pytorch"
"jymsuper/SpeakerRecognition_tutorial" -> "Janghyun1230/Speaker_Verification"
"jymsuper/SpeakerRecognition_tutorial" -> "VITA-Group/AutoSpeech"
"jymsuper/SpeakerRecognition_tutorial" -> "yistLin/dvector"
"jymsuper/SpeakerRecognition_tutorial" -> "taylorlu/Speaker-Diarization"
"jymsuper/SpeakerRecognition_tutorial" -> "Aurora11111/speaker-recognition-pytorch"
"jymsuper/SpeakerRecognition_tutorial" -> "Dannynis/xvector_pytorch"
"jymsuper/SpeakerRecognition_tutorial" -> "clovaai/voxceleb_trainer"
"jymsuper/SpeakerRecognition_tutorial" -> "bjfu-ai-institute/speaker-recognition-papers"
"jymsuper/SpeakerRecognition_tutorial" -> "wangleiai/dVectorSpeakerRecognition"
"SuperKogito/Voice-based-gender-recognition" -> "x4nth055/gender-recognition-by-voice"
"SuperKogito/Voice-based-gender-recognition" -> "primaryobjects/voice-gender"
"SuperKogito/Voice-based-gender-recognition" -> "SuperKogito/Voice-based-speaker-identification"
"SuperKogito/Voice-based-gender-recognition" -> "danstowell/smacpy" ["e"=1]
"SuperKogito/Voice-based-gender-recognition" -> "Abhay0899193/Speaker-Recognition"
"a-nagrani/VGGVox" -> "WeidiXie/VGG-Speaker-Recognition"
"a-nagrani/VGGVox" -> "qqueing/DeepSpeaker-pytorch"
"a-nagrani/VGGVox" -> "linhdvu14/vggvox-speaker-identification"
"a-nagrani/VGGVox" -> "clovaai/voxceleb_trainer"
"a-nagrani/VGGVox" -> "HarryVolek/PyTorch_Speaker_Verification"
"a-nagrani/VGGVox" -> "philipperemy/deep-speaker"
"a-nagrani/VGGVox" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"a-nagrani/VGGVox" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"a-nagrani/VGGVox" -> "astorfi/3D-convolutional-speaker-recognition"
"a-nagrani/VGGVox" -> "hbredin/TristouNet"
"a-nagrani/VGGVox" -> "Janghyun1230/Speaker_Verification"
"a-nagrani/VGGVox" -> "rajathkmp/speaker-verification"
"a-nagrani/VGGVox" -> "mravanelli/SincNet"
"a-nagrani/VGGVox" -> "manojpamk/pytorch_xvectors"
"a-nagrani/VGGVox" -> "andabi/voice-vector"
"amaurycrickx/recognito" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"amaurycrickx/recognito" -> "Adirockzz95/Piwho"
"amaurycrickx/recognito" -> "ppwwyyxx/speaker-recognition"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "mycrazycracy/tf-kaldi-speaker"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "qqueing/SR_with_kaldi"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "zeroQiaoba/ivector-xvector"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "WeidiXie/VGG-Speaker-Recognition"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "jefflai108/pytorch-kaldi-neural-speaker-embeddings"
"BUTSpeechFIT/x-vector-kaldi-tf" -> "KarelVesely84/kaldi-io-for-python" ["e"=1]
"BUTSpeechFIT/x-vector-kaldi-tf" -> "mycrazycracy/speaker-embedding-with-phonetic-information"
"abhijeet3922/Speaker-identification-using-GMMs" -> "genzen2103/Speaker-Recognition-System-using-GMM"
"abhijeet3922/Speaker-identification-using-GMMs" -> "dominoanty/SpeakerRecognition"
"SuperKogito/Voice-based-speaker-identification" -> "Abhay0899193/Speaker-Recognition"
"dake/openVP" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"dake/openVP" -> "ibillxia/VoicePrintReco"
"ppwwyyxx/speaker-recognition" -> "crouchred/speaker-recognition-py3"
"ppwwyyxx/speaker-recognition" -> "astorfi/3D-convolutional-speaker-recognition"
"ppwwyyxx/speaker-recognition" -> "philipperemy/deep-speaker"
"ppwwyyxx/speaker-recognition" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"ppwwyyxx/speaker-recognition" -> "qqueing/DeepSpeaker-pytorch"
"ppwwyyxx/speaker-recognition" -> "Atul-Anand-Jha/Speaker-Identification-Python"
"ppwwyyxx/speaker-recognition" -> "a-nagrani/VGGVox"
"ppwwyyxx/speaker-recognition" -> "orchidas/Speaker-Recognition"
"ppwwyyxx/speaker-recognition" -> "pannous/tensorflow-speech-recognition" ["e"=1]
"ppwwyyxx/speaker-recognition" -> "jameslyons/python_speech_features" ["e"=1]
"ppwwyyxx/speaker-recognition" -> "WeidiXie/VGG-Speaker-Recognition"
"ppwwyyxx/speaker-recognition" -> "GauravWaghmare/Speaker-Identification"
"ppwwyyxx/speaker-recognition" -> "amaurycrickx/recognito"
"ppwwyyxx/speaker-recognition" -> "microsoft/Cognitive-SpeakerRecognition-Python" ["e"=1]
"ppwwyyxx/speaker-recognition" -> "andabi/voice-vector"
"sonaam1234/DeepLearningInFinance" -> "Rez79Kh/Temperature-Control-System"
"sonaam1234/DeepLearningInFinance" -> "jjakimoto/finance_ml" ["e"=1]
"sonaam1234/DeepLearningInFinance" -> "mahdeslami11/randomCNN-voice-transfer"
"sonaam1234/DeepLearningInFinance" -> "karim-aly/intro-to-tensorflow-for-ai-coursera"
"sonaam1234/DeepLearningInFinance" -> "madhavtummala/SS-Lab"
"sonaam1234/DeepLearningInFinance" -> "jhultman/signals-and-systems"
"sonaam1234/DeepLearningInFinance" -> "aliasad059/Signals-Systems"
"sonaam1234/DeepLearningInFinance" -> "izlandman/iVector"
"sonaam1234/DeepLearningInFinance" -> "SJ-byte/Deep-Learning-For-Finance"
"sonaam1234/DeepLearningInFinance" -> "mahdeslami11/Zero-shot-Singing-Voice-Conversion"
"sonaam1234/DeepLearningInFinance" -> "JoseRZapata/SyS"
"sonaam1234/DeepLearningInFinance" -> "tokheim/iVector"
"sonaam1234/DeepLearningInFinance" -> "tiagofrepereira2012/ivector_example"
"sonaam1234/DeepLearningInFinance" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"sonaam1234/DeepLearningInFinance" -> "christianvazquez7/ivector"
"mhyousefi/MIPS-pipeline-processor" -> "neelkshah/MIPS-Processor"
"mhyousefi/MIPS-pipeline-processor" -> "maze1377/pipeline-mips-verilog"
"mhyousefi/MIPS-pipeline-processor" -> "valar1234/MIPS"
"pyannote/pyannote-metrics" -> "pyannote/pyannote-core"
"pyannote/pyannote-metrics" -> "pyannote/pyannote-database"
"pyannote/pyannote-metrics" -> "nryant/dscore"
"pyannote/pyannote-metrics" -> "wq2012/SpectralCluster"
"pyannote/pyannote-metrics" -> "hitachi-speech/EEND"
"pyannote/pyannote-metrics" -> "yinruiqing/change_detection"
"pyannote/pyannote-metrics" -> "joonson/voxconverse"
"pyannote/pyannote-metrics" -> "wq2012/SimpleDER"
"pyannote/pyannote-metrics" -> "HuangZiliAndy/RPNSD"
"pyannote/pyannote-metrics" -> "FlorianKrey/DNC"
"Anwarvic/Arabic-Speech-Recognition" -> "Anwarvic/CS224n--NLP-with-Deep-Learning"
"Primtee/Voiceprint-recognition-Speaker-recognition" -> "Aurora11111/speaker-recognition-pytorch"
"Primtee/Voiceprint-recognition-Speaker-recognition" -> "Primtee/triplet-loss-train-for-speaker-recognition"
"MohamadMerchant/Voice-Authentication-and-Face-Recognition" -> "bedangSen/VoiceSens"
"MohamadMerchant/Voice-Authentication-and-Face-Recognition" -> "rhythmize/user-authentication-using-voice-biometrics"
"MohamadMerchant/Voice-Authentication-and-Face-Recognition" -> "NaveedShahid/Voice-Authentication-CNN"
"MohamadMerchant/Voice-Authentication-and-Face-Recognition" -> "Speaker-Identification/You-Only-Speak-Once"
"wq2012/SpectralCluster" -> "taylorlu/Speaker-Diarization"
"wq2012/SpectralCluster" -> "google/uis-rnn"
"wq2012/SpectralCluster" -> "wq2012/awesome-diarization"
"wq2012/SpectralCluster" -> "hitachi-speech/EEND"
"wq2012/SpectralCluster" -> "nryant/dscore"
"wq2012/SpectralCluster" -> "google/speaker-id"
"wq2012/SpectralCluster" -> "BUTSpeechFIT/VBx"
"wq2012/SpectralCluster" -> "pyannote/pyannote-metrics"
"wq2012/SpectralCluster" -> "HarryVolek/PyTorch_Speaker_Verification"
"wq2012/SpectralCluster" -> "Snowdar/asv-subtools"
"wq2012/SpectralCluster" -> "manojpamk/pytorch_xvectors"
"wq2012/SpectralCluster" -> "FlorianKrey/DNC"
"wq2012/SpectralCluster" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"wq2012/SpectralCluster" -> "Jamiroquai88/VBDiarization"
"wq2012/SpectralCluster" -> "Janghyun1230/Speaker_Verification"
"taylorlu/Speaker-Diarization" -> "wq2012/SpectralCluster"
"taylorlu/Speaker-Diarization" -> "google/uis-rnn"
"taylorlu/Speaker-Diarization" -> "wq2012/awesome-diarization"
"taylorlu/Speaker-Diarization" -> "WeidiXie/VGG-Speaker-Recognition"
"taylorlu/Speaker-Diarization" -> "HarryVolek/PyTorch_Speaker_Verification"
"taylorlu/Speaker-Diarization" -> "hitachi-speech/EEND"
"taylorlu/Speaker-Diarization" -> "google/speaker-id"
"taylorlu/Speaker-Diarization" -> "Jamiroquai88/VBDiarization"
"taylorlu/Speaker-Diarization" -> "DonkeyShot21/uis-rnn-sml"
"taylorlu/Speaker-Diarization" -> "aalto-speech/speaker-diarization"
"taylorlu/Speaker-Diarization" -> "Janghyun1230/Speaker_Verification"
"taylorlu/Speaker-Diarization" -> "nryant/dscore"
"taylorlu/Speaker-Diarization" -> "jymsuper/SpeakerRecognition_tutorial"
"taylorlu/Speaker-Diarization" -> "BUTSpeechFIT/VBx"
"taylorlu/Speaker-Diarization" -> "clovaai/voxceleb_trainer"
"zeroQiaoba/ivector-xvector" -> "idiap/kaldi-ivector"
"zeroQiaoba/ivector-xvector" -> "manojpamk/pytorch_xvectors"
"zeroQiaoba/ivector-xvector" -> "tiagofrepereira2012/ivector_example"
"zeroQiaoba/ivector-xvector" -> "eghbalz/ivector_extractor"
"zeroQiaoba/ivector-xvector" -> "Dannynis/xvector_pytorch"
"zeroQiaoba/ivector-xvector" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"zeroQiaoba/ivector-xvector" -> "tokheim/iVector"
"zeroQiaoba/ivector-xvector" -> "christianvazquez7/ivector"
"zeroQiaoba/ivector-xvector" -> "tuanvu92/VCC2020"
"duhanmin/phonetic-recognition" -> "duhanmin/face-recognition"
"duhanmin/phonetic-recognition" -> "duhanmin/rocketmq-flink"
"duhanmin/phonetic-recognition" -> "duhanmin/Spark-Streaming"
"duhanmin/phonetic-recognition" -> "duhanmin/log-router"
"duhanmin/phonetic-recognition" -> "crouchred/speaker-recognition-py3"
"duhanmin/phonetic-recognition" -> "duhanmin/kafka-flink-hbase"
"qqueing/DeepSpeaker-pytorch" -> "philipperemy/deep-speaker"
"qqueing/DeepSpeaker-pytorch" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"qqueing/DeepSpeaker-pytorch" -> "HarryVolek/PyTorch_Speaker_Verification"
"qqueing/DeepSpeaker-pytorch" -> "manojpamk/pytorch_xvectors"
"qqueing/DeepSpeaker-pytorch" -> "astorfi/3D-convolutional-speaker-recognition-pytorch"
"qqueing/DeepSpeaker-pytorch" -> "a-nagrani/VGGVox"
"qqueing/DeepSpeaker-pytorch" -> "astorfi/3D-convolutional-speaker-recognition"
"qqueing/DeepSpeaker-pytorch" -> "jymsuper/SpeakerRecognition_tutorial"
"qqueing/DeepSpeaker-pytorch" -> "WeidiXie/VGG-Speaker-Recognition"
"qqueing/DeepSpeaker-pytorch" -> "rajathkmp/speaker-verification"
"qqueing/DeepSpeaker-pytorch" -> "hbredin/TristouNet"
"qqueing/DeepSpeaker-pytorch" -> "Janghyun1230/Speaker_Verification"
"qqueing/DeepSpeaker-pytorch" -> "Snowdar/asv-subtools"
"qqueing/DeepSpeaker-pytorch" -> "clovaai/voxceleb_trainer"
"qqueing/DeepSpeaker-pytorch" -> "wangleiai/dVectorSpeakerRecognition"
"Anwarvic/Speaker-Recognition" -> "Anwarvic/CS224n--NLP-with-Deep-Learning"
"Anwarvic/Speaker-Recognition" -> "Anwarvic/Deep-Learning-Nanodegree"
"Anwarvic/Speaker-Recognition" -> "Anwarvic/Deep-Learning-Specialization--Coursera"
"Anwarvic/Speaker-Recognition" -> "vvestman/pytorch-ivectors"
"Anwarvic/Speaker-Recognition" -> "scelesticsiva/speaker_recognition_GMM_UBM"
"Anwarvic/Speaker-Recognition" -> "wangleiai/dVectorSpeakerRecognition"
"Anwarvic/Speaker-Recognition" -> "prajual/Master-Voice_Prints"
"Suhee05/Text-Independent-Speaker-Verification" -> "funcwj/ge2e-speaker-verification"
"andabi/voice-vector" -> "philipperemy/deep-speaker"
"andabi/voice-vector" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"andabi/voice-vector" -> "qqueing/DeepSpeaker-pytorch"
"andabi/voice-vector" -> "bjfu-ai-institute/speaker-recognition-papers"
"andabi/voice-vector" -> "linhdvu14/vggvox-speaker-identification"
"andabi/voice-vector" -> "h-meru/Tacotron-WaveRNN" ["e"=1]
"andabi/voice-vector" -> "SiddGururani/Pytorch-TDNN"
"andabi/voice-vector" -> "rajathkmp/speaker-verification"
"andabi/voice-vector" -> "Kyubyong/expressive_tacotron" ["e"=1]
"andabi/voice-vector" -> "a-nagrani/VGGVox"
"andabi/voice-vector" -> "Janghyun1230/Speaker_Verification"
"ina-foss/inaSpeechSegmenter" -> "taylorlu/Speaker-Diarization"
"ina-foss/inaSpeechSegmenter" -> "amsehili/auditok" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "wq2012/awesome-diarization"
"ina-foss/inaSpeechSegmenter" -> "philipperemy/deep-speaker"
"ina-foss/inaSpeechSegmenter" -> "wiseman/py-webrtcvad" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "qlemaire22/speech-music-detection"
"ina-foss/inaSpeechSegmenter" -> "jtkim-kaist/VAD" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "lhotse-speech/lhotse" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "Snowdar/asv-subtools"
"ina-foss/inaSpeechSegmenter" -> "wq2012/SpectralCluster"
"ina-foss/inaSpeechSegmenter" -> "pykaldi/pykaldi" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "lumaku/ctc-segmentation" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "google/uis-rnn"
"ina-foss/inaSpeechSegmenter" -> "k2-fsa/k2" ["e"=1]
"ina-foss/inaSpeechSegmenter" -> "filippogiruzzi/voice_activity_detection" ["e"=1]
"Mohammed-Raafat/Signals-and-Systems-Project" -> "madhavtummala/SS-Lab"
"Mohammed-Raafat/Signals-and-Systems-Project" -> "jhultman/signals-and-systems"
"cvqluu/GE2E-Loss" -> "funcwj/ge2e-speaker-verification"
"wangleiai/dVectorSpeakerRecognition" -> "bjfu-ai-institute/speaker-recognition-papers"
"wangleiai/dVectorSpeakerRecognition" -> "zengchang233/Speaker_Verification_Tencent"
"wangleiai/dVectorSpeakerRecognition" -> "rajathkmp/speaker-verification"
"wangleiai/dVectorSpeakerRecognition" -> "liyongze/lstm_speaker_verification"
"wangleiai/dVectorSpeakerRecognition" -> "zacharyclam/speaker_recognition"
"wangleiai/dVectorSpeakerRecognition" -> "RicherMans/PLDA"
"WeidiXie/VGG-Speaker-Recognition" -> "taylorlu/Speaker-Diarization"
"WeidiXie/VGG-Speaker-Recognition" -> "mycrazycracy/tf-kaldi-speaker"
"WeidiXie/VGG-Speaker-Recognition" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"WeidiXie/VGG-Speaker-Recognition" -> "HarryVolek/PyTorch_Speaker_Verification"
"WeidiXie/VGG-Speaker-Recognition" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"WeidiXie/VGG-Speaker-Recognition" -> "a-nagrani/VGGVox"
"WeidiXie/VGG-Speaker-Recognition" -> "philipperemy/deep-speaker"
"WeidiXie/VGG-Speaker-Recognition" -> "qqueing/DeepSpeaker-pytorch"
"WeidiXie/VGG-Speaker-Recognition" -> "funcwj/ge2e-speaker-verification"
"WeidiXie/VGG-Speaker-Recognition" -> "linhdvu14/vggvox-speaker-identification"
"WeidiXie/VGG-Speaker-Recognition" -> "Janghyun1230/Speaker_Verification"
"WeidiXie/VGG-Speaker-Recognition" -> "Jungjee/RawNet"
"WeidiXie/VGG-Speaker-Recognition" -> "mravanelli/SincNet"
"WeidiXie/VGG-Speaker-Recognition" -> "Snowdar/asv-subtools"
"WeidiXie/VGG-Speaker-Recognition" -> "manojpamk/pytorch_xvectors"
"zengchang233/GMM_baseline" -> "zengchang233/Speaker_Verification_Tencent"
"duhanmin/face-recognition" -> "duhanmin/phonetic-recognition"
"duhanmin/face-recognition" -> "duhanmin/rocketmq-flink"
"duhanmin/face-recognition" -> "duhanmin/log-router"
"duhanmin/face-recognition" -> "duhanmin/Spark-Streaming"
"duhanmin/face-recognition" -> "duhanmin/kafka-flink-hbase"
"duhanmin/face-recognition" -> "duhanmin/structured-streaming-Kafka2HBase"
"wangwei2009/MSR-Identity-Toolkit-v1.0" -> "zengchang233/Speaker_Verification_Tencent"
"bedangSen/VoiceSens" -> "MohamadMerchant/Voice-Authentication-and-Face-Recognition"
"Anwarvic/Deep-Learning-Nanodegree" -> "Anwarvic/CS224n--NLP-with-Deep-Learning"
"Anwarvic/Deep-Learning-Nanodegree" -> "Anwarvic/Deep-Learning-Specialization--Coursera"
"Anwarvic/Deep-Learning-Nanodegree" -> "Anwarvic/COMS_W4705--NLP"
"duhanmin/log-router" -> "duhanmin/rocketmq-flink"
"revdotcom/revai-python-sdk" -> "revdotcom/revai-node-sdk"
"revdotcom/revai-python-sdk" -> "revdotcom/revai-java-sdk"
"revdotcom/revai-python-sdk" -> "revdotcom/revai-go"
"revdotcom/revai-node-sdk" -> "revdotcom/revai-java-sdk"
"revdotcom/revai-node-sdk" -> "revdotcom/revai-go"
"revdotcom/revai-node-sdk" -> "revdotcom/revai-python-sdk"
"bjfu-ai-institute/speaker-recognition-papers" -> "RaviSoji/plda"
"bjfu-ai-institute/speaker-recognition-papers" -> "wangleiai/dVectorSpeakerRecognition"
"bjfu-ai-institute/speaker-recognition-papers" -> "zengchang233/Speaker_Verification_Tencent"
"bjfu-ai-institute/speaker-recognition-papers" -> "mycrazycracy/tf-kaldi-speaker"
"bjfu-ai-institute/speaker-recognition-papers" -> "RicherMans/PLDA"
"bjfu-ai-institute/speaker-recognition-papers" -> "GauravWaghmare/Speaker-Identification"
"rajathkmp/speaker-verification" -> "wangleiai/dVectorSpeakerRecognition"
"rajathkmp/speaker-verification" -> "GauravWaghmare/Speaker-Identification"
"rajathkmp/speaker-verification" -> "qqueing/DeepSpeaker-pytorch"
"rajathkmp/speaker-verification" -> "RicherMans/PLDA"
"rajathkmp/speaker-verification" -> "bjfu-ai-institute/speaker-recognition-papers"
"rajathkmp/speaker-verification" -> "Janghyun1230/Speaker_Verification"
"rajathkmp/speaker-verification" -> "prajual/Master-Voice_Prints"
"rajathkmp/speaker-verification" -> "philipperemy/deep-speaker"
"linhdvu14/vggvox-speaker-identification" -> "GauravWaghmare/Speaker-Identification"
"linhdvu14/vggvox-speaker-identification" -> "a-nagrani/VGGVox"
"linhdvu14/vggvox-speaker-identification" -> "mycrazycracy/tf-kaldi-speaker"
"linhdvu14/vggvox-speaker-identification" -> "WeidiXie/VGG-Speaker-Recognition"
"linhdvu14/vggvox-speaker-identification" -> "Suhee05/Text-Independent-Speaker-Verification"
"linhdvu14/vggvox-speaker-identification" -> "bjfu-ai-institute/speaker-recognition-papers"
"duhanmin/kafka-flink-hbase" -> "duhanmin/structured-streaming-Kafka2HBase"
"duhanmin/kafka-flink-hbase" -> "xxrznj/flink-kafka-sql"
"spatialaudio/digital-signal-processing-exercises" -> "madhavtummala/SS-Lab"
"spatialaudio/digital-signal-processing-exercises" -> "jhultman/signals-and-systems"
"spatialaudio/digital-signal-processing-exercises" -> "aliasad059/Signals-Systems"
"spatialaudio/digital-signal-processing-exercises" -> "Rez79Kh/Temperature-Control-System"
"spatialaudio/digital-signal-processing-exercises" -> "izlandman/iVector"
"spatialaudio/digital-signal-processing-exercises" -> "JoseRZapata/SyS"
"spatialaudio/digital-signal-processing-exercises" -> "tokheim/iVector"
"spatialaudio/digital-signal-processing-exercises" -> "tiagofrepereira2012/ivector_example"
"spatialaudio/digital-signal-processing-exercises" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"spatialaudio/digital-signal-processing-exercises" -> "d-dimos/microprocessors_laboratory_ntua"
"spatialaudio/digital-signal-processing-exercises" -> "ZeyadTarekk/The86-Pgame"
"spatialaudio/digital-signal-processing-exercises" -> "codieboomboom/CE2007---Microprocessors"
"spatialaudio/digital-signal-processing-exercises" -> "eghbalz/ivector_extractor"
"philipperemy/speaker-change-detection" -> "yinruiqing/change_detection"
"philipperemy/speaker-change-detection" -> "alumae/online_speaker_change_detector"
"qqueing/SR_with_kaldi" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"cvqluu/TDNN" -> "cvqluu/Factorized-TDNN"
"cvqluu/TDNN" -> "jonasvdd/TDNN"
"cvqluu/TDNN" -> "SiddGururani/Pytorch-TDNN"
"cvqluu/TDNN" -> "manojpamk/pytorch_xvectors"
"cvqluu/TDNN" -> "Dannynis/xvector_pytorch"
"cvqluu/TDNN" -> "KrishnaDN/x-vector-pytorch"
"cvqluu/TDNN" -> "RaviSoji/plda"
"cvqluu/TDNN" -> "kefirski/pytorch_TDNN"
"cvqluu/TDNN" -> "jymsuper/SpeakerRecognition_tutorial"
"cvqluu/TDNN" -> "Jamiroquai88/VBDiarization"
"cvqluu/TDNN" -> "funcwj/ge2e-speaker-verification"
"cvqluu/TDNN" -> "jefflai108/pytorch-kaldi-neural-speaker-embeddings"
"cvqluu/TDNN" -> "yuyq96/D-TDNN"
"cvqluu/TDNN" -> "HarryVolek/PyTorch_Speaker_Verification"
"cvqluu/TDNN" -> "qqueing/DeepSpeaker-pytorch"
"funcwj/ge2e-speaker-verification" -> "cvqluu/GE2E-Loss"
"funcwj/ge2e-speaker-verification" -> "Suhee05/Text-Independent-Speaker-Verification"
"funcwj/ge2e-speaker-verification" -> "Dannynis/xvector_pytorch"
"funcwj/ge2e-speaker-verification" -> "jefflai108/pytorch-kaldi-neural-speaker-embeddings"
"funcwj/ge2e-speaker-verification" -> "PiotrTa/Huawei-Challenge-Speaker-Identification"
"funcwj/ge2e-speaker-verification" -> "HarryVolek/PyTorch_Speaker_Verification"
"funcwj/ge2e-speaker-verification" -> "Aurora11111/speaker-recognition-pytorch"
"funcwj/ge2e-speaker-verification" -> "qqueing/speaker_embedding-pytorch"
"Dannynis/xvector_pytorch" -> "SiddGururani/Pytorch-TDNN"
"Dannynis/xvector_pytorch" -> "manojpamk/pytorch_xvectors"
"Dannynis/xvector_pytorch" -> "funcwj/ge2e-speaker-verification"
"Dannynis/xvector_pytorch" -> "cvqluu/TDNN"
"Dannynis/xvector_pytorch" -> "zeroQiaoba/ivector-xvector"
"tiagofrepereira2012/ivector_example" -> "madhavtummala/SS-Lab"
"tiagofrepereira2012/ivector_example" -> "jhultman/signals-and-systems"
"tiagofrepereira2012/ivector_example" -> "aliasad059/Signals-Systems"
"mycrazycracy/speaker-embedding-with-phonetic-information" -> "mycrazycracy/tf-kaldi-speaker"
"mycrazycracy/speaker-embedding-with-phonetic-information" -> "Tianchi-Liu9/SUV"
"fgnt/lazy_dataset" -> "fgnt/paderbox"
"duhanmin/rocketmq-flink" -> "duhanmin/log-router"
"swshon/voxceleb-ivector" -> "vvestman/pytorch-ivectors"
"mycrazycracy/tf-kaldi-speaker" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"mycrazycracy/tf-kaldi-speaker" -> "mycrazycracy/speaker-embedding-with-phonetic-information"
"mycrazycracy/tf-kaldi-speaker" -> "WeidiXie/VGG-Speaker-Recognition"
"mycrazycracy/tf-kaldi-speaker" -> "jefflai108/pytorch-kaldi-neural-speaker-embeddings"
"mycrazycracy/tf-kaldi-speaker" -> "bjfu-ai-institute/speaker-recognition-papers"
"mycrazycracy/tf-kaldi-speaker" -> "RicherMans/PLDA"
"mycrazycracy/tf-kaldi-speaker" -> "funcwj/ge2e-speaker-verification"
"mycrazycracy/tf-kaldi-speaker" -> "linhdvu14/vggvox-speaker-identification"
"mycrazycracy/tf-kaldi-speaker" -> "mycrazycracy/Backends-for-SRE19"
"mycrazycracy/tf-kaldi-speaker" -> "iiscleap/NeuralPlda"
"mycrazycracy/tf-kaldi-speaker" -> "yuyq96/D-TDNN"
"Abhay0899193/Speaker-Recognition" -> "genzen2103/Speaker-Recognition-System-using-GMM"
"pyannote/pyannote-core" -> "pyannote/pyannote-metrics"
"pyannote/pyannote-core" -> "pyannote/pyannote-database"
"scelesticsiva/speaker_recognition_GMM_UBM" -> "dominoanty/SpeakerRecognition"
"scelesticsiva/speaker_recognition_GMM_UBM" -> "fedderrico/ubm_map_diarization"
"Anwarvic/CS224n--NLP-with-Deep-Learning" -> "Anwarvic/Deep-Learning-Nanodegree"
"fedderrico/ubm_map_diarization" -> "dominoanty/SpeakerRecognition"
"Anwarvic/Deep-Learning-Specialization--Coursera" -> "Anwarvic/CS224n--NLP-with-Deep-Learning"
"Anwarvic/Deep-Learning-Specialization--Coursera" -> "Anwarvic/Deep-Learning-Nanodegree"
"Anwarvic/Deep-Learning-Specialization--Coursera" -> "Anwarvic/COMS_W4705--NLP"
"Anwarvic/COMS_W4705--NLP" -> "Anwarvic/CS224n--NLP-with-Deep-Learning"
"zengchang233/Speaker_Verification_Tencent" -> "zengchang94622/x-vector_pytorch"
"zengchang94622/x-vector_pytorch" -> "zengchang233/Speaker_Verification_Tencent"
"yeyupiaoling/VoiceprintRecognition-Keras" -> "yeyupiaoling/VoiceprintRecognition-Tensorflow"
"yeyupiaoling/VoiceprintRecognition-Keras" -> "mialrr/Speaker-Recognition"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "yeyupiaoling/VoiceprintRecognition-Keras"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "yeyupiaoling/VoiceprintRecognition-Pytorch"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "Kevinnan-teen/Speaker-Recognition"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "SunYanCN/Voiceprint-Recognition"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "yeyupiaoling/VoiceprintRecognition-PaddlePaddle" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "LCF2764/speaker-feature-extractor"
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "fighting41love/zhvoice" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Tensorflow" -> "yeyupiaoling/AudioClassification-Tensorflow" ["e"=1]
"KrishnaDN/x-vector-pytorch" -> "manojpamk/pytorch_xvectors"
"KrishnaDN/x-vector-pytorch" -> "cvqluu/TDNN"
"KrishnaDN/x-vector-pytorch" -> "SiddGururani/Pytorch-TDNN"
"hitachi-speech/EEND" -> "Xflick/EEND_PyTorch"
"hitachi-speech/EEND" -> "BUTSpeechFIT/VBx"
"hitachi-speech/EEND" -> "nryant/dscore"
"hitachi-speech/EEND" -> "BUTSpeechFIT/EEND"
"hitachi-speech/EEND" -> "nttcslab-sp/EEND-vector-clustering"
"hitachi-speech/EEND" -> "wq2012/SpectralCluster"
"hitachi-speech/EEND" -> "wq2012/awesome-diarization"
"hitachi-speech/EEND" -> "desh2608/dover-lap"
"hitachi-speech/EEND" -> "DongKeon/Awesome-Speaker-Diarization"
"hitachi-speech/EEND" -> "yufan-aslp/AliMeeting"
"hitachi-speech/EEND" -> "google/speaker-id"
"hitachi-speech/EEND" -> "manojpamk/pytorch_xvectors"
"hitachi-speech/EEND" -> "Snowdar/asv-subtools"
"hitachi-speech/EEND" -> "taylorlu/Speaker-Diarization"
"hitachi-speech/EEND" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"BUTSpeechFIT/VBx" -> "nryant/dscore"
"BUTSpeechFIT/VBx" -> "desh2608/dover-lap"
"BUTSpeechFIT/VBx" -> "hitachi-speech/EEND"
"BUTSpeechFIT/VBx" -> "BUTSpeechFIT/EEND"
"BUTSpeechFIT/VBx" -> "nttcslab-sp/EEND-vector-clustering"
"BUTSpeechFIT/VBx" -> "yufan-aslp/AliMeeting"
"BUTSpeechFIT/VBx" -> "Snowdar/asv-subtools"
"BUTSpeechFIT/VBx" -> "liyunlongaaa/NSD-MS2S"
"BUTSpeechFIT/VBx" -> "Xflick/EEND_PyTorch"
"BUTSpeechFIT/VBx" -> "desh2608/diarizer"
"BUTSpeechFIT/VBx" -> "BUTSpeechFIT/speakerbeam" ["e"=1]
"BUTSpeechFIT/VBx" -> "phonexiaresearch/VBx-training-recipe"
"BUTSpeechFIT/VBx" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"BUTSpeechFIT/VBx" -> "wq2012/SpectralCluster"
"BUTSpeechFIT/VBx" -> "Jamiroquai88/VBDiarization"
"Snowdar/asv-subtools" -> "clovaai/voxceleb_trainer"
"Snowdar/asv-subtools" -> "wenet-e2e/wespeaker"
"Snowdar/asv-subtools" -> "manojpamk/pytorch_xvectors"
"Snowdar/asv-subtools" -> "zyzisyz/mfa_conformer"
"Snowdar/asv-subtools" -> "BUTSpeechFIT/VBx"
"Snowdar/asv-subtools" -> "Jungjee/RawNet"
"Snowdar/asv-subtools" -> "TaoRuijie/ECAPA-TDNN"
"Snowdar/asv-subtools" -> "hitachi-speech/EEND"
"Snowdar/asv-subtools" -> "wq2012/awesome-diarization"
"Snowdar/asv-subtools" -> "lhotse-speech/lhotse" ["e"=1]
"Snowdar/asv-subtools" -> "k2-fsa/k2" ["e"=1]
"Snowdar/asv-subtools" -> "KarelVesely84/kaldi-io-for-python" ["e"=1]
"Snowdar/asv-subtools" -> "nryant/dscore"
"Snowdar/asv-subtools" -> "HarryVolek/PyTorch_Speaker_Verification"
"Snowdar/asv-subtools" -> "qqueing/DeepSpeaker-pytorch"
"Xflick/EEND_PyTorch" -> "BUTSpeechFIT/EEND"
"Xflick/EEND_PyTorch" -> "nttcslab-sp/EEND-vector-clustering"
"Xflick/EEND_PyTorch" -> "hitachi-speech/EEND"
"Xflick/EEND_PyTorch" -> "zcxu-eric/AVA-AVD" ["e"=1]
"Xflick/EEND_PyTorch" -> "Audio-WestlakeU/FS-EEND"
"Xflick/EEND_PyTorch" -> "Maokui-He/NSD-MA-MSE"
"Xflick/EEND_PyTorch" -> "yufan-aslp/AliMeeting"
"Xflick/EEND_PyTorch" -> "BUTSpeechFIT/VBx"
"clovaai/voxceleb_trainer" -> "TaoRuijie/ECAPA-TDNN"
"clovaai/voxceleb_trainer" -> "Snowdar/asv-subtools"
"clovaai/voxceleb_trainer" -> "wenet-e2e/wespeaker"
"clovaai/voxceleb_trainer" -> "Jungjee/RawNet"
"clovaai/voxceleb_trainer" -> "HarryVolek/PyTorch_Speaker_Verification"
"clovaai/voxceleb_trainer" -> "manojpamk/pytorch_xvectors"
"clovaai/voxceleb_trainer" -> "wq2012/awesome-diarization"
"clovaai/voxceleb_trainer" -> "mravanelli/SincNet"
"clovaai/voxceleb_trainer" -> "a-nagrani/VGGVox"
"clovaai/voxceleb_trainer" -> "BUTSpeechFIT/VBx"
"clovaai/voxceleb_trainer" -> "s3prl/s3prl" ["e"=1]
"clovaai/voxceleb_trainer" -> "hitachi-speech/EEND"
"clovaai/voxceleb_trainer" -> "zyzisyz/mfa_conformer"
"clovaai/voxceleb_trainer" -> "qqueing/DeepSpeaker-pytorch"
"clovaai/voxceleb_trainer" -> "taylorlu/Speaker-Diarization"
"Python-World/Python_and_the_Web" -> "Python-World/snippets"
"Python-World/Python_and_the_Web" -> "Py-Contributors/awesomeScripts" ["e"=1]
"Python-World/Python_and_the_Web" -> "aayushi-droid/Python-Thunder"
"Python-World/Python_and_the_Web" -> "Python-World/Joble"
"Python-World/Python_and_the_Web" -> "Python-World/Py-Resources"
"Python-World/Python_and_the_Web" -> "Python-World/python-world.github.io"
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "funcwj/ge2e-speaker-verification"
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "cvqluu/dropclass_speaker"
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "nii-yamagishilab/multi-speaker-tacotron" ["e"=1]
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "mycrazycracy/tf-kaldi-speaker"
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" -> "manojpamk/pytorch_xvectors"
"yistLin/dvector" -> "manojpamk/pytorch_xvectors"
"yistLin/dvector" -> "yistLin/universal-vocoder" ["e"=1]
"yistLin/dvector" -> "cyhuang-tw/AdaIN-VC" ["e"=1]
"yistLin/dvector" -> "yistLin/FragmentVC" ["e"=1]
"yistLin/dvector" -> "jymsuper/SpeakerRecognition_tutorial"
"yistLin/dvector" -> "HarryVolek/PyTorch_Speaker_Verification"
"yistLin/dvector" -> "howard1337/S2VC" ["e"=1]
"fgnt/paderbox" -> "fgnt/lazy_dataset"
"Speaker-Identification/You-Only-Speak-Once" -> "NaveedShahid/Voice-Authentication-CNN"
"joonson/voxconverse" -> "nryant/dscore"
"joonson/voxconverse" -> "BUTSpeechFIT/AMI-diarization-setup"
"joonson/voxconverse" -> "tuanvu92/VCC2020"
"joonson/voxconverse" -> "pedrocolon93/ivectormatlabmsrit"
"joonson/voxconverse" -> "nttcslab-sp/EEND-vector-clustering"
"joonson/voxconverse" -> "madhavtummala/SS-Lab"
"joonson/voxconverse" -> "jhultman/signals-and-systems"
"joonson/voxconverse" -> "aliasad059/Signals-Systems"
"joonson/voxconverse" -> "izlandman/iVector"
"joonson/voxconverse" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"joonson/voxconverse" -> "JoseRZapata/SyS"
"joonson/voxconverse" -> "tokheim/iVector"
"joonson/voxconverse" -> "tiagofrepereira2012/ivector_example"
"joonson/voxconverse" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"joonson/voxconverse" -> "christianvazquez7/ivector"
"HuangZiliAndy/RPNSD" -> "FlorianKrey/DNC"
"HuangZiliAndy/RPNSD" -> "iiscleap/self_supervised_AHC"
"HuangZiliAndy/RPNSD" -> "desh2608/dover-lap"
"HuangZiliAndy/RPNSD" -> "nttcslab-sp/EEND-vector-clustering"
"DonkeyShot21/uis-rnn-sml" -> "FlorianKrey/DNC"
"TheSUPERCD/8bit_MicroComputer_Verilog" -> "adibis/Interrupt_Controller"
"TheSUPERCD/8bit_MicroComputer_Verilog" -> "sudhamshu091/RISC-Pipelined-Processor-32-bit-Verilog"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "desh2608/dover-lap"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "BUTSpeechFIT/EEND"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "nttcslab-sp/EEND-vector-clustering"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "nryant/dscore"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "HuangZiliAndy/RPNSD"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "BUTSpeechFIT/VBx"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "joonson/voxconverse"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "hitachi-speech/EEND"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "liyunlongaaa/NSD-MS2S"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "Xflick/EEND_PyTorch"
"tango4j/Auto-Tuning-Spectral-Clustering" -> "yufan-aslp/AliMeeting"
"SunYanCN/Voiceprint-Recognition" -> "mialrr/Speaker-Recognition"
"vJechsmayr/PythonAlgorithms" -> "aayushi-droid/Python-Thunder"
"x4nth055/gender-recognition-by-voice" -> "SuperKogito/Voice-based-gender-recognition"
"yuyq96/D-TDNN" -> "cvqluu/Factorized-TDNN"
"FlorianKrey/DNC" -> "HuangZiliAndy/RPNSD"
"FlorianKrey/DNC" -> "DonkeyShot21/uis-rnn-sml"
"aayushi-droid/Python-Thunder" -> "NullDev/Hacktoberfest-2020-FizzBuzz"
"lawlict/ECAPA-TDNN" -> "yuyq96/D-TDNN"
"lawlict/ECAPA-TDNN" -> "ranchlai/speaker-verification"
"lawlict/ECAPA-TDNN" -> "TaoRuijie/ECAPA-TDNN"
"VITA-Group/AutoSpeech" -> "Jungjee/RawNet"
"VITA-Group/AutoSpeech" -> "jymsuper/SpeakerRecognition_tutorial"
"VITA-Group/AutoSpeech" -> "joonson/voxceleb_unsupervised"
"VITA-Group/AutoSpeech" -> "seongmin-kye/meta-SR"
"VITA-Group/AutoSpeech" -> "Snowdar/asv-subtools"
"VITA-Group/AutoSpeech" -> "yistLin/dvector"
"revdotcom/revai-java-sdk" -> "revdotcom/revai-go"
"revdotcom/revai-java-sdk" -> "revdotcom/revai-node-sdk"
"cvqluu/Factorized-TDNN" -> "cvqluu/TDNN"
"cvqluu/Factorized-TDNN" -> "yuyq96/D-TDNN"
"cvqluu/Factorized-TDNN" -> "manojpamk/pytorch_xvectors"
"cvqluu/Factorized-TDNN" -> "RicherMans/PLDA"
"cvqluu/Factorized-TDNN" -> "kefirski/pytorch_TDNN"
"cvqluu/Factorized-TDNN" -> "RaviSoji/plda"
"cvqluu/Factorized-TDNN" -> "lawlict/ECAPA-TDNN"
"iiscleap/NeuralPlda" -> "cvqluu/dropclass_speaker"
"iiscleap/NeuralPlda" -> "RaviSoji/plda"
"iiscleap/NeuralPlda" -> "iiscleap/E2E-NPLDA"
"joonson/voxceleb_unsupervised" -> "a-nagrani/VoxSRC2020"
"joonson/voxceleb_unsupervised" -> "theolepage/sslsv"
"joonson/voxceleb_unsupervised" -> "TaoRuijie/Loss-Gated-Learning"
"joonson/voxceleb_unsupervised" -> "wngh1187/RawNeXt"
"Python-World/Joble" -> "Python-World/GitProfile"
"manojpamk/pytorch_xvectors" -> "KrishnaDN/x-vector-pytorch"
"manojpamk/pytorch_xvectors" -> "Dannynis/xvector_pytorch"
"manojpamk/pytorch_xvectors" -> "Snowdar/asv-subtools"
"manojpamk/pytorch_xvectors" -> "zeroQiaoba/ivector-xvector"
"manojpamk/pytorch_xvectors" -> "cvqluu/TDNN"
"manojpamk/pytorch_xvectors" -> "qqueing/DeepSpeaker-pytorch"
"manojpamk/pytorch_xvectors" -> "HarryVolek/PyTorch_Speaker_Verification"
"manojpamk/pytorch_xvectors" -> "yistLin/dvector"
"manojpamk/pytorch_xvectors" -> "hitachi-speech/EEND"
"manojpamk/pytorch_xvectors" -> "RaviSoji/plda"
"manojpamk/pytorch_xvectors" -> "clovaai/voxceleb_trainer"
"manojpamk/pytorch_xvectors" -> "jefflai108/pytorch-kaldi-neural-speaker-embeddings"
"manojpamk/pytorch_xvectors" -> "cvqluu/Factorized-TDNN"
"manojpamk/pytorch_xvectors" -> "iiscleap/NeuralPlda"
"manojpamk/pytorch_xvectors" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"desh2608/dover-lap" -> "desh2608/diarizer"
"desh2608/dover-lap" -> "BUTSpeechFIT/VBx"
"desh2608/dover-lap" -> "desh2608/gss"
"zengchang233/MTGAN" -> "zengchang233/Speaker_Verification_Tencent"
"jhultman/signals-and-systems" -> "madhavtummala/SS-Lab"
"fgnt/padertorch" -> "fgnt/lazy_dataset"
"fgnt/padertorch" -> "fgnt/meeteval"
"fgnt/padertorch" -> "fgnt/paderbox"
"vvestman/pytorch-ivectors" -> "swshon/voxceleb-ivector"
"dodohow1011/TS-VAD" -> "desh2608/diarizer"
"dodohow1011/TS-VAD" -> "desh2608/dover-lap"
"dodohow1011/TS-VAD" -> "BUTSpeechFIT/EEND"
"revdotcom/revai-go" -> "revdotcom/revai-java-sdk"
"revdotcom/revai-go" -> "revdotcom/revai-node-sdk"
"a-nagrani/VoxSRC2020" -> "joonson/voxceleb_unsupervised"
"jsalt2020-asrdiar/jsalt2020_simulate" -> "liyunlongaaa/NSD-MS2S"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "TaoRuijie/ECAPA-TDNN"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/VoiceprintRecognition-Tensorflow"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "fighting41love/zhvoice" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/AudioClassification-Pytorch" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "wenet-e2e/wespeaker"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "modelscope/3D-Speaker"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "clovaai/voxceleb_trainer"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/VoiceprintRecognition-PaddlePaddle" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "Snowdar/asv-subtools"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/MASR" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "zyzisyz/mfa_conformer"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "Kevinnan-teen/Speaker-Recognition"
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "yeyupiaoling/PPASR" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "wenet-e2e/wekws" ["e"=1]
"yeyupiaoling/VoiceprintRecognition-Pytorch" -> "2DIPW/audio_dataset_vpr" ["e"=1]
"Python-World/Py-Resources" -> "madhavtummala/SS-Lab"
"Python-World/Py-Resources" -> "jhultman/signals-and-systems"
"Python-World/Py-Resources" -> "aliasad059/Signals-Systems"
"Python-World/Py-Resources" -> "izlandman/iVector"
"Python-World/Py-Resources" -> "JoseRZapata/SyS"
"Python-World/Py-Resources" -> "tokheim/iVector"
"Python-World/Py-Resources" -> "tiagofrepereira2012/ivector_example"
"Python-World/Py-Resources" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"Python-World/Py-Resources" -> "christianvazquez7/ivector"
"Python-World/Py-Resources" -> "d-dimos/microprocessors_laboratory_ntua"
"Python-World/Py-Resources" -> "ZeyadTarekk/The86-Pgame"
"Python-World/Py-Resources" -> "Rehan-Ahmad/SpeakerDiarization"
"Python-World/Py-Resources" -> "tuanvu92/VCC2020"
"Python-World/Py-Resources" -> "eghbalz/ivector_extractor"
"Python-World/Py-Resources" -> "Rez79Kh/Temperature-Control-System"
"sudhamshu091/Single-Cycle-Risc-Processor-32-bit-Verilog" -> "sudhamshu091/Single-Cycle-Risc-Pipelined-Processor-Verilog"
"cvqluu/simple_diarizer" -> "desh2608/diarizer"
"Kevinnan-teen/Speaker-Recognition" -> "yeyupiaoling/VoiceprintRecognition-Tensorflow"
"revdotcom/speech-datasets" -> "revdotcom/fstalign"
"sudhamshu091/RISC-Pipelined-Processor-32-bit-Verilog" -> "sudhamshu091/Single-Cycle-Risc-Pipelined-Processor-Verilog"
"NullDev/Hacktoberfest-2020-FizzBuzz" -> "aayushi-droid/Python-Thunder"
"revdotcom/fstalign" -> "revdotcom/revai-node-sdk"
"revdotcom/fstalign" -> "revdotcom/revai-java-sdk"
"revdotcom/fstalign" -> "revdotcom/revai-python-sdk"
"revdotcom/fstalign" -> "revdotcom/speech-datasets"
"revdotcom/fstalign" -> "revdotcom/revai-go"
"revdotcom/fstalign" -> "revdotcom/reverb"
"ranchlai/speaker-verification" -> "lawlict/ECAPA-TDNN"
"ranchlai/speaker-verification" -> "zhilangtaosha/SpeakerVerification_AMSoftmax_pytorch"
"phonexiaresearch/VBx-training-recipe" -> "BUTSpeechFIT/DVBx"
"pyannote/AMI-diarization-setup" -> "BUTSpeechFIT/AMI-diarization-setup"
"BUTSpeechFIT/AMI-diarization-setup" -> "pyannote/AMI-diarization-setup"
"NaveedShahid/Voice-Authentication-CNN" -> "SEERNET/Voice-Prints"
"desh2608/spyder" -> "desh2608/diarizer"
"alumae/kiirkirjutaja" -> "alumae/streaming-punctuator"
"alumae/kiirkirjutaja" -> "alumae/online_speaker_change_detector"
"nii-yamagishilab/Attention_Backend_for_ASV" -> "theolepage/sslsv"
"Python-World/snippets" -> "Python-World/GitProfile"
"felixfuyihui/AISHELL-4" -> "yufan-aslp/AliMeeting"
"felixfuyihui/AISHELL-4" -> "desh2608/dover-lap"
"felixfuyihui/AISHELL-4" -> "chenzhuo1011/libri_css" ["e"=1]
"wenet-e2e/wespeaker" -> "Snowdar/asv-subtools"
"wenet-e2e/wespeaker" -> "modelscope/3D-Speaker"
"wenet-e2e/wespeaker" -> "clovaai/voxceleb_trainer"
"wenet-e2e/wespeaker" -> "TaoRuijie/ECAPA-TDNN"
"wenet-e2e/wespeaker" -> "zyzisyz/mfa_conformer"
"wenet-e2e/wespeaker" -> "wenet-e2e/wekws" ["e"=1]
"wenet-e2e/wespeaker" -> "wenet-e2e/wesep" ["e"=1]
"wenet-e2e/wespeaker" -> "ddlBoJack/Speech-Resources" ["e"=1]
"wenet-e2e/wespeaker" -> "IDRnD/redimnet"
"wenet-e2e/wespeaker" -> "hitachi-speech/EEND"
"wenet-e2e/wespeaker" -> "k2-fsa/k2" ["e"=1]
"wenet-e2e/wespeaker" -> "BUTSpeechFIT/VBx"
"wenet-e2e/wespeaker" -> "DongKeon/Awesome-Speaker-Diarization"
"wenet-e2e/wespeaker" -> "k2-fsa/icefall" ["e"=1]
"wenet-e2e/wespeaker" -> "ga642381/speech-trident" ["e"=1]
"TaoRuijie/ECAPA-TDNN" -> "clovaai/voxceleb_trainer"
"TaoRuijie/ECAPA-TDNN" -> "wenet-e2e/wespeaker"
"TaoRuijie/ECAPA-TDNN" -> "Snowdar/asv-subtools"
"TaoRuijie/ECAPA-TDNN" -> "zyzisyz/mfa_conformer"
"TaoRuijie/ECAPA-TDNN" -> "lawlict/ECAPA-TDNN"
"TaoRuijie/ECAPA-TDNN" -> "yeyupiaoling/VoiceprintRecognition-Pytorch"
"TaoRuijie/ECAPA-TDNN" -> "TaoRuijie/Loss-Gated-Learning"
"TaoRuijie/ECAPA-TDNN" -> "Jungjee/RawNet"
"TaoRuijie/ECAPA-TDNN" -> "ranchlai/speaker-verification"
"TaoRuijie/ECAPA-TDNN" -> "asvspoof-challenge/2021" ["e"=1]
"TaoRuijie/ECAPA-TDNN" -> "modelscope/3D-Speaker"
"TaoRuijie/ECAPA-TDNN" -> "ddlBoJack/Speech-Resources" ["e"=1]
"TaoRuijie/ECAPA-TDNN" -> "manojpamk/pytorch_xvectors"
"TaoRuijie/ECAPA-TDNN" -> "nii-yamagishilab/project-NN-Pytorch-scripts" ["e"=1]
"TaoRuijie/ECAPA-TDNN" -> "aliutkus/speechmetrics" ["e"=1]
"yufan-aslp/AliMeeting" -> "desh2608/dover-lap"
"yufan-aslp/AliMeeting" -> "desh2608/gss"
"yufan-aslp/AliMeeting" -> "BUTSpeechFIT/VBx"
"yufan-aslp/AliMeeting" -> "Sanyuan-Chen/CSS_with_Conformer" ["e"=1]
"yufan-aslp/AliMeeting" -> "Xflick/EEND_PyTorch"
"yufan-aslp/AliMeeting" -> "felixfuyihui/AISHELL-4"
"zyzisyz/mfa_conformer" -> "TaoRuijie/Loss-Gated-Learning"
"zyzisyz/mfa_conformer" -> "Snowdar/asv-subtools"
"zyzisyz/mfa_conformer" -> "TaoRuijie/AVCleanse" ["e"=1]
"zyzisyz/mfa_conformer" -> "joonson/voxceleb_unsupervised"
"zyzisyz/mfa_conformer" -> "TaoRuijie/ECAPA-TDNN"
"zyzisyz/mfa_conformer" -> "wenet-e2e/wespeaker"
"zyzisyz/mfa_conformer" -> "theolepage/sslsv"
"zyzisyz/mfa_conformer" -> "wngh1187/RawNeXt"
"nikvaessen/w2v2-speaker" -> "nii-yamagishilab/Attention_Backend_for_ASV"
"nikvaessen/w2v2-speaker" -> "ranchlai/speaker-verification"
"nikvaessen/w2v2-speaker" -> "zyzisyz/mfa_conformer"
"idiap/kaldi-ivector" -> "tiagofrepereira2012/ivector_example"
"idiap/kaldi-ivector" -> "eghbalz/ivector_extractor"
"idiap/kaldi-ivector" -> "izlandman/iVector"
"idiap/kaldi-ivector" -> "pedrocolon93/ivectormatlabmsrit"
"idiap/kaldi-ivector" -> "tokheim/iVector"
"idiap/kaldi-ivector" -> "madhavtummala/SS-Lab"
"idiap/kaldi-ivector" -> "jhultman/signals-and-systems"
"idiap/kaldi-ivector" -> "aliasad059/Signals-Systems"
"idiap/kaldi-ivector" -> "JoseRZapata/SyS"
"idiap/kaldi-ivector" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"idiap/kaldi-ivector" -> "christianvazquez7/ivector"
"idiap/kaldi-ivector" -> "d-dimos/microprocessors_laboratory_ntua"
"idiap/kaldi-ivector" -> "ZeyadTarekk/The86-Pgame"
"idiap/kaldi-ivector" -> "Rehan-Ahmad/SpeakerDiarization"
"idiap/kaldi-ivector" -> "tuanvu92/VCC2020"
"nttcslab-sp/EEND-vector-clustering" -> "BUTSpeechFIT/EEND"
"nttcslab-sp/EEND-vector-clustering" -> "Xflick/EEND_PyTorch"
"nttcslab-sp/EEND-vector-clustering" -> "desh2608/diarizer"
"nttcslab-sp/EEND-vector-clustering" -> "BUTSpeechFIT/EEND_dataprep"
"pedrocolon93/ivectormatlabmsrit" -> "izlandman/iVector"
"RicherMans/PLDA" -> "RaviSoji/plda"
"RicherMans/PLDA" -> "Dannynis/xvector_pytorch"
"RicherMans/PLDA" -> "iiscleap/NeuralPlda"
"RicherMans/PLDA" -> "bjfu-ai-institute/speaker-recognition-papers"
"RicherMans/PLDA" -> "wangleiai/dVectorSpeakerRecognition"
"RicherMans/PLDA" -> "mycrazycracy/tf-kaldi-speaker"
"desh2608/gss" -> "liyunlongaaa/NSD-MS2S"
"desh2608/gss" -> "desh2608/diarizer"
"desh2608/gss" -> "fgnt/meeteval"
"desh2608/gss" -> "desh2608/dover-lap"
"desh2608/gss" -> "fgnt/pb_chime5" ["e"=1]
"BUTSpeechFIT/EEND" -> "BUTSpeechFIT/EEND_dataprep"
"BUTSpeechFIT/EEND" -> "Audio-WestlakeU/FS-EEND"
"BUTSpeechFIT/EEND" -> "nttcslab-sp/EEND-vector-clustering"
"BUTSpeechFIT/EEND" -> "Xflick/EEND_PyTorch"
"BUTSpeechFIT/EEND" -> "Maokui-He/NSD-MA-MSE"
"desh2608/diarizer" -> "desh2608/dover-lap"
"desh2608/diarizer" -> "desh2608/spyder"
"desh2608/diarizer" -> "liyunlongaaa/NSD-MS2S"
"desh2608/diarizer" -> "BUTSpeechFIT/EEND_dataprep"
"desh2608/diarizer" -> "Maokui-He/NSD-MA-MSE"
"BUTSpeechFIT/EEND_dataprep" -> "BUTSpeechFIT/EEND"
"BUTSpeechFIT/EEND_dataprep" -> "Maokui-He/NSD-MA-MSE"
"BUTSpeechFIT/EEND_dataprep" -> "fgnt/mms_msg"
"BUTSpeechFIT/EEND_dataprep" -> "desh2608/diarizer"
"Audio-WestlakeU/RCT" -> "Audio-WestlakeU/VINP"
"eghbalz/ivector_extractor" -> "tiagofrepereira2012/ivector_example"
"eghbalz/ivector_extractor" -> "izlandman/iVector"
"eghbalz/ivector_extractor" -> "madhavtummala/SS-Lab"
"eghbalz/ivector_extractor" -> "jhultman/signals-and-systems"
"eghbalz/ivector_extractor" -> "aliasad059/Signals-Systems"
"wngh1187/ExU-Net" -> "ductuantruong/enskd"
"spatialaudio/signals-and-systems-lecture" -> "spatialaudio/digital-signal-processing-lecture" ["e"=1]
"spatialaudio/signals-and-systems-lecture" -> "spatialaudio/digital-signal-processing-exercises"
"spatialaudio/signals-and-systems-lecture" -> "spatialaudio/signals-and-systems-exercises"
"spatialaudio/signals-and-systems-lecture" -> "Mohammed-Raafat/Signals-and-Systems-Project"
"spatialaudio/signals-and-systems-lecture" -> "spatialaudio/data-driven-audio-signal-processing-lecture" ["e"=1]
"spatialaudio/signals-and-systems-lecture" -> "madhavtummala/SS-Lab"
"spatialaudio/signals-and-systems-lecture" -> "jhultman/signals-and-systems"
"spatialaudio/signals-and-systems-lecture" -> "aliasad059/Signals-Systems"
"spatialaudio/signals-and-systems-lecture" -> "izlandman/iVector"
"spatialaudio/signals-and-systems-lecture" -> "JoseRZapata/SyS"
"spatialaudio/signals-and-systems-lecture" -> "tokheim/iVector"
"spatialaudio/signals-and-systems-lecture" -> "tiagofrepereira2012/ivector_example"
"spatialaudio/signals-and-systems-lecture" -> "d-dimos/microprocessors_laboratory_ntua"
"spatialaudio/signals-and-systems-lecture" -> "ZeyadTarekk/The86-Pgame"
"spatialaudio/signals-and-systems-lecture" -> "eghbalz/ivector_extractor"
"TaoRuijie/Loss-Gated-Learning" -> "zyzisyz/mfa_conformer"
"TaoRuijie/Loss-Gated-Learning" -> "theolepage/sslsv"
"TaoRuijie/Loss-Gated-Learning" -> "joonson/voxceleb_unsupervised"
"TaoRuijie/Loss-Gated-Learning" -> "TaoRuijie/AVCleanse" ["e"=1]
"TaoRuijie/Loss-Gated-Learning" -> "shkim816/temporal_dynamic_cnn" ["e"=1]
"aalto-speech/speaker-diarization" -> "taylorlu/Speaker-Diarization"
"aalto-speech/speaker-diarization" -> "aalto-speech/AaltoASR"
"aalto-speech/speaker-diarization" -> "Jamiroquai88/VBDiarization"
"aalto-speech/speaker-diarization" -> "egonina/pycasp"
"aalto-speech/speaker-diarization" -> "yinruiqing/change_detection"
"aalto-speech/speaker-diarization" -> "philipperemy/speaker-change-detection"
"aalto-speech/speaker-diarization" -> "funcwj/deep-clustering" ["e"=1]
"orchidas/Speaker-Recognition" -> "crouchred/speaker-recognition-py3"
"orchidas/Speaker-Recognition" -> "genzen2103/Speaker-Recognition-System-using-GMM"
"GauravWaghmare/Speaker-Identification" -> "swshon/voxceleb-ivector"
"GauravWaghmare/Speaker-Identification" -> "rajathkmp/speaker-verification"
"GauravWaghmare/Speaker-Identification" -> "linhdvu14/vggvox-speaker-identification"
"GauravWaghmare/Speaker-Identification" -> "Atul-Anand-Jha/Speaker-Identification-Python"
"GauravWaghmare/Speaker-Identification" -> "bjfu-ai-institute/speaker-recognition-papers"
"pengzhendong/pyannote-onnx" -> "leohuang2013/pyannote-audio_speaker-diarization_cpp"
"pengzhendong/pyannote-onnx" -> "pengzhendong/pysilero"
"Maokui-He/NSD-MA-MSE" -> "liyunlongaaa/NSD-MS2S"
"Maokui-He/NSD-MA-MSE" -> "BUTSpeechFIT/EEND_dataprep"
"Maokui-He/NSD-MA-MSE" -> "FrenchKrab/IS2023-powerset-diarization"
"Rezar/MLBook" -> "madhavtummala/SS-Lab"
"Rezar/MLBook" -> "jhultman/signals-and-systems"
"Rezar/MLBook" -> "aliasad059/Signals-Systems"
"Rezar/MLBook" -> "izlandman/iVector"
"fgnt/meeteval" -> "liyunlongaaa/NSD-MS2S"
"fgnt/meeteval" -> "desh2608/gss"
"fgnt/meeteval" -> "chimechallenge/chime-utils"
"fgnt/meeteval" -> "BUTSpeechFIT/TS-ASR-Whisper"
"fgnt/meeteval" -> "fgnt/padertorch"
"fgnt/meeteval" -> "desh2608/dover-lap"
"fgnt/meeteval" -> "fgnt/mms_msg"
"astorfi/QR_Code" -> "astorfi/Caffe_Deep_Learning"
"astorfi/QR_Code" -> "astorfi/Local-Histogram-Equalization"
"astorfi/QR_Code" -> "astorfi/Leethcode"
"astorfi/QR_Code" -> "astorfi/Create-LMDB-from-Numpy"
"astorfi/QR_Code" -> "astorfi/Data-Structures-and-Algorithms"
"astorfi/QR_Code" -> "astorfi/OpenCV-Installation"
"modelscope/3D-Speaker" -> "wenet-e2e/wespeaker"
"modelscope/3D-Speaker" -> "FunAudioLLM/SenseVoice" ["e"=1]
"modelscope/3D-Speaker" -> "Snowdar/asv-subtools"
"modelscope/3D-Speaker" -> "TaoRuijie/ECAPA-TDNN"
"modelscope/3D-Speaker" -> "clovaai/voxceleb_trainer"
"modelscope/3D-Speaker" -> "modelscope/FunASR" ["e"=1]
"modelscope/3D-Speaker" -> "wenet-e2e/wenet" ["e"=1]
"modelscope/3D-Speaker" -> "modelscope/ClearerVoice-Studio" ["e"=1]
"modelscope/3D-Speaker" -> "yeyupiaoling/VoiceprintRecognition-Pytorch"
"modelscope/3D-Speaker" -> "ddlBoJack/emotion2vec" ["e"=1]
"modelscope/3D-Speaker" -> "pyannote/pyannote-audio" ["e"=1]
"modelscope/3D-Speaker" -> "FireRedTeam/FireRedASR" ["e"=1]
"modelscope/3D-Speaker" -> "s3prl/s3prl" ["e"=1]
"modelscope/3D-Speaker" -> "QwenLM/Qwen-Audio" ["e"=1]
"modelscope/3D-Speaker" -> "snakers4/silero-vad" ["e"=1]
"hbredin/TristouNet" -> "idiap/kaldi-ivector"
"hbredin/TristouNet" -> "qqueing/DeepSpeaker-pytorch"
"hbredin/TristouNet" -> "RicherMans/PLDA"
"hbredin/TristouNet" -> "qqueing/SR_with_kaldi"
"Audio-WestlakeU/FS-EEND" -> "BUTSpeechFIT/EEND"
"Audio-WestlakeU/FS-EEND" -> "FrenchKrab/IS2023-powerset-diarization"
"Audio-WestlakeU/FS-EEND" -> "liyunlongaaa/NSD-MS2S"
"Audio-WestlakeU/FS-EEND" -> "joonaskalda/PixIT"
"Audio-WestlakeU/FS-EEND" -> "Maokui-He/NSD-MA-MSE"
"Audio-WestlakeU/FS-EEND" -> "Audio-WestlakeU/SAR-SSL"
"Audio-WestlakeU/FS-EEND" -> "Audio-WestlakeU/RealMAN" ["e"=1]
"Audio-WestlakeU/FS-EEND" -> "DongKeon/Awesome-Speaker-Diarization"
"Audio-WestlakeU/FS-EEND" -> "BUTSpeechFIT/EEND_dataprep"
"Audio-WestlakeU/FS-EEND" -> "Audio-WestlakeU/FN-SSL" ["e"=1]
"Audio-WestlakeU/FS-EEND" -> "nttcslab-sp/mamba-diarization"
"primaryobjects/voice-gender" -> "x4nth055/gender-recognition-by-voice"
"primaryobjects/voice-gender" -> "SuperKogito/Voice-based-gender-recognition"
"DongKeon/Awesome-Speaker-Diarization" -> "Audio-WestlakeU/FS-EEND"
"DongKeon/Awesome-Speaker-Diarization" -> "liyunlongaaa/NSD-MS2S"
"DongKeon/Awesome-Speaker-Diarization" -> "FrenchKrab/IS2023-powerset-diarization"
"DongKeon/Awesome-Speaker-Diarization" -> "BUTSpeechFIT/EEND"
"DongKeon/Awesome-Speaker-Diarization" -> "hitachi-speech/EEND"
"DongKeon/Awesome-Speaker-Diarization" -> "joonaskalda/PixIT"
"DongKeon/Awesome-Speaker-Diarization" -> "Maokui-He/NSD-MA-MSE"
"DongKeon/Awesome-Speaker-Diarization" -> "BUTSpeechFIT/EEND_dataprep"
"DongKeon/Awesome-Speaker-Diarization" -> "Xflick/EEND_PyTorch"
"DongKeon/Awesome-Speaker-Diarization" -> "wenet-e2e/wesep" ["e"=1]
"DongKeon/Awesome-Speaker-Diarization" -> "fgnt/meeteval"
"DongKeon/Awesome-Speaker-Diarization" -> "google/speaker-id"
"DongKeon/Awesome-Speaker-Diarization" -> "desh2608/gss"
"DongKeon/Awesome-Speaker-Diarization" -> "BUTSpeechFIT/VBx"
"DongKeon/Awesome-Speaker-Diarization" -> "desh2608/diarizer"
"liuxp0827/govpr" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"liuxp0827/govpr" -> "liuxp0827/Jvpr"
"liuxp0827/govpr" -> "dake/openVP"
"liuxp0827/govpr" -> "ibillxia/VoicePrintReco"
"IDRnD/VoxTube" -> "IDRnD/redimnet"
"ductuantruong/enskd" -> "wngh1187/ExU-Net"
"ALIZE-Speaker-Recognition/LIA_RAL" -> "ALIZE-Speaker-Recognition/alize-core"
"ALIZE-Speaker-Recognition/LIA_RAL" -> "ALIZE-Speaker-Recognition/android-alize"
"ALIZE-Speaker-Recognition/LIA_RAL" -> "ibillxia/VoicePrintReco"
"liyunlongaaa/NSD-MS2S" -> "Maokui-He/NSD-MA-MSE"
"liyunlongaaa/NSD-MS2S" -> "desh2608/diarizer"
"liyunlongaaa/NSD-MS2S" -> "jsalt2020-asrdiar/jsalt2020_simulate"
"liyunlongaaa/NSD-MS2S" -> "fgnt/meeteval"
"liyunlongaaa/NSD-MS2S" -> "Audio-WestlakeU/FS-EEND"
"liyunlongaaa/NSD-MS2S" -> "desh2608/gss"
"liyunlongaaa/NSD-MS2S" -> "joonaskalda/PixIT"
"ALIZE-Speaker-Recognition/alize-core" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"ALIZE-Speaker-Recognition/alize-core" -> "ALIZE-Speaker-Recognition/android-alize"
"ALIZE-Speaker-Recognition/alize-core" -> "ibillxia/VoicePrintReco"
"FrenchKrab/IS2023-powerset-diarization" -> "Maokui-He/NSD-MA-MSE"
"FrenchKrab/IS2023-powerset-diarization" -> "Audio-WestlakeU/FS-EEND"
"FrenchKrab/IS2023-powerset-diarization" -> "clement-pages/gryannote"
"leohuang2013/pyannote-audio_speaker-diarization_cpp" -> "leohuang2013/pyannote-audio_overlapped-speech-detection_cpp"
"pyannote/pyannote-database" -> "pyannote/pyannote-metrics"
"pyannote/pyannote-database" -> "pyannote/pyannote-core"
"pyannote/pyannote-database" -> "pyannote/AMI-diarization-setup"
"Audio-WestlakeU/UMA-ASR" -> "Audio-WestlakeU/VINP"
"Audio-WestlakeU/RVAE-EM" -> "Audio-WestlakeU/VINP"
"chimechallenge/C8DASR-Baseline-NeMo" -> "chimechallenge/chime-utils"
"crouchred/speaker-recognition-py3" -> "ppwwyyxx/speaker-recognition"
"crouchred/speaker-recognition-py3" -> "orchidas/Speaker-Recognition"
"crouchred/speaker-recognition-py3" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"crouchred/speaker-recognition-py3" -> "wangleiai/dVectorSpeakerRecognition"
"crouchred/speaker-recognition-py3" -> "linhdvu14/vggvox-speaker-identification"
"crouchred/speaker-recognition-py3" -> "scelesticsiva/speaker_recognition_GMM_UBM"
"crouchred/speaker-recognition-py3" -> "astorfi/3D-convolutional-speaker-recognition"
"crouchred/speaker-recognition-py3" -> "duhanmin/phonetic-recognition"
"crouchred/speaker-recognition-py3" -> "qqueing/DeepSpeaker-pytorch"
"crouchred/speaker-recognition-py3" -> "GauravWaghmare/Speaker-Identification"
"crouchred/speaker-recognition-py3" -> "Abhay0899193/Speaker-Recognition"
"crouchred/speaker-recognition-py3" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"crouchred/speaker-recognition-py3" -> "jymsuper/SpeakerRecognition_tutorial"
"crouchred/speaker-recognition-py3" -> "idiap/kaldi-ivector"
"crouchred/speaker-recognition-py3" -> "bjfu-ai-institute/speaker-recognition-papers"
"huggingface/diarizers" -> "Audio-WestlakeU/FS-EEND"
"huggingface/diarizers" -> "BUTSpeechFIT/DiariZen"
"huggingface/diarizers" -> "google/speaker-id"
"huggingface/diarizers" -> "huggingface/dataspeech" ["e"=1]
"ALIZE-Speaker-Recognition/android-alize" -> "ALIZE-Speaker-Recognition/alize-core"
"clement-pages/gryannote" -> "nttcslab-sp/mamba-diarization"
"clement-pages/gryannote" -> "FrenchKrab/IS2023-powerset-diarization"
"Audio-WestlakeU/SAR-SSL" -> "Audio-WestlakeU/UMA-ASR"
"Audio-WestlakeU/SAR-SSL" -> "Audio-WestlakeU/VINP"
"dmlguq456/NeXt_TDNN_ASV" -> "ductuantruong/enskd"
"joonaskalda/PixIT" -> "Audio-WestlakeU/FS-EEND"
"microsoft/NOTSOFAR1-Challenge" -> "chimechallenge/chime-utils"
"chimechallenge/chime-utils" -> "chimechallenge/C8DASR-Baseline-NeMo"
"ibillxia/VoicePrintReco" -> "ALIZE-Speaker-Recognition/LIA_RAL"
"ibillxia/VoicePrintReco" -> "ALIZE-Speaker-Recognition/alize-core"
"astorfi/Caffe_Deep_Learning" -> "astorfi/Leethcode"
"astorfi/Caffe_Deep_Learning" -> "astorfi/Create-LMDB-from-Numpy"
"astorfi/Caffe_Deep_Learning" -> "astorfi/Local-Histogram-Equalization"
"astorfi/Caffe_Deep_Learning" -> "astorfi/Data-Structures-and-Algorithms"
"VoxBlink2/ScriptsForVoxBlink2" -> "VoxBlink/ScriptsForVoxBlink"
"valar1234/MIPS" -> "patc15/mipscpu"
"revdotcom/reverb" -> "revdotcom/fstalign"
"revdotcom/reverb" -> "revdotcom/reverb-self-hosted"
"revdotcom/reverb" -> "BUTSpeechFIT/DiariZen"
"revdotcom/reverb" -> "pengzhendong/pyannote-onnx"
"revdotcom/reverb" -> "IDRnD/redimnet"
"modelscope/MemoryScope" -> "revdotcom/reverb"
"modelscope/MemoryScope" -> "memodb-io/memobase" ["e"=1]
"yinruiqing/change_detection" -> "philipperemy/speaker-change-detection"
"astorfi/speechpy" -> "astorfi/3D-convolutional-speaker-recognition"
"astorfi/speechpy" -> "astorfi/TensorFlow-World-Resources" ["e"=1]
"astorfi/speechpy" -> "astorfi/QR_Code"
"astorfi/speechpy" -> "astorfi/Caffe_Deep_Learning"
"astorfi/speechpy" -> "astorfi/Local-Histogram-Equalization"
"astorfi/speechpy" -> "astorfi/Leethcode"
"astorfi/speechpy" -> "jameslyons/python_speech_features" ["e"=1]
"astorfi/speechpy" -> "astorfi/Create-LMDB-from-Numpy"
"astorfi/speechpy" -> "astorfi/pythonic-automatic-email"
"astorfi/speechpy" -> "r9y9/pysptk" ["e"=1]
"astorfi/speechpy" -> "pykaldi/pykaldi" ["e"=1]
"astorfi/speechpy" -> "qqueing/DeepSpeaker-pytorch"
"astorfi/speechpy" -> "ppwwyyxx/speaker-recognition"
"astorfi/speechpy" -> "astorfi/Data-Structures-and-Algorithms"
"astorfi/speechpy" -> "philipperemy/deep-speaker"
"dominoanty/SpeakerRecognition" -> "scelesticsiva/speaker_recognition_GMM_UBM"
"dominoanty/SpeakerRecognition" -> "fedderrico/ubm_map_diarization"
"BUTSpeechFIT/DiariZen" -> "BUTSpeechFIT/TS-ASR-Whisper"
"BUTSpeechFIT/DiariZen" -> "nttcslab-sp/mamba-diarization"
"BUTSpeechFIT/DiariZen" -> "Audio-WestlakeU/FS-EEND"
"BUTSpeechFIT/DiariZen" -> "liyunlongaaa/NSD-MS2S"
"BUTSpeechFIT/DiariZen" -> "clement-pages/gryannote"
"BUTSpeechFIT/DiariZen" -> "BUTSpeechFIT/DiaPer"
"BUTSpeechFIT/DiariZen" -> "BUTSpeechFIT/DiCoW"
"BUTSpeechFIT/DiariZen" -> "BUTSpeechFIT/EEND"
"BUTSpeechFIT/DiariZen" -> "desh2608/diarizer"
"BUTSpeechFIT/DiariZen" -> "Xflick/EEND_PyTorch"
"BUTSpeechFIT/DiariZen" -> "FrenchKrab/IS2023-powerset-diarization"
"BUTSpeechFIT/DiariZen" -> "Maokui-He/NSD-MA-MSE"
"BUTSpeechFIT/DiariZen" -> "tango4j/Auto-Tuning-Spectral-Clustering"
"IDRnD/redimnet" -> "IDRnD/VoxTube"
"IDRnD/redimnet" -> "dmlguq456/NeXt_TDNN_ASV"
"IDRnD/redimnet" -> "VoxBlink2/ScriptsForVoxBlink2"
"IDRnD/redimnet" -> "wenet-e2e/wespeaker"
"IDRnD/redimnet" -> "BUTSpeechFIT/DiariZen"
"BUTSpeechFIT/TS-ASR-Whisper" -> "BUTSpeechFIT/DiCoW"
"BUTSpeechFIT/TS-ASR-Whisper" -> "fgnt/speaker_reassignment"
"BUTSpeechFIT/TS-ASR-Whisper" -> "BUTSpeechFIT/DiaPer"
"BUTSpeechFIT/TS-ASR-Whisper" -> "chimechallenge/chime-utils"
"kefirski/pytorch_TDNN" -> "SiddGururani/Pytorch-TDNN"
"kefirski/pytorch_TDNN" -> "jonasvdd/TDNN"
"RaviSoji/plda" -> "RicherMans/PLDA"
"RaviSoji/plda" -> "iiscleap/NeuralPlda"
"RaviSoji/plda" -> "bjfu-ai-institute/speaker-recognition-papers"
"RaviSoji/plda" -> "manojpamk/pytorch_xvectors"
"RaviSoji/plda" -> "cvqluu/TDNN"
"RaviSoji/plda" -> "juanmc2005/torch-plda"
"RaviSoji/plda" -> "vzxxbacq/PLDA"
"RaviSoji/plda" -> "BUTSpeechFIT/x-vector-kaldi-tf"
"RaviSoji/plda" -> "zeroQiaoba/ivector-xvector"
"RaviSoji/plda" -> "yuyq96/D-TDNN"
"RaviSoji/plda" -> "cvqluu/Factorized-TDNN"
"philipperemy/deep-speaker" -> "qqueing/DeepSpeaker-pytorch"
"philipperemy/deep-speaker" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"philipperemy/deep-speaker" -> "HarryVolek/PyTorch_Speaker_Verification"
"philipperemy/deep-speaker" -> "astorfi/3D-convolutional-speaker-recognition"
"philipperemy/deep-speaker" -> "Janghyun1230/Speaker_Verification"
"philipperemy/deep-speaker" -> "WeidiXie/VGG-Speaker-Recognition"
"philipperemy/deep-speaker" -> "mravanelli/SincNet"
"philipperemy/deep-speaker" -> "wq2012/awesome-diarization"
"philipperemy/deep-speaker" -> "andabi/voice-vector"
"philipperemy/deep-speaker" -> "a-nagrani/VGGVox"
"philipperemy/deep-speaker" -> "manojpamk/pytorch_xvectors"
"philipperemy/deep-speaker" -> "rajathkmp/speaker-verification"
"philipperemy/deep-speaker" -> "google/uis-rnn"
"philipperemy/deep-speaker" -> "taylorlu/Speaker-Diarization"
"philipperemy/deep-speaker" -> "Snowdar/asv-subtools"
"Jamiroquai88/VBDiarization" -> "nryant/dscore"
"Jamiroquai88/VBDiarization" -> "BUTSpeechFIT/VBx"
"Jamiroquai88/VBDiarization" -> "HuangZiliAndy/RPNSD"
"astorfi/3D-convolutional-speaker-recognition" -> "philipperemy/deep-speaker"
"astorfi/3D-convolutional-speaker-recognition" -> "qqueing/DeepSpeaker-pytorch"
"astorfi/3D-convolutional-speaker-recognition" -> "ppwwyyxx/speaker-recognition"
"astorfi/3D-convolutional-speaker-recognition" -> "HarryVolek/PyTorch_Speaker_Verification"
"astorfi/3D-convolutional-speaker-recognition" -> "astorfi/speechpy"
"astorfi/3D-convolutional-speaker-recognition" -> "Janghyun1230/Speaker_Verification"
"astorfi/3D-convolutional-speaker-recognition" -> "WeidiXie/VGG-Speaker-Recognition"
"astorfi/3D-convolutional-speaker-recognition" -> "astorfi/3D-convolutional-speaker-recognition-pytorch"
"astorfi/3D-convolutional-speaker-recognition" -> "crouchred/speaker-recognition-py3"
"astorfi/3D-convolutional-speaker-recognition" -> "a-nagrani/VGGVox"
"astorfi/3D-convolutional-speaker-recognition" -> "Walleclipse/Deep_Speaker-speaker_recognition_system"
"astorfi/3D-convolutional-speaker-recognition" -> "mravanelli/SincNet"
"astorfi/3D-convolutional-speaker-recognition" -> "rajathkmp/speaker-verification"
"astorfi/3D-convolutional-speaker-recognition" -> "andabi/voice-vector"
"astorfi/3D-convolutional-speaker-recognition" -> "google/uis-rnn"
"SiddGururani/Pytorch-TDNN" -> "kefirski/pytorch_TDNN"
"SiddGururani/Pytorch-TDNN" -> "Dannynis/xvector_pytorch"
"SiddGururani/Pytorch-TDNN" -> "jonasvdd/TDNN"
"SiddGururani/Pytorch-TDNN" -> "cvqluu/TDNN"
"Audio-WestlakeU/CleanMel" -> "Audio-WestlakeU/VINP"
"Audio-WestlakeU/CleanMel" -> "Audio-WestlakeU/RCT"
"astorfi/pythonic-automatic-email" -> "astorfi/Local-Histogram-Equalization"
"astorfi/pythonic-automatic-email" -> "astorfi/Leethcode"
"astorfi/pythonic-automatic-email" -> "astorfi/Caffe_Deep_Learning"
"astorfi/pythonic-automatic-email" -> "astorfi/Create-LMDB-from-Numpy"
"astorfi/pythonic-automatic-email" -> "astorfi/QR_Code"
"astorfi/pythonic-automatic-email" -> "astorfi/Data-Structures-and-Algorithms"
"astorfi/pythonic-automatic-email" -> "astorfi/OpenCV-Installation"
"BUTSpeechFIT/DiCoW" -> "BUTSpeechFIT/TS-ASR-Whisper"
"nryant/dscore" ["l"="36.968,3.219"]
"BUTSpeechFIT/VBx" ["l"="36.979,3.192"]
"joonson/voxconverse" ["l"="36.923,3.298"]
"hitachi-speech/EEND" ["l"="36.985,3.21"]
"desh2608/dover-lap" ["l"="36.964,3.159"]
"wq2012/SpectralCluster" ["l"="37.003,3.223"]
"Jamiroquai88/VBDiarization" ["l"="36.985,3.246"]
"HuangZiliAndy/RPNSD" ["l"="36.933,3.21"]
"nttcslab-sp/EEND-vector-clustering" ["l"="36.938,3.192"]
"pyannote/pyannote-metrics" ["l"="36.924,3.237"]
"tango4j/Auto-Tuning-Spectral-Clustering" ["l"="36.948,3.203"]
"FlorianKrey/DNC" ["l"="36.947,3.222"]
"Xflick/EEND_PyTorch" ["l"="36.951,3.176"]
"yufan-aslp/AliMeeting" ["l"="36.978,3.165"]
"wq2012/awesome-diarization" ["l"="37.021,3.203"]
"google/speaker-id" ["l"="36.962,3.193"]
"google/uis-rnn" ["l"="37.055,3.21"]
"taylorlu/Speaker-Diarization" ["l"="37.03,3.237"]
"pyannote/pyannote-audio" ["l"="40.503,3.253"]
"Snowdar/asv-subtools" ["l"="37.008,3.247"]
"HarryVolek/PyTorch_Speaker_Verification" ["l"="37.06,3.26"]
"clovaai/voxceleb_trainer" ["l"="37.018,3.264"]
"DongKeon/Awesome-Speaker-Diarization" ["l"="36.947,3.158"]
"juanmc2005/diart" ["l"="40.467,3.212"]
"philipperemy/deep-speaker" ["l"="37.091,3.236"]
"lhotse-speech/lhotse" ["l"="35.675,2.368"]
"neelkshah/MIPS-Processor" ["l"="36.89,3.397"]
"zslwyuan/Basic-SIMD-Processor-Verilog-Tutorial" ["l"="32.924,-2.771"]
"adibis/DDR2_Controller" ["l"="32.86,-2.772"]
"madhavtummala/SS-Lab" ["l"="36.91,3.367"]
"jhultman/signals-and-systems" ["l"="36.911,3.358"]
"aliasad059/Signals-Systems" ["l"="36.906,3.362"]
"izlandman/iVector" ["l"="36.906,3.353"]
"TheSUPERCD/8bit_MicroComputer_Verilog" ["l"="36.882,3.467"]
"JoseRZapata/SyS" ["l"="36.9,3.365"]
"tokheim/iVector" ["l"="36.921,3.359"]
"tiagofrepereira2012/ivector_example" ["l"="36.921,3.365"]
"Mohammed-Raafat/Signals-and-Systems-Project" ["l"="36.899,3.358"]
"d-dimos/microprocessors_laboratory_ntua" ["l"="36.921,3.383"]
"ZeyadTarekk/The86-Pgame" ["l"="36.923,3.392"]
"mravanelli/SincNet" ["l"="37.062,3.234"]
"mravanelli/pytorch-kaldi" ["l"="35.563,2.316"]
"Jungjee/RawNet" ["l"="37.035,3.278"]
"santi-pdp/pase" ["l"="35.76,2.334"]
"WeidiXie/VGG-Speaker-Recognition" ["l"="37.077,3.273"]
"KarelVesely84/kaldi-io-for-python" ["l"="35.679,2.347"]
"manojpamk/pytorch_xvectors" ["l"="37.046,3.295"]
"pykaldi/pykaldi" ["l"="35.62,2.358"]
"grausof/keras-sincnet" ["l"="37.097,3.171"]
"s3prl/s3prl" ["l"="37.227,2.374"]
"astorfi/3D-convolutional-speaker-recognition-pytorch" ["l"="37.106,3.291"]
"qqueing/DeepSpeaker-pytorch" ["l"="37.093,3.277"]
"jymsuper/SpeakerRecognition_tutorial" ["l"="37.083,3.288"]
"Walleclipse/Deep_Speaker-speaker_recognition_system" ["l"="37.111,3.257"]
"Aurora11111/speaker-recognition-pytorch" ["l"="37.142,3.324"]
"funcwj/ge2e-speaker-verification" ["l"="37.1,3.314"]
"zacharyclam/speaker_recognition" ["l"="37.134,3.23"]
"Suhee05/Text-Independent-Speaker-Verification" ["l"="37.127,3.309"]
"Dannynis/xvector_pytorch" ["l"="37.069,3.325"]
"VITA-Group/AutoSpeech" ["l"="37.025,3.3"]
"asvspoof-challenge/2021" ["l"="38.088,2.498"]
"sasv-challenge/SASVC2022_Baseline" ["l"="38.098,2.46"]
"clovaai/aasist" ["l"="38.096,2.483"]
"TakHemlata/SSL_Anti-spoofing" ["l"="38.1,2.508"]
"TaoRuijie/ECAPA-TDNN" ["l"="36.982,3.29"]
"joonson/voxceleb_unsupervised" ["l"="36.985,3.331"]
"seongmin-kye/meta-SR" ["l"="37.035,3.317"]
"Janghyun1230/Speaker_Verification" ["l"="37.081,3.253"]
"rajathkmp/speaker-verification" ["l"="37.125,3.246"]
"astorfi/3D-convolutional-speaker-recognition" ["l"="37.13,3.264"]
"yistLin/dvector" ["l"="37.063,3.291"]
"RDShi/voiceprint" ["l"="37.242,3.164"]
"prajual/Master-Voice_Prints" ["l"="37.203,3.198"]
"wiseman/py-webrtcvad" ["l"="36.78,4.48"]
"maum-ai/voicefilter" ["l"="36.642,4.325"]
"Atul-Anand-Jha/Speaker-Identification-Python" ["l"="37.181,3.268"]
"GauravWaghmare/Speaker-Identification" ["l"="37.162,3.273"]
"abhijeet3922/Speaker-identification-using-GMMs" ["l"="37.233,3.253"]
"oscarknagg/voicemap" ["l"="37.175,3.247"]
"SuperKogito/Voice-based-speaker-identification" ["l"="37.273,3.251"]
"orchidas/Speaker-Recognition" ["l"="37.203,3.268"]
"ppwwyyxx/speaker-recognition" ["l"="37.175,3.294"]
"VaibhavBhapkar/Speaker-Identification-Using-Machine-Learning" ["l"="37.223,3.283"]
"Speaker-Identification/You-Only-Speak-Once" ["l"="37.308,3.288"]
"crouchred/speaker-recognition-py3" ["l"="37.154,3.261"]
"linhdvu14/vggvox-speaker-identification" ["l"="37.137,3.284"]
"PiotrTa/Huawei-Challenge-Speaker-Identification" ["l"="37.154,3.302"]
"bjfu-ai-institute/speaker-recognition-papers" ["l"="37.128,3.291"]
"a-nagrani/VGGVox" ["l"="37.097,3.263"]
"andabi/voice-vector" ["l"="37.117,3.28"]
"wangleiai/dVectorSpeakerRecognition" ["l"="37.144,3.249"]
"BUTSpeechFIT/EEND" ["l"="36.934,3.169"]
"huggingface/diarizers" ["l"="36.906,3.171"]
"Audio-WestlakeU/FS-EEND" ["l"="36.916,3.138"]
"BUTSpeechFIT/DiariZen" ["l"="36.894,3.141"]
"dodohow1011/TS-VAD" ["l"="36.967,3.144"]
"cvqluu/TDNN" ["l"="37.056,3.326"]
"SuperKogito/Voice-based-gender-recognition" ["l"="37.33,3.23"]
"x4nth055/gender-recognition-by-voice" ["l"="37.361,3.232"]
"primaryobjects/voice-gender" ["l"="37.368,3.208"]
"danstowell/smacpy" ["l"="38.192,4.166"]
"Abhay0899193/Speaker-Recognition" ["l"="37.253,3.25"]
"BUTSpeechFIT/x-vector-kaldi-tf" ["l"="37.083,3.318"]
"hbredin/TristouNet" ["l"="37.064,3.311"]
"amaurycrickx/recognito" ["l"="37.243,3.325"]
"ALIZE-Speaker-Recognition/LIA_RAL" ["l"="37.288,3.372"]
"Adirockzz95/Piwho" ["l"="37.28,3.332"]
"mycrazycracy/tf-kaldi-speaker" ["l"="37.113,3.329"]
"qqueing/SR_with_kaldi" ["l"="37.087,3.352"]
"zeroQiaoba/ivector-xvector" ["l"="37.003,3.339"]
"jefflai108/pytorch-kaldi-neural-speaker-embeddings" ["l"="37.091,3.336"]
"mycrazycracy/speaker-embedding-with-phonetic-information" ["l"="37.12,3.362"]
"genzen2103/Speaker-Recognition-System-using-GMM" ["l"="37.243,3.27"]
"dominoanty/SpeakerRecognition" ["l"="37.257,3.23"]
"dake/openVP" ["l"="37.342,3.384"]
"ibillxia/VoicePrintReco" ["l"="37.318,3.387"]
"pannous/tensorflow-speech-recognition" ["l"="35.519,2.312"]
"jameslyons/python_speech_features" ["l"="35.493,2.279"]
"microsoft/Cognitive-SpeakerRecognition-Python" ["l"="-44.762,7.862"]
"sonaam1234/DeepLearningInFinance" ["l"="36.873,3.369"]
"Rez79Kh/Temperature-Control-System" ["l"="36.876,3.396"]
"jjakimoto/finance_ml" ["l"="-9.111,12.973"]
"mahdeslami11/randomCNN-voice-transfer" ["l"="36.819,3.384"]
"karim-aly/intro-to-tensorflow-for-ai-coursera" ["l"="36.833,3.365"]
"SJ-byte/Deep-Learning-For-Finance" ["l"="36.845,3.382"]
"mahdeslami11/Zero-shot-Singing-Voice-Conversion" ["l"="36.836,3.404"]
"christianvazquez7/ivector" ["l"="36.928,3.349"]
"mhyousefi/MIPS-pipeline-processor" ["l"="36.808,3.447"]
"maze1377/pipeline-mips-verilog" ["l"="36.787,3.471"]
"valar1234/MIPS" ["l"="36.758,3.464"]
"pyannote/pyannote-core" ["l"="36.887,3.227"]
"pyannote/pyannote-database" ["l"="36.877,3.244"]
"yinruiqing/change_detection" ["l"="36.944,3.322"]
"wq2012/SimpleDER" ["l"="36.866,3.22"]
"Anwarvic/Arabic-Speech-Recognition" ["l"="37.308,3.134"]
"Anwarvic/CS224n--NLP-with-Deep-Learning" ["l"="37.284,3.157"]
"Primtee/Voiceprint-recognition-Speaker-recognition" ["l"="37.213,3.346"]
"Primtee/triplet-loss-train-for-speaker-recognition" ["l"="37.24,3.36"]
"MohamadMerchant/Voice-Authentication-and-Face-Recognition" ["l"="37.378,3.294"]
"bedangSen/VoiceSens" ["l"="37.405,3.307"]
"rhythmize/user-authentication-using-voice-biometrics" ["l"="37.409,3.283"]
"NaveedShahid/Voice-Authentication-CNN" ["l"="37.351,3.3"]
"DonkeyShot21/uis-rnn-sml" ["l"="36.971,3.237"]
"aalto-speech/speaker-diarization" ["l"="36.995,3.317"]
"idiap/kaldi-ivector" ["l"="36.951,3.353"]
"eghbalz/ivector_extractor" ["l"="36.931,3.37"]
"tuanvu92/VCC2020" ["l"="36.94,3.345"]
"duhanmin/phonetic-recognition" ["l"="37.201,3.167"]
"duhanmin/face-recognition" ["l"="37.222,3.13"]
"duhanmin/rocketmq-flink" ["l"="37.21,3.144"]
"duhanmin/Spark-Streaming" ["l"="37.202,3.134"]
"duhanmin/log-router" ["l"="37.223,3.148"]
"duhanmin/kafka-flink-hbase" ["l"="37.225,3.106"]
"Anwarvic/Speaker-Recognition" ["l"="37.243,3.192"]
"Anwarvic/Deep-Learning-Nanodegree" ["l"="37.286,3.175"]
"Anwarvic/Deep-Learning-Specialization--Coursera" ["l"="37.273,3.168"]
"vvestman/pytorch-ivectors" ["l"="37.23,3.208"]
"scelesticsiva/speaker_recognition_GMM_UBM" ["l"="37.236,3.226"]
"h-meru/Tacotron-WaveRNN" ["l"="37.381,2.597"]
"SiddGururani/Pytorch-TDNN" ["l"="37.072,3.359"]
"Kyubyong/expressive_tacotron" ["l"="37.261,2.578"]
"ina-foss/inaSpeechSegmenter" ["l"="37.052,3.171"]
"amsehili/auditok" ["l"="36.753,4.532"]
"qlemaire22/speech-music-detection" ["l"="37.074,3.113"]
"jtkim-kaist/VAD" ["l"="36.765,4.511"]
"lumaku/ctc-segmentation" ["l"="35.757,2.357"]
"k2-fsa/k2" ["l"="35.642,2.36"]
"filippogiruzzi/voice_activity_detection" ["l"="36.736,4.556"]
"cvqluu/GE2E-Loss" ["l"="37.137,3.349"]
"zengchang233/Speaker_Verification_Tencent" ["l"="37.157,3.206"]
"liyongze/lstm_speaker_verification" ["l"="37.176,3.217"]
"RicherMans/PLDA" ["l"="37.11,3.311"]
"zengchang233/GMM_baseline" ["l"="37.165,3.157"]
"duhanmin/structured-streaming-Kafka2HBase" ["l"="37.246,3.103"]
"wangwei2009/MSR-Identity-Toolkit-v1.0" ["l"="37.174,3.176"]
"Anwarvic/COMS_W4705--NLP" ["l"="37.3,3.159"]
"revdotcom/revai-python-sdk" ["l"="36.724,3.005"]
"revdotcom/revai-node-sdk" ["l"="36.716,3.019"]
"revdotcom/revai-java-sdk" ["l"="36.726,3.029"]
"revdotcom/revai-go" ["l"="36.733,3.016"]
"RaviSoji/plda" ["l"="37.077,3.341"]
"xxrznj/flink-kafka-sql" ["l"="37.237,3.073"]
"spatialaudio/digital-signal-processing-exercises" ["l"="36.909,3.38"]
"codieboomboom/CE2007---Microprocessors" ["l"="36.901,3.421"]
"philipperemy/speaker-change-detection" ["l"="36.957,3.369"]
"alumae/online_speaker_change_detector" ["l"="36.954,3.442"]
"cvqluu/Factorized-TDNN" ["l"="37.043,3.345"]
"jonasvdd/TDNN" ["l"="37.069,3.386"]
"KrishnaDN/x-vector-pytorch" ["l"="37.056,3.346"]
"kefirski/pytorch_TDNN" ["l"="37.052,3.382"]
"yuyq96/D-TDNN" ["l"="37.053,3.365"]
"qqueing/speaker_embedding-pytorch" ["l"="37.123,3.349"]
"Tianchi-Liu9/SUV" ["l"="37.134,3.396"]
"fgnt/lazy_dataset" ["l"="36.945,3.022"]
"fgnt/paderbox" ["l"="36.934,3.011"]
"swshon/voxceleb-ivector" ["l"="37.21,3.229"]
"mycrazycracy/Backends-for-SRE19" ["l"="37.138,3.373"]
"iiscleap/NeuralPlda" ["l"="37.1,3.36"]
"fedderrico/ubm_map_diarization" ["l"="37.27,3.219"]
"zengchang94622/x-vector_pytorch" ["l"="37.172,3.191"]
"yeyupiaoling/VoiceprintRecognition-Keras" ["l"="36.778,3.307"]
"yeyupiaoling/VoiceprintRecognition-Tensorflow" ["l"="36.816,3.291"]
"mialrr/Speaker-Recognition" ["l"="36.741,3.308"]
"yeyupiaoling/VoiceprintRecognition-Pytorch" ["l"="36.907,3.28"]
"Kevinnan-teen/Speaker-Recognition" ["l"="36.842,3.292"]
"SunYanCN/Voiceprint-Recognition" ["l"="36.76,3.29"]
"yeyupiaoling/VoiceprintRecognition-PaddlePaddle" ["l"="35.576,1.948"]
"LCF2764/speaker-feature-extractor" ["l"="36.785,3.276"]
"fighting41love/zhvoice" ["l"="38.51,2.015"]
"yeyupiaoling/AudioClassification-Tensorflow" ["l"="39.606,5.354"]
"liyunlongaaa/NSD-MS2S" ["l"="36.938,3.127"]
"desh2608/diarizer" ["l"="36.95,3.135"]
"BUTSpeechFIT/speakerbeam" ["l"="36.594,4.296"]
"phonexiaresearch/VBx-training-recipe" ["l"="37.012,3.13"]
"wenet-e2e/wespeaker" ["l"="36.948,3.246"]
"zyzisyz/mfa_conformer" ["l"="36.965,3.3"]
"zcxu-eric/AVA-AVD" ["l"="47.402,34.034"]
"Maokui-He/NSD-MA-MSE" ["l"="36.927,3.137"]
"Python-World/Python_and_the_Web" ["l"="36.835,3.519"]
"Python-World/snippets" ["l"="36.819,3.55"]
"Py-Contributors/awesomeScripts" ["l"="24.213,-24.506"]
"aayushi-droid/Python-Thunder" ["l"="36.794,3.58"]
"Python-World/Joble" ["l"="36.839,3.553"]
"Python-World/Py-Resources" ["l"="36.909,3.394"]
"Python-World/python-world.github.io" ["l"="36.811,3.527"]
"cvqluu/dropclass_speaker" ["l"="37.108,3.382"]
"nii-yamagishilab/multi-speaker-tacotron" ["l"="37.33,2.509"]
"yistLin/universal-vocoder" ["l"="37.314,2.751"]
"cyhuang-tw/AdaIN-VC" ["l"="37.307,2.727"]
"yistLin/FragmentVC" ["l"="37.317,2.689"]
"howard1337/S2VC" ["l"="37.302,2.76"]
"BUTSpeechFIT/AMI-diarization-setup" ["l"="36.867,3.285"]
"pedrocolon93/ivectormatlabmsrit" ["l"="36.917,3.332"]
"iiscleap/self_supervised_AHC" ["l"="36.897,3.202"]
"adibis/Interrupt_Controller" ["l"="36.873,3.491"]
"sudhamshu091/RISC-Pipelined-Processor-32-bit-Verilog" ["l"="36.886,3.51"]
"vJechsmayr/PythonAlgorithms" ["l"="36.761,3.605"]
"NullDev/Hacktoberfest-2020-FizzBuzz" ["l"="36.794,3.605"]
"lawlict/ECAPA-TDNN" ["l"="37.008,3.352"]
"ranchlai/speaker-verification" ["l"="36.991,3.375"]
"iiscleap/E2E-NPLDA" ["l"="37.113,3.409"]
"a-nagrani/VoxSRC2020" ["l"="36.981,3.359"]
"theolepage/sslsv" ["l"="36.968,3.349"]
"TaoRuijie/Loss-Gated-Learning" ["l"="36.965,3.322"]
"wngh1187/RawNeXt" ["l"="36.96,3.335"]
"Python-World/GitProfile" ["l"="36.828,3.57"]
"desh2608/gss" ["l"="36.958,3.121"]
"zengchang233/MTGAN" ["l"="37.155,3.175"]
"fgnt/padertorch" ["l"="36.935,3.049"]
"fgnt/meeteval" ["l"="36.931,3.096"]
"jsalt2020-asrdiar/jsalt2020_simulate" ["l"="36.947,3.089"]
"yeyupiaoling/AudioClassification-Pytorch" ["l"="39.631,5.38"]
"modelscope/3D-Speaker" ["l"="36.941,3.277"]
"yeyupiaoling/MASR" ["l"="35.622,2.188"]
"yeyupiaoling/PPASR" ["l"="35.615,2.21"]
"wenet-e2e/wekws" ["l"="35.574,2.465"]
"2DIPW/audio_dataset_vpr" ["l"="38.058,2.003"]
"Rehan-Ahmad/SpeakerDiarization" ["l"="36.937,3.394"]
"sudhamshu091/Single-Cycle-Risc-Processor-32-bit-Verilog" ["l"="36.89,3.571"]
"sudhamshu091/Single-Cycle-Risc-Pipelined-Processor-Verilog" ["l"="36.889,3.544"]
"cvqluu/simple_diarizer" ["l"="36.971,3.067"]
"revdotcom/speech-datasets" ["l"="36.754,3.008"]
"revdotcom/fstalign" ["l"="36.748,3.038"]
"revdotcom/reverb" ["l"="36.777,3.09"]
"zhilangtaosha/SpeakerVerification_AMSoftmax_pytorch" ["l"="36.995,3.427"]
"BUTSpeechFIT/DVBx" ["l"="37.023,3.094"]
"pyannote/AMI-diarization-setup" ["l"="36.852,3.266"]
"SEERNET/Voice-Prints" ["l"="37.366,3.318"]
"desh2608/spyder" ["l"="36.964,3.104"]
"alumae/kiirkirjutaja" ["l"="36.954,3.489"]
"alumae/streaming-punctuator" ["l"="36.955,3.516"]
"nii-yamagishilab/Attention_Backend_for_ASV" ["l"="36.965,3.406"]
"felixfuyihui/AISHELL-4" ["l"="36.989,3.13"]
"chenzhuo1011/libri_css" ["l"="36.641,4.343"]
"wenet-e2e/wesep" ["l"="36.687,4.159"]
"ddlBoJack/Speech-Resources" ["l"="38.441,2.095"]
"IDRnD/redimnet" ["l"="36.848,3.175"]
"k2-fsa/icefall" ["l"="35.652,2.377"]
"ga642381/speech-trident" ["l"="38.479,2.021"]
"nii-yamagishilab/project-NN-Pytorch-scripts" ["l"="38.166,2.422"]
"aliutkus/speechmetrics" ["l"="36.784,4.347"]
"Sanyuan-Chen/CSS_with_Conformer" ["l"="36.561,4.339"]
"TaoRuijie/AVCleanse" ["l"="47.387,34.046"]
"nikvaessen/w2v2-speaker" ["l"="36.969,3.386"]
"BUTSpeechFIT/EEND_dataprep" ["l"="36.927,3.15"]
"fgnt/pb_chime5" ["l"="36.764,4.466"]
"fgnt/mms_msg" ["l"="36.91,3.096"]
"Audio-WestlakeU/RCT" ["l"="36.897,2.966"]
"Audio-WestlakeU/VINP" ["l"="36.889,2.985"]
"wngh1187/ExU-Net" ["l"="36.726,3.161"]
"ductuantruong/enskd" ["l"="36.748,3.161"]
"spatialaudio/signals-and-systems-lecture" ["l"="36.893,3.379"]
"spatialaudio/digital-signal-processing-lecture" ["l"="38.233,3.896"]
"spatialaudio/signals-and-systems-exercises" ["l"="36.869,3.413"]
"spatialaudio/data-driven-audio-signal-processing-lecture" ["l"="38.204,3.88"]
"shkim816/temporal_dynamic_cnn" ["l"="39.803,5.507"]
"aalto-speech/AaltoASR" ["l"="37.002,3.396"]
"egonina/pycasp" ["l"="37.012,3.375"]
"funcwj/deep-clustering" ["l"="36.577,4.48"]
"pengzhendong/pyannote-onnx" ["l"="36.707,3.065"]
"leohuang2013/pyannote-audio_speaker-diarization_cpp" ["l"="36.67,3.065"]
"pengzhendong/pysilero" ["l"="36.68,3.045"]
"FrenchKrab/IS2023-powerset-diarization" ["l"="36.901,3.123"]
"Rezar/MLBook" ["l"="36.884,3.348"]
"chimechallenge/chime-utils" ["l"="36.89,3.059"]
"BUTSpeechFIT/TS-ASR-Whisper" ["l"="36.884,3.087"]
"astorfi/QR_Code" ["l"="37.195,3.393"]
"astorfi/Caffe_Deep_Learning" ["l"="37.201,3.379"]
"astorfi/Local-Histogram-Equalization" ["l"="37.201,3.366"]
"astorfi/Leethcode" ["l"="37.185,3.38"]
"astorfi/Create-LMDB-from-Numpy" ["l"="37.212,3.372"]
"astorfi/Data-Structures-and-Algorithms" ["l"="37.191,3.372"]
"astorfi/OpenCV-Installation" ["l"="37.21,3.414"]
"FunAudioLLM/SenseVoice" ["l"="38.548,1.675"]
"modelscope/FunASR" ["l"="38.511,1.579"]
"wenet-e2e/wenet" ["l"="35.55,2.34"]
"modelscope/ClearerVoice-Studio" ["l"="38.521,1.83"]
"ddlBoJack/emotion2vec" ["l"="38.422,2.038"]
"FireRedTeam/FireRedASR" ["l"="38.448,1.952"]
"QwenLM/Qwen-Audio" ["l"="38.476,1.993"]
"snakers4/silero-vad" ["l"="40.53,3.28"]
"joonaskalda/PixIT" ["l"="36.921,3.114"]
"Audio-WestlakeU/SAR-SSL" ["l"="36.9,3.042"]
"Audio-WestlakeU/RealMAN" ["l"="36.686,4.224"]
"Audio-WestlakeU/FN-SSL" ["l"="36.661,4.234"]
"nttcslab-sp/mamba-diarization" ["l"="36.873,3.135"]
"liuxp0827/govpr" ["l"="37.339,3.413"]
"liuxp0827/Jvpr" ["l"="37.359,3.431"]
"IDRnD/VoxTube" ["l"="36.822,3.164"]
"ALIZE-Speaker-Recognition/alize-core" ["l"="37.301,3.394"]
"ALIZE-Speaker-Recognition/android-alize" ["l"="37.291,3.41"]
"clement-pages/gryannote" ["l"="36.876,3.118"]
"leohuang2013/pyannote-audio_overlapped-speech-detection_cpp" ["l"="36.648,3.06"]
"Audio-WestlakeU/UMA-ASR" ["l"="36.894,3.007"]
"Audio-WestlakeU/RVAE-EM" ["l"="36.867,2.963"]
"chimechallenge/C8DASR-Baseline-NeMo" ["l"="36.877,3.042"]
"huggingface/dataspeech" ["l"="38.358,2.129"]
"dmlguq456/NeXt_TDNN_ASV" ["l"="36.787,3.161"]
"microsoft/NOTSOFAR1-Challenge" ["l"="36.867,3.025"]
"VoxBlink2/ScriptsForVoxBlink2" ["l"="36.798,3.185"]
"VoxBlink/ScriptsForVoxBlink" ["l"="36.768,3.191"]
"patc15/mipscpu" ["l"="36.731,3.476"]
"revdotcom/reverb-self-hosted" ["l"="36.757,3.069"]
"modelscope/MemoryScope" ["l"="36.721,3.099"]
"memodb-io/memobase" ["l"="41.266,0.394"]
"astorfi/speechpy" ["l"="37.176,3.339"]
"astorfi/TensorFlow-World-Resources" ["l"="47.481,28.69"]
"astorfi/pythonic-automatic-email" ["l"="37.213,3.392"]
"r9y9/pysptk" ["l"="37.241,2.455"]
"BUTSpeechFIT/DiaPer" ["l"="36.857,3.101"]
"BUTSpeechFIT/DiCoW" ["l"="36.876,3.103"]
"fgnt/speaker_reassignment" ["l"="36.863,3.066"]
"juanmc2005/torch-plda" ["l"="37.09,3.383"]
"vzxxbacq/PLDA" ["l"="37.084,3.394"]
"Audio-WestlakeU/CleanMel" ["l"="36.889,2.951"]
}