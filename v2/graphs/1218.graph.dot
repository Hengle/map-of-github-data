digraph G {
"lucidrains/compressive-transformer-pytorch" -> "lucidrains/memformer"
"lucidrains/memory-transformer-xl" -> "lucidrains/memformer"
"lucidrains/memformer" -> "lucidrains/memory-transformer-xl"
"lucidrains/memformer" -> "lucidrains/compressive-transformer-pytorch"
"lucidrains/memorizing-transformers-pytorch" -> "google-research/meliad"
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/memformer"
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/block-recurrent-transformer-pytorch"
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/RETRO-pytorch" ["e"=1]
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/memory-efficient-attention-pytorch"
"lucidrains/memorizing-transformers-pytorch" -> "CStanKonrad/long_llama"
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/simple-hierarchical-transformer" ["e"=1]
"lucidrains/memorizing-transformers-pytorch" -> "Victorwz/LongMem"
"lucidrains/memorizing-transformers-pytorch" -> "lucidrains/compressive-transformer-pytorch"
"lucidrains/memorizing-transformers-pytorch" -> "epfml/landmark-attention"
"lucidrains/memorizing-transformers-pytorch" -> "princeton-nlp/TRIME" ["e"=1]
"lucidrains/memorizing-transformers-pytorch" -> "ArvinZhuang/DSI-transformers" ["e"=1]
"booydar/recurrent-memory-transformer" -> "booydar/LM-RMT"
"booydar/recurrent-memory-transformer" -> "lucidrains/recurrent-memory-transformer-pytorch"
"booydar/recurrent-memory-transformer" -> "booydar/babilong"
"booydar/recurrent-memory-transformer" -> "abertsch72/unlimiformer"
"booydar/recurrent-memory-transformer" -> "yurakuratov/t5-experiments"
"booydar/recurrent-memory-transformer" -> "Victorwz/LongMem"
"booydar/recurrent-memory-transformer" -> "crosleythomas/MirrorGPT"
"booydar/recurrent-memory-transformer" -> "allenai/mmc4" ["e"=1]
"lucidrains/memory-efficient-attention-pytorch" -> "lucidrains/flash-cosine-sim-attention" ["e"=1]
"lucidrains/memory-efficient-attention-pytorch" -> "AminRezaei0x443/memory-efficient-attention"
"lucidrains/memory-efficient-attention-pytorch" -> "lucidrains/memory-compressed-attention"
"lucidrains/memory-efficient-attention-pytorch" -> "lucidrains/memorizing-transformers-pytorch"
"AminRezaei0x443/memory-efficient-attention" -> "Birch-san/diffusers-play"
"google-research/meliad" -> "lucidrains/memorizing-transformers-pytorch"
"google-research/meliad" -> "lucidrains/block-recurrent-transformer-pytorch"
"Shark-NLP/CoNT" -> "HKUNLP/STRING"
"Shark-NLP/CoNT" -> "OpenLMLab/LEval"
"Shark-NLP/CoNT" -> "Shark-NLP/EVALM" ["e"=1]
"Shark-NLP/CoNT" -> "OpenLMLab/LongWanjuan"
"booydar/LM-RMT" -> "lucidrains/recurrent-memory-transformer-pytorch"
"booydar/LM-RMT" -> "booydar/recurrent-memory-transformer"
"txsun1997/nlp-paradigm-shift" -> "open-nlplab/fastIE"
"google-deepmind/dramatron" -> "premieroctet/photoshot" ["e"=1]
"google-deepmind/dramatron" -> "aiwaves-cn/RecurrentGPT"
"google-deepmind/dramatron" -> "yangkevin2/doc-story-generation"
"google-deepmind/dramatron" -> "gtoxlili/wechat-chatGPT" ["e"=1]
"google-deepmind/dramatron" -> "riffusion/riffusion-app-hobby" ["e"=1]
"google-deepmind/dramatron" -> "FrozenBurning/Text2Light" ["e"=1]
"google-deepmind/dramatron" -> "jbilcke/latent-browser"
"google-deepmind/dramatron" -> "facebookresearch/doc-storygen-v2"
"lucidrains/block-recurrent-transformer-pytorch" -> "lucidrains/recurrent-memory-transformer-pytorch"
"lucidrains/block-recurrent-transformer-pytorch" -> "dashstander/block-recurrent-transformer"
"lucidrains/block-recurrent-transformer-pytorch" -> "google-research/meliad"
"yangkevin2/emnlp22-re3-story-generation" -> "yangkevin2/doc-story-generation"
"yangkevin2/emnlp22-re3-story-generation" -> "facebookresearch/doc-storygen-v2"
"yangkevin2/emnlp22-re3-story-generation" -> "yingpengma/Awesome-Story-Generation"
"yangkevin2/doc-story-generation" -> "yangkevin2/emnlp22-re3-story-generation"
"yangkevin2/doc-story-generation" -> "facebookresearch/doc-storygen-v2"
"ayyyq/DORE" -> "KaiLv69/DuoDecoding"
"conceptofmind/PaLM" -> "s-JoL/Open-Llama" ["e"=1]
"conceptofmind/PaLM" -> "lucidrains/PaLM-pytorch" ["e"=1]
"conceptofmind/PaLM" -> "abertsch72/unlimiformer"
"conceptofmind/PaLM" -> "neuml/txtinstruct" ["e"=1]
"conceptofmind/PaLM" -> "colonelwatch/abstracts-search" ["e"=1]
"conceptofmind/PaLM" -> "rmihaylov/falcontune" ["e"=1]
"conceptofmind/PaLM" -> "alasdairforsythe/tokenmonster"
"zhongwanjun/MemoryBank-SiliconFriend" -> "nuster1128/LLM_Agent_Memory_Survey"
"zhongwanjun/MemoryBank-SiliconFriend" -> "snap-research/locomo"
"zhongwanjun/MemoryBank-SiliconFriend" -> "Victorwz/LongMem"
"zhongwanjun/MemoryBank-SiliconFriend" -> "LuJunru/MemoChat"
"zhongwanjun/MemoryBank-SiliconFriend" -> "leolee99/LD-Agent"
"zhongwanjun/MemoryBank-SiliconFriend" -> "wbbeyourself/SCM4LLMs"
"zhongwanjun/MemoryBank-SiliconFriend" -> "choosewhatulike/trainable-agents" ["e"=1]
"zhongwanjun/MemoryBank-SiliconFriend" -> "wangyu-ustc/MemoryLLM" ["e"=1]
"zhongwanjun/MemoryBank-SiliconFriend" -> "LeapLabTHU/ExpeL" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "lupantech/chameleon-llm" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "billxbf/ReWOO"
"ctlllll/LLM-ToolMaker" -> "aiwaves-cn/RecurrentGPT"
"ctlllll/LLM-ToolMaker" -> "thunlp/ToolLearningPapers" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "salesforce/CodeTF" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "kyegomez/tree-of-thoughts" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "CStanKonrad/long_llama"
"ctlllll/LLM-ToolMaker" -> "lyuchenyang/Macaw-LLM" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "salesforce/xgen"
"ctlllll/LLM-ToolMaker" -> "IBM/Dromedary" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "Victorwz/LongMem"
"ctlllll/LLM-ToolMaker" -> "OpenBMB/ToolBench" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "huchenxucs/ChatDB"
"ctlllll/LLM-ToolMaker" -> "OSU-NLP-Group/Mind2Web" ["e"=1]
"ctlllll/LLM-ToolMaker" -> "mbzuai-nlp/LaMini-LM" ["e"=1]
"mzbac/qlora-fine-tune" -> "eugenepentland/landmark-attention-qlora"
"kyegomez/LongNet" -> "CStanKonrad/long_llama"
"kyegomez/LongNet" -> "fkodom/dilated-attention-pytorch"
"kyegomez/LongNet" -> "kyegomez/Andromeda" ["e"=1]
"kyegomez/LongNet" -> "epfml/landmark-attention"
"kyegomez/LongNet" -> "dmytrostriletskyi/threads-net"
"kyegomez/LongNet" -> "abertsch72/unlimiformer"
"kyegomez/LongNet" -> "Victorwz/LongMem"
"kyegomez/LongNet" -> "alexisrozhkov/dilated-self-attention"
"kyegomez/LongNet" -> "haoliuhl/ringattention" ["e"=1]
"kyegomez/LongNet" -> "kyegomez/zeta" ["e"=1]
"kyegomez/LongNet" -> "Beomi/BitNet-Transformers" ["e"=1]
"kyegomez/LongNet" -> "microsoft/torchscale" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "jackaduma/Recurrent-LLM"
"aiwaves-cn/RecurrentGPT" -> "ctlllll/LLM-ToolMaker"
"aiwaves-cn/RecurrentGPT" -> "femnn/RecurrentGPT-zh"
"aiwaves-cn/RecurrentGPT" -> "Victorwz/LongMem"
"aiwaves-cn/RecurrentGPT" -> "yingpengma/Awesome-Story-Generation"
"aiwaves-cn/RecurrentGPT" -> "kyegomez/tree-of-thoughts" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "Vahe1994/SpQR" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "kreneskyp/ix" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "yangkevin2/doc-story-generation"
"aiwaves-cn/RecurrentGPT" -> "CStanKonrad/long_llama"
"aiwaves-cn/RecurrentGPT" -> "huchenxucs/ChatDB"
"aiwaves-cn/RecurrentGPT" -> "aiwaves-cn/agents" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "FranxYao/chain-of-thought-hub" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "thunlp/WebCPM" ["e"=1]
"aiwaves-cn/RecurrentGPT" -> "teknium1/GPTeacher" ["e"=1]
"Victorwz/LongMem" -> "epfml/landmark-attention"
"Victorwz/LongMem" -> "zhongwanjun/MemoryBank-SiliconFriend"
"Victorwz/LongMem" -> "CStanKonrad/long_llama"
"Victorwz/LongMem" -> "abertsch72/unlimiformer"
"Victorwz/LongMem" -> "aiwaves-cn/RecurrentGPT"
"Victorwz/LongMem" -> "huchenxucs/ChatDB"
"Victorwz/LongMem" -> "ctlllll/LLM-ToolMaker"
"Victorwz/LongMem" -> "lucidrains/memorizing-transformers-pytorch"
"Victorwz/LongMem" -> "rmihaylov/falcontune" ["e"=1]
"Victorwz/LongMem" -> "princeton-nlp/AutoCompressors"
"Victorwz/LongMem" -> "jquesnelle/yarn"
"Victorwz/LongMem" -> "QuangBK/generativeAgent_LLM" ["e"=1]
"Victorwz/LongMem" -> "bojone/NBCE"
"Victorwz/LongMem" -> "sail-sg/lorahub" ["e"=1]
"Victorwz/LongMem" -> "dvlab-research/LongLoRA"
"junhoyeo/threads-api" -> "dmytrostriletskyi/threads-net"
"junhoyeo/threads-api" -> "threadsjs/threads.js"
"junhoyeo/threads-api" -> "m1guelpf/threads-re"
"junhoyeo/threads-api" -> "Danie1/threads-api"
"junhoyeo/threads-api" -> "junhoyeo/threads-py"
"junhoyeo/threads-api" -> "junhoyeo/react-threads"
"junhoyeo/threads-api" -> "KudoAI/chatgpt.js" ["e"=1]
"junhoyeo/threads-api" -> "facebook/igl" ["e"=1]
"junhoyeo/threads-api" -> "KiwiTalk/KiwiTalk" ["e"=1]
"junhoyeo/threads-api" -> "farizrifqi/Threads-Media-Downloader"
"junhoyeo/threads-api" -> "m1guelpf/threads-api"
"junhoyeo/threads-api" -> "Bamdoliro/marururu" ["e"=1]
"junhoyeo/threads-api" -> "noodle-run/noodle" ["e"=1]
"junhoyeo/threads-api" -> "kyegomez/LongNet"
"junhoyeo/threads-api" -> "toss/slash" ["e"=1]
"billxbf/ReWOO" -> "Gentopia-AI/Gentopia" ["e"=1]
"billxbf/ReWOO" -> "ctlllll/LLM-ToolMaker"
"billxbf/ReWOO" -> "OSU-NLP-Group/Mind2Web" ["e"=1]
"billxbf/ReWOO" -> "THUDM/AgentBench" ["e"=1]
"billxbf/ReWOO" -> "lupantech/chameleon-llm" ["e"=1]
"billxbf/ReWOO" -> "allenai/lumos" ["e"=1]
"billxbf/ReWOO" -> "ysymyth/ReAct" ["e"=1]
"billxbf/ReWOO" -> "princeton-nlp/intercode" ["e"=1]
"billxbf/ReWOO" -> "salesforce/CodeTF" ["e"=1]
"billxbf/ReWOO" -> "SwiftSage/SwiftSage" ["e"=1]
"billxbf/ReWOO" -> "huchenxucs/ChatDB"
"billxbf/ReWOO" -> "Vahe1994/SpQR" ["e"=1]
"billxbf/ReWOO" -> "CStanKonrad/long_llama"
"billxbf/ReWOO" -> "web-arena-x/webarena" ["e"=1]
"billxbf/ReWOO" -> "101dotxyz/GPTeam" ["e"=1]
"bojone/bytepiece" -> "bojone/rerope"
"bojone/bytepiece" -> "bojone/NBCE"
"bojone/bytepiece" -> "GanjinZero/RRHF" ["e"=1]
"bojone/bytepiece" -> "liwenju0/cutword"
"bojone/bytepiece" -> "OpenLMLab/MOSS-RLHF" ["e"=1]
"bojone/bytepiece" -> "JunnYu/RoFormer_pytorch" ["e"=1]
"alasdairforsythe/tokenmonster" -> "epfml/landmark-attention"
"alasdairforsythe/tokenmonster" -> "jondurbin/airoboros" ["e"=1]
"alasdairforsythe/tokenmonster" -> "OoriData/OgbujiPT" ["e"=1]
"alasdairforsythe/tokenmonster" -> "AgileRL/AgileRL" ["e"=1]
"alasdairforsythe/tokenmonster" -> "jquesnelle/yarn"
"alasdairforsythe/tokenmonster" -> "salesforce/xgen"
"jquesnelle/yarn" -> "THUDM/LongBench"
"jquesnelle/yarn" -> "dvlab-research/LongLoRA"
"jquesnelle/yarn" -> "HKUNLP/ChunkLlama"
"jquesnelle/yarn" -> "gkamradt/LLMTest_NeedleInAHaystack"
"jquesnelle/yarn" -> "DachengLi1/LongChat"
"jquesnelle/yarn" -> "jondurbin/airoboros" ["e"=1]
"jquesnelle/yarn" -> "FranxYao/Long-Context-Data-Engineering"
"jquesnelle/yarn" -> "zhuzilin/ring-flash-attention" ["e"=1]
"jquesnelle/yarn" -> "jzhang38/EasyContext"
"jquesnelle/yarn" -> "CStanKonrad/long_llama"
"jquesnelle/yarn" -> "bojone/rerope"
"jquesnelle/yarn" -> "OpenBMB/InfiniteBench"
"jquesnelle/yarn" -> "OpenLMLab/LEval"
"jquesnelle/yarn" -> "dwzhu-pku/PoSE"
"jquesnelle/yarn" -> "XueFuzhao/OpenMoE" ["e"=1]
"THUDM/LongBench" -> "OpenBMB/InfiniteBench"
"THUDM/LongBench" -> "OpenLMLab/LEval"
"THUDM/LongBench" -> "THUDM/LongAlign"
"THUDM/LongBench" -> "FasterDecoding/SnapKV" ["e"=1]
"THUDM/LongBench" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"THUDM/LongBench" -> "gkamradt/LLMTest_NeedleInAHaystack"
"THUDM/LongBench" -> "FranxYao/Long-Context-Data-Engineering"
"THUDM/LongBench" -> "bigai-nlco/LooGLE"
"THUDM/LongBench" -> "jquesnelle/yarn"
"THUDM/LongBench" -> "NVIDIA/RULER"
"THUDM/LongBench" -> "HKUNLP/ChunkLlama"
"THUDM/LongBench" -> "jy-yuan/KIVI" ["e"=1]
"THUDM/LongBench" -> "FMInference/H2O" ["e"=1]
"THUDM/LongBench" -> "nelson-liu/lost-in-the-middle"
"THUDM/LongBench" -> "dvlab-research/LongLoRA"
"dvlab-research/LongLoRA" -> "mit-han-lab/streaming-llm" ["e"=1]
"dvlab-research/LongLoRA" -> "jquesnelle/yarn"
"dvlab-research/LongLoRA" -> "THUDM/LongBench"
"dvlab-research/LongLoRA" -> "CStanKonrad/long_llama"
"dvlab-research/LongLoRA" -> "FasterDecoding/Medusa" ["e"=1]
"dvlab-research/LongLoRA" -> "artidoro/qlora" ["e"=1]
"dvlab-research/LongLoRA" -> "dvlab-research/3D-Box-Segment-Anything" ["e"=1]
"dvlab-research/LongLoRA" -> "PhoebusSi/Alpaca-CoT" ["e"=1]
"dvlab-research/LongLoRA" -> "huggingface/alignment-handbook" ["e"=1]
"dvlab-research/LongLoRA" -> "dvlab-research/VoxelNeXt" ["e"=1]
"dvlab-research/LongLoRA" -> "open-compass/opencompass" ["e"=1]
"dvlab-research/LongLoRA" -> "OpenRLHF/OpenRLHF" ["e"=1]
"dvlab-research/LongLoRA" -> "baichuan-inc/Baichuan2" ["e"=1]
"dvlab-research/LongLoRA" -> "FlagOpen/FlagEmbedding" ["e"=1]
"dvlab-research/LongLoRA" -> "mit-han-lab/llm-awq" ["e"=1]
"m1guelpf/threads-re" -> "m1guelpf/threads-api"
"m1guelpf/threads-re" -> "junhoyeo/threads-api"
"m1guelpf/threads-re" -> "Eltion/Instagram-SSL-Pinning-Bypass" ["e"=1]
"m1guelpf/threads-re" -> "threadsjs/threads.js"
"m1guelpf/threads-re" -> "dmytrostriletskyi/threads-net"
"epfml/landmark-attention" -> "eugenepentland/landmark-attention-qlora"
"epfml/landmark-attention" -> "Victorwz/LongMem"
"epfml/landmark-attention" -> "dwzhu-pku/PoSE"
"epfml/landmark-attention" -> "FasterDecoding/SnapKV" ["e"=1]
"epfml/landmark-attention" -> "princeton-nlp/AutoCompressors"
"epfml/landmark-attention" -> "DachengLi1/LongChat"
"epfml/landmark-attention" -> "CStanKonrad/long_llama"
"epfml/landmark-attention" -> "rmihaylov/falcontune" ["e"=1]
"epfml/landmark-attention" -> "jquesnelle/yarn"
"epfml/landmark-attention" -> "THUDM/LongBench"
"epfml/landmark-attention" -> "FMInference/H2O" ["e"=1]
"epfml/landmark-attention" -> "princeton-nlp/ProLong"
"epfml/landmark-attention" -> "HKUNLP/ChunkLlama"
"nelson-liu/lost-in-the-middle" -> "THUDM/LongBench"
"nelson-liu/lost-in-the-middle" -> "OpenLMLab/LEval"
"nelson-liu/lost-in-the-middle" -> "nightdessert/Retrieval_Head"
"nelson-liu/lost-in-the-middle" -> "bigai-nlco/LooGLE"
"nelson-liu/lost-in-the-middle" -> "DachengLi1/LongChat"
"nelson-liu/lost-in-the-middle" -> "princeton-nlp/ALCE" ["e"=1]
"nelson-liu/lost-in-the-middle" -> "princeton-nlp/CEPE"
"nelson-liu/lost-in-the-middle" -> "HKUNLP/ChunkLlama"
"nelson-liu/lost-in-the-middle" -> "facebookresearch/FiD" ["e"=1]
"nelson-liu/lost-in-the-middle" -> "FasterDecoding/SnapKV" ["e"=1]
"nelson-liu/lost-in-the-middle" -> "FMInference/H2O" ["e"=1]
"nelson-liu/lost-in-the-middle" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"tomaarsen/attention_sinks" -> "mit-han-lab/streaming-llm" ["e"=1]
"tomaarsen/attention_sinks" -> "Glaciohound/LM-Infinite"
"tomaarsen/attention_sinks" -> "THUDM/LongBench"
"tomaarsen/attention_sinks" -> "epfml/landmark-attention"
"tomaarsen/attention_sinks" -> "datamllab/LongLM"
"tomaarsen/attention_sinks" -> "tomaarsen/SpanMarkerNER" ["e"=1]
"tomaarsen/attention_sinks" -> "FMInference/H2O" ["e"=1]
"tomaarsen/attention_sinks" -> "FasterDecoding/SnapKV" ["e"=1]
"tomaarsen/attention_sinks" -> "hao-ai-lab/LookaheadDecoding" ["e"=1]
"tomaarsen/attention_sinks" -> "jy-yuan/KIVI" ["e"=1]
"tomaarsen/attention_sinks" -> "huggingface/setfit" ["e"=1]
"tomaarsen/attention_sinks" -> "mit-han-lab/duo-attention" ["e"=1]
"tomaarsen/attention_sinks" -> "dwzhu-pku/PoSE"
"tomaarsen/attention_sinks" -> "dvlab-research/LongLoRA"
"tomaarsen/attention_sinks" -> "princeton-nlp/AutoCompressors"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "THUDM/LongBench"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "OpenBMB/InfiniteBench"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "microsoft/MInference" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "October2001/Awesome-KV-Cache-Compression" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "gkamradt/LLMTest_NeedleInAHaystack"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "HuangOwen/Awesome-LLM-Compression" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "horseee/Awesome-Efficient-LLM" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "FranxYao/Long-Context-Data-Engineering"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "NVIDIA/RULER"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "jzhang38/EasyContext"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "FasterDecoding/SnapKV" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "hemingkx/SpeculativeDecodingPapers" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "atfortes/Awesome-LLM-Reasoning" ["e"=1]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "nightdessert/Retrieval_Head"
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" -> "OpenLMLab/LEval"
"CStanKonrad/long_llama" -> "dvlab-research/LongLoRA"
"CStanKonrad/long_llama" -> "DachengLi1/LongChat"
"CStanKonrad/long_llama" -> "jquesnelle/yarn"
"CStanKonrad/long_llama" -> "kyegomez/LongNet"
"CStanKonrad/long_llama" -> "THUDM/LongBench"
"CStanKonrad/long_llama" -> "epfml/landmark-attention"
"CStanKonrad/long_llama" -> "Victorwz/LongMem"
"CStanKonrad/long_llama" -> "OpenLMLab/LOMO"
"CStanKonrad/long_llama" -> "abertsch72/unlimiformer"
"CStanKonrad/long_llama" -> "salesforce/xgen"
"CStanKonrad/long_llama" -> "OpenLMLab/LEval"
"CStanKonrad/long_llama" -> "jzhang38/EasyContext"
"CStanKonrad/long_llama" -> "abacusai/Long-Context"
"CStanKonrad/long_llama" -> "AetherCortex/Llama-X" ["e"=1]
"CStanKonrad/long_llama" -> "ctlllll/LLM-ToolMaker"
"princeton-nlp/AutoCompressors" -> "getao/icae"
"princeton-nlp/AutoCompressors" -> "jayelm/gisting"
"princeton-nlp/AutoCompressors" -> "princeton-nlp/CEPE"
"princeton-nlp/AutoCompressors" -> "liyucheng09/Selective_Context"
"princeton-nlp/AutoCompressors" -> "snu-mllab/Context-Memory"
"princeton-nlp/AutoCompressors" -> "jeffreysijuntan/lloco"
"princeton-nlp/AutoCompressors" -> "THUDM/LongBench"
"princeton-nlp/AutoCompressors" -> "booydar/LM-RMT"
"princeton-nlp/AutoCompressors" -> "epfml/landmark-attention"
"getao/icae" -> "princeton-nlp/AutoCompressors"
"getao/icae" -> "snu-mllab/Context-Memory"
"getao/icae" -> "jeffreysijuntan/lloco"
"getao/icae" -> "princeton-nlp/CEPE"
"OpenMOSS/CoLLiE" -> "OpenLMLab/LOMO"
"OpenMOSS/CoLLiE" -> "OpenMOSS/Thus-Spake-Long-Context-LLM"
"OpenMOSS/CoLLiE" -> "Shark-NLP/CoNT"
"OpenMOSS/CoLLiE" -> "GAIR-NLP/alignment-for-honesty" ["e"=1]
"OpenMOSS/CoLLiE" -> "OpenLMLab/ChatZoo"
"OpenMOSS/CoLLiE" -> "OpenLMLab/LongWanjuan"
"OpenMOSS/CoLLiE" -> "xiami2019/CLAIF"
"OpenMOSS/CoLLiE" -> "GAIR-NLP/weak-to-strong-reasoning" ["e"=1]
"OpenMOSS/CoLLiE" -> "OpenLMLab/LEval"
"OpenMOSS/CoLLiE" -> "open-nlplab/fastIE"
"OpenMOSS/CoLLiE" -> "HKUNLP/STRING"
"OpenLMLab/LOMO" -> "OpenMOSS/CoLLiE"
"OpenLMLab/LOMO" -> "jiaweizzhao/GaLore" ["e"=1]
"OpenLMLab/LOMO" -> "princeton-nlp/MeZO" ["e"=1]
"OpenLMLab/LOMO" -> "CStanKonrad/long_llama"
"OpenLMLab/LOMO" -> "locuslab/wanda" ["e"=1]
"OpenLMLab/LOMO" -> "OpenLMLab/LEval"
"OpenLMLab/LOMO" -> "OpenLMLab/OpenChineseLLaMA" ["e"=1]
"OpenLMLab/LOMO" -> "hiyouga/FastEdit" ["e"=1]
"OpenLMLab/LOMO" -> "dvlab-research/LongLoRA"
"OpenLMLab/LOMO" -> "PhoebusSi/Alpaca-CoT" ["e"=1]
"OpenLMLab/LOMO" -> "AetherCortex/Llama-X" ["e"=1]
"OpenLMLab/LOMO" -> "dandelionsllm/pandallm" ["e"=1]
"OpenLMLab/LOMO" -> "princeton-nlp/LLM-Shearing" ["e"=1]
"OpenLMLab/LOMO" -> "FasterDecoding/Medusa" ["e"=1]
"OpenLMLab/LOMO" -> "InternLM/InternLM-techreport" ["e"=1]
"huchenxucs/ChatDB" -> "cubenlp/ChatSQL" ["e"=1]
"huchenxucs/ChatDB" -> "Victorwz/LongMem"
"huchenxucs/ChatDB" -> "MohammadrezaPourreza/Few-shot-NL2SQL-with-prompting" ["e"=1]
"huchenxucs/ChatDB" -> "ctlllll/LLM-ToolMaker"
"huchenxucs/ChatDB" -> "RUCKBReasoning/RESDSQL" ["e"=1]
"huchenxucs/ChatDB" -> "CStanKonrad/long_llama"
"huchenxucs/ChatDB" -> "billxbf/ReWOO"
"abertsch72/unlimiformer" -> "CStanKonrad/long_llama"
"abertsch72/unlimiformer" -> "epfml/landmark-attention"
"abertsch72/unlimiformer" -> "Victorwz/LongMem"
"abertsch72/unlimiformer" -> "princeton-nlp/AutoCompressors"
"abertsch72/unlimiformer" -> "lucidrains/recurrent-memory-transformer-pytorch"
"abertsch72/unlimiformer" -> "booydar/recurrent-memory-transformer"
"abertsch72/unlimiformer" -> "jquesnelle/yarn"
"abertsch72/unlimiformer" -> "bojone/NBCE"
"abertsch72/unlimiformer" -> "lupantech/chameleon-llm" ["e"=1]
"abertsch72/unlimiformer" -> "booydar/LM-RMT"
"abertsch72/unlimiformer" -> "wbbeyourself/SCM4LLMs"
"abertsch72/unlimiformer" -> "haoliuhl/ringattention" ["e"=1]
"abertsch72/unlimiformer" -> "lucidrains/MEGABYTE-pytorch" ["e"=1]
"abertsch72/unlimiformer" -> "conceptofmind/PaLM"
"abertsch72/unlimiformer" -> "kyegomez/LongNet"
"DachengLi1/LongChat" -> "OpenLMLab/LEval"
"DachengLi1/LongChat" -> "THUDM/LongBench"
"DachengLi1/LongChat" -> "CStanKonrad/long_llama"
"DachengLi1/LongChat" -> "OpenBMB/InfiniteBench"
"DachengLi1/LongChat" -> "jquesnelle/yarn"
"DachengLi1/LongChat" -> "bojone/rerope"
"DachengLi1/LongChat" -> "RulinShao/LightSeq" ["e"=1]
"DachengLi1/LongChat" -> "FasterDecoding/SnapKV" ["e"=1]
"DachengLi1/LongChat" -> "epfml/landmark-attention"
"DachengLi1/LongChat" -> "abacusai/Long-Context"
"DachengLi1/LongChat" -> "nelson-liu/lost-in-the-middle"
"DachengLi1/LongChat" -> "mit-han-lab/Quest" ["e"=1]
"DachengLi1/LongChat" -> "THUDM/LongAlign"
"DachengLi1/LongChat" -> "bojone/NBCE"
"DachengLi1/LongChat" -> "FMInference/H2O" ["e"=1]
"jackaduma/Recurrent-LLM" -> "aiwaves-cn/RecurrentGPT"
"jackaduma/Recurrent-LLM" -> "william970/WritingGod"
"yingpengma/Awesome-Story-Generation" -> "facebookresearch/doc-storygen-v2"
"yingpengma/Awesome-Story-Generation" -> "yangkevin2/doc-story-generation"
"yingpengma/Awesome-Story-Generation" -> "yangkevin2/emnlp22-re3-story-generation"
"yingpengma/Awesome-Story-Generation" -> "GOAT-AI-lab/GOAT-Storytelling-Agent"
"yingpengma/Awesome-Story-Generation" -> "InteractiveNLP-Team/RoleLLM-public" ["e"=1]
"yingpengma/Awesome-Story-Generation" -> "aiwaves-cn/RecurrentGPT"
"yingpengma/Awesome-Story-Generation" -> "TencentARC/SEED-Story" ["e"=1]
"yingpengma/Awesome-Story-Generation" -> "thu-coai/PaperForONLG" ["e"=1]
"yingpengma/Awesome-Story-Generation" -> "Neph0s/awesome-llm-role-playing-with-persona" ["e"=1]
"yingpengma/Awesome-Story-Generation" -> "vaew/SkyScript-100M"
"yingpengma/Awesome-Story-Generation" -> "jackaduma/Recurrent-LLM"
"yingpengma/Awesome-Story-Generation" -> "datacrystals/AIStoryWriter"
"dmytrostriletskyi/threads-net" -> "threadsjs/threads.js"
"dmytrostriletskyi/threads-net" -> "junhoyeo/threads-api"
"dmytrostriletskyi/threads-net" -> "Danie1/threads-api"
"dmytrostriletskyi/threads-net" -> "m1guelpf/threads-re"
"dmytrostriletskyi/threads-net" -> "junhoyeo/react-threads"
"dmytrostriletskyi/threads-net" -> "kyegomez/LongNet"
"OpenLMLab/ChatZoo" -> "OpenLMLab/LongWanjuan"
"bojone/NBCE" -> "bojone/rerope"
"bojone/NBCE" -> "AI21Labs/Parallel-Context-Windows"
"bojone/NBCE" -> "OpenBuddy/OpenBuddy" ["e"=1]
"bojone/NBCE" -> "bojone/bytepiece"
"bojone/NBCE" -> "DachengLi1/LongChat"
"bojone/NBCE" -> "HazyResearch/TART"
"georgesung/llm_qlora" -> "mzbac/qlora-fine-tune"
"abacusai/Long-Context" -> "DachengLi1/LongChat"
"abacusai/Long-Context" -> "FranxYao/Long-Context-Data-Engineering"
"abacusai/Long-Context" -> "jquesnelle/yarn"
"abacusai/Long-Context" -> "dwzhu-pku/PoSE"
"abacusai/Long-Context" -> "CStanKonrad/long_llama"
"abacusai/Long-Context" -> "OpenLMLab/LEval"
"abacusai/Long-Context" -> "THUDM/LongBench"
"abacusai/Long-Context" -> "datamllab/LongLM"
"abacusai/Long-Context" -> "HKUNLP/ChunkLlama"
"abacusai/Long-Context" -> "jshuadvd/LongRoPE"
"bojone/rerope" -> "DachengLi1/LongChat"
"bojone/rerope" -> "bojone/NBCE"
"bojone/rerope" -> "Glaciohound/LM-Infinite"
"bojone/rerope" -> "jquesnelle/yarn"
"bojone/rerope" -> "dwzhu-pku/PoSE"
"bojone/rerope" -> "FasterDecoding/SnapKV" ["e"=1]
"bojone/rerope" -> "bojone/bytepiece"
"bojone/rerope" -> "princeton-nlp/ProLong"
"bojone/rerope" -> "princeton-nlp/CEPE"
"lucidrains/recurrent-memory-transformer-pytorch" -> "booydar/LM-RMT"
"lucidrains/recurrent-memory-transformer-pytorch" -> "lucidrains/block-recurrent-transformer-pytorch"
"lucidrains/recurrent-memory-transformer-pytorch" -> "lucidrains/CoLT5-attention" ["e"=1]
"lucidrains/recurrent-memory-transformer-pytorch" -> "lucidrains/st-moe-pytorch" ["e"=1]
"lucidrains/recurrent-memory-transformer-pytorch" -> "lucidrains/ring-attention-pytorch" ["e"=1]
"lucidrains/recurrent-memory-transformer-pytorch" -> "lucidrains/memformer"
"Danie1/threads-api" -> "junhoyeo/threads-py"
"liyucheng09/Selective_Context" -> "princeton-nlp/AutoCompressors"
"liyucheng09/Selective_Context" -> "getao/icae"
"liyucheng09/Selective_Context" -> "3DAgentWorld/Toolkit-for-Prompt-Compression" ["e"=1]
"salesforce/xgen" -> "maszhongming/UniEval" ["e"=1]
"salesforce/xgen" -> "CStanKonrad/long_llama"
"salesforce/xgen" -> "OpenLMLab/LEval"
"salesforce/xgen" -> "facebookresearch/Shepherd" ["e"=1]
"salesforce/xgen" -> "ctlllll/LLM-ToolMaker"
"OpenLMLab/LEval" -> "THUDM/LongBench"
"OpenLMLab/LEval" -> "bigai-nlco/LooGLE"
"OpenLMLab/LEval" -> "HKUNLP/ChunkLlama"
"OpenLMLab/LEval" -> "HKUNLP/STRING"
"OpenLMLab/LEval" -> "OpenBMB/InfiniteBench"
"OpenLMLab/LEval" -> "Shark-NLP/CoNT"
"OpenLMLab/LEval" -> "THUDM/LongAlign"
"OpenLMLab/LEval" -> "DachengLi1/LongChat"
"OpenLMLab/LEval" -> "FranxYao/Long-Context-Data-Engineering"
"OpenLMLab/LEval" -> "FasterDecoding/SnapKV" ["e"=1]
"OpenLMLab/LEval" -> "nightdessert/Retrieval_Head"
"OpenLMLab/LEval" -> "nelson-liu/lost-in-the-middle"
"OpenLMLab/LEval" -> "dwzhu-pku/PoSE"
"OpenLMLab/LEval" -> "booydar/babilong"
"OpenLMLab/LEval" -> "princeton-nlp/ProLong"
"jayelm/gisting" -> "princeton-nlp/AutoCompressors"
"jayelm/gisting" -> "snu-mllab/Context-Memory"
"jayelm/gisting" -> "FasterDecoding/SnapKV" ["e"=1]
"jayelm/gisting" -> "FMInference/H2O" ["e"=1]
"jayelm/gisting" -> "getao/icae"
"threadsjs/threads.js" -> "dmytrostriletskyi/threads-net"
"threadsjs/threads.js" -> "junhoyeo/threads-api"
"threadsjs/threads.js" -> "m1guelpf/threads-re"
"threadsjs/threads.js" -> "junhoyeo/react-threads"
"facebookresearch/doc-storygen-v2" -> "yangkevin2/doc-story-generation"
"facebookresearch/doc-storygen-v2" -> "YichenZW/Pacing"
"eugenepentland/landmark-attention-qlora" -> "epfml/landmark-attention"
"dwzhu-pku/PoSE" -> "HKUNLP/ChunkLlama"
"dwzhu-pku/PoSE" -> "dwzhu-pku/LongEmbed"
"dwzhu-pku/PoSE" -> "PKU-TANGENT/ConFiguRe" ["e"=1]
"dwzhu-pku/PoSE" -> "booydar/babilong"
"dwzhu-pku/PoSE" -> "F2-Song/ICDPO"
"fkodom/dilated-attention-pytorch" -> "alexisrozhkov/dilated-self-attention"
"alexisrozhkov/dilated-self-attention" -> "fkodom/dilated-attention-pytorch"
"Strivin0311/llms-learning" -> "NJUDeepEngine/llm-course-lecture"
"Strivin0311/llms-learning" -> "NJUDeepEngine/open-llm-assignments"
"gkamradt/LLMTest_NeedleInAHaystack" -> "THUDM/LongBench"
"gkamradt/LLMTest_NeedleInAHaystack" -> "NVIDIA/RULER"
"gkamradt/LLMTest_NeedleInAHaystack" -> "FranxYao/Long-Context-Data-Engineering"
"gkamradt/LLMTest_NeedleInAHaystack" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"gkamradt/LLMTest_NeedleInAHaystack" -> "OpenBMB/InfiniteBench"
"gkamradt/LLMTest_NeedleInAHaystack" -> "jquesnelle/yarn"
"gkamradt/LLMTest_NeedleInAHaystack" -> "OpenLMLab/LEval"
"gkamradt/LLMTest_NeedleInAHaystack" -> "tatsu-lab/alpaca_eval" ["e"=1]
"gkamradt/LLMTest_NeedleInAHaystack" -> "EleutherAI/lm-evaluation-harness" ["e"=1]
"gkamradt/LLMTest_NeedleInAHaystack" -> "dvlab-research/LongLoRA"
"gkamradt/LLMTest_NeedleInAHaystack" -> "huggingface/alignment-handbook" ["e"=1]
"gkamradt/LLMTest_NeedleInAHaystack" -> "jzhang38/EasyContext"
"gkamradt/LLMTest_NeedleInAHaystack" -> "OpenRLHF/OpenRLHF" ["e"=1]
"gkamradt/LLMTest_NeedleInAHaystack" -> "FranxYao/chain-of-thought-hub" ["e"=1]
"gkamradt/LLMTest_NeedleInAHaystack" -> "nelson-liu/lost-in-the-middle"
"microsoft/FILM" -> "princeton-nlp/ProLong"
"microsoft/FILM" -> "dwzhu-pku/PoSE"
"NVIDIA/RULER" -> "THUDM/LongBench"
"NVIDIA/RULER" -> "jzhang38/EasyContext"
"NVIDIA/RULER" -> "OpenBMB/InfiniteBench"
"NVIDIA/RULER" -> "gkamradt/LLMTest_NeedleInAHaystack"
"NVIDIA/RULER" -> "FranxYao/Long-Context-Data-Engineering"
"NVIDIA/RULER" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"NVIDIA/RULER" -> "microsoft/MInference" ["e"=1]
"NVIDIA/RULER" -> "mit-han-lab/Quest" ["e"=1]
"NVIDIA/RULER" -> "booydar/babilong"
"NVIDIA/RULER" -> "princeton-nlp/ProLong"
"NVIDIA/RULER" -> "FasterDecoding/SnapKV" ["e"=1]
"NVIDIA/RULER" -> "OpenLMLab/LEval"
"NVIDIA/RULER" -> "THUDM/LongAlign"
"NVIDIA/RULER" -> "mit-han-lab/duo-attention" ["e"=1]
"NVIDIA/RULER" -> "HKUNLP/ChunkLlama"
"liwenju0/cutword" -> "bojone/bytepiece"
"liwenju0/cutword" -> "liangwq/Chatglm_lora_multi-gpu" ["e"=1]
"liwenju0/cutword" -> "27182812/ChatGLM-LLaMA-chinese-insturct" ["e"=1]
"liwenju0/cutword" -> "WangRongsheng/Aurora" ["e"=1]
"TIGER-AI-Lab/LongICLBench" -> "google-deepmind/loft"
"mustafaaljadery/gemma-2B-10M" -> "Beomi/InfiniTransformer"
"mustafaaljadery/gemma-2B-10M" -> "jgravelle/AutoGroq" ["e"=1]
"mustafaaljadery/gemma-2B-10M" -> "microsoft/Samba" ["e"=1]
"mustafaaljadery/gemma-2B-10M" -> "dingo-actual/infini-transformer"
"mustafaaljadery/gemma-2B-10M" -> "Doriandarko/RepoToTextForLLMs" ["e"=1]
"mustafaaljadery/gemma-2B-10M" -> "jzhang38/EasyContext"
"mustafaaljadery/gemma-2B-10M" -> "ai-ng/2txt" ["e"=1]
"mustafaaljadery/gemma-2B-10M" -> "datamllab/LongLM"
"princeton-nlp/CEPE" -> "princeton-nlp/ProLong"
"princeton-nlp/CEPE" -> "jeffreysijuntan/lloco"
"princeton-nlp/CEPE" -> "princeton-nlp/AutoCompressors"
"princeton-nlp/CEPE" -> "snu-mllab/Context-Memory"
"OpenBMB/InfiniteBench" -> "THUDM/LongBench"
"OpenBMB/InfiniteBench" -> "bigai-nlco/LooGLE"
"OpenBMB/InfiniteBench" -> "princeton-nlp/ProLong"
"OpenBMB/InfiniteBench" -> "THUDM/LongAlign"
"OpenBMB/InfiniteBench" -> "OpenLMLab/LEval"
"OpenBMB/InfiniteBench" -> "FasterDecoding/SnapKV" ["e"=1]
"OpenBMB/InfiniteBench" -> "nightdessert/Retrieval_Head"
"OpenBMB/InfiniteBench" -> "booydar/babilong"
"OpenBMB/InfiniteBench" -> "MozerWang/Loong"
"OpenBMB/InfiniteBench" -> "thunlp/InfLLM" ["e"=1]
"OpenBMB/InfiniteBench" -> "google-deepmind/loft"
"OpenBMB/InfiniteBench" -> "FMInference/H2O" ["e"=1]
"OpenBMB/InfiniteBench" -> "FranxYao/Long-Context-Data-Engineering"
"OpenBMB/InfiniteBench" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"OpenBMB/InfiniteBench" -> "HKUNLP/ChunkLlama"
"FranxYao/Long-Context-Data-Engineering" -> "princeton-nlp/ProLong"
"FranxYao/Long-Context-Data-Engineering" -> "jzhang38/EasyContext"
"FranxYao/Long-Context-Data-Engineering" -> "bigai-nlco/LooGLE"
"FranxYao/Long-Context-Data-Engineering" -> "THUDM/LongBench"
"FranxYao/Long-Context-Data-Engineering" -> "OpenLMLab/LEval"
"FranxYao/Long-Context-Data-Engineering" -> "jshuadvd/LongRoPE"
"FranxYao/Long-Context-Data-Engineering" -> "HKUNLP/ChunkLlama"
"FranxYao/Long-Context-Data-Engineering" -> "Strivin0311/long-llms-learning"
"FranxYao/Long-Context-Data-Engineering" -> "THUDM/LongAlign"
"FranxYao/Long-Context-Data-Engineering" -> "OpenBMB/InfiniteBench"
"FranxYao/Long-Context-Data-Engineering" -> "datamllab/LongLM"
"FranxYao/Long-Context-Data-Engineering" -> "gkamradt/LLMTest_NeedleInAHaystack"
"FranxYao/Long-Context-Data-Engineering" -> "NVIDIA/RULER"
"FranxYao/Long-Context-Data-Engineering" -> "FasterDecoding/SnapKV" ["e"=1]
"FranxYao/Long-Context-Data-Engineering" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"datamllab/LongLM" -> "HKUNLP/ChunkLlama"
"datamllab/LongLM" -> "THUDM/LongBench"
"datamllab/LongLM" -> "jy-yuan/KIVI" ["e"=1]
"datamllab/LongLM" -> "dwzhu-pku/PoSE"
"datamllab/LongLM" -> "FranxYao/Long-Context-Data-Engineering"
"datamllab/LongLM" -> "jzhang38/EasyContext"
"datamllab/LongLM" -> "princeton-nlp/ProLong"
"datamllab/LongLM" -> "thunlp/InfLLM" ["e"=1]
"datamllab/LongLM" -> "FasterDecoding/SnapKV" ["e"=1]
"datamllab/LongLM" -> "sdan/selfextend" ["e"=1]
"datamllab/LongLM" -> "henryzhongsc/longctx_bench" ["e"=1]
"datamllab/LongLM" -> "OpenLMLab/LEval"
"datamllab/LongLM" -> "jshuadvd/LongRoPE"
"datamllab/LongLM" -> "OpenBMB/InfiniteBench"
"datamllab/LongLM" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"HKUNLP/ChunkLlama" -> "HKUNLP/STRING"
"HKUNLP/ChunkLlama" -> "dwzhu-pku/PoSE"
"HKUNLP/ChunkLlama" -> "OpenLMLab/LEval"
"HKUNLP/ChunkLlama" -> "datamllab/LongLM"
"HKUNLP/ChunkLlama" -> "FranxYao/Long-Context-Data-Engineering"
"HKUNLP/ChunkLlama" -> "THUDM/LongBench"
"HKUNLP/ChunkLlama" -> "FasterDecoding/SnapKV" ["e"=1]
"HKUNLP/ChunkLlama" -> "OpenBMB/InfiniteBench"
"HKUNLP/ChunkLlama" -> "princeton-nlp/ProLong"
"HKUNLP/ChunkLlama" -> "jshuadvd/LongRoPE"
"HKUNLP/ChunkLlama" -> "jquesnelle/yarn"
"HKUNLP/ChunkLlama" -> "jzhang38/EasyContext"
"HKUNLP/ChunkLlama" -> "Shark-NLP/CoNT"
"HKUNLP/ChunkLlama" -> "thunlp/InfLLM" ["e"=1]
"HKUNLP/ChunkLlama" -> "microsoft/MInference" ["e"=1]
"jshuadvd/LongRoPE" -> "microsoft/LongRoPE"
"jshuadvd/LongRoPE" -> "FranxYao/Long-Context-Data-Engineering"
"Strivin0311/long-llms-learning" -> "FranxYao/Long-Context-Data-Engineering"
"Strivin0311/long-llms-learning" -> "Strivin0311/llms-learning"
"Strivin0311/long-llms-learning" -> "OpenBMB/InfiniteBench"
"Strivin0311/long-llms-learning" -> "HKUNLP/ChunkLlama"
"Strivin0311/long-llms-learning" -> "feifeibear/long-context-attention" ["e"=1]
"Beomi/InfiniTransformer" -> "dingo-actual/infini-transformer"
"Beomi/InfiniTransformer" -> "jlamprou/Infini-Attention"
"Beomi/InfiniTransformer" -> "FranxYao/Long-Context-Data-Engineering"
"Beomi/InfiniTransformer" -> "jzhang38/EasyContext"
"Beomi/InfiniTransformer" -> "vmarinowski/infini-attention"
"Beomi/InfiniTransformer" -> "Beomi/Gemma-EasyLM"
"Beomi/InfiniTransformer" -> "jshuadvd/LongRoPE"
"Beomi/InfiniTransformer" -> "HKUNLP/ChunkLlama"
"Beomi/InfiniTransformer" -> "OpenNLPLab/lightning-attention" ["e"=1]
"dingo-actual/infini-transformer" -> "Beomi/InfiniTransformer"
"dingo-actual/infini-transformer" -> "vmarinowski/infini-attention"
"dingo-actual/infini-transformer" -> "kyegomez/Infini-attention"
"nuster1128/LLM_Agent_Memory_Survey" -> "zhongwanjun/MemoryBank-SiliconFriend"
"snap-research/locomo" -> "xiaowu0162/LongMemEval"
"THUDM/LongAlign" -> "THUDM/LongBench"
"THUDM/LongAlign" -> "princeton-nlp/ProLong"
"THUDM/LongAlign" -> "OpenBMB/InfiniteBench"
"THUDM/LongAlign" -> "OpenLMLab/LEval"
"THUDM/LongAlign" -> "booydar/babilong"
"THUDM/LongAlign" -> "THUDM/LongReward"
"THUDM/LongAlign" -> "TIGER-AI-Lab/LongICLBench"
"THUDM/LongAlign" -> "bigai-nlco/LooGLE"
"THUDM/LongAlign" -> "FranxYao/Long-Context-Data-Engineering"
"THUDM/LongAlign" -> "jshuadvd/LongRoPE"
"THUDM/LongAlign" -> "zhuzilin/ring-flash-attention" ["e"=1]
"jzhang38/EasyContext" -> "zhuzilin/ring-flash-attention" ["e"=1]
"jzhang38/EasyContext" -> "feifeibear/long-context-attention" ["e"=1]
"jzhang38/EasyContext" -> "FranxYao/Long-Context-Data-Engineering"
"jzhang38/EasyContext" -> "princeton-nlp/ProLong"
"jzhang38/EasyContext" -> "NVIDIA/RULER"
"jzhang38/EasyContext" -> "datamllab/LongLM"
"jzhang38/EasyContext" -> "HKUNLP/ChunkLlama"
"jzhang38/EasyContext" -> "haoliuhl/ringattention" ["e"=1]
"jzhang38/EasyContext" -> "Xnhyacinth/Awesome-LLM-Long-Context-Modeling"
"jzhang38/EasyContext" -> "THUDM/LongBench"
"jzhang38/EasyContext" -> "OpenBMB/InfiniteBench"
"jzhang38/EasyContext" -> "jquesnelle/yarn"
"jzhang38/EasyContext" -> "THUDM/LongAlign"
"jzhang38/EasyContext" -> "RulinShao/LightSeq" ["e"=1]
"jzhang38/EasyContext" -> "lucidrains/ring-attention-pytorch" ["e"=1]
"jlamprou/Infini-Attention" -> "Beomi/InfiniTransformer"
"microsoft/LongRoPE" -> "jshuadvd/LongRoPE"
"microsoft/LongRoPE" -> "evalplus/repoqa" ["e"=1]
"microsoft/LongRoPE" -> "princeton-nlp/ProLong"
"jeffreysijuntan/lloco" -> "snu-mllab/Context-Memory"
"nightdessert/Retrieval_Head" -> "FasterDecoding/SnapKV" ["e"=1]
"nightdessert/Retrieval_Head" -> "princeton-nlp/ProLong"
"nightdessert/Retrieval_Head" -> "mit-han-lab/duo-attention" ["e"=1]
"nightdessert/Retrieval_Head" -> "princeton-nlp/HELMET"
"nightdessert/Retrieval_Head" -> "OpenBMB/InfiniteBench"
"nightdessert/Retrieval_Head" -> "mutonix/pyramidinfer" ["e"=1]
"nightdessert/Retrieval_Head" -> "mit-han-lab/Quest" ["e"=1]
"dwzhu-pku/LongEmbed" -> "dwzhu-pku/PoSE"
"GOAT-AI-lab/GOAT-Storytelling-Agent" -> "datacrystals/AIStoryWriter"
"booydar/babilong" -> "princeton-nlp/ProLong"
"booydar/babilong" -> "OpenBMB/InfiniteBench"
"booydar/babilong" -> "bigai-nlco/LooGLE"
"booydar/babilong" -> "dwzhu-pku/PoSE"
"booydar/babilong" -> "THUDM/LongAlign"
"booydar/babilong" -> "princeton-nlp/CEPE"
"booydar/babilong" -> "princeton-nlp/HELMET"
"booydar/babilong" -> "PKU-ML/LongPPL"
"OpenLMLab/scaling-rope" -> "OpenMOSS/Thus-Spake-Long-Context-LLM"
"bigai-nlco/LooGLE" -> "OpenBMB/InfiniteBench"
"bigai-nlco/LooGLE" -> "OpenLMLab/LEval"
"bigai-nlco/LooGLE" -> "FranxYao/Long-Context-Data-Engineering"
"bigai-nlco/LooGLE" -> "MozerWang/Loong"
"bigai-nlco/LooGLE" -> "THUDM/LongBench"
"bigai-nlco/LooGLE" -> "booydar/babilong"
"bigai-nlco/LooGLE" -> "TIGER-AI-Lab/LongICLBench"
"bigai-nlco/LooGLE" -> "princeton-nlp/ProLong"
"snu-mllab/Context-Memory" -> "snu-mllab/Neural-Relation-Graph" ["e"=1]
"zhiyuanhubj/UoT" -> "zhiyuanhubj/LongRecipe"
"xiaowu0162/LongMemEval" -> "snap-research/locomo"
"HKUNLP/STRING" -> "Shark-NLP/CoNT"
"datacrystals/AIStoryWriter" -> "GOAT-AI-lab/GOAT-Storytelling-Agent"
"datacrystals/AIStoryWriter" -> "dylanhogg/gptauthor"
"princeton-nlp/HELMET" -> "princeton-nlp/ProLong"
"princeton-nlp/HELMET" -> "google-deepmind/loft"
"princeton-nlp/HELMET" -> "princeton-pli/LongProc"
"princeton-nlp/HELMET" -> "nightdessert/Retrieval_Head"
"google-deepmind/loft" -> "princeton-nlp/HELMET"
"google-deepmind/loft" -> "TIGER-AI-Lab/LongICLBench"
"google-deepmind/loft" -> "zexuanqiu/CLongEval"
"google-deepmind/loft" -> "princeton-nlp/ProLong"
"google-deepmind/loft" -> "MozerWang/Loong"
"google-deepmind/loft" -> "OpenBMB/InfiniteBench"
"NJUDeepEngine/llm-course-lecture" -> "Strivin0311/llms-learning"
"THUDM/LongCite" -> "THUDM/LongReward"
"THUDM/LongCite" -> "THUDM/LongAlign"
"THUDM/LongCite" -> "THUDM/LongBench"
"THUDM/LongCite" -> "sunnynexus/Search-o1" ["e"=1]
"zhiyuanhubj/LongRecipe" -> "princeton-nlp/ProLong"
"princeton-nlp/ProLong" -> "princeton-nlp/HELMET"
"princeton-nlp/ProLong" -> "zhiyuanhubj/LongRecipe"
"princeton-nlp/ProLong" -> "FranxYao/Long-Context-Data-Engineering"
"princeton-nlp/ProLong" -> "nightdessert/Retrieval_Head"
"princeton-nlp/ProLong" -> "booydar/babilong"
"princeton-nlp/ProLong" -> "princeton-nlp/CEPE"
"princeton-nlp/ProLong" -> "OpenBMB/InfiniteBench"
"princeton-nlp/ProLong" -> "THUDM/LongAlign"
"princeton-nlp/ProLong" -> "PKU-ML/LongPPL"
"MozerWang/Loong" -> "MozerWang/promISe" ["e"=1]
"MozerWang/Loong" -> "bigai-nlco/LooGLE"
"MozerWang/Loong" -> "MozerWang/AMPO" ["e"=1]
"MozerWang/Loong" -> "OpenBMB/InfiniteBench"
"tengxiaoliu/LM_skip" -> "ayyyq/DORE"
"OpenMOSS/Thus-Spake-Long-Context-LLM" -> "OpenLMLab/scaling-rope"
"OpenMOSS/Thus-Spake-Long-Context-LLM" -> "tengxiaoliu/LM_skip"
"KaiLv69/DuoDecoding" -> "ayyyq/DORE"
"lucidrains/compressive-transformer-pytorch" ["l"="37.944,-1.659"]
"lucidrains/memformer" ["l"="37.966,-1.65"]
"lucidrains/memory-transformer-xl" ["l"="37.962,-1.68"]
"lucidrains/memorizing-transformers-pytorch" ["l"="37.965,-1.611"]
"google-research/meliad" ["l"="37.925,-1.628"]
"lucidrains/block-recurrent-transformer-pytorch" ["l"="37.937,-1.606"]
"lucidrains/RETRO-pytorch" ["l"="-5.216,-23.353"]
"lucidrains/memory-efficient-attention-pytorch" ["l"="37.902,-1.663"]
"CStanKonrad/long_llama" ["l"="38.013,-1.527"]
"lucidrains/simple-hierarchical-transformer" ["l"="40.509,1.529"]
"Victorwz/LongMem" ["l"="38.048,-1.571"]
"epfml/landmark-attention" ["l"="38.036,-1.5"]
"princeton-nlp/TRIME" ["l"="36.984,-2.623"]
"ArvinZhuang/DSI-transformers" ["l"="54.42,25.668"]
"booydar/recurrent-memory-transformer" ["l"="38.077,-1.555"]
"booydar/LM-RMT" ["l"="38.041,-1.548"]
"lucidrains/recurrent-memory-transformer-pytorch" ["l"="37.996,-1.591"]
"booydar/babilong" ["l"="38.013,-1.405"]
"abertsch72/unlimiformer" ["l"="38.06,-1.534"]
"yurakuratov/t5-experiments" ["l"="38.108,-1.577"]
"crosleythomas/MirrorGPT" ["l"="38.125,-1.591"]
"allenai/mmc4" ["l"="49.046,30.301"]
"lucidrains/flash-cosine-sim-attention" ["l"="21.882,13.835"]
"AminRezaei0x443/memory-efficient-attention" ["l"="37.857,-1.711"]
"lucidrains/memory-compressed-attention" ["l"="37.868,-1.679"]
"Birch-san/diffusers-play" ["l"="37.833,-1.734"]
"Shark-NLP/CoNT" ["l"="37.917,-1.401"]
"HKUNLP/STRING" ["l"="37.918,-1.419"]
"OpenLMLab/LEval" ["l"="37.982,-1.424"]
"Shark-NLP/EVALM" ["l"="36.839,-2.423"]
"OpenLMLab/LongWanjuan" ["l"="37.878,-1.375"]
"txsun1997/nlp-paradigm-shift" ["l"="37.795,-1.388"]
"open-nlplab/fastIE" ["l"="37.829,-1.392"]
"google-deepmind/dramatron" ["l"="37.999,-1.771"]
"premieroctet/photoshot" ["l"="-3.312,-30.372"]
"aiwaves-cn/RecurrentGPT" ["l"="38.041,-1.672"]
"yangkevin2/doc-story-generation" ["l"="38.034,-1.752"]
"gtoxlili/wechat-chatGPT" ["l"="43.669,1.33"]
"riffusion/riffusion-app-hobby" ["l"="38.762,1.98"]
"FrozenBurning/Text2Light" ["l"="64.218,3.61"]
"jbilcke/latent-browser" ["l"="37.971,-1.82"]
"facebookresearch/doc-storygen-v2" ["l"="38.03,-1.779"]
"dashstander/block-recurrent-transformer" ["l"="37.888,-1.615"]
"yangkevin2/emnlp22-re3-story-generation" ["l"="38.053,-1.779"]
"yingpengma/Awesome-Story-Generation" ["l"="38.066,-1.752"]
"ayyyq/DORE" ["l"="37.745,-1.34"]
"KaiLv69/DuoDecoding" ["l"="37.728,-1.333"]
"conceptofmind/PaLM" ["l"="38.012,-1.565"]
"s-JoL/Open-Llama" ["l"="39.123,-2.289"]
"lucidrains/PaLM-pytorch" ["l"="-5.186,-23.312"]
"neuml/txtinstruct" ["l"="-33.992,16.084"]
"colonelwatch/abstracts-search" ["l"="41.394,1.385"]
"rmihaylov/falcontune" ["l"="42.563,-1.963"]
"alasdairforsythe/tokenmonster" ["l"="37.959,-1.535"]
"zhongwanjun/MemoryBank-SiliconFriend" ["l"="38.109,-1.636"]
"nuster1128/LLM_Agent_Memory_Survey" ["l"="38.132,-1.666"]
"snap-research/locomo" ["l"="38.155,-1.684"]
"LuJunru/MemoChat" ["l"="38.108,-1.667"]
"leolee99/LD-Agent" ["l"="38.143,-1.643"]
"wbbeyourself/SCM4LLMs" ["l"="38.094,-1.599"]
"choosewhatulike/trainable-agents" ["l"="39.187,-1.626"]
"wangyu-ustc/MemoryLLM" ["l"="65.195,3.429"]
"LeapLabTHU/ExpeL" ["l"="49.317,32.967"]
"ctlllll/LLM-ToolMaker" ["l"="38.024,-1.604"]
"lupantech/chameleon-llm" ["l"="36.795,-2.439"]
"billxbf/ReWOO" ["l"="38.019,-1.635"]
"thunlp/ToolLearningPapers" ["l"="36.759,-2.419"]
"salesforce/CodeTF" ["l"="36.153,-0.162"]
"kyegomez/tree-of-thoughts" ["l"="36.576,-2.223"]
"lyuchenyang/Macaw-LLM" ["l"="47.559,29.998"]
"salesforce/xgen" ["l"="37.98,-1.554"]
"IBM/Dromedary" ["l"="37.245,-0.171"]
"OpenBMB/ToolBench" ["l"="36.72,-2.262"]
"huchenxucs/ChatDB" ["l"="38.05,-1.616"]
"OSU-NLP-Group/Mind2Web" ["l"="36.785,-1.508"]
"mbzuai-nlp/LaMini-LM" ["l"="37.256,-0.058"]
"mzbac/qlora-fine-tune" ["l"="38.168,-1.587"]
"eugenepentland/landmark-attention-qlora" ["l"="38.098,-1.527"]
"kyegomez/LongNet" ["l"="38.125,-1.544"]
"fkodom/dilated-attention-pytorch" ["l"="38.16,-1.554"]
"kyegomez/Andromeda" ["l"="48.654,32.901"]
"dmytrostriletskyi/threads-net" ["l"="38.226,-1.552"]
"alexisrozhkov/dilated-self-attention" ["l"="38.155,-1.54"]
"haoliuhl/ringattention" ["l"="38.899,-0.433"]
"kyegomez/zeta" ["l"="49.172,34.235"]
"Beomi/BitNet-Transformers" ["l"="38.638,-0.263"]
"microsoft/torchscale" ["l"="38.755,-0.718"]
"jackaduma/Recurrent-LLM" ["l"="38.057,-1.714"]
"femnn/RecurrentGPT-zh" ["l"="38.068,-1.691"]
"Vahe1994/SpQR" ["l"="38.818,-0.268"]
"kreneskyp/ix" ["l"="41.143,-3.713"]
"aiwaves-cn/agents" ["l"="36.726,-2.215"]
"FranxYao/chain-of-thought-hub" ["l"="37.241,-0.207"]
"thunlp/WebCPM" ["l"="50.705,2.93"]
"teknium1/GPTeacher" ["l"="42.501,-2.047"]
"princeton-nlp/AutoCompressors" ["l"="38.083,-1.46"]
"jquesnelle/yarn" ["l"="38.005,-1.472"]
"QuangBK/generativeAgent_LLM" ["l"="40.999,-4.11"]
"bojone/NBCE" ["l"="38.097,-1.489"]
"sail-sg/lorahub" ["l"="38.39,-0.282"]
"dvlab-research/LongLoRA" ["l"="37.983,-1.5"]
"junhoyeo/threads-api" ["l"="38.258,-1.569"]
"threadsjs/threads.js" ["l"="38.263,-1.534"]
"m1guelpf/threads-re" ["l"="38.281,-1.548"]
"Danie1/threads-api" ["l"="38.257,-1.601"]
"junhoyeo/threads-py" ["l"="38.284,-1.606"]
"junhoyeo/react-threads" ["l"="38.243,-1.535"]
"KudoAI/chatgpt.js" ["l"="-44.331,6.625"]
"facebook/igl" ["l"="-23.302,-27.466"]
"KiwiTalk/KiwiTalk" ["l"="-4.977,-20.866"]
"farizrifqi/Threads-Media-Downloader" ["l"="38.298,-1.587"]
"m1guelpf/threads-api" ["l"="38.306,-1.561"]
"Bamdoliro/marururu" ["l"="-5.64,-21.989"]
"noodle-run/noodle" ["l"="15.873,-10.476"]
"toss/slash" ["l"="-5.336,-21.914"]
"Gentopia-AI/Gentopia" ["l"="36.809,-1.259"]
"THUDM/AgentBench" ["l"="36.724,-2.315"]
"allenai/lumos" ["l"="36.768,-1.272"]
"ysymyth/ReAct" ["l"="36.695,-2.331"]
"princeton-nlp/intercode" ["l"="36.835,-2.347"]
"SwiftSage/SwiftSage" ["l"="57.456,18.735"]
"web-arena-x/webarena" ["l"="36.821,-1.486"]
"101dotxyz/GPTeam" ["l"="41.192,-3.781"]
"bojone/bytepiece" ["l"="38.142,-1.456"]
"bojone/rerope" ["l"="38.066,-1.449"]
"GanjinZero/RRHF" ["l"="37.215,-0.204"]
"liwenju0/cutword" ["l"="38.197,-1.429"]
"OpenLMLab/MOSS-RLHF" ["l"="37.173,-0.251"]
"JunnYu/RoFormer_pytorch" ["l"="53.413,27.063"]
"jondurbin/airoboros" ["l"="42.563,-2.031"]
"OoriData/OgbujiPT" ["l"="43.066,1.674"]
"AgileRL/AgileRL" ["l"="59.371,17.441"]
"THUDM/LongBench" ["l"="38.005,-1.432"]
"HKUNLP/ChunkLlama" ["l"="37.966,-1.421"]
"gkamradt/LLMTest_NeedleInAHaystack" ["l"="38.029,-1.426"]
"DachengLi1/LongChat" ["l"="38.027,-1.456"]
"FranxYao/Long-Context-Data-Engineering" ["l"="37.969,-1.402"]
"zhuzilin/ring-flash-attention" ["l"="38.944,-0.407"]
"jzhang38/EasyContext" ["l"="37.968,-1.438"]
"OpenBMB/InfiniteBench" ["l"="37.986,-1.394"]
"dwzhu-pku/PoSE" ["l"="37.988,-1.446"]
"XueFuzhao/OpenMoE" ["l"="38.703,-0.482"]
"THUDM/LongAlign" ["l"="37.992,-1.378"]
"FasterDecoding/SnapKV" ["l"="38.994,-0.251"]
"Xnhyacinth/Awesome-LLM-Long-Context-Modeling" ["l"="38.02,-1.385"]
"bigai-nlco/LooGLE" ["l"="37.976,-1.38"]
"NVIDIA/RULER" ["l"="37.996,-1.408"]
"jy-yuan/KIVI" ["l"="38.94,-0.257"]
"FMInference/H2O" ["l"="38.951,-0.285"]
"nelson-liu/lost-in-the-middle" ["l"="38.031,-1.405"]
"mit-han-lab/streaming-llm" ["l"="38.853,-0.645"]
"FasterDecoding/Medusa" ["l"="38.899,-0.485"]
"artidoro/qlora" ["l"="39.956,0.604"]
"dvlab-research/3D-Box-Segment-Anything" ["l"="64.54,11.193"]
"PhoebusSi/Alpaca-CoT" ["l"="39.078,-2.202"]
"huggingface/alignment-handbook" ["l"="38.666,-0.614"]
"dvlab-research/VoxelNeXt" ["l"="64.59,11.181"]
"open-compass/opencompass" ["l"="38.902,-2.019"]
"OpenRLHF/OpenRLHF" ["l"="37.161,-0.425"]
"baichuan-inc/Baichuan2" ["l"="39.047,-2.027"]
"FlagOpen/FlagEmbedding" ["l"="38.963,-1.98"]
"mit-han-lab/llm-awq" ["l"="38.87,-0.434"]
"Eltion/Instagram-SSL-Pinning-Bypass" ["l"="38.004,33.888"]
"princeton-nlp/ProLong" ["l"="38.002,-1.387"]
"nightdessert/Retrieval_Head" ["l"="38.012,-1.364"]
"princeton-nlp/ALCE" ["l"="54.43,25.535"]
"princeton-nlp/CEPE" ["l"="38.066,-1.411"]
"facebookresearch/FiD" ["l"="54.475,25.57"]
"tomaarsen/attention_sinks" ["l"="38.046,-1.473"]
"Glaciohound/LM-Infinite" ["l"="38.104,-1.463"]
"datamllab/LongLM" ["l"="37.948,-1.425"]
"tomaarsen/SpanMarkerNER" ["l"="41.14,1.073"]
"hao-ai-lab/LookaheadDecoding" ["l"="38.917,-0.43"]
"huggingface/setfit" ["l"="52.568,25.752"]
"mit-han-lab/duo-attention" ["l"="38.971,-0.271"]
"microsoft/MInference" ["l"="38.971,-0.326"]
"October2001/Awesome-KV-Cache-Compression" ["l"="38.971,-0.289"]
"HuangOwen/Awesome-LLM-Compression" ["l"="38.841,-0.343"]
"horseee/Awesome-Efficient-LLM" ["l"="38.867,-0.356"]
"hemingkx/SpeculativeDecodingPapers" ["l"="38.909,-0.376"]
"atfortes/Awesome-LLM-Reasoning" ["l"="37.156,-0.385"]
"OpenLMLab/LOMO" ["l"="37.925,-1.483"]
"abacusai/Long-Context" ["l"="37.975,-1.465"]
"AetherCortex/Llama-X" ["l"="39.103,-2.269"]
"getao/icae" ["l"="38.108,-1.422"]
"jayelm/gisting" ["l"="38.121,-1.439"]
"liyucheng09/Selective_Context" ["l"="38.135,-1.414"]
"snu-mllab/Context-Memory" ["l"="38.094,-1.422"]
"jeffreysijuntan/lloco" ["l"="38.101,-1.401"]
"OpenMOSS/CoLLiE" ["l"="37.88,-1.402"]
"OpenMOSS/Thus-Spake-Long-Context-LLM" ["l"="37.81,-1.361"]
"GAIR-NLP/alignment-for-honesty" ["l"="37.493,-0.414"]
"OpenLMLab/ChatZoo" ["l"="37.856,-1.36"]
"xiami2019/CLAIF" ["l"="37.844,-1.381"]
"GAIR-NLP/weak-to-strong-reasoning" ["l"="37.504,-0.405"]
"jiaweizzhao/GaLore" ["l"="38.696,-0.325"]
"princeton-nlp/MeZO" ["l"="38.707,-0.248"]
"locuslab/wanda" ["l"="38.784,-0.27"]
"OpenLMLab/OpenChineseLLaMA" ["l"="55.559,25.901"]
"hiyouga/FastEdit" ["l"="39.082,-2.123"]
"dandelionsllm/pandallm" ["l"="39.147,-2.242"]
"princeton-nlp/LLM-Shearing" ["l"="38.7,-0.299"]
"InternLM/InternLM-techreport" ["l"="38.794,-1.827"]
"cubenlp/ChatSQL" ["l"="37.474,-1.45"]
"MohammadrezaPourreza/Few-shot-NL2SQL-with-prompting" ["l"="37.462,-1.541"]
"RUCKBReasoning/RESDSQL" ["l"="37.496,-1.553"]
"lucidrains/MEGABYTE-pytorch" ["l"="40.522,1.478"]
"RulinShao/LightSeq" ["l"="38.944,-0.474"]
"mit-han-lab/Quest" ["l"="38.991,-0.289"]
"william970/WritingGod" ["l"="38.084,-1.727"]
"GOAT-AI-lab/GOAT-Storytelling-Agent" ["l"="38.097,-1.782"]
"InteractiveNLP-Team/RoleLLM-public" ["l"="39.169,-1.645"]
"TencentARC/SEED-Story" ["l"="33.385,31.201"]
"thu-coai/PaperForONLG" ["l"="53.53,26.243"]
"Neph0s/awesome-llm-role-playing-with-persona" ["l"="39.195,-1.645"]
"vaew/SkyScript-100M" ["l"="38.071,-1.806"]
"datacrystals/AIStoryWriter" ["l"="38.104,-1.802"]
"AI21Labs/Parallel-Context-Windows" ["l"="38.142,-1.497"]
"OpenBuddy/OpenBuddy" ["l"="39.15,-2.144"]
"HazyResearch/TART" ["l"="38.172,-1.486"]
"georgesung/llm_qlora" ["l"="38.204,-1.626"]
"jshuadvd/LongRoPE" ["l"="37.938,-1.398"]
"lucidrains/CoLT5-attention" ["l"="38.485,-0.424"]
"lucidrains/st-moe-pytorch" ["l"="38.573,-0.443"]
"lucidrains/ring-attention-pytorch" ["l"="38.964,-0.403"]
"3DAgentWorld/Toolkit-for-Prompt-Compression" ["l"="-54.437,-11.579"]
"maszhongming/UniEval" ["l"="58.33,28.917"]
"facebookresearch/Shepherd" ["l"="37.334,-0.14"]
"YichenZW/Pacing" ["l"="38.026,-1.808"]
"dwzhu-pku/LongEmbed" ["l"="37.935,-1.455"]
"PKU-TANGENT/ConFiguRe" ["l"="37.111,-1.104"]
"F2-Song/ICDPO" ["l"="37.952,-1.469"]
"Strivin0311/llms-learning" ["l"="37.907,-1.283"]
"NJUDeepEngine/llm-course-lecture" ["l"="37.888,-1.262"]
"NJUDeepEngine/open-llm-assignments" ["l"="37.907,-1.255"]
"tatsu-lab/alpaca_eval" ["l"="37.246,-0.242"]
"EleutherAI/lm-evaluation-harness" ["l"="38.704,-0.669"]
"microsoft/FILM" ["l"="37.949,-1.37"]
"liangwq/Chatglm_lora_multi-gpu" ["l"="39.2,-2.189"]
"27182812/ChatGLM-LLaMA-chinese-insturct" ["l"="39.21,-2.212"]
"WangRongsheng/Aurora" ["l"="39.33,-2.058"]
"TIGER-AI-Lab/LongICLBench" ["l"="37.971,-1.326"]
"google-deepmind/loft" ["l"="37.99,-1.336"]
"mustafaaljadery/gemma-2B-10M" ["l"="37.874,-1.458"]
"Beomi/InfiniTransformer" ["l"="37.884,-1.429"]
"jgravelle/AutoGroq" ["l"="41.28,0.441"]
"microsoft/Samba" ["l"="38.866,-0.168"]
"dingo-actual/infini-transformer" ["l"="37.83,-1.445"]
"Doriandarko/RepoToTextForLLMs" ["l"="41.37,0.478"]
"ai-ng/2txt" ["l"="41.527,0.948"]
"MozerWang/Loong" ["l"="37.972,-1.353"]
"thunlp/InfLLM" ["l"="39.038,-0.24"]
"Strivin0311/long-llms-learning" ["l"="37.942,-1.35"]
"sdan/selfextend" ["l"="38.529,-0.16"]
"henryzhongsc/longctx_bench" ["l"="38.988,-0.176"]
"microsoft/LongRoPE" ["l"="37.921,-1.363"]
"feifeibear/long-context-attention" ["l"="38.982,-0.409"]
"jlamprou/Infini-Attention" ["l"="37.851,-1.421"]
"vmarinowski/infini-attention" ["l"="37.83,-1.421"]
"Beomi/Gemma-EasyLM" ["l"="37.844,-1.463"]
"OpenNLPLab/lightning-attention" ["l"="39.488,5.94"]
"kyegomez/Infini-attention" ["l"="37.786,-1.449"]
"xiaowu0162/LongMemEval" ["l"="38.175,-1.704"]
"THUDM/LongReward" ["l"="38.034,-1.326"]
"evalplus/repoqa" ["l"="36.282,-0.016"]
"princeton-nlp/HELMET" ["l"="38.017,-1.343"]
"mutonix/pyramidinfer" ["l"="39.035,-0.187"]
"PKU-ML/LongPPL" ["l"="38,-1.351"]
"OpenLMLab/scaling-rope" ["l"="37.793,-1.341"]
"snu-mllab/Neural-Relation-Graph" ["l"="51.313,30.235"]
"zhiyuanhubj/UoT" ["l"="38.02,-1.268"]
"zhiyuanhubj/LongRecipe" ["l"="38.012,-1.32"]
"dylanhogg/gptauthor" ["l"="38.122,-1.834"]
"princeton-pli/LongProc" ["l"="38.03,-1.3"]
"zexuanqiu/CLongEval" ["l"="37.98,-1.29"]
"THUDM/LongCite" ["l"="38.054,-1.344"]
"sunnynexus/Search-o1" ["l"="37.293,-0.55"]
"MozerWang/promISe" ["l"="29.941,28.181"]
"MozerWang/AMPO" ["l"="29.971,28.2"]
"tengxiaoliu/LM_skip" ["l"="37.772,-1.35"]
}